---
title: 音视频基础
description: 图像是像素的集合，视频是一系列的图像组合。
date: 2022-11-24
slug: 
image: 
draft: false
categories:
    - 音视频
tags:
---

# 音视频基础

## 媒体基础知识

### 图像

「图像」是「像素」的集合，有宽度和高度，每个像素块是单一的颜色。

「图像分辨率」表示图像的质量和像素数，由 x 轴乘以 Y 轴的像素个数得出，常见分辨率:

+ HD( 1920 * 1080 ) 
+ UHD ( 3840*2160 )
+ 4K ( 4096*2160 )

图像的纵横比是宽高比，常见的有

+ 16:9 
+ 4:3

常见分辨率

| 格式            | 分辨率    |
| --------------- | --------- |
| 360P(流畅)      | 640x360   |
| 480P(标清)      | 854x480   |
| **720P(高清)**  | 1280*720  |
| **1080P(高清)** | 1920*1080 |
| 2160P(4K)       | 3840*2160 |
| 4320P(8K)       | 7860*4320 |

### 视频

视频是一系列的图像，在视频上下文中，每个图像称为「帧」，「帧率」(fps)表示每秒有多少帧，常见的帧率:

+ 15 (实时通信)
+ 25 (动画)
+ 30 (实时通信)
+ 60 (电影/游戏)

未编码视频的 RGB 码流计算方法  = `分辨率 * 3 * 帧率`

例如`1280*720*3*25`，约等于每秒 69MB。

### YUV

+ Y 明亮度
+ UV 色彩及饱和度

主要的采样格式有:

+ `YUV4:2:0`，应用最广泛的格式，
+ `YUV4:2:2`，每一个横行隔一个含有一个 uv
+ `YUV4:4:4`

RGB 用于屏幕图像的展示，YUV 用于采集和编码 

**生成 YUV**

```bash
ffmpeg -i input.mp4 \
			 -an \
			 -c:v rawvideo \
			 -pix_fmt yuv420p \
			 out.yuv
```

+ `-i` 输入
+ `-an`，audio null，表示过滤掉音频
+ `-c`，指定视频编码器为 rawvideo

### 视频编解码

H.264，在今天互联网上使用最多，与 YUV 的压缩比是百分之一。

H.265 是前者的继承者，提供了更好的压缩效果

VP9，起源于 Google

GOP，强相关的一组帧，强相关的帧放在一起压缩，压缩率更高



**编码帧的分类**

+ I (interframe frame) 帧，关键帧，采用帧内压缩技术
+ P (forward predicted frame)，向前参考帧，压缩时只参考前面已经处理的帧，采用帧间压缩技术，占 I 帧一半大小。
+ B (Bidirectionally predicted frame)，双向参考帧，压缩时即参考前面已处理的帧，也参考后面的帧，帧间压缩技术，占 I 帧 ¼ 大小。B 帧越多，延迟越大，占用 CPU，空间最小。

IDR 帧是解码器立即刷新帧，解码器遇到 IDR 帧会清空 buffer 中的数据，防止错误的传播，每个 GOP 中的第一帧就是 IDR 帧。IDR 帧是一种特殊的 I 帧。

在每个 IDR 帧前面都有 SPS 与 PPS。

+ SPS (Sequence Parameter Set): 约束，参考帧的数量，解码图像尺寸，编码模式
+ PPS (Picture Parameter set): 图像参数集。

![image-20221120224546740](http://img.golang.space/img-1668955546874.png)

**H264压缩技术**

+ 帧内压缩，解决的是空域数据冗余问题 (有损)
+ 帧间压缩，解决的是时域数据冗余问题 (有损)
+ 整数离散余弦变化(DCT)，将空间上的相关性变为频域上无关数据然后进行量化
+ CABAC 压缩

**宏块**

宏块是视频压缩操作的基本单元，无论是帧内压缩还是帧间压缩，他们都以宏块为单位。

![image-20221120225437330](http://img.golang.space/img-1668956077431.png)

**视频花屏原因**

GOP 分组中的帧丢失，造成解码端的图像发生错误，会出现花屏。

**视频卡顿原因**

为了避免花屏问题发生，发现有帧丢失时，就丢弃 GOP 内的所有帧，直到下一个 IDR 帧重新刷新图像。

I 帧有一个比较长的周期，在下一个 I 帧来之前不显示后面的图像，视频就静止不动了，即出现卡顿现象。

### 视频压缩

它的工作原理是从原始图像或视频帧中去除冗余信息，有两种冗余信息

+ 图像或帧存在冗余
+ 同一场景的每两个连续帧之间存在冗余  

H264 Profile，对视频压缩特性的描述。

H264 Level 是对视频的描述，Level 越高，视频的码率，分辨率，fps 越高。

### 音频

音频样本通常存储为 8 位，16 位，24 位，甚至是 32 位的值，位数越多，意味着音频质量越高。采样率表示每秒有多少个样本，可以对 44.1kHZ ....采样，频率越高意味着更高的质量。

音频  channel 表示单个采样序列，channels 可以组成不同的布局，单个 channel 称为单声道，两个 channel 称为立体声(左声道/右声道)。

音轨(track) 表示 channel 的集合，单个媒体文件中可以有多个音轨。不同的音轨用于组织与同一时间线相关的不同声音

**编解码**

+ PCM，最流行的格式，但不压缩
+ AAC
+ MP3

### container

通常表示一种文件格式，媒体数据在文件中的组织方式。比如文件有多少流，哪里可以找到音轨等等。

+ MP4，最受欢迎的
+ MXF，大多数高质量的专业摄像机记录
+ QT/MOV
+ MKV

**音频**

+ WAV，用于存储高质量和压缩的 PCM 音频
+ M4A，用于存储压缩的 AAC 音频

![image-20221113210354707](http://img.golang.space/img-1668344634827.png)



## 架构模型

+ 流媒体服务器
+ 推流工具( ffmepg / obs )
+ 拉流 (ffplay / vlc / iina)

示例

```bash
# 推流
ffmpeg -i video.mp4 -f flv -rtmp_playpath "BSWMSId4g?sign=BSZaSIO4gz" rtmp://localhost/live 

# 拉流
ffplay rtmp://localhost/live/BSWMSId4g
```

+ `-i` 表示输入
+ `-f` 表示输出格式
+ `-rtmp_playpath` 指定路径

简单尝试一下，会发现推流失败或清晰度不高的问题。

+ `-re` 让媒体以原来音视频同步的速度播放，增加此参数可以避免推流失败

使用 `-f` 指定输出格式，会将原格式编解码到新格式，将损失一定的质量，所以清晰度不高。

+ `-c copy`  不重新编码，使用原来的音视频方式，将会是原视频的清晰度。



## 音频处理流程

![image-20221118164146264](http://img.golang.space/img-1668760906384.png)

音频数据流

`原始数据 PCM`  => `压缩数据 AAC/MP3` => `多媒体包 MP4/FLV` 

`HZ` ，声音在一秒内震动的次数，人类听觉范围是 20HZ ~ 20KHZ。

声音三要素:

+ 音调，音频的快慢
+ 音量，振动的幅度
+ 音色，谐波

模数转换，对声音进行量化，将十进制转换为二进制。

音频原始数据有两种，原始数据是 PCM，封装成格式后为 WAV。WAV 是在 PCM 的基础上套了一个 Header，增加了描述信息，如通道数，采样率，采样大小，字节对齐，采样率的字节数，

+ 采样大小，一个采样用多少 bit 存放，常用是 16bit。
+ 采样率，8K，16K，32K，44.1K，48K，通常打电话是 8K 有一定的失真。
+ 声道数，单声道，双声道，多声道。比如在电影院感受到的声音就很震撼，有很多喇叭围绕在四周。

 码率计算

PCM 音频流的码率 = 采样率 * 采样大小 * 声道数

例如: 采样率=44.1KHz，采样大小为 16bit，双声道的 PCM 编码文件，44.1K * 16*2 = 1411.2KB/s。

### AAC 规格

+ AAC LC:(Low Complexity)低复杂度规格，码流是 128K，音质好。
+ AAC HE:等于 AAC LC + SBR，核心思想是按频谱分保存。码流是 64K。
+ AAC HE v2:等于 AAC LC + SBR + PS，双声道的声音存在某种相似性，只需存储一个声道，并花很少字节描述另一个声道不同的地方。

### AAC 格式

+ ADIF (audio date interchange format)，可以确定的找到音频数据的开始，只能从头开始解码。

+ ADTS (audio data transport stream)，每一帧都有一个同步字，可以在音频任意位置解码，适用性更广，更适合流媒体传输。

  由 7/9 个字节组成，

### 通过 ffmpeg 生成 AAC 文件

```bash
ffmpeg -i xxx.mp4  \
			 -vn \
			 -c:a aac \
			 -ar 44100 \
			 -channels 2 \
			 -profile:a aac_he_v2 \
			 xxx.aac
```

+ `-vn`: video null，用于过滤掉视频
+ `-c`: 指定编码器，`a` 表示 audio，`libfdk_aac` 相对而言，这个性能是最好的编码器
+ `-ar`: audio rate 采样率
+ `-channels`: 通道数
+ `-profile`:指定参数

### 音频重采样?

**什么是音频重采样?**

将音频三元组转换成另外一组值，例如将 `44100/16/2` => `48000/16/2`

**为什么要重采样?**

+ 采样的音频数据与编码器要求的数据不一致
+ 扬声器要求的音频数据与要播放的音频数据不一致
+ 方便运算，比如回音消除，需要将其转成单声道处理

**如何知道是否需要进行重采样?**

+ 了解音频设备的参数
+ 查看 ffmpeg 源码

**重采样的步骤**

+ 创建重采样上下文
+ 设置参数
+ 初始化重采样
+ 进行重采样

## 流媒体

### RTMP 创建流的基本流程

+ tcp 连接
+ rtmp 握手
+ 建立 rtmp 连接
+ 创建 rtmp 流

![image-20221121172305496](http://img.golang.space/img-1669022585632.png)

![image-20221121172423006](http://img.golang.space/img-1669022663102.png)

![image-20221121231457324](http://img.golang.space/img-1669043697470.png)

## 参考

[ffmpeg 推流 rtmp 的参数设置](https://blog.csdn.net/impingo/article/details/104163365)

[码流参考值](https://docs.agora.io/cn)

