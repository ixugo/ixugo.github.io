<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Redis on ixugo</title>
        <link>https://blog.golang.space/categories/redis/</link>
        <description>Recent content in Redis on ixugo</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <lastBuildDate>Sat, 22 Jan 2022 15:00:00 +0000</lastBuildDate><atom:link href="https://blog.golang.space/categories/redis/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>&lt;Redis 核心技术与实战&gt;读书笔记</title>
        <link>https://blog.golang.space/p/redis-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</link>
        <pubDate>Sat, 22 Jan 2022 15:00:00 +0000</pubDate>
        
        <guid>https://blog.golang.space/p/redis-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</guid>
        <description>&lt;h1 id=&#34;redis-核心技术与实战读书笔记&#34;&gt;&amp;lt;Redis 核心技术与实战&amp;gt;读书笔记&lt;/h1&gt;
&lt;h2 id=&#34;基础&#34;&gt;基础&lt;/h2&gt;
&lt;p&gt;简单来说，底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653566560556.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。&lt;/p&gt;
&lt;p&gt;哈希表的最大好处很明显，就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653567032596.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么哈希表操作变慢了？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当你往哈希表中写入更多数据时，哈希冲突是不可避免的问题。这里的哈希冲突，也就是指，两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。&lt;/p&gt;
&lt;p&gt;Redis 解决哈希冲突的方式，就是链式哈希。就是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。&lt;/p&gt;
&lt;p&gt;哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653567220995.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;对于 String 类型来说，找到哈希桶就能直接增删改查了，所以，哈希表的 O(1) 操作复杂度也就是它的复杂度了。&lt;/p&gt;
&lt;p&gt;对于集合类型来说，即使找到哈希桶了，还要在集合中再进一步操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653567373705.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM、SRANDMEMBER 复杂度也是 O(1)。&lt;/p&gt;
&lt;p&gt;范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。&lt;/p&gt;
&lt;p&gt;统计操作，是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。&lt;/p&gt;
&lt;p&gt;例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。&lt;/p&gt;
&lt;h2 id=&#34;宕机了如何避免数据丢失&#34;&gt;宕机了，如何避免数据丢失&lt;/h2&gt;
&lt;p&gt;一旦服务器宕机，内存中的数据将全部丢失。&lt;/p&gt;
&lt;p&gt;Redis 的持久化主要有两种方式:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AOF（Append Only File）日志&lt;/li&gt;
&lt;li&gt;RDB (Redis DataBase) 快照&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;aof&#34;&gt;AOF&lt;/h3&gt;
&lt;p&gt;Redis 是先执行命令，把数据写入内存，然后才记录日志。&lt;/p&gt;
&lt;p&gt;传统数据库( 如 Mysql )的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。&lt;/p&gt;
&lt;p&gt;我们以 Redis 收到“set testkey ”命令后记录的日志为例，看看 AOF 日志的内容。&lt;/p&gt;
&lt;p&gt;“*3”表示当前命令有三个部分，每部分都是由“$+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“$3 set”表示这部分有 3 个字节，也就是“set”命令。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653572640406.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;但是，为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。&lt;/p&gt;
&lt;p&gt;而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。&lt;/p&gt;
&lt;p&gt;不过，AOF 也有两个潜在的风险。&lt;/p&gt;
&lt;p&gt;首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。&lt;/p&gt;
&lt;p&gt;其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。&lt;/p&gt;
&lt;p&gt;这两个风险都是和 AOF 写回磁盘的时机相关的。这也就意味着，如果我们能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就解除了。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;-&lt;/th&gt;
&lt;th&gt;优点&lt;/th&gt;
&lt;th&gt;风险&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;AOF&lt;/td&gt;
&lt;td&gt;避免额外的检查开销，避免出现记录错误命令的情况&lt;/td&gt;
&lt;td&gt;会出现没有来得及记日志就宕机的情况，可能会给下一个操作带来阻塞风险&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;三种写回策略&#34;&gt;三种写回策略&lt;/h3&gt;
&lt;p&gt;AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选值。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;-&lt;/th&gt;
&lt;th&gt;-&lt;/th&gt;
&lt;th&gt;可靠性&lt;/th&gt;
&lt;th&gt;高性能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Always&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;同步写回&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;Everysec&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;每秒写回，先放缓冲区&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;td&gt;中&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;No&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;操作系统控制的写回，先放缓冲区&lt;/td&gt;
&lt;td&gt;低&lt;/td&gt;
&lt;td&gt;高&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;我们一定要小心 AOF 文件过大带来的性能问题。这里的“性能问题”，主要在于以下三个方面：一是，文件系统本身对文件大小有限制，无法保存过大的文件；二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。&lt;/p&gt;
&lt;h3 id=&#34;日志文件太大了怎么办&#34;&gt;日志文件太大了怎么办？&lt;/h3&gt;
&lt;p&gt;AOF 重写机制，在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件。&lt;/p&gt;
&lt;p&gt;重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。&lt;/p&gt;
&lt;p&gt;当一个键值对被多条写命令反复修改时，AOF 文件会记录相应的多条命令。但是，在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用一条命令就行了，而且，在日志恢复时，只用执行这条命令，就可以直接完成这个键值对的写入了。&lt;/p&gt;
&lt;h3 id=&#34;aof-重写会阻塞吗&#34;&gt;AOF 重写会阻塞吗?&lt;/h3&gt;
&lt;p&gt;不会! 和 AOF 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。&lt;/p&gt;
&lt;p&gt;fork子进程时，子进程是会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。&lt;/p&gt;
&lt;p&gt;因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653575257969.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;rdb-快照&#34;&gt;RDB 快照&lt;/h3&gt;
&lt;p&gt;所谓内存快照，就是指内存中的数据在某一个时刻的状态记录。&lt;/p&gt;
&lt;p&gt;全量数据越多，RDB 文件就越大，往磁盘上写数据的时间开销就越大。&lt;/p&gt;
&lt;p&gt;对于 Redis 而言，它的单线程模型就决定了，我们要尽量避免所有会阻塞主线程的操作，所以，针对任何操作，我们都会提一个灵魂之问：“它会阻塞主线程吗?”RDB 文件的生成是否会阻塞主线程，这就关系到是否会降低 Redis 的性能。&lt;/p&gt;
&lt;p&gt;Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;-&lt;/th&gt;
&lt;th&gt;-&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;save&lt;/td&gt;
&lt;td&gt;主线程执行，会导致阻塞&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;bgsave(默认)&lt;/td&gt;
&lt;td&gt;创建一个子进程，专门用于写入 RDB 文件，避免主线程阻塞&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h4 id=&#34;快照时数据能修改吗&#34;&gt;快照时数据能修改吗?&lt;/h4&gt;
&lt;p&gt;给别人拍照时，一旦对方动了，那么这张照片就拍糊了，我们就需要重拍，所以我们当然希望对方保持不动。对于内存快照而言，我们也不希望数据“动”。&lt;/p&gt;
&lt;p&gt;为了快照而暂停写操作，肯定是不能接受的。所以这个时候，Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。&lt;/p&gt;
&lt;p&gt;如果主线程要修改一块数据，那么，这块数据就会被复制一份，生成该数据的副本。然后，主线程在这个数据副本上进行修改。同时，bgsave 子进程可以继续把原来的数据写入 RDB 文件。&lt;/p&gt;
&lt;h4 id=&#34;混合-aofrdb&#34;&gt;混合 AOF/RDB&lt;/h4&gt;
&lt;p&gt;Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。&lt;/p&gt;
&lt;p&gt;这个方法既能享受到 RDB 文件快速恢复的好处，又能享受到 AOF 只记录操作命令的简单优势，颇有点“鱼和熊掌可以兼得”的感觉，建议你在实践中用起来。&lt;/p&gt;
&lt;p&gt;关于 AOF 和 RDB 的选择问题，我想再给你提三点建议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；&lt;/li&gt;
&lt;li&gt;如果允许分钟级别的数据丢失，可以只使用 RDB；&lt;/li&gt;
&lt;li&gt;如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意: 写比读多时，RDB 的性能问题。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# 开启 RDB 持久化&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;save 60 10000 &lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 60 秒内执行 1000 次操作，持久化 &lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;save 300 10   &lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 300 秒内执行 10 次操操作，持久化&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;save 600 1    &lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 600 秒内执行 1 次操作，持久化&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 开启 AOF 持久化&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;appendonly yes&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;appendfilename &amp;#34;appendonly.aof&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;appenddirname &amp;#34;appendonlydir&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;l&#34;&gt;appendfsync everysec&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;主从库实现数据一致&#34;&gt;主从库实现数据一致&lt;/h2&gt;
&lt;p&gt;现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们在实例 2 上执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;replicaof 172.16.19.3 &lt;span class=&#34;m&#34;&gt;6379&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653707925873.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;第一阶段，从库向主库发送 psync 命令，其中包含 runID (主库唯一标识) 和 offset (复制进度) 两个参数，首次同步，&lt;code&gt;runID=?&lt;/code&gt;，&lt;code&gt;offset=-1&lt;/code&gt;。主库返回正确的 runID 和 offset。&lt;/p&gt;
&lt;p&gt;第二阶段，主库执行 bgsave 生成 RDB 文件，发给从库。从库收到后清空当前数据库，加载 RDB 文件。&lt;/p&gt;
&lt;p&gt;第三阶段，主库在同步过程中新增的命令，专门记录到 replication buffer，此时发给从库。从库执行这些操作完成数据同步。&lt;/p&gt;
&lt;p&gt;一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。&lt;/p&gt;
&lt;h2 id=&#34;主从级联模式分担全量复制时的主库压力&#34;&gt;主从级联模式分担全量复制时的主库压力&lt;/h2&gt;
&lt;p&gt;一主多从模式中，同步数据，主库生成 RDB 和 发送 RDB 会消耗性能和带宽。可以通过级联，将压力分担到从库上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653708919832.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;主从库间网络断了怎么办&#34;&gt;主从库间网络断了怎么办？&lt;/h2&gt;
&lt;p&gt;基于长连接的命令传播这个过程中存在着风险点，最常见的就是网络断连或阻塞。&lt;/p&gt;
&lt;p&gt;从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。&lt;/p&gt;
&lt;p&gt;repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。&lt;/p&gt;
&lt;p&gt;网络断了后，将主库写位置和从库读位置的之间的命令同步给从库。&lt;/p&gt;
&lt;p&gt;因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。&lt;/p&gt;
&lt;p&gt;因此，我们要想办法避免这一情况，一般而言，我们可以调整 repl_backlog_size 这个参数。&lt;/p&gt;
&lt;p&gt;一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。&lt;/p&gt;
&lt;h2 id=&#34;哨兵机制-主库挂了不间断服务&#34;&gt;哨兵机制: 主库挂了，不间断服务&lt;/h2&gt;
&lt;h3 id=&#34;基本流程&#34;&gt;基本流程&lt;/h3&gt;
&lt;p&gt;哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。&lt;/p&gt;
&lt;p&gt;监控是指哨兵进程在运行时，周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的 PING 命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。&lt;/p&gt;
&lt;p&gt;主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。&lt;/p&gt;
&lt;p&gt;最后，哨兵会执行最后一个任务：通知。在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653710992310.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;哨兵机制通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653712116209.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。&lt;/p&gt;
&lt;h3 id=&#34;如何选定新主库&#34;&gt;如何选定新主库？&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1653712343768.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;首先过滤掉不符合条件的，如果在选主时，一个从库正常运行，我们把它选为新主库开始使用了。可是，很快它的网络出了故障，此时，我们就得重新选主了。这显然不是我们期望的结果。&lt;/p&gt;
&lt;p&gt;如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。&lt;/p&gt;
&lt;p&gt;接下来就要给剩余的从库打分。我们可以分别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。&lt;/p&gt;
&lt;p&gt;第一轮：优先级最高的从库得分高。用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。如果从库的优先级都一样，那么哨兵开始第二轮打分。&lt;/p&gt;
&lt;p&gt;第二轮：和旧主库同步程度最接近的从库得分高。如果从库的优先级都一样，那么哨兵开始第三轮打分。&lt;/p&gt;
&lt;p&gt;第三轮：ID 号小的从库得分高。&lt;/p&gt;
&lt;h2 id=&#34;如果有哨兵实例在运行时发生了故障主从库还能正常切换吗&#34;&gt;如果有哨兵实例在运行时发生了故障，主从库还能正常切换吗？&lt;/h2&gt;
&lt;p&gt;在配置哨兵的信息时，我们只需要用到下面的这个配置项，设置主库的 IP 和端口，并没有配置其他哨兵的连接信息。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;sentinel monitor &amp;lt;master-name&amp;gt; &amp;lt;ip&amp;gt; &amp;lt;redis-port&amp;gt; &amp;lt;quorum&amp;gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这些哨兵实例既然都不知道彼此的地址，又是怎么组成集群的呢？要弄明白这个问题，我们就需要学习一下哨兵集群的组成和运行机制了。&lt;/p&gt;
&lt;h3 id=&#34;基于-pubsub-机制的哨兵集群&#34;&gt;基于 pub/sub 机制的哨兵集群&lt;/h3&gt;
&lt;p&gt;哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。&lt;/p&gt;
&lt;p&gt;哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。&lt;/p&gt;
&lt;p&gt;在主从集群中，主库上有一个名为“&lt;strong&gt;sentinel&lt;/strong&gt;:hello”的频道，不同哨兵就是通过它来相互发现，实现互相通信的。&lt;/p&gt;
&lt;h2 id=&#34;实战篇&#34;&gt;实战篇&lt;/h2&gt;
&lt;h3 id=&#34;redis-在消息队列上的应用&#34;&gt;Redis 在消息队列上的应用&lt;/h3&gt;
&lt;p&gt;消息队列在存取消息时，必须要满足三个需求，分别是消息保序、处理重复的消息和保证消息可靠性。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;消息保序&lt;/p&gt;
&lt;p&gt;假设有 3 个消息&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;减库存 5&lt;/li&gt;
&lt;li&gt;读库存&lt;/li&gt;
&lt;li&gt;减库存 2&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;如果发生乱序处理任务，优先执行了 321，此时 2 读到的库存是错误的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重复消息处理&lt;/p&gt;
&lt;p&gt;因为网络堵塞而出现消息重传的情况，可能到收到多条重复消息。&lt;/p&gt;
&lt;p&gt;一个任务扣 1 个库存，因为重复消息，却扣了 5 次就不对了。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;消息可靠性保证&lt;/p&gt;
&lt;p&gt;因为故障或宕机导致消息没有处理完成。当消费者重启后，可以重新读取消息处理&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Redis 的 List 和 Streams 两种数据类型，就可以满足消息队列的这三个需求&lt;/p&gt;
&lt;h4 id=&#34;基于-list-的消息队列解决方案&#34;&gt;基于 List 的消息队列解决方案&lt;/h4&gt;
&lt;p&gt;List 本身就是按先进先出的顺序对数据进行存取的，所以，如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1655050082707.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;当 List 中没有值，RPOP 命令会读到空值。为了解决这个问题，Redis 提供了 BRPOP 命令，BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。&lt;/p&gt;
&lt;p&gt;List 本身是不会为每个消息生成 ID 号的，所以，消息的全局唯一 ID 号就需要生产者程序在发送消息前自行生成。生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。&lt;/p&gt;
&lt;p&gt;当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。为了留存消息，List 类型提供了 BRPOPLPUSH 命令，这个命令的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存。这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1655050887922.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;img&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;基于 List 类型，我们可以满足分布式组件对消息队列的三大需求。但是，在用 List 做消息队列时，我们还可能遇到过一个问题：生产者消息发送很快，而消费者处理消息的速度比较慢，这就导致 List 中的消息越积越多，给 Redis 的内存带来很大压力。&lt;/p&gt;
&lt;p&gt;我们希望启动多个消费者程序组成一个消费组，一起分担处理 List 中的消息。但是，List 类型并不支持消费组的实现。那么，还有没有更合适的解决方案呢？这就要说到 Redis 从 5.0 版本开始提供的 Streams 数据类型了。&lt;/p&gt;
&lt;h4 id=&#34;基于-streams-的消息队列解决方案&#34;&gt;基于 Streams 的消息队列解决方案&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;http://img.golang.space/shot-1655091098148.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;image-20220613113138049&#34;
	
	
&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 往 mqstream 队列插入 {resp:5}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 星号表示自动生成全局唯一的 ID&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;XADD mqstream * resp &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://time.geekbang.org/column/article/268253&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Redis 核心技术与实战&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
