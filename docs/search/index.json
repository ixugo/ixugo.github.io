[{"content":"背景 客户端: ClashX\n服务端: xray\n部署 创建目录并增加 docker compose 文件\n1 2 mkdir -p apps/xray vim apps/xray/docker-compose.yml 文件内容如下:\n1 2 3 4 5 6 7 8 9 10 services: xray: image: ghcr.io/xtls/xray-core:25.10.15 container_name: xray user: root restart: unless-stopped command: [\u0026#34;run\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;/usr/local/etc/xray/config.json\u0026#34;] volumes: - ./config.json:/usr/local/etc/xray/config.json:ro network_mode: host 增加配置文件 vim config.json\n配置文件中几个动态参数需要替换一下。\n生成 UUID 和随机前缀，注意这两个参数不能泄露!!!\n1 uuidgen 执行两次，分别作为 id 和前缀，替换以下配置中的动态参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 { \u0026#34;log\u0026#34;: { \u0026#34;loglevel\u0026#34;: \u0026#34;info\u0026#34; }, \u0026#34;inbounds\u0026#34;: [ { \u0026#34;listen\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;: 6000, \u0026#34;protocol\u0026#34;: \u0026#34;vless\u0026#34;, \u0026#34;settings\u0026#34;: { \u0026#34;clients\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;[填写 UUID]\u0026#34; } ], \u0026#34;decryption\u0026#34;: \u0026#34;none\u0026#34; }, \u0026#34;streamSettings\u0026#34;: { \u0026#34;network\u0026#34;: \u0026#34;ws\u0026#34;, \u0026#34;security\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;wsSettings\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/[随机前缀]\u0026#34; } } } ], \u0026#34;outbounds\u0026#34;: [ { \u0026#34;protocol\u0026#34;: \u0026#34;freedom\u0026#34;, \u0026#34;settings\u0026#34;: {} } ] } 执行启动命令\n1 docker compose up -d 可以检查容器是否启动成功，接下来做个反向代理。\n反向代理 反向代理可以用 Nginx，Caddy2，Trarfik 等等，这里使用 Trarfik 完成反向代理。\n第一步搞定域名解析。\n创建目录和 compose 文件\n1 2 mkdir -p apps/traefik vim apps/traefik/docker-copmose.yml 写入以下内容\n1 2 3 4 5 6 7 8 9 10 11 12 services: traefik: image: traefik:v3.2 container_name: traefik restart: unless-stopped network_mode: host volumes: - ./traefik.yml:/etc/traefik/traefik.yml:ro - ./config:/config:ro - ./letsencrypt:/letsencrypt environment: - TZ=Asia/Shanghai 编辑配置 vim traefik.yml，这里有个动态参数，填写你的邮箱\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 api: dashboard: false entryPoints: web: address: \u0026#34;:80\u0026#34; http: redirections: entryPoint: to: websecure scheme: https websecure: address: \u0026#34;:443\u0026#34; certificatesResolvers: letsencrypt: acme: email: [邮箱] storage: /letsencrypt/acme.json httpChallenge: entryPoint: web providers: file: filename: /config/dynamic.yml watch: true log: level: INFO 编辑反向代理配置\n1 2 mkdir -p app/traefik/config vim app/traefik/config/dynamic.yml 写入以下内容，这里有 2 个动态参数，填入第一步操作的域名，以及在 xray 配置中填写的前缀\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 http: routers: # Xray WebSocket 代理 xray: rule: \u0026#34;Host(`域名`) \u0026amp;\u0026amp; PathPrefix(`/[前缀]`)\u0026#34; service: xray tls: certResolver: letsencrypt entryPoints: - websecure services: # Xray 服务 xray: loadBalancer: servers: - url: \u0026#34;http://127.0.0.1:6000\u0026#34; 执行启动命令，检查是否成功，服务端就部署完毕了。\nClashX 进入 「配置」-「打开配置文件夹」，快键键是 CMD+O\n创建配置文件，比如 my.yaml，写入以下内容，这里有 3 个动态参数，替换域名，前缀，UUID，必须跟之前在服务端配置相同的参数。\n保存并切换此配置，重载配置文件，上网试试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 proxies: - name: \u0026#34;xx\u0026#34; type: vless server: [域名] port: 443 uuid: [UUID] tls: true network: ws ws-opts: path: \u0026#34;/[前缀]\u0026#34; headers: Host: \u0026#34;[域名]\u0026#34; udp: true skip-cert-verify: false proxy-groups: - name: \u0026#34;PROXY\u0026#34; type: select proxies: - \u0026#34;xx\u0026#34; - \u0026#34;DIRECT\u0026#34; rules: - \u0026#34;GEOIP,CN,DIRECT\u0026#34; - \u0026#34;MATCH,xx\u0026#34; 规则 可以从其他配置中拷贝规则，并替换匹配的 name 即可。\n意外 最开始在容器里面监听了 443 端口，启动后提示以下错误 listen tcp 0.0.0.0:443: bind: permission denied， 给 compose 增加 user: root 后解决。\n当然现在的版本已经不使用 443 端口了，同样 compose 里的相关配置可以删掉。\n","date":"2025-11-19T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%BD%91%E7%BB%9C%E4%BB%A3%E7%90%86-xray/","title":"网络代理 xray"},{"content":"\n最近某款小程序游戏广告铺天盖地，出于好奇和学习的目的体验了一下，果然“上头”——玩法简单却极其消磨时间。\n游戏机制中，绝大多数活动都依赖“体力”系统：\n体力每 5 分钟恢复 1 点； 每日 6:00、12:00、18:00、21:00 四个整点，可在“食堂”领取烤肉，每个烤肉恢复 30 点体力； 烤肉最多可存储 60 个（即上限 1800 点体力）。 由此可知：只要一段时间不登录，体力就会大量堆积。而手动清空这些体力，意味着长时间重复操作——堪称“肝帝专属任务”。\n那么，能否实现自动化消耗体力？\n从技术角度看，最高效的方式是直接调用游戏后端接口，通过抓包分析请求报文，构造自动化脚本。但这种方式风险极高——轻则触发风控，重则直接封号，得不偿失。\n相比之下，模拟人类操作是最稳妥的方案：\n行为符合正常用户路径； 不触及服务端逻辑，规避反作弊机制； 可实现“睡后挂机”，解放双手。 因此，我决定采用 基于 OpenCV 的图像识别 + 自动化点击 方案：\n利用屏幕截图与模板匹配定位关键 UI 元素（如“开始战斗”、“领取烤肉”等按钮）； 结合 PyAutoGUI 模拟鼠标点击，完成闭环操作。 此举一举两得： 一方面实现游戏挂机，高效清体力； 另一方面深入实践 OpenCV 在真实场景中的应用，“劳逸结合，边玩边学” (狗头)。\n依赖安装 1 2 3 pip install pyautogui pip install numpy pip install cv2 基础知识 以下代码都放在这里 游戏自动化\n点击事件 这款游戏主要就是靠鼠标点击，首先要了解 python 库 pyautogui ，此库允许 python 脚本控制鼠标和键盘，从而实现与其他应用程序的自动化交互。\n1 2 3 4 5 6 7 8 9 10 11 import pyautogui import time if __name__ == \u0026#34;__main__\u0026#34;: # 在部分游戏比如小程序中，click 点击是无效的 # pyautogui.click(366, 970) # 模拟鼠标点击 pyautogui.mouseDown(366, 970) time.sleep(0.1) pyautogui.mouseUp(366, 970) 这样就完成点击操作，mouseDown 前 2 个参数分别表示 x 轴与 y 轴坐标。\n在部分游戏，比如小程序中，click 点击是无效的，可能是游戏防止自动化的措施，拦截了相关操作，此时可以使用 mouseDown 和 mouseUp。\n截屏与截取区域 全屏截取同样使用 pyautogui 库完成截屏操作，将数据转换为 opencv 的 BGR 色彩空间，pyautogui.screenshot() 返回的是 RGB 顺序，OpenCV 默认使用 BGR 颜色顺序，为了确保其他 OpenCV 函数能正确显示和处理，此处需要做转换操作。\n为什么 OpenCV 采用 BGR 顺序呢?\n据了解，历史原因 + 早期硬件/软件生态的影响，如果直接修改会导致旧代码颜色全部错乱，最终保留了 BGR 默认行为，延续至今。\n这里还要学一个灰度图，to_gray 将图片转换为灰色处理，模板匹配的准确率会更高，颜色容易受到设备，光照，压缩等因素干扰，而灰度图只关注亮度结构，更稳定。\n彩色图，3 通道(RGB)，匹配时需要同时对齐 3 个维度，适合匹配形状一样，但色彩不一样，比如游戏中的 \u0026ldquo;蓝色药水\u0026rdquo; 与 \u0026ldquo;红色药水\u0026rdquo;，交通灯识别等。 灰度图，1 通道，问题简化，计算更稳定，适合按钮，图标，文字区域匹配等场景 截取区域的目的是缩小范围，一则降低误判，二则分析会更快，适合游戏窗口，人员入侵电子围栏标记等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import os import pyautogui import numpy as np import cv2 # 截取屏幕 def capture_screen() -\u0026gt; cv2.typing.MatLike: screenshot = pyautogui.screenshot() # 转换为 OpenCV 格式 frame = np.array(screenshot) # PIL: RGB # 统一使用 OpenCV 的 BGR 色彩空间 return cv2.cvtColor(frame, cv2.COLOR_RGB2BGR) def to_gray(frame: cv2.typing.MatLike) -\u0026gt; cv2.typing.MatLike: # 输入已统一为 BGR return cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # 截取范围 def capture_screen_range( frame: cv2.typing.MatLike, x1: int, x2: int, y1: int, y2: int ) -\u0026gt; cv2.typing.MatLike: size = pyautogui.size() # 考虑 retina 高分辨率 scale = frame.shape[1] / size.width x1 = int(x1 * scale) x2 = int(x2 * scale) y1 = int(y1 * scale) y2 = int(y2 * scale) return frame[y1:y2, x1:x2] if __name__ == \u0026#34;__main__\u0026#34;: name = \u0026#34;screenshot.png\u0026#34; os.remove(name) frame = to_gray(capture_screen()) frame = capture_screen_range(frame, 0, 100, 0, 100) # 保存图片 cv2.imwrite(name, frame) macos 授权辅助功能权限 我使用 macos 操作游戏，截屏和点击事件需要对应的权限，可以通过代码检查是否存在权限，不存在权限时触发打开相关设置，提醒用户开启。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 import platform import pyautogui import subprocess import time # 检查 macos 是否获取了辅助功能权限 def check_accessibility_permission(): \u0026#34;\u0026#34;\u0026#34;检查 macOS 辅助功能权限\u0026#34;\u0026#34;\u0026#34; if platform.system() != \u0026#34;Darwin\u0026#34;: # 非 macOS 系统 return True try: # 尝试获取辅助功能权限（通过尝试移动鼠标来测试） # 如果失败会抛出异常 try: # 尝试获取鼠标位置（需要辅助功能权限） current_pos = pyautogui.position() print(\u0026#34;✓ 辅助功能权限已授予\u0026#34;) return True except Exception: pass # 使用 AppleScript 检查权限 script = \u0026#34;\u0026#34;\u0026#34; tell application \u0026#34;System Events\u0026#34; try set UI elements enabled to true return \u0026#34;granted\u0026#34; on error return \u0026#34;denied\u0026#34; end try end tell \u0026#34;\u0026#34;\u0026#34; result = subprocess.run( [\u0026#34;osascript\u0026#34;, \u0026#34;-e\u0026#34;, script], capture_output=True, text=True, timeout=5 ) if \u0026#34;granted\u0026#34; in result.stdout.lower() or result.returncode == 0: print(\u0026#34;✓ 辅助功能权限已授予\u0026#34;) return True else: print(\u0026#34;\\n\u0026#34; + \u0026#34;=\u0026#34; * 60) print(\u0026#34;⚠️ 需要授予辅助功能权限才能执行点击操作！\u0026#34;) print(\u0026#34;=\u0026#34; * 60) print(\u0026#34;\\n正在打开系统设置页面...\u0026#34;) try: subprocess.run( [ \u0026#34;open\u0026#34;, \u0026#34;x-apple.systempreferences:com.apple.preference.security?Privacy_Accessibility\u0026#34;, ], timeout=5, ) print(\u0026#34;✓ 已打开系统设置页面\u0026#34;) print(\u0026#34;\\n请按照以下步骤操作：\u0026#34;) print(\u0026#34;1. 在系统设置中找到 \u0026#39;辅助功能\u0026#39;\u0026#34;) print(\u0026#34;2. 找到 Terminal 或 Python（取决于您使用的终端）\u0026#34;) print(\u0026#34;3. 勾选复选框以授予权限\u0026#34;) print(\u0026#34;4. 如果找不到，点击 \u0026#39;+\u0026#39; 按钮添加应用程序\u0026#34;) print(\u0026#34;\\n授权完成后，脚本将自动继续...\u0026#34;) print(\u0026#34;=\u0026#34; * 60 + \u0026#34;\\n\u0026#34;) # 等待用户授权（最多等待60秒） for i in range(60): time.sleep(1) try: current_pos = pyautogui.position() print(\u0026#34;✓ 权限已授予！继续运行...\u0026#34;) return True except: if i % 10 == 0: print(f\u0026#34;等待授权中... ({i}/60秒)\u0026#34;) print(\u0026#34;⚠️ 等待超时，请手动授权后重新运行脚本\u0026#34;) return False except Exception as e: print(f\u0026#34;无法自动打开设置页面: {e}\u0026#34;) print(\u0026#34;\\n请手动打开：系统设置 → 隐私与安全性 → 辅助功能\u0026#34;) print(\u0026#34;然后添加 Terminal 或 Python 并授予权限\u0026#34;) return False except Exception as e: print(f\u0026#34;检查权限时出错: {e}\u0026#34;) print(\u0026#34;请确保已授予辅助功能权限\u0026#34;) return False if __name__ == \u0026#34;__main__\u0026#34;: check_accessibility_permission() 以上代码有点长，主要是调用了 apple script。\nOpenCV 模板匹配 定义的入参分别是截图，素材图片，准确度阈值。\n匹配方法是 cv2.TM_CCOEFF_NORMED，采用归一化的相关系数匹配法，除非有特殊要求，否则一律用该方法即可，值越接近 1 越相似。\n还有其它匹配方法，有些方法的值是越大越好，有些则是越小越好。 minMaxLoc的返回值在 cv2.TM_CCOEFF_NORMED 方法中，关注最大值即可，\n最后是模板缩放匹配，为了适配不同屏幕(1080P，2K，4K) 会动态缩放 UI 元素， 素材图片的像素原始尺寸，可能在实际的游戏中进行了缩放，OpenCV 的 cv2.matchTemplate() 是严格基于像素对齐的，一旦实际显示尺寸 ≠ 模板尺寸，即使内容一模一样也可能匹配失败。\n还有一个思路是让程序计算按钮相对位置，自动截图素材，这样准确率最高。\n先试试原图，不够好再试试缩放，是成熟且高效的工程实践。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 # 比较图片相似度 def find_image( img1: cv2.typing.MatLike, img2: cv2.typing.MatLike, threshold: float = 0.8 ): # 对图片进行预处理，提高匹配率 # 转换为灰度图 screen_gray = ( cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY) if len(img1.shape) == 3 else img1 ) target_gray = ( cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY) if len(img2.shape) == 3 else img2 ) # 比较宽高，如果模板比屏幕大，直接返回 if ( target_gray.shape[0] \u0026gt; screen_gray.shape[0] or target_gray.shape[1] \u0026gt; screen_gray.shape[1] ): return None method = cv2.TM_CCOEFF_NORMED result = cv2.matchTemplate(screen_gray, target_gray, method) # 矩阵中的最小数值，最大数值，最小值所在坐标，最大值所在坐标 min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result) # 如果原始尺寸匹配度已经很高，直接返回 if max_val \u0026gt;= threshold: h, w = target_gray.shape[:2] center_x = max_loc[0] + w // 2 center_y = max_loc[1] + h // 2 return (center_x, center_y, max_loc, target_gray.shape[:2]) # 如果匹配度接近阈值，尝试多尺度匹配 # 可能因为缩放了界面，或不同分辨率的屏幕上运行，导致匹配度不高 if max_val \u0026gt;= 0.5: scales = [0.95, 1.05, 0.9, 1.1] for scale in scales: h, w = target_gray.shape[:2] scaled_h = int(h * scale) scaled_w = int(w * scale) # 检查尺寸是否有效 if ( scaled_h \u0026lt;= 0 or scaled_w \u0026lt;= 0 or scaled_h \u0026gt; screen_gray.shape[0] or scaled_w \u0026gt; screen_gray.shape[1] ): continue # 缩放模板 scaled_target = cv2.resize( target_gray, (scaled_w, scaled_h), interpolation=cv2.INTER_AREA ) # 执行模板匹配 result = cv2.matchTemplate(screen_gray, scaled_target, method) min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result) if max_val \u0026gt;= threshold: # 计算中心点坐标,考虑缩放后的尺寸 center_x = max_loc[0] + scaled_w // 2 center_y = max_loc[1] + scaled_h // 2 return (center_x, center_y, max_loc, target_gray.shape[:2]) return None 将找到的位置画框标记并保存图片\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 画框 def draw_box(img: cv2.typing.MatLike, max_loc: cv2.typing.Point, size: tuple[int, int]): x, y = max_loc w, h = size x2 = x + w y2 = y + h center = (x + w // 2, y + h // 2) cv2.rectangle(img, (x, y), (x2, y2), (0, 255, 0), 2) cv2.putText( img, f\u0026#34;Match: ({center[0]},{center[1]})\u0026#34;, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, ) return img def save_image( screen: cv2.typing.MatLike, max_loc: cv2.typing.Point, size: tuple[int, int] ): img = screen.copy() # 画框 draw_box(img, max_loc, size) # 保存图片 cv2.imwrite(\u0026#34;screenshot.png\u0026#34;, img) 有了以上基础知识，其实就是拼积木一样，按照游戏的流程，识别对应的操作，触发点击即可。\n","date":"2025-11-16T00:00:00Z","image":"http://img.golang.space/img-1763296949834.png","permalink":"https://blog.golang.space/p/opencv-%E4%B9%8B%E6%B8%B8%E6%88%8F%E8%87%AA%E5%8A%A8%E5%8C%96/","title":"OpenCV 之游戏自动化"},{"content":"\n背景 规定要求采用服务端播放音乐，所以要在服务端实现并提供播放器的能力。\n一个房间只能有一个音乐播放器，且由房间拥有者控制，房间拥有者退出房间，则播放器销毁。\n需求收集 播放器有哪些功能??\n音乐文件上传预检 添加到播放队列 从播放队列移除 ( 不影响当前播放的音乐正常播放 ) 清除播放队列( 不影响当前播放的音乐正常播放 ) 上一首/下一首 暂停/播放 循环模式: 顺序播放/单曲循环/队列循环 设置音量大小 ( 服务端实现此功能较为复杂，后续将重点说明 ) 获取播放状态(播放进度/播放模式) 查询播放队列 插播 播放器销毁 功能说明 音乐文件上传预检 提供上传预检接口，采用基于内容指纹的秒传机制，判断音乐文件是否存在，若命中缓存则复用已有资源，跳过实际数据传输环节，从而降低上行带宽消耗，减少存储冗余，音乐更快的响应到用户的耳朵。\n另外也是校验文件的完整性，文件损坏则响应提示给调用者。\n添加到播放队列 播放队列的生命周期随房间拥有者操作而创建，房间拥有者离开则销毁，仅提供队列能力。\n根据上传预检的结果，判断是否需要上传音乐文件，如果携带音乐文件，会持久化到临时存储，作为转码任务的输入源，系统立即触发音频转码任务，最后将音乐的元数据添加到指定房间的播放器队列中。\n在播放过程中，可以提前将音乐添加到队列的队尾。\n正在播放的音乐不受影响，当队列为空时，添加到播放队列则立即播放此音乐。\n播放采用异步缓冲架构，防止音频受指令时间影响造成的卡顿。\n除了首次操作添加会自动播放，其余播放是暂停状态时，添加队列依然维持暂停播放状态，所以移动端可以尽管缓冲队列，不会让用户产生明明暂停了，却莫名其妙的又开始播放。\n从播放队列移除 可以将音乐从播放队列移除，此后将不会再播放该音乐。\n将正在播放的音乐从队列移除，会导致指针与所播放的音乐不同步问题，那此时操作\u0026quot;上一首\u0026quot;是未移除之前的上一首还是上上一首呢? 为保障播放过程中的原子性和状态一致性，禁止移除正在播放的音乐。\n注意，移除当前播放音乐之前的索引，其指针位置需要变动，避免播放的是 a 音乐，指针跑到 b 音乐上的状态不一致问题。\n清除播放队列 可以将全部音乐从播放队列移除。\n注意，正在播放的音乐不受影响，当前播放完后自动停止。\n上一首 如果在队列中确实存在上一首，则立即播放上一首。\n如果当前已经是队首，则重新播放该音乐。\n暂停状态下，可以切换，但不会播放，需要播放可以与播放组合使用。\n下一首 如果在队列中确实存在下一首，则立即播放下一首。\n顺序播放模式 和 单曲循环模式下，如果当前已经是队尾，则不会做任何操作。\n队列循环播放模式下，如果当前已经是队尾，则会跳到队首播放。\n暂停状态下，可以切换，但不会播放，需要播放可以与播放组合使用。\n暂停/播放 如果播放队列为空，一切保持暂停状态。\n如果是暂停状态，则播放。\n如果是播放状态，则暂停。\n循环模式: 顺序播放/单曲循环/队列循环 顺序播放，按照播放队列依次的播放，播放完自动停止，该模式是默认模式。\n单曲循环，按照当前播放的歌曲，无限循环。\n队列循环，按照顺序播放，播放完后回到队首，开始新的一轮顺序播放，循环往复。\n设置音量大小 音量 1~10，根据音量调整音乐的大小，客户端应避免在 1 秒内连续调整调用接口。\n这个功能对于服务端有一定复杂度，音量的播放在是客户端，客户端可以设定声音，服务端如何控制客户端的声音呢??\n再次明确背景，此设计是基于服务端!! 站在服务端的角度实现功能!!! 在不打破规则的前提下，只能重新编解码音频文件，控制音频增益。\n采用异步实时编码，对 PCM 做音量增益，封装成 opus 音频流，优点是操作跟手，调整音量后能尽快感知到音量变化。\n缺点是占用运行内存和硬盘存储较高，比方案一多 10 倍存储量，每个编码任务占用 20MB 左右内存。\n获取播放状态 查询播放进度，播放状态，播放模式\n查询播放队列 查询播放队列和当前播放位置\n插播 如果想播放的音乐在队尾，要播放到指定音乐要等 20 分钟，是播放器先着急还是用户先着急?\n插播就是为了解决这个问题，可以将指定音乐插入到 \u0026ldquo;下一首\u0026rdquo; 位置。\n插播不会中断当前播放。\n播放器销毁 音乐由房间拥有者播放，房间拥有者退出房间播放器自动销毁。就好比房间拥有者带着音响离开了，房间内不应该余音绕梁三日不绝。\n尽快销毁播放器，有助于资源回收，提升资源利用率。\n验证测试 ✅️在播放或暂停状态中，清空播放队列，是指除了当前正在播放的都清空\n✅️在顺序播放完时，清空播放队列，是指清除全部\n✅️移除上一首音乐，上一首，即 1,2,3 移除 2 播放 1\n✅️移除下一首音乐，下一首，即 2,3,4 移除 3 播放 4\n✅️设置单曲循环时，上一首/下一首，测试表现应为上一首直到队首，下一首直到队尾\n✅️设置队列循环时，上一首/下一首，测试表现应为上一首直到队首，下一首可以循环队列。\n✅️设置顺序播放时，上一首/下一首，测试表现与单曲循环效果相同\n顺序播放结束，自动暂停，触发播放，应从队首重新开始\n✅️暂停 5 分钟后，触发播放，还在之前停止的位置继续播放\n✅️不在播放中，且队列没有音乐时，触发播放将响应提示\n✅️添加音乐到队列中，首次添加时自动触发播放，非首次添加，保持旧的播放状态\n✅️重复添加相同音乐到队列中，响应提示\n处理在未知的房间播放音乐，响应提示\n房间拥有者离开/房间内没人/主动调用接口，三者任意结可销毁音乐播放器\n播放中房间拥有者断网，播放器应延迟 1 分钟销毁\n插播正在播放的歌曲，当前播放 A 插播 A，此操作不可行，响应提示。\n✅️队列为空时，下一首，此操作不可行，响应提示\n✅️同一文件多次上传，预检应命中，复用资源\n✅️播放器销毁后继续调用播放接口，应返回 \u0026ldquo;播放器不存在\u0026rdquo; 错误\n播放进度查询精度，是否准确表达出音频播放位置\n在随机房间播放音乐，可能该房间没有人，此操作不可行，响应提示。\n","date":"2025-11-13T00:00:00Z","image":"http://img.golang.space/img-1763003117835.png","permalink":"https://blog.golang.space/p/webrtc-%E9%9F%B3%E4%B9%90%E6%92%AD%E6%94%BE%E5%99%A8/","title":"WebRTC 音乐播放器"},{"content":"什么是异步函数？ 同步函数非常简单。调用它，它执行一些操作后返回。\n异步函数则不同。调用它即返回，然后它继续执行一些操作。\n举一个具体的例子，虽然有些不自然，但下面的 Cleanup 函数是同步的。你调用它，它会删除一个缓存目录，然后返回。\n1 2 3 func (c *Cache) Cleanup() { os.RemoveAll(c.cacheDir) } CleanupInBackground 是一个异步函数。你调用它即返回，然后缓存目录就会被删除……这迟早会发生。\n1 2 3 func (c *Cache) CleanupInBackground() { go os.RemoveAll(c.cacheDir) } 有时异步函数会在将来执行某些操作。例如， context 包的 WithDeadline 函数返回一个将来会被取消的 context。\n1 2 3 4 5 package context // WithDeadline returns a derived context // with a deadline no later than d. func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) 当我谈到测试并发代码时，我的意思是测试这些类型的异步操作，包括使用实时的操作和不使用实时的操作。\n测试 测试验证系统的行为是否符合我们的预期。描述测试类型的术语有很多，例如单元测试、集成测试等等，但就我们的目的而言，每种测试都简化为三个步骤：\n设置初始条件 告诉被测系统做某事 验证结果 测试同步函数很简单\n调用该函数 函数执行并返回 验证结果 然后，测试异步函数很棘手:\n调用该函数 它返回 等待它完成要做的事情 验证结果 如果没有等待正确的时间，可能会发现自己正在验证尚未发生或仅部分发生的操作的结果。这绝对不会有好结果。\n当你想断言某件事尚未发生时，测试异步函数尤其棘手。你可以验证这件事尚未发生，但如何确定它稍后不会发生呢？\n举一个栗子 为了使事情更具体一些，让我们来看一个真实的例子。再次考虑 context 包的 WithDeadline 函数。\n有两个明显的测试需要为 WithDeadline 编写。\n期限前未取消上下文 截止日期过后，该上下文将被取消 让我们写一个测试。\n为了使代码量稍微不那么繁琐，我们只测试第二种情况：截止日期过后，上下文被取消。\n1 2 3 4 5 6 7 8 9 10 func TestWithDeadlineAfterDeadline(t *testing.T) { deadline := time.Now().Add(1 * time.Second) ctx, _ := context.WithDeadline(t.Context(), deadline) time.Sleep(time.Until(deadline)) if err := ctx.Err(); err != context.DeadlineExceeded { t.Fatalf(\u0026#34;context not canceled after deadline\u0026#34;) } } 这个测试很简单：\n使用 context.WithDeadline 创建一个具有未来一秒截止期限的上下文。 等到最后期限 验证上下文是否已取消 不幸的是，这个测试显然有问题。它会一直休眠到截止时间到期的那一瞬间。很有可能，当我们检查它的时候，上下文还没有被取消。这个测试充其量也只能算是个很不稳定的测试。\n让我们修复它。\n1 time.Sleep(time.Until(deadline) + 100*time.Millisecond) 我们可以等到截止时间过后100毫秒再休眠。对计算机而言，这100毫秒已经绰绰有余，完全足够任务完成。\n不幸的是，我们仍然面临两个问题。\n首先，这个测试执行耗时 1.1 秒。这太慢了。这是一个简单的测试，最多应该在几毫秒内完成。\n其次，这个测试不够稳定。一百毫秒在计算机范畴内堪称漫长，但在负载过重的持续集成（CI）系统中，出现远超这个时长的延迟并不罕见。该测试在开发者的工作站上或许能持续通过，但在CI系统中很可能出现间歇性失败。\n缓慢或不稳定: 请选择两项 使用实时的测试总是很慢或不稳定。通常两者兼而有之。如果测试等待的时间超过必要时间，它就会很慢。如果等待的时间不够长，它就会不稳定。你可以让测试更慢、更稳定，或者让测试更慢、更不稳定，但你无法让它快速可靠。\nnet/http 包里有很多测试都用到了这种方法。它们都很慢，而且/或者不稳定，这就是我今天开始研究这个问题的原因。\n编写同步函数 测试异步函数最简单的方法就是不去测试它。同步函数很容易测试。如果你能把异步函数转换成同步函数，测试起来会更容易。\n例如，如果我们考虑之前的缓存清理函数，同步 Cleanup 显然比异步 CleanupInBackground 更好。同步函数更容易测试，并且调用者可以根据需要轻松启动一个新的 Goroutine 在后台运行它。通常而言，将并发处理推向调用栈的越高层越好。\n1 2 3 4 5 6 // CleanupInBackground is hard to test. cache.CleanupInBackground() // Cleanup is easy to test, // and easy to run in the background when needed. go cache.Cleanup() 不幸的是，这种转换并不总是可行的。例如， context.WithDeadline 本质上是一个异步 API。\n检查代码的可测试性 更好的方法是让我们的代码更易于测试。\n以下是我们的 WithDeadline 测试的一个示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func TestWithDeadlineAfterDeadline(t *testing.T) { clock := fakeClock() timeout := 1 * time.Second deadline := clock.Now().Add(timeout) ctx, _ := context.WithDeadlineClock( t.Context(), deadline, clock) clock.Advance(timeout) context.WaitUntilIdle(ctx) if err := ctx.Err(); err != context.DeadlineExceeded { t.Fatalf(\u0026#34;context not canceled after deadline\u0026#34;) } } 我们不使用真实时间，而是使用伪时间实现。使用伪时间可以避免不必要的测试速度变慢，因为我们永远不会无所事事地等待。它还有助于避免测试不稳定，因为当前时间仅在测试调整时才会更改。\n有各种虚假的时间包，或者你可以编写自己的时间包。\n要使用虚假时间，我们需要修改 API 以接受虚假时钟。我在这里添加了一个 context.WithDeadlineClock 函数，它接受一个额外的时钟参数：\n1 2 ctx, _ := context.WithDeadlineClock( t.Context(), deadline, clock) 当我们向前拨动模拟时钟时，会遇到一个问题：时间推进是异步操作。休眠中的协程可能被唤醒、定时器可能向通道发送信号、计时器函数可能被触发——我们需要等待这些操作全部完成，才能开始测试系统的预期行为。\n我在这里添加了一个 context.WaitUntilIdle 函数，它等待与上下文相关的任何后台工作完成：\n1 2 clock.Advance(timeout) context.WaitUntilIdle(ctx) 这是一个简单的例子，但它演示了编写可测试并发代码的两个基本原则：\n使用假时间（如果您使用时间）。 有某种方式来等待静止，这是一种说法“所有后台活动都已停止并且系统稳定”。 当然，有趣的问题是我们如何做到这一点。在这个例子中，我略过了细节，因为这种方法存在一些很大的缺点。\n这很难。使用假时钟并不难，但确定后台并发工作何时完成，以及何时可以安全地检查系统状态却很难。\n你的代码变得不那么符合惯用语法了。你不能使用标准的 time 包函数。你需要非常小心地跟踪后台发生的所有事情。\n你不仅需要检测你的代码，还需要检测你使用的其他任何包。如果你调用了任何第三方并发代码，那么你可能就没那么幸运了。\n最糟糕的是，将这种方法改进到现有的代码库中几乎是不可能的。\n我尝试将这种方法应用于 Go 的 HTTP 实现，虽然在某些地方取得了一些成功，但 HTTP/2 服务器却让我束手无策。尤其是，如果不进行大量重写，添加检测静止状态的工具就被证明是不可行的，或者至少超出了我的能力范围。\n糟糕的运行时 hack 如果我们不能使我们的代码可测试，我们该怎么办？\n如果我们不对我们的代码进行检测，而是有办法观察未检测系统的行为，那会怎样？\n一个 Go 程序由一组 Goroutine 组成。这些 Goroutine 有状态。我们只需要等待所有 Goroutine 停止运行即可。\n不幸的是，Go 运行时没有提供任何方法来判断这些 goroutine 正在做什么。或者有？\nruntime 包中包含一个函数，它可以提供每个正在运行的 goroutine 的堆栈跟踪及其状态。这是供人类阅读的文本，但我们可以解析该输出。我们可以用它来检测静止状态吗？\n当然，这绝对是个糟糕的主意。这些堆栈跟踪的格式无法保证长期稳定。你不应该这么做。\n我做到了。而且成功了。事实上，效果出奇地好。\n通过简单实现一个假时钟、少量仪器来跟踪哪些 goroutine 是测试的一部分，以及对 runtime.Stack 的一些可怕的滥用。Stack，我终于找到了一种为 http 包编写快速、可靠的测试的方法。\n这些测试的底层实现很糟糕，但它表明这里有一个有用的概念。\n使用 synctest 进行测试 上面介绍了背景，简单来说识别到协程阻塞就推进时钟，接下来看看怎么使用。\n1 2 3 4 5 6 7 8 9 10 11 12 func TestWithDeadlineAfterDeadline(t *testing.T) { synctest.Test(t, func(t *testing.T) { deadline := time.Now().Add(1 * time.Second) ctx, _ := context.WithDeadline(t.Context(), deadline) time.Sleep(time.Until(deadline)) synctest.Wait() if err := ctx.Err(); err != context.DeadlineExceeded { t.Fatalf(\u0026#34;context not canceled after deadline\u0026#34;) } }) } 我们将测试包装在 synctest.Test 调用中，让它在一个隔离环境里执行，并且额外添加了一个 synctest.Wait 调用。\n该测试快速可靠，几乎可以立即运行，能够精确测试被测系统的预期行为，并且无需修改 context 包。\n时间 气泡中的时间行为与 Go Playground 中的伪时间非常相似。时间从 UTC 时间 2000 年 1 月 1 日午夜开始。如果您出于某种原因需要在某个特定时间点运行测试，您可以休眠到那时。\n1 2 3 4 5 6 7 8 9 10 11 12 13 func TestAtSpecificTime(t *testing.T) { synctest.Test(t, func(t *testing.T) { // 2000-01-01 00:00:00 +0000 UTC t.Log(time.Now().In(time.UTC)) // This does not take 25 years. time.Sleep(time.Until( time.Date(2025, 1, 1, 0, 0, 0, 0, time.UTC))) // 2025-01-01 00:00:00 +0000 UTC t.Log(time.Now().In(time.UTC)) }) } 时间只会在隔离环境中的所有协程都进入阻塞状态时才会流逝。您可以将这个隔离环境想象成一台模拟无限速度的计算机：无论进行多少计算，都不会消耗任何时间。\n以下测试函数无论实际经过多长时间，都会打印出测试开始后模拟时间的流逝为0秒：\n1 2 3 4 5 6 7 8 9 func TestExpensiveWork(t *testing.T) { synctest.Test(t, func(t *testing.T) { start := time.Now() for range 1e7 { // do expensive work } t.Log(time.Since(start)) // 0s }) } 而在接下来的测试中，time.Sleep 调用会立即返回，而不是等待真实的十秒。该测试将始终打印出自测试开始后，正好有十秒模拟时间已经流逝：\n1 2 3 4 5 6 7 func TestSleep(t *testing.T) { synctest.Test(t, func(t *testing.T) { start := time.Now() time.Sleep(10 * time.Second) t.Log(time.Since(start)) // 10s }) } wait synctest.Wait 函数让我们等待后台活动完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 func TestWait(t *testing.T) { synctest.Test(t, func(t *testing.T) { done := false go func() { done = true }() // 等待上面的任务完成 synctest.Wait() t.Log(done) // true }) } 如果上面的测试中没有 Wait 调用，就会出现竞争条件：一个 Goroutine 修改了 done 变量，而另一个 Goroutine 却在不同步的情况下读取了该变量。 Wait 调用提供了这种同步。\n您可能熟悉 -race 测试标志，它启用了数据竞争检测器。竞争检测器知道 Wait 提供的同步机制，因此不会对此测试发出警告。如果我们忘记了 Wait 调用，竞争检测器就会正确地发出警告。\nsynctest.Wait 函数可提供同步功能，但时间的流逝无法提供同步功能。\n在下一个示例中，一个 goroutine 向 done 变量写入数据，而另一个 goroutine 则先休眠一纳秒，再从该变量读取数据。显然，若在 synctest 环境之外使用真实时钟运行这段代码，其中会存在竞态条件。在 synctest 环境中，尽管虚拟时钟会确保该 goroutine 在 time.Sleep 返回前完成操作，但竞态检测器仍会报告数据竞争 —— 就像这段代码在 synctest 环境外运行时的情况一样。\n1 2 3 4 5 6 7 8 9 10 11 12 func TestTimeDataRace(t *testing.T) { synctest.Test(t, func(t *testing.T) { done := false go func() { done = true // write }() time.Sleep(1 * time.Nanosecond) t.Log(done) // read (unsynchronized) }) } 添加 Wait 调用可提供显式同步并修复数据争用：\n1 2 3 time.Sleep(1 * time.Nanosecond) synctest.Wait() // synchronize t.Log(done) // read Example: io.Copy¶ 利用 synctest.Wait 提供的同步机制，我们能够编写更简洁的测试，减少显式同步操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func TestIOCopy(t *testing.T) { synctest.Test(t, func(t *testing.T) { srcReader, srcWriter := io.Pipe() defer srcWriter.Close() var dst bytes.Buffer go io.Copy(\u0026amp;dst, srcReader) data := \u0026#34;1234\u0026#34; srcWriter.Write([]byte(\u0026#34;1234\u0026#34;)) synctest.Wait() if got, want := dst.String(), data; got != want { t.Errorf(\u0026#34;Copy wrote %q, want %q\u0026#34;, got, want) } }) } 参考 Testing Time (and other asynchronicities) ","date":"2025-10-23T00:00:00Z","permalink":"https://blog.golang.space/p/%E6%B5%8B%E8%AF%95%E6%97%B6%E9%97%B4%E5%92%8C%E5%85%B6%E5%AE%83%E5%BC%82%E6%AD%A5/","title":"测试时间和其它异步"},{"content":"某些并发操作不需要显式同步。我们可以利用这些操作来创建无锁类型和函数，以便多个 goroutine 可以安全地使用它们。让我们深入探讨这个话题！\n非原子增量 假设多个 goroutines 增加一个共享计数器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 func main(){ total := 0 var wg sync.WaitGroup for range 5 { wg.Go(func() { for range 10000 { total++ } }) } wg.Wait() fmt.Println(\u0026#34;total\u0026#34;, total) } 这里有 5 个 Goroutine，每个 Goroutine total 执行 10,000 次递增，所以最终结果应该是 50,000。但通常情况下会更少。让我们再运行几次代码：\n1 2 3 total 26775 total 22978 total 30357 竞争检测器报告了一个问题：\n1 2 3 4 5 6 7 $ go run -race total.go ================== WARNING: DATA RACE ... ================== total 33274 Found 1 data race(s) 这看起来可能有点奇怪—— total++ 操作难道不应该是原子的吗？其实不然。它包含三个步骤（读取-修改-写入）：\n读取 total 的当前值。 +1 将新值写会到 total 如果两个 Goroutine 都读取了值 42 ，然后分别对其进行加一和写回，新的 total 将是 43 而不是应该的 44 。结果，计数器的一些增量将会丢失，最终值将小于 50,000 。\n可以使用互斥锁或其他同步工具使操作具有原子性。但在本章中，我们约定不使用它们。这里，我所说的“原子操作”是指不需要调用者使用显式锁，但在并发环境中仍然可以安全使用的操作。\n一个没有同步的操作只有转化为单条处理器指令才能真正实现原子性。这样的操作不需要锁，并且在并发调用时（即使是写操作）也不会引发问题。\n在理想情况下，每个操作都应该是原子的，我们不必处理互斥锁。但实际上，原子操作只有少数几种，它们都可以在 sync/atomic 包中找到。该包提供了一组原子类型：\n原子操作 每种原子类型都提供以下方法：\nLoad 读取变量的值， Store 设置新值：\n1 2 3 var n atomic.Int32 n.Store(10) fmt.Println(\u0026#34;Store\u0026#34;, n.Load()) Swap 设置一个新值（如 Store ）并返回旧值：\n1 2 3 4 var n atomic.Int32 n.Store(10) old := n.Swap(42) fmt.Println(\u0026#34;Swap\u0026#34;, old, \u0026#34;-\u0026gt;\u0026#34;, n.Load()) 仅当当前值仍符合你的预期时， CompareAndSwap 才会设置新值：\n1 2 3 4 5 var n atomic.Int32 n.Store(10) swapped := n.CompareAndSwap(10, 42) fmt.Println(\u0026#34;CompareAndSwap 10 -\u0026gt; 42:\u0026#34;, swapped) fmt.Println(\u0026#34;n =\u0026#34;, n.Load()) 1 2 3 4 5 var n atomic.Int32 n.Store(10) swapped := n.CompareAndSwap(33, 42) fmt.Println(\u0026#34;CompareAndSwap 33 -\u0026gt; 42:\u0026#34;, swapped) fmt.Println(\u0026#34;n =\u0026#34;, n.Load()) 数字类型还提供了一种 Add 方法，可以将值增加指定的量：\n1 2 3 4 var n atomic.Int32 n.Store(10) n.Add(32) fmt.Println(\u0026#34;Add 32:\u0026#34;, n.Load()) 用于位运算的 And / Or 方法（Go 1.23+）：\n1 2 3 4 5 6 7 8 9 10 11 const ( modeRead = 0b100 modeWrite = 0b010 modeExec = 0b001 ) var mode atomic.Int32 mode.Store(modeRead) old := mode.Or(modeWrite) fmt.Printf(\u0026#34;mode: %b -\u0026gt; %b\\n\u0026#34;, old, mode.Load()) 所有方法都被转换为单个 CPU 指令，因此它们对于并发调用是安全的。\n严格来说，这并非总是如此。并非所有处理器都支持完整的并发操作，因此有时需要多条指令。但我们不必担心这一点——Go 为调用者保证 sync/atomic 操作的原子性。它使用特定于每个处理器架构的低级机制来做到这一点。\n与其他同步原语一样，每个原子变量都有其自身的内部状态。因此，您应该仅将其作为指针传递，而不是通过值传递，以避免意外复制状态。\n使用 atomic.Value 时，所有读取和存储操作都应该使用相同的具体类型。以下代码将引发 panic：\n1 2 3 var v atomic.Value v.Store(10) v.Store(\u0026#34;hi\u0026#34;) 现在，让我们回到计数器程序，并将其重写为使用原子计数器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 var total atomic.Int32 var wg sync.WaitGroup for range 5 { wg.Go(func() { for range 10000 { total.Add(1) } }) } wg.Wait() fmt.Println(\u0026#34;total\u0026#34;, total.Load()) 现在好了，没有数据竞争。\n原子构成 并发程序中的原子操作非常重要。此类操作通常转换为单处理器指令，并且不需要锁。你可以安全地从不同的 goroutine 调用它，并获得可预测的结果。\n但是如果将原子操作结合起来会发生什么呢？让我们来一探究竟。\n原子性 让我们看一个增加计数器的函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 var counter int32 // increment increases the counter value by two. func increment() { counter += 1 sleep(10) counter += 1 } // sleep pauses the current goroutine for up to maxMs ms. func sleep(maxMs int) { dur := time.Duration(rand.IntN(maxMs)) * time.Millisecond time.Sleep(dur) } 正如你所知，从多个 goroutine 调用 increment 是不安全的，因为 counter += 1 会导致数据争用。\n现在我将尝试解决这个问题，并提出几种方案。在每种情况下，请回答以下问题：如果从 100 个 Goroutine 调用 increment ， counter 的最终值是否能保证？\n1 2 3 4 5 6 7 8 // example 1: var counter atomic.Int32 func increment() { counter.Add(1) sleep(10) counter.Add(1) } 1 2 3 4 5 6 7 8 9 10 11 12 // example 2: var counter atomic.Int32 func increment() { if counter.Load()%2 == 0 { sleep(10) counter.Add(1) } else { sleep(10) counter.Add(2) } } 1 2 3 4 5 6 7 8 9 // example 3: var delta atomic.Int32 var counter atomic.Int32 func increment() { delta.Add(1) sleep(10) counter.Add(delta.Load()) } 构成 人们有时会认为原子操作的组合也会神奇地变成原子操作。但事实并非如此。\n例如上面例子中的第二个，从不同的 goroutines 调用 increment 100 次，使用 -race 运行程序 — 没有竞争。\n1 2 3 4 5 6 % go run atomic-2.go 192 % go run atomic-2.go 191 % go run atomic-2.go 189 但是我们能确定 counter 的最终值吗？不能。 counter.Load 和 counter.Add 调用是在不同的 goroutine 中交错进行的。这会导致竞争条件（不要与数据竞争混淆），并导致 counter 值不可预测。\n在哪个例子中 increment 是原子操作？\n答案 在所有示例中， increment 都不是原子操作。原子的组合始终是非原子的。\n然而，第一个例子保证了并发环境中 counter 的最终值，如果我们运行 100 个 goroutine， counter 最终将等于 200。\n原因是 Add 是一个与顺序无关的操作，运行时可以按照任意顺序执行此类操作，结果都不会改变。\n第二和第三个例子使用了顺序相关的操作。当我们运行 100 个 goroutine 时，每次操作的顺序都不一样。因此，结果也不同。\n使复合操作原子化并防止竞争条件的一种可靠方法是使用互斥锁：\n1 2 3 4 5 6 7 8 9 10 11 var delta int32 var counter int32 var mu sync.Mutex func increment() { mu.Lock() delta += 1 sleep(10) counter += delta mu.Unlock() } 但有时你只需要一个带有 CompareAndSwap 原子变量。让我们看一个例子。\n原子性而非互斥性 假设我们有一扇需要关闭的门：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 type Gate struct { closed bool // gate state } func (g *Gate) Close() { if g.closed { return // ignore repeated calls } g.closed = true // free resources } func work() { var g Gate defer g.Close() // do something while the gate is open } 在并发环境中， closed 字段存在数据竞争。我们可以使用互斥锁来解决这个问题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 type Gate struct { closed bool mu sync.Mutex // protects the state } func (g *Gate) Close() { g.mu.Lock() defer g.mu.Unlock() if g.closed { return // ignore repeated calls } g.closed = true // free resources } 或者，我们可以在原子 Bool 上使用 CompareAndSwap 而不是互斥锁：\n1 2 3 4 5 6 7 8 9 10 11 type Gate struct { closed atomic.Bool } func (g *Gate) Close() { if !g.closed.CompareAndSwap(false, true) { return // ignore repeated calls } // The gate is closed. // We can free resources now. } Gate 类型现在更加紧凑和简单。\n这不是一个很常见的用例——我们通常希望一个 goroutine 等待一个锁定的互斥锁，并在解锁后继续执行。但对于“提前退出”的情况，它是完美的。\n总结 原子操作是一种特殊但实用的工具。您可以将其用于简单的计数器和标志，但在使用更复杂的操作时要非常小心。您也可以使用它们代替互斥锁来提前退出。\n并发编程的核心目标是为了在不确定的，混乱的调度中，为关键性部分创造出确定性。通过同步机制(mutex,channel)，强制让那些原本可能交错执行的指令，以我们期望的，确定的顺序执行。\n还有一种场景比较适合原子操作，在聊天房间中，谁说话了要显示出当前说话人，张三发言时显示张三，李四发言时显示李四，可能同时说话，谁后说话就赋值谁。这是一个典型 ‘无关计算’ 的场景。我们采用‘最后者获胜’的冲突解决策略，因此不需要使用互斥锁进行同步，只需要保证赋值的原子性和内存可见性即可。\n无关计算是指与变量的旧值无关，不依赖时序或其它并发操作的中间状态。\n最后者获胜是兵法冲突下的解决策略，冲突是允许发生的，系统会接受最后一个完成的操作。\n那么这种场景不用原子操作行不行? 不行!\n有个极端的坏情况，协程 A 开始写入字符串，写到一半\u0026quot;张\u0026quot;，协程 B 抢占了 CPU 并完整的写入了\u0026quot;李四\u0026quot;，协程 A 恢复执行写入\u0026quot;三\u0026quot;，这既不是 \u0026ldquo;张三\u0026rdquo; 也不是 \u0026ldquo;李四\u0026rdquo;，而是一个损坏的，无效的数据。\n原子操作防止了数据损坏，涉及并发的场景可以用 -race 辅助检测，共享状态的读写并发，没有原子操作一定是不安全的。\n参考 Gist of Go: Atomics\n","date":"2025-10-16T00:00:00Z","permalink":"https://blog.golang.space/p/golang-%E7%9A%84-atomic/","title":"Golang 的 Atomic"},{"content":"微信支付 微信支付与支付宝支付接口有几个区别要重点注意，从接口上微信更严格一些\n支付宝采用 float64 表示金额，单位是元。微信采用 int64 表示金额，单位是分。 微信要求订单号长度不能超过 32 位 微信要求订单描述不能超过 127 个字节 开通微信支付流程 「账户中心」-「API 安全」- 「申请证书/管理证书」，根据流程操作在本地电脑生成证书 「账户中心」- 「API 安全」- 「解密回调/API v3 秘钥设置」，自定义个长度为 32 位的秘钥 「产品中心」- 「开发配置」拿到商户号 「产品中心」- 「AppID 账户管理」关联相关的 AppID，要求服务号，政府/媒体订阅号，小程序，企业微信等，一般订阅号不行。 「账户中心」-「API 安全」-「管理证书」-「序列号」，注意这个序列化是假的!!巨坑，用这个序列号请求最终会导致接口报错 商户证书序列号有误。请使用签名私钥匹配的证书序列号，在终端执行openssl x509 -in apiclient_cert.pem -noout -serial 获取序列号。 「产品中心」-「我的产品」 要开通对应的产品，比如 JSAPI 支付，APP 支付等。 参数说明 - 微信支付官方文档\napiclient_key.pem 是私钥文件，通过以上步骤拿到了必要的请求参数，注意回调解析等，基本就大差不差了。\n支付宝周期付款 1. 登录支付宝开放平台\n打开 产品介绍，此页面可以检测当前账号是否允许调用相关 API，未开通相关产品时，根据文档引导流程前往商家平台产品中心 开通。\n注意扣款单笔限额 100 元。\n开通需要公司主体注册资金 2000 万。\n","date":"2025-10-09T00:00:00Z","permalink":"https://blog.golang.space/p/%E6%94%AF%E4%BB%98%E7%9B%B8%E5%85%B3/","title":"支付相关"},{"content":"背景描述 想象有一个服务端，且称其为 a 服务，当请求 /login 的时候，会触发重定向到 /home。\n即访问 a.com/login 时，页面重定向到 a.com/home。\n现在给 a 服务增加一个 nginx 反向代理，nginx 下也有其它服务，当然可以通过域名的方式区分访问的是哪个服务器，但在这个场景下，咱们限定只能通过前缀区分服务。即访问 nginx.proxy.com/a/login ，会被代理到 a.com/login，现在发出请求，会发现浏览器重定向到了 a.com/home，这不是我想要的结果，前端不应该直接访问到 a 服务，理想的结果是 nginx.proxy.com/a/home。\n一种简单的方案如下\n1 2 3 4 5 location /a/ { proxy_pass http://a.com/; # 把后端返回的 \u0026#34;Location: /xxx\u0026#34; 改成 \u0026#34;Location: /a/xxx\u0026#34; proxy_redirect / /a/; } 这是重定向，如果返回的链接也需要加前缀呢?\n解决方案 为了解决上面的问题，我们可以在 nginx 配置中定义一个 X-Forwarded-Prefix，例如\n1 2 3 4 location /a/ { proxy_pass http://a.com/; proxy_set_header X-Forwarded-Prefix /a; } 考虑到外层可能还有多个反向代理的情况\n采用逗号分隔，记住每一层代理的前缀，我觉得意义不大，应该只有最外层的有效，层层传递即可，没有对应的 header 则当前层就是最外层。\n配置可以这样改\n1 2 3 4 5 6 7 8 location /a/ { proxy_pass http://a.com/; # 如果没有 X-Forwarded-Prefix，则设置 if ($http_x_forwarded_prefix = \u0026#34;\u0026#34;) { proxy_set_header X-Forwarded-Prefix /a; } } 在业务层，可以通过以下方式获取\n1 2 3 4 5 func home(w http.Response, req *http.Request) { prefix := req.Header.Get(\u0026#34;X-Forwarded-Prefix\u0026#34;) path := prefix + \u0026#34;/home\u0026#34; // 响应结果 } 相对路径时可以这样拼接，当使用绝对路径时，要使用上 X-Forwarded-Proto 和 X-Forwarded-Host，前者用于标识请求协议 http/https，后者用于标识请求地址。\n最终的 nginx 设置如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 # 仅在不存在时才设置前缀 map $http_x_forwarded_prefix $prefix_for_test { \u0026#34;\u0026#34; /test; # 这里根据实际 prefix 动态修改 default $http_x_forwarded_prefix; } # 仅在不存在时才设置 X-Forwarded-Proto map $http_x_forwarded_proto $proto_for_test { \u0026#34;\u0026#34; $scheme; default $http_x_forwarded_proto; } # 仅在不存在时才设置 X-Forwarded-Host map $http_x_forwarded_host $host_for_test { \u0026#34;\u0026#34; $http_host; default $http_x_forwarded_host; } server{ # 略 location /a/ { proxy_pass http://a.com/; # 使用 map 变量设置头 proxy_set_header X-Forwarded-Prefix $prefix_for_test; proxy_set_header X-Forwarded-Proto $proto_for_test; proxy_set_header X-Forwarded-Host $host_for_test; # 原始 Host proxy_set_header Host $host; # 调用者 IP proxy_set_header X-Real-IP $remote_addr; # 多层代理下，最终会变成 逗号分隔的链条，记录所有经过的代理 IP，通过解析第一个能获取到原始客户端 IP # Client 1.1.1.1 → ProxyA → ProxyB → ProxyC → Nginx → 后端 # 1.1.1.1, ProxyA_IP, ProxyB_IP, ProxyC_IP, Nginx_IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } 上面的配置，假设 nginx 代理前缀是 /test，当访问 http://localhost:8002/test/login 时，业务层就可以通过 header 取到 http，localhsot:8002，/test 三个参数。\n不需要多层代理，更简单的 nginx 写法:\n1 2 3 4 5 6 7 8 9 10 location /a/ { proxy_pass http://a.com/; proxy_set_header X-Forwarded-Prefix /a; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-Host $http_host; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } 关于 X-Forwarded-Prefix 我在网上查询到微软，spring 都在使用这种方式，我倾向于沿用这种方案。\n与所有以 X- 开头的 header 一样， X-Forwarded-Prefix 并非“标准”，且不如 X-Forwarded-Proto 之类的 header 那么知名，但它被一些较大的产品/供应商使用。 微软的 YARP 文档中有一个具体示例，其中指出：\nX-Forwarded-Prefix - Sets the request\u0026rsquo;s original PathBase, if any, to the X-Forwarded-Prefix header.\nGolang 的 gin 框架默认的重定向操作也使用这种方式。在 gin 默认的行为里，请求 /foo/，但仅存在 /foo 的路由，则客户端被重定向到 /foo，GET 请求返回 HTTP状态码 301，其它请求方法返回 307 。\n以下代码取自gin@v1.10.1 gin.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func redirectTrailingSlash(c *Context) { req := c.Request p := req.URL.Path if prefix := path.Clean(c.Request.Header.Get(\u0026#34;X-Forwarded-Prefix\u0026#34;)); prefix != \u0026#34;.\u0026#34; { prefix = regSafePrefix.ReplaceAllString(prefix, \u0026#34;\u0026#34;) prefix = regRemoveRepeatedChar.ReplaceAllString(prefix, \u0026#34;/\u0026#34;) p = prefix + \u0026#34;/\u0026#34; + req.URL.Path } req.URL.Path = p + \u0026#34;/\u0026#34; if length := len(p); length \u0026gt; 1 \u0026amp;\u0026amp; p[length-1] == \u0026#39;/\u0026#39; { req.URL.Path = p[:length-1] } redirectRequest(c) } 参考 spring issues\nwhat-is-the-correct-value-for-x-forward-prefix-header\nusing-the-x-forwarded-prefix-header-to-prefix-your-hateoas-links\nX-Forwarded-Proto\n","date":"2025-09-26T00:00:00Z","permalink":"https://blog.golang.space/p/%E4%BD%BF%E7%94%A8-x-forwarded/","title":"使用 X-Forwarded"},{"content":"在 Go 语言开发中，MD5计算是一个常见的操作。再过去的使用中，我总会想方设法优化 MD5 的计算性能，然而，通过深入的性能测试和源码分析，发现：MD5计算本身并不需要性能优化，真正的优化点在于调用者的内存使用。\n性能测试结果对比 让我们先来看一组 benchmark 测试结果，测试对象是1MB的字符串数据：\n1 2 3 BenchmarkMD5/segment_md5-8 81\t42623578 ns/op\t1120 B/op\t4 allocs/op BenchmarkMD5/md5-8 84\t43422871 ns/op\t32 B/op\t1 allocs/op BenchmarkMD5/io_md5-8 85\t41750913 ns/op\t192 B/op\t4 allocs/op 从结果可以看出几个关键点：\n性能差异微乎其微：三种方式的执行时间都在4千万纳秒左右，差异不到5% 内存分配差异显著： md5(直接调用基础库): 仅32字节分配，1次分配 io_md5(使用 io.Copy): 92字节分配，4次分配 segment_md5(对字节数组分片): 1120字节分配，4次分配 测试的三种MD5实现方式 让我们看看这三种不同的实现方式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // 方式1：直接计算 func MD5(s []byte) string { b := md5.Sum(s) return hex.EncodeToString(b[:]) } // 方式2：分段读取 func SegmentMD5(r io.Reader) (string, error) { h := md5.New() buf := make([]byte, 1*1024) // 1KB缓冲区 for { n, err := r.Read(buf) if n \u0026gt; 0 { if _, err := h.Write(buf[:n]); err != nil { return \u0026#34;\u0026#34;, err } } if err != nil { if errors.Is(err, io.EOF) { break } return \u0026#34;\u0026#34;, err } } return hex.EncodeToString(h.Sum(nil)), nil } // 方式3：使用io.Copy func IOMD5(r io.Reader) (string, error) { h := md5.New() if _,err := io.Copy(h, r); err != nil { return \u0026#34;\u0026#34;,err } return hex.EncodeToString(h.Sum(nil)), nil } 为什么MD5计算不需要性能优化？ 底层算法的真正优化 Go标准库的MD5实现已经经过高度优化。让我们看看真正的Write函数实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func (d *digest) Write(p []byte) (nn int, err error) { // .... if len(p) \u0026gt;= BlockSize { n := len(p) \u0026amp;^ (BlockSize - 1) if haveAsm { for n \u0026gt; maxAsmSize { block(d, p[:maxAsmSize]) p = p[maxAsmSize:] n -= maxAsmSize } block(d, p[:n]) } else { blockGeneric(d, p[:n]) } p = p[n:] } if len(p) \u0026gt; 0 { d.nx = copy(d.x[:], p) } return } 优化点详解 大数据处理优化：\n1 2 3 4 5 for n \u0026gt; maxAsmSize { block(d, p[:maxAsmSize]) p = p[maxAsmSize:] n -= maxAsmSize } 对超过64KB（maxAsmSize）的数据进行分批处理，这是因为汇编实现是非抢占式的，不能被中断。\n汇编优化：\n1 2 3 4 5 if haveAsm { block(d, d.x[:]) // 优化的汇编版本 } else { blockGeneric(d, d.x[:]) // 通用Go版本 } 在支持的平台（如amd64）上，使用专门优化的汇编实现block，在其他平台使用通用版本blockGeneric。\n在amd64平台上，block函数使用汇编实现：\n1 2 3 4 5 6 7 TEXT ·block(SB), NOSPLIT, $8-32 MOVQ dig+0(FP), BP MOVQ p_base+8(FP), SI MOVQ p_len+16(FP), DX SHRQ $0x06, DX // 除以64，计算块数 SHLQ $0x06, DX // 乘以64，计算总字节数 // ... 优化的MD5算法实现 汇编版本通过直接操作CPU寄存器，避免了Go函数调用的开销，并且使用了SIMD指令等底层优化。\n上层优化的正确姿势 既然 MD5 计算本身不需要优化，我们应该将注意力放在上层调用上：\n选择合适的读取方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // 推荐：处理大文件时使用流式处理 func ProcessLargeFile(filename string) (string, error) { file, err := os.Open(filename) if err != nil { return \u0026#34;\u0026#34;, err } defer file.Close() h := md5.New() if _, err := io.Copy(h, file); err != nil { return \u0026#34;\u0026#34;, err } return hex.EncodeToString(h.Sum(nil)), nil } // 不推荐：一次性读取大文件 func ProcessLargeFileBad(filename string) (string, error) { data, err := os.ReadFile(filename) // 可能消耗大量内存 if err != nil { return \u0026#34;\u0026#34;, err } return MD5(data), nil } 在处理大文件时，流式处理相比一次性读取的优势在于不必一次性分配大量内存。\n总结 对于 MD5 计算，标准库的实现已经是最佳选择。我们要做的是在上层调用上做出明智的选择，避免不必要的内存开销。\n想要了解更多Go语言中的优化实践，欢迎访问 goddd web 框架模板，这里有更多关于Go语言开发的最佳实践。\n","date":"2025-08-24T00:00:00Z","permalink":"https://blog.golang.space/p/%E5%88%AB%E5%9C%A8%E5%8F%8D%E5%90%91%E4%BC%98%E5%8C%96-md5/","title":"别在反向优化 MD5"},{"content":"指数退避算法是一种网络错误处理策略，用于在客户端重试失败的请求时，增加每次重试之间的延迟时间。这种算法旨在避免连续的请求冲突，并提高网络资源的利用率。\n当客户端在网络请求失败后，不是立即重试，而是等待一段固定的时间间隔后再进行重试。这个时间间隔会随着重试次数的增加而呈指数级增长。例如，第一次重试可能等待1秒，第二次重试等待2秒，第三次重试等待4秒，依此类推。﻿﻿\n公式\n1 等待时间 = 初试时间 * (倍数 ^ 重试次数) + 随机抖动 Go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import \u0026#34;github.com/cenkalti/backoff/v4\u0026#34; // 截止 202507 已发布 v5 func Run(){ backOff := \u0026amp;backoff.ExponentialBackOff{ InitialInterval: backoff.DefaultInitialInterval, // 初始等待时间：500ms RandomizationFactor: backoff.DefaultRandomizationFactor, // 随机因子：0.5 Multiplier: backoff.DefaultMultiplier, // 倍数：1.5 MaxInterval: 3 * time.Second, // 最大间隔：3秒 MaxElapsedTime: time.Duration(0), // 最大总时间：无限制 Stop: backoff.Stop, // 停止信号 Clock: backoff.SystemClock, // 时钟 } operation := func() error { // 业务逻辑 return nil } if err := backoff.Retry(operation, backOff);err!=nil{ return err } fmt.Println(\u0026#34;连接成功\u0026#34;) } 有几个参数注意\nbackoff.Permanent(err) 返回不可 back 的错误\nbackoff.RetryAfter(seconds) 指定延迟多久后重试\n最终执行的结果大概是这样\n1 2 3 4 5 6 第1次重试: 500ms ± 250ms = 250ms ~ 750ms 第2次重试: 500ms × 1.5 = 750ms ± 375ms = 375ms ~ 1.125s 第3次重试: 750ms × 1.5 = 1.125s ± 562ms = 563ms ~ 1.687s 第4次重试: 1.125s × 1.5 = 1.687s ± 843ms = 844ms ~ 2.53s 第5次重试: 1.687s × 1.5 = 2.53s ± 1.265s = 1.265s ~ 3s 第6次重试: 达到最大间隔 3s，之后都是 3s ± 1.5s ","date":"2025-07-30T00:00:00Z","permalink":"https://blog.golang.space/p/%E6%8C%87%E6%95%B0%E9%80%80%E9%81%BF%E7%AE%97%E6%B3%95/","title":"指数退避算法"},{"content":"是什么? tap 和 tun 都是虚拟网络内核接口，在创建网络连接方面起着至关重要的作用，在 Linux Kernel 2.4.x 版本后实现。\nTap（也称为以太网分流器）是在 OSI 模型的第 2 层运行的虚拟网络接口。它可用于将虚拟机、容器或其他网络设备连接到物理网络。Tap 接口通常用于桥接网络。\nTun 是 Tunnel 的缩写，是在 OSI 模型的第 3 层运行的虚拟网络接口。与 tap 接口不同，tun 用于点对点网络连接，通常用于 VPN（虚拟专用网络）实施。\n在 Linux Kernel 2.6.x 之后的版本中， tun/tap 对应的字符设备文件分别为:\ntap: /dev/tap0 tun: /dev/net/tun 当应用程序打开设备文件时，驱动程序就会创建并注册相应的虚拟设备接口，一般以 tunX 或 tapX 命名。当应用程序关闭文件时，驱动也会自动删除 tunX 和 tapX 设备，还会删除已经建立起来的路由等信息。\n怎么用? tap\n1 2 3 4 5 6 # 创建 sudo ip tuntap add tap0 mode tap # 查看 sudo ip link set tap0 up # 分配 ip 地址 sudo ip addr add 192.168.0.1/24 dev tap0 tun\n1 2 3 4 5 6 # 创建 sudo ip tuntap add tun0 mode tun # 启动 sudo ip link set tun0 up # 分配 ip 地址 sudo ip addr add 10.0.0.1/24 dev tun0 用 Golang 调用 注意，这里使用 github.com/songgao/water 库\n通过文件字符设备读数据实验\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 package main import ( \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;github.com/fatih/color\u0026#34; \u0026#34;github.com/songgao/water\u0026#34; flag \u0026#34;github.com/spf13/pflag\u0026#34; ) var ( tunName = flag.String(\u0026#34;dev\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;local tun device name\u0026#34;) ) func main() { flag.Parse() // create tun/tap interface iface, err := water.New(water.Config{ DeviceType: water.TUN, }) if err != nil { color.Red(\u0026#34;create tun device failed,error: %v\u0026#34;, err) return } // 起一个协程去读取数据 go IfaceRead(iface) sig := make(chan os.Signal, 3) signal.Notify(sig, syscall.SIGINT, syscall.SIGABRT, syscall.SIGHUP) \u0026lt;-sig } /* IfaceRead 从 tun 设备读取数据 */ func IfaceRead(iface *water.Interface) { packet := make([]byte, 2048) for { // 不断从 tun 设备读取数据 n, err := iface.Read(packet) if err != nil { color.Red(\u0026#34;READ: read from tun failed\u0026#34;) break } // 在这里你可以对拿到的数据包做一些数据，比如加密。这里只对其进行简单的打印 color.Cyan(\u0026#34;get data from tun: %v\u0026#34;, packet[:n]) } } 通过文件字符设备写数据实验\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func IfaceReadAndWrite(iface *water.Interface) { packet := make([]byte, 2048) for { // 不断从 tun 设备读取数据 n, err := iface.Read(packet) if err != nil { color.Red(\u0026#34;READ: read from tun failed\u0026#34;) break } // 再把数据原封不动写入 tun 设备 _,err= iface.Write(packet[:n]) if err != nil { color.Red(\u0026#34;WRITE: write to tun failed\u0026#34;) break } } } Tap/Tun 的区别 tun、tap 作为虚拟网卡，除了不具备物理网卡的硬件功能外，它们和物理网卡的功能是一样的，此外tun、tap负责在内核网络协议栈和用户空间之间传输数据。\ntun 和 tap 都是虚拟网卡设备，但是:\ntun 是三层设备，其封装的外层是 IP 头 tap 是二层设备，其封装的外层是以太网帧(frame)头 tun 是 PPP 点对点设备，没有 MAC 地址 tap 是以太网设备，有 MAC 地址 tap 比 tun 更接近于物理网卡，可以认为，tap设备等价于去掉了硬件功能的物理网卡 参考 Tap vs Tun: A Comprehensive Guide\nTun Tap and Veth for Fun\nLinux虚拟网络设备之tun/tap\n","date":"2025-07-15T00:00:00Z","permalink":"https://blog.golang.space/p/tun-tap/","title":"TUN \u0026 TAP"},{"content":"在 linux 中，父进程创建了子进程，例如 exec.Command() 命令启动一个子命令。当父进程因为意外崩溃退出，没来得及控制子进程的生命周期，此时子进程成为孤儿进程继续运行。\n本文调研的内容是控制当父进程因为任何原因退出时，子进程必须立即结束。\n进程组 进程组确实是一组相关进程的集合，每个进程都有唯一的进程 ID（pid），同时属于一个进程组，进程组有唯一的进程组 ID（pgid）。通常，进程组由一个 “领头进程” 创建，其pid会成为该进程组的pgid。\n当 kill 命令的参数是 pgid 时，kill 会向进程组内的所有进程发送信号，进程可以捕获或忽略信号(SIGTERM)。\n进程组仅支持 linux，windows 是没有进程组的概念 主进程崩溃，子进程还是会成为孤儿进程运行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 import ( \u0026#34;fmt\u0026#34; \u0026#34;os/exec\u0026#34; \u0026#34;syscall\u0026#34; ) func main() { // 创建一个命令 cmd := exec.Command(\u0026#34;sleep\u0026#34;, \u0026#34;1000\u0026#34;) // 示例命令，让进程休眠 1000 秒 // 设置 SysProcAttr 以创建新进程组 cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{ Setpgid: true, // 创建新进程组 Pgid: 0, // 0 表示使用子进程的 PID 作为进程组 ID } // 启动命令 if err := cmd.Start(); err != nil { fmt.Printf(\u0026#34;启动进程失败: %v\\n\u0026#34;, err) return } // 获取进程组 ID（等于子进程的 PID） pgid := -cmd.Process.Pid // 在 Linux 中，负 PID 表示进程组 fmt.Printf(\u0026#34;子进程 PID: %d\\n\u0026#34;, cmd.Process.Pid) fmt.Printf(\u0026#34;进程组 ID: %d\\n\u0026#34;, pgid) // 向进程组发送信号（例如 SIGTERM） if err := syscall.Kill(pgid, syscall.SIGTERM); err != nil { fmt.Printf(\u0026#34;发送信号失败: %v\\n\u0026#34;, err) return } fmt.Println(\u0026#34;已向进程组发送终止信号\u0026#34;) // 等待命令执行完成 if err := cmd.Wait(); err != nil { fmt.Printf(\u0026#34;命令执行完成: %v\\n\u0026#34;, err) } } 尝试解决方案 异步监听标准输入 1 2 3 4 5 6 7 8 9 10 // interrupt 用于阻塞 interrupt := make(chan os.Signal, 1) signal.Notify(interrupt, syscall.SIGINT, syscall.SIGTERM) go func() { _, err := io.Copy(io.Discard, os.Stdin) // 持续读取标准输入（但丢弃数据） slog.Info(\u0026#34;main -\u0026gt; Copy\u0026#34;, \u0026#34;err\u0026#34;, err) // 记录读取结束时的错误（如 EOF） interrupt \u0026lt;- syscall.SIGTERM // 发送终止信号 }() \u0026lt;- interrupt 父进程通过 exec.Command() 启动子进程，子进程持续从标准输入读取数据，并直接丢弃。如果输入流关闭(终端关闭，管道断开等)， io.Copy 会立即结束，并发送终止信号。\n通过监听标准输入的关闭事件，触发程序的优雅退出机制。\n但如果是以服务方式启动，子进程会立即退出，服务管理器通过会将标准输入设置为空设备 (/dev/null) 或直接关闭，导致子进程的 os.Stdin 在启动时已经处于 EOF 状态。\n1 2 3 4 5 6 7 8 // 判断是否在服务模式下运行（stdin 指向 /dev/null 或已关闭） func isServiceMode() bool { info, err := os.Stdin.Stat() if err != nil { return true // 无法获取状态，假设为服务模式 } return info.Mode()\u0026amp;os.ModeCharDevice == 0 // 非终端设备（如 /dev/null） } 既然可以监听标准输入的方式判断父进程是否存活，那么通过进程通信管道呢?\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 package main import ( \u0026#34;bytes\u0026#34; \u0026#34;log/slog\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/exec\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;time\u0026#34; ) func main() { // 创建用于通信的管道 r, w, err := os.Pipe() if err != nil { slog.Error(\u0026#34;创建管道失败\u0026#34;, \u0026#34;err\u0026#34;, err) return } defer w.Close() // 启动子进程，并将管道写入端传递给子进程 cmd := exec.Command(\u0026#34;./child\u0026#34;) // 假设子进程程序名为 child cmd.Stdin = r // 子进程从管道读取数据 cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr // 启动子进程 if err := cmd.Start(); err != nil { slog.Error(\u0026#34;启动子进程失败\u0026#34;, \u0026#34;err\u0026#34;, err) return } slog.Info(\u0026#34;子进程已启动\u0026#34;, \u0026#34;pid\u0026#34;, cmd.Process.Pid) // 父进程定期向管道写入数据（心跳） go func() { ticker := time.NewTicker(time.Second) defer ticker.Stop() for range ticker.C { _, err := w.Write([]byte(\u0026#34;heartbeat\\n\u0026#34;)) if err != nil { slog.Warn(\u0026#34;写入管道失败，子进程可能已退出\u0026#34;, \u0026#34;err\u0026#34;, err) break } } }() // 处理父进程退出信号 sigCh := make(chan os.Signal, 1) signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-sigCh slog.Info(\u0026#34;父进程正在退出...\u0026#34;) w.Close() // 关闭管道，通知子进程 // 等待子进程退出 if err := cmd.Wait(); err != nil { slog.Error(\u0026#34;等待子进程失败\u0026#34;, \u0026#34;err\u0026#34;, err) } slog.Info(\u0026#34;父进程已退出\u0026#34;) } 子进程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 package main import ( \u0026#34;io\u0026#34; \u0026#34;log/slog\u0026#34; \u0026#34;os\u0026#34; \u0026#34;os/signal\u0026#34; \u0026#34;syscall\u0026#34; \u0026#34;time\u0026#34; ) func main() { interrupt := make(chan os.Signal, 1) signal.Notify(interrupt, syscall.SIGTERM, syscall.SIGINT) // 获取父进程 PID parentPID := os.Getppid() slog.Info(\u0026#34;父进程 PID\u0026#34;, \u0026#34;pid\u0026#34;, parentPID) // 监听管道关闭事件（父进程崩溃或正常退出） go func() { // 从 stdin 读取数据（实际连接到父进程创建的管道） _, err := io.Copy(io.Discard, os.Stdin) if err != nil { slog.Info(\u0026#34;管道关闭\u0026#34;, \u0026#34;err\u0026#34;, err) } else { slog.Info(\u0026#34;管道正常关闭\u0026#34;) } interrupt \u0026lt;- syscall.SIGTERM // 触发优雅退出 }() // 定期检查父进程是否存活（双重保险） go func() { ticker := time.NewTicker(2 * time.Second) defer ticker.Stop() for range ticker.C { // 尝试向父进程发送 0 信号（仅检查进程是否存在） err := syscall.Kill(parentPID, 0) if err != nil { slog.Info(\u0026#34;父进程已退出\u0026#34;, \u0026#34;err\u0026#34;, err) interrupt \u0026lt;- syscall.SIGTERM // 触发优雅退出 break } } }() slog.Info(\u0026#34;子进程运行中...\u0026#34;) \u0026lt;-interrupt // 阻塞直到收到退出信号 slog.Info(\u0026#34;子进程优雅退出\u0026#34;) } 总结 主要有两个方案\n子进程定期检测父进程是否存活，可以监听固定端口也好，pid 状态也好，网络通信也好。(子进程跟随父进程生命周期) 父进程启动子进程时，记录子进程的 id，下次启动时，根据需要再停止子进程或继续复用子进程。(允许子进程存活，并在下次启动时接管) ","date":"2025-07-14T00:00:00Z","permalink":"https://blog.golang.space/p/%E5%AD%90%E8%BF%9B%E7%A8%8B%E9%9A%8F%E7%9D%80%E7%88%B6%E8%BF%9B%E7%A8%8B%E5%85%B3%E9%97%AD%E8%B0%83%E7%A0%94/","title":"子进程随着父进程关闭调研"},{"content":"我费了好大劲才弄清楚，为什么这样一个看似无关紧要的变化会导致如此巨大的性能差异。最终，最有帮助的是 Go 工具链中一个很棒的工具：使用 -base 选项可视化两个性能配置文件之间的差异， pprof 。\n使用 pprof 获取两个配置文件的差异 Go 语言自带一个强大的性能分析工具 pprof 。与其他一些语言不同，您必须在代码中显式启用它才能获取性能分析结果；您无法事后或使用命令行参数启用它。这很简单，但您必须编写代码才能实现。在我们的例子中，我将其直接放在要分析的测试方法中。\n1 2 3 4 5 6 7 8 func TestRegressionTests(t *testing.T) { // We\u0026#39;ll only run this on GitHub Actions, so set this environment variable to run locally if _, ok := os.LookupEnv(\u0026#34;REGRESSION_TESTING\u0026#34;); !ok { // t.Skip() } p := profile.Start(profile.CPUProfile) defer p.Stop() 此代码片段的最后两行启动 CPU 性能分析，并在方法完成时停止。它使用了 github.com/pkg/profile 包，该包为内置性能分析器库提供了一个更符合人体工程学的包装器。运行执行此操作的代码，您将看到如下输出：\n1 2025/06/20 14:10:40.548730 profile: cpu profiling disabled, C:\\Users\\ZACHMU~1\\AppData\\Local\\Temp\\profile1113350212\\cpu.pprof 这是运行生成的配置文件的位置，您应该记下它或将其复制到具有更容易记住的名称的其他位置。\n为了测试，我想看看 main 分支和当前分支之间的性能变化，所以我在每个分支上都启用了性能分析功能，并进行了测试。现在，我可以使用 -base 参数和 pprof 来比较它们。\n检查性能差异 获得每个分支的概况后，现在我只需要对它们进行比较。\n1 go tool pprof -http=:8090 -base main.pprof branch.pprof -base 标志告诉 pprof 在报告性能数据时，从另一个配置文件中“减去”指定的配置文件。在本例中，我想查看 branch.pprof 中发生的情况，而不是 main.pprof 运行太慢了。我还一直使用 -http 参数，它会运行一个交互式 Web 服务器，而不是命令行界面。我发现在分析性能配置文件时，使用这个参数要方便得多。\n当我运行该命令时，我的 Web 浏览器会启动到默认显示界面，即一张按函数大致拓扑排序的累计 CPU 采样图，这样你就可以看到哪些函数调用了哪些函数。与普通的配置文件分析不同，这里显示的数字严格来说是两个配置文件之间的差异，而不是它们的绝对运行时间。以下是我在 Web 视图中看到的内容：\nDatabase.tableInsensitive 函数用于获取查询引擎使用的表对象。不知何故，尽管我没有直接修改它，但我的修改却使这个函数变得非常非常慢。有了这个线索，我找到了性能问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // from tableInsensitive() ... tableNames, err := db.getAllTableNames(ctx, root, true) if err != nil { return doltdb.TableName{}, nil, false, err } if root.TableListHash() != 0 { tableMap := make(map[string]string) for _, table := range tableNames { tableMap[strings.ToLower(table)] = table } dbState.SessionCache().CacheTableNameMap(root.TableListHash(), tableMap) } tableName, ok = sql.GetTableNameInsensitive(tableName, tableNames) if !ok { return doltdb.TableName{}, nil, false, nil } 如果所有表名尚未缓存在会话中，则代码片段的第一行会从数据库中加载它们。这是必要的，因为我们的表名存储时区分大小写，而 SQL 不区分大小写。因此，在从数据库加载表的过程中，我们需要将查询中请求的不区分大小写的名称更正为区分大小写的名称，以便在存储和 I/O 层使用。但是，对 db.getAllTableNames() 的调用包含一个最终参数： includeGeneratedSystemTables 。它被硬编码为 true，这意味着它总是调用新的、更昂贵的方法来获取生成的系统表的列表，其中包括潜在的磁盘访问以获取数据库模式集，然后对它们进行大量的迭代。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 schemas, err := root.GetDatabaseSchemas(ctx) if err != nil { return nil, err } // For dolt there are no stored schemas, search the default (empty string) schema if len(schemas) == 0 { schemas = append(schemas, schema.DatabaseSchema{Name: doltdb.DefaultSchemaName}) } for _, schema := range schemas { tableNames, err := root.GetTableNames(ctx, schema.Name) if err != nil { return nil, err } for _, pre := range doltdb.GeneratedSystemTablePrefixes { for _, tableName := range tableNames { s.Add(doltdb.TableName{ Name: pre + tableName, Schema: schema.Name, }) } } // For doltgres, we also support the legacy dolt_ table names, addressable in any user schema if UseSearchPath \u0026amp;\u0026amp; schema.Name != \u0026#34;pg_catalog\u0026#34; \u0026amp;\u0026amp; schema.Name != doltdb.DoltNamespace { for _, name := range doltdb.DoltGeneratedTableNames { s.Add(doltdb.TableName{ Name: name, Schema: schema.Name, }) } } } 事实证明，硬编码的 true 完全是错误的——该方法根本不需要考虑系统生成的表名。但在我让生成这些名称的过程变得更加昂贵之前，这是一个相对无害的错误，并且多年来一直存在于代码中而未被注意到。将此值更改为 false 以消除不必要的工作，修复了性能回归问题，并且还稍微加快了 Dolt 的基准测试速度。\nread_tests 读取测试 from_latency to_latency 延迟 percent_change 百分比变化 covering_index_scan 覆盖索引扫描 0.68 0.67 -1.4 groupby_scan 19.65 19.29 -1.83 index_join 索引连接 2.57 2.52 -1.95 index_join_scan 索引连接扫描 1.44 1.44 0.0 index_scan 索引扫描 30.26 29.72 -1.78 oltp_point_select 0.29 0.28 -3.45 oltp_read_only 5.37 5.28 -1.68 select_random_points 选择随机点 0.61 0.6 -1.64 select_random_ranges 选择随机范围 0.64 0.62 -3.13 table_scan 表扫描 32.53 31.94 -1.81 types_table_scan 类型表扫描 127.81 125.52 -1.79 如果没有 -base 标志为我指明正确的方向，我不确定我是否能找出这种低效率的根源。\n参考 本文翻译于 Finding performance problems by diffing two Go profiles\n","date":"2025-06-30T00:00:00Z","permalink":"https://blog.golang.space/p/%E6%AF%94%E8%BE%83%E4%B8%A4%E4%B8%AA-go-pprof-%E6%96%87%E4%BB%B6%E6%9D%A5%E6%9F%A5%E6%89%BE%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/","title":"比较两个 go pprof 文件来查找性能问题"},{"content":"Go 1.25 中 json 包的 v2 版本是一个重大更新，它有很多突破性的变化。v2 包添加了新功能，修复了 API 问题和行为缺陷，并提高了性能。让我们来看看发生了什么变化！\nMarshal 和 Unmarshal 的基本用例保持不变。此代码适用于 v1 和 v2：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 type Person struct { Name string Age int } alice := Person{Name: \u0026#34;Alice\u0026#34;, Age: 25} // Marshal Alice. b, err := json.Marshal(alice) fmt.Println(string(b), err) // Unmarshal Alice. err = json.Unmarshal(b, \u0026amp;alice) fmt.Println(alice, err) 但其余的则大不相同。\nMarshalWrite and UnmarshalRead 在 v1 中，是这样的\n1 2 3 4 5 6 7 8 9 10 11 12 13 // Marshal Alice. alice := Person{Name: \u0026#34;Alice\u0026#34;, Age: 25} out := new(strings.Builder) // io.Writer enc := json.NewEncoder(out) enc.Encode(alice) fmt.Println(out.String()) // Unmarshal Bob. in := strings.NewReader(`{\u0026#34;Name\u0026#34;:\u0026#34;Bob\u0026#34;,\u0026#34;Age\u0026#34;:30}`) // io.Reader dec := json.NewDecoder(in) var bob Person dec.Decode(\u0026amp;bob) fmt.Println(bob) 在 v2 中，可以直接使用 MarshalWrite 和 UnmarshalRead，无需任何中介：\n1 2 3 4 5 6 7 8 9 10 11 // Marshal Alice. alice := Person{Name: \u0026#34;Alice\u0026#34;, Age: 25} out := new(strings.Builder) json.MarshalWrite(out, alice) fmt.Println(out.String()) // Unmarshal Bob. in := strings.NewReader(`{\u0026#34;Name\u0026#34;:\u0026#34;Bob\u0026#34;,\u0026#34;Age\u0026#34;:30}`) var bob Person json.UnmarshalRead(in, \u0026amp;bob) fmt.Println(bob) 不过，它们不能互换：\n与旧的 Encoder.Encode 不同，MarshalWrite 不添加换行符。 UnmarshalRead 会读取读取器中的所有内容，直到它到达 io。EOF，而旧的 Decoder.Decode 仅读取下一个 JSON 值。 MarshalEncode and UnmarshalDecode Encoder 和 Decoder 类型已移至新的 jsontext 包中，它们的接口已发生重大变化（以支持低级流式编码/解码作）。\n你可以将它们与 json 函数一起使用来读取和写入 JSON 流，类似于之前 Encode 和 Decode 的工作方式：\nv1 Encoder.Encode → v2 json.MarshalEncode + jsontext.Encoder. v1 Decoder.Decode → v2 json.UnmarshalDecode + jsontext.Decoder. 流式处理编码器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 people := []Person{ {Name: \u0026#34;Alice\u0026#34;, Age: 25}, {Name: \u0026#34;Bob\u0026#34;, Age: 30}, {Name: \u0026#34;Cindy\u0026#34;, Age: 15}, } out := new(strings.Builder) enc := jsontext.NewEncoder(out) for _, p := range people { json.MarshalEncode(enc, p) } fmt.Print(out.String()) 流式解码器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 in := strings.NewReader(` {\u0026#34;Name\u0026#34;:\u0026#34;Alice\u0026#34;,\u0026#34;Age\u0026#34;:25} {\u0026#34;Name\u0026#34;:\u0026#34;Bob\u0026#34;,\u0026#34;Age\u0026#34;:30} {\u0026#34;Name\u0026#34;:\u0026#34;Cindy\u0026#34;,\u0026#34;Age\u0026#34;:15} `) dec := jsontext.NewDecoder(in) for { var p Person // Decodes one Person object per call. err := json.UnmarshalDecode(dec, \u0026amp;p) if err == io.EOF { break } fmt.Println(p) } 与 UnmarshalRead 不同，UnmarshalDecode 以完全流式处理的方式工作，每次调用一次解码一个值，而不是读取所有内容直到 io.EOF.\n选项 选项使用特定功能配置编组和解组功能：\nFormatNilMapAsNull 和 FormatNilSliceAsNull 定义如何编码 nil 映射和切片。 MatchCaseInsensitiveNames 允许匹配 Name ↔ name 等。 Multiline 将 JSON 对象扩展为多行。 OmitZeroStructFields 从输出中省略具有零值的字段。 SpaceAfterColon 和 SpaceAfterComma 在每个 : 或 , 后添加一个空格 StringifyNumbers 将数字类型表示为字符串。 WithIndent 和 WithIndentPrefix 缩进嵌套属性（请注意， MarshalIndent 函数已被删除）。 每个编组或解组函数可以采用任意数量的选项：\n1 2 3 4 5 6 7 8 alice := Person{Name: \u0026#34;Alice\u0026#34;, Age: 25} b, _ := json.Marshal( alice, json.OmitZeroStructFields(true), json.StringifyNumbers(true), jsontext.WithIndent(\u0026#34; \u0026#34;), ) fmt.Println(string(b)) 还可以将选项与 JoinOptions 组合：\n1 2 3 4 5 6 7 alice := Person{Name: \u0026#34;Alice\u0026#34;, Age: 25} opts := json.JoinOptions( jsontext.SpaceAfterColon(true), jsontext.SpaceAfterComma(true), ) b, _ := json.Marshal(alice, opts) fmt.Println(string(b)) 请参阅文档中的完整选项列表：一些位于 json 包中，其他位于 jsontext 包中。\nTags v2 支持 v1 中定义的字段标签：\nomitzero 和 omitempty 省略空值，omitempty 是 go1.24 之前用于省略 nil 对象的，omitzero 是 go1.24 加入用于省略零值对象。 string 将数字类型表示为字符串。 - 忽略字段。 并添加了一些：\ncase:ignore 或 case:strict 指定如何处理大小写差异。 format:template 根据模板格式化字段值。 inline 通过将嵌套对象的字段提升到父级来展平输出。 unknown 为未知字段提供了“全部捕获”。 下面是一个演示 inline 和 format 示例：\n匿名属性一样有 inline 的效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 type Person struct { Name string `json:\u0026#34;name\u0026#34;` // Format date as yyyy-mm-dd. BirthDate time.Time `json:\u0026#34;birth_date,format:DateOnly\u0026#34;` // Inline address fields into the Person object. Address `json:\u0026#34;,inline\u0026#34;` } type Address struct { Street string `json:\u0026#34;street\u0026#34;` City string `json:\u0026#34;city\u0026#34;` } func main() { alice := Person{ Name: \u0026#34;Alice\u0026#34;, BirthDate: time.Date(2001, 7, 15, 12, 35, 43, 0, time.UTC), Address: Address{ Street: \u0026#34;123 Main St\u0026#34;, City: \u0026#34;Wonderland\u0026#34;, }, } b, _ := json.Marshal(alice, jsontext.WithIndent(\u0026#34; \u0026#34;)) fmt.Println(string(b)) } //{ // \u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, // \u0026#34;birth_date\u0026#34;: \u0026#34;2001-07-15\u0026#34;, // \u0026#34;street\u0026#34;: \u0026#34;123 Main St\u0026#34;, // \u0026#34;city\u0026#34;: \u0026#34;Wonderland\u0026#34; //} unknown 用于将结构体中未定义的内容，在反序列化时收束到此，搭配 map[string]any 使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 type Person struct { Name string `json:\u0026#34;name\u0026#34;` // Collect all unknown Person fields // into the Data field. Data map[string]any `json:\u0026#34;,unknown\u0026#34;` } func main() { src := `{ \u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;hobby\u0026#34;: \u0026#34;adventure\u0026#34;, \u0026#34;friends\u0026#34;: [ {\u0026#34;name\u0026#34;: \u0026#34;Bob\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;Cindy\u0026#34;} ] }` var alice Person json.Unmarshal([]byte(src), \u0026amp;alice) fmt.Println(alice) } // {Alice map[friends:[map[name:Bob] map[name:Cindy]] hobby:adventure]} 自定义marshaling 使用 Marshaler 和 Unmarshaler 接口进行自定义封送处理的基本用例保持不变。以下代码在 v1 和 v2 版本中均有效：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // A custom boolean type represented // as \u0026#34;✓\u0026#34; for true and \u0026#34;✗\u0026#34; for false. type Success bool func (s Success) MarshalJSON() ([]byte, error) { if s { return []byte(`\u0026#34;✓\u0026#34;`), nil } return []byte(`\u0026#34;✗\u0026#34;`), nil } func (s *Success) UnmarshalJSON(data []byte) error { // Data validation omitted for brevity. *s = string(data) == `\u0026#34;✓\u0026#34;` return nil } func main() { // Marshaling. val := Success(true) data, err := json.Marshal(val) fmt.Println(string(data), err) // Unmarshaling. src := []byte(`\u0026#34;✓\u0026#34;`) err = json.Unmarshal(src, \u0026amp;val) fmt.Println(val, err) } 但是，Go 标准库文档建议使用新的 MarshalerTo 和 UnmarshalerFrom 接口（它们以纯流方式工作，速度更快）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // A custom boolean type represented // as \u0026#34;✓\u0026#34; for true and \u0026#34;✗\u0026#34; for false. type Success bool func (s Success) MarshalJSONTo(enc *jsontext.Encoder) error { if s { return enc.WriteToken(jsontext.String(\u0026#34;✓\u0026#34;)) } return enc.WriteToken(jsontext.String(\u0026#34;✗\u0026#34;)) } func (s *Success) UnmarshalJSONFrom(dec *jsontext.Decoder) error { // Data validation omitted for brevity. tok, err := dec.ReadToken() *s = tok.String() == `\u0026#34;✓\u0026#34;` return err } func main() { // Marshaling. val := Success(true) data, err := json.Marshal(val) fmt.Println(string(data), err) // Unmarshaling. src := []byte(`\u0026#34;✓\u0026#34;`) err = json.Unmarshal(src, \u0026amp;val) fmt.Println(val, err) } 更棒的是，不再局限于只使用一种特定类型的 marshaling 方式。现在，您可以随时通过通用的 MarshalFunc 和 UnmarshalFunc 函数使用自定义的 marshalers and unmarshalers。\n1 2 func MarshalFunc[T any](fn func(T) ([]byte, error)) *Marshalers func UnmarshalFunc[T any](fn func([]byte, T) error) *Unmarshalers 例如，可以将 bool 值编组为 ✓ 或 ✗ 而无需创建自定义类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // Custom marshaler for bool values. boolMarshaler := json.MarshalFunc( func(val bool) ([]byte, error) { if val { return []byte(`\u0026#34;✓\u0026#34;`), nil } return []byte(`\u0026#34;✗\u0026#34;`), nil }, ) // Pass the custom marshaler to Marshal // using the WithMarshalers option. val := true data, err := json.Marshal(val, json.WithMarshalers(boolMarshaler)) fmt.Println(string(data), err) 并将 ✓ 或 ✗ 解组为 bool ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Custom unmarshaler for bool values. boolUnmarshaler := json.UnmarshalFunc( func(data []byte, val *bool) error { *val = string(data) == `\u0026#34;✓\u0026#34;` return nil }, ) // Pass the custom unmarshaler to Unmarshal // using the WithUnmarshalers option. src := []byte(`\u0026#34;✓\u0026#34;`) var val bool err := json.Unmarshal(src, \u0026amp;val, json.WithUnmarshalers(boolUnmarshaler)) fmt.Println(val, err) 还有 MarshalToFunc 和 UnmarshalFromFunc 函数用于创建自定义编组器。它们与 MarshalFunc 和 UnmarshalFunc 类似，但它们与 jsontext.Encoder 和 jsontext.Decoder 一起使用，而不是字节切片。\n1 2 func MarshalToFunc[T any](fn func(*jsontext.Encoder, T) error) *Marshalers func UnmarshalFromFunc[T any](fn func(*jsontext.Decoder, T) error) *Unmarshalers 可以使用 JoinMarshalers 组合 marshalers（并使用 JoinUnmarshalers 组合unmarshalers）。例如，以下示例展示了如何将布尔值（ true / false ）和“类布尔”字符串（ on / off ）封送为 ✓ 或 ✗ ，同时保留所有其他值的默认封送方式。\n首先，我们为布尔值定义一个自定义 marshaler：\n1 2 3 4 5 6 7 8 9 // Marshals boolean values to ✓ or ✗.. boolMarshaler := json.MarshalToFunc( func(enc *jsontext.Encoder, val bool) error { if val { return enc.WriteToken(jsontext.String(\u0026#34;✓\u0026#34;)) } return enc.WriteToken(jsontext.String(\u0026#34;✗\u0026#34;)) }, ) 然后我们为布尔字符串定义一个自定义 marshaler：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // Marshals boolean-like strings to ✓ or ✗. strMarshaler := json.MarshalToFunc( func(enc *jsontext.Encoder, val string) error { if val == \u0026#34;on\u0026#34; || val == \u0026#34;true\u0026#34; { return enc.WriteToken(jsontext.String(\u0026#34;✓\u0026#34;)) } if val == \u0026#34;off\u0026#34; || val == \u0026#34;false\u0026#34; { return enc.WriteToken(jsontext.String(\u0026#34;✗\u0026#34;)) } // SkipFunc is a special type of error that tells Go to skip // the current marshaler and move on to the next one. In our case, // the next one will be the default marshaler for strings. return json.SkipFunc }, ) 最后，我们将编组器与 JoinMarshalers 结合起来，并使用 WithMarshalers 选项将它们传递给编组函数：\n1 2 3 4 5 6 7 8 // Combine custom marshalers with JoinMarshalers. marshalers := json.JoinMarshalers(boolMarshaler, strMarshaler) // Marshal some values. vals := []any{true, \u0026#34;off\u0026#34;, \u0026#34;hello\u0026#34;} data, err := json.Marshal(vals, json.WithMarshalers(marshalers)) fmt.Println(string(data), err) // [\u0026#34;✓\u0026#34;,\u0026#34;✗\u0026#34;,\u0026#34;hello\u0026#34;] \u0026lt;nil\u0026gt; 这不是很酷吗？\n默认行为 v2 不仅改变了包接口，还改变了默认的编组/解组行为。\n一些值得注意的编组差异包括：\nv1 将 nil 切片封送为 null ，v2 则封送为 [] 。您可以使用FormatNilSliceAsNull 选项进行更改。 v1 将 nil map 封送为 null ，v2 则将其封送为 {} 。您可以使用 FormatNilMapAsNull 选项进行更改。 v1 将字节数组编组为数字数组，v2 则将其编组为 base64 编码的字符串。您可以使用 format:array 和 format:base64 标签进行更改。 v1 允许字符串中包含无效的 UTF-8 字符，而 v2 则不允许。您可以使用 AllowInvalidUTF8 选项进行更改。 以下是默认 v2 行为的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 type Person struct { Name string Hobbies []string Skills map[string]int Secret [5]byte } func main() { alice := Person{ Name: \u0026#34;Alice\u0026#34;, Secret: [5]byte{1, 2, 3, 4, 5}, } b, _ := json.Marshal(alice, jsontext.Multiline(true)) fmt.Println(string(b)) } //{ // \u0026#34;Name\u0026#34;: \u0026#34;Alice\u0026#34;, // \u0026#34;Hobbies\u0026#34;: [], // \u0026#34;Skills\u0026#34;: {}, // \u0026#34;Secret\u0026#34;: \u0026#34;AQIDBAU=\u0026#34; //} 以下是强制执行 v1 行为的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 type Person struct { Name string Hobbies []string Skills map[string]int Secret [5]byte `json:\u0026#34;,format:array\u0026#34;` } func main() { alice := Person{ Name: \u0026#34;Alice\u0026#34;, Secret: [5]byte{1, 2, 3, 4, 5}, } b, _ := json.Marshal( alice, json.FormatNilMapAsNull(true), json.FormatNilSliceAsNull(true), jsontext.Multiline(true), ) fmt.Println(string(b)) } // { // \u0026#34;Name\u0026#34;: \u0026#34;Alice\u0026#34;, // \u0026#34;Hobbies\u0026#34;: null, // \u0026#34;Skills\u0026#34;: null, // \u0026#34;Secret\u0026#34;: [ // 1, // 2, // 3, // 4, // 5 // ] // } 一些值得注意的解组差异包括：\nv1 版本使用不区分大小写的字段名称匹配，v2 版本则使用精确匹配，区分大小写。您可以使用 MatchCaseInsensitiveNames 选项或 case 标签进行更改。 v1 版本允许对象中存在重复字段，而 v2 版本则不允许。您可以使用 AllowDuplicateNames 选项进行更改。 以下是默认 v2 行为（区分大小写）的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 type Person struct { FirstName string LastName string } func main() { src := []byte(`{\u0026#34;firstname\u0026#34;:\u0026#34;Alice\u0026#34;,\u0026#34;lastname\u0026#34;:\u0026#34;Zakas\u0026#34;}`) var alice Person json.Unmarshal(src, \u0026amp;alice) fmt.Printf(\u0026#34;%+v\\n\u0026#34;, alice) } // {FirstName: LastName:} 以下是强制执行 v1 行为的方法（不区分大小写）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type Person struct { FirstName string LastName string } func main() { src := []byte(`{\u0026#34;firstname\u0026#34;:\u0026#34;Alice\u0026#34;,\u0026#34;lastname\u0026#34;:\u0026#34;Zakas\u0026#34;}`) var alice Person json.Unmarshal( src, \u0026amp;alice, json.MatchCaseInsensitiveNames(true), ) fmt.Printf(\u0026#34;%+v\\n\u0026#34;, alice) } // {FirstName:Alice LastName:Zakas} 请参阅文档中的行为变化的完整列表。\n表现 编组 (Marshaling) 时，v2 的性能与 v1 大致相同。对于某些数据集，它的速度更快，但对于其他数据集，它的速度较慢。然而，解组 (Unmarshaling) 的性能要好得多 ：v2 比 v1 快 2.7 倍到 10.2 倍。\n此外，从常规的 MarshalJSON 和 UnmarshalJSON 切换到其流式替代方案—— MarshalJSONTo 和 UnmarshalJSONFrom ，可以获得显著的性能提升。据 Go 团队称，它允许将某些 O(n²) 的运行时场景转换为 O(n)。例如，在 Kubernetes OpenAPI 规范中，从 UnmarshalJSON 切换到 UnmarshalJSONFrom 使其速度提高了约 40 倍 。\n有关基准测试的详细信息，请参阅 jsonbench repo。\n最后的想法 呼！这可真是让人费解。v2 包比 v1 功能更多、更灵活，但也复杂得多，尤其是拆分成了 json/v2 和 jsontext 两个子包之后。\n需要记住以下几点：\n从 Go 1.25 开始， json/v2 包处于实验阶段，可以通过在构建时设置 GOEXPERIMENT=jsonv2 来启用。该包的 API 可能会在未来的版本中发生变化。 开启 GOEXPERIMENT=jsonv2 会使 v1 json 包使用新的 JSON 实现，速度更快，并支持一些选项，以便更好地兼容旧的编组和解组行为。 最后，这里有一些链接可以了解有关 v2 设计和实现的更多信息：\nproposal p.1 • proposal p.2 • json/v2 • jsontext\n参考 本文翻译于 JSON evolution in Go: from v1 to v2\n","date":"2025-06-29T00:00:00Z","permalink":"https://blog.golang.space/p/go-%E4%B8%AD%E7%9A%84-json-%E6%BC%94%E5%8F%98-%E4%BB%8E-v1-%E5%88%B0-v2/","title":"Go 中的 JSON 演变, 从 v1 到 v2"},{"content":"Golang clear 很消耗性能吗? clear 内置函数在 Go 1.21 版本中新增。\n此函数用于清除 map 和 slice。对于 map 会删除所有键值对，从而生成一个空 map，对于 slice，会将长度以内全部设置为对应元素类型的零值。\n那么 clear 消耗性能吗?\n让我看图写文\nclear(make([]byte,256*1024)) 时，runtime 调用了 memclrNoHeapPointers\nloop_zva 是这段 ARM64 汇编代码中的一个关键循环，用于高效清零大块内存，利用了 ARM64 的 DC ZVA（Data Cache Zero by VA） 指令。它的作用是通过硬件加速的方式，快速清零缓存行（cache line）大小的内存块，比普通的 STP（存储零值）指令更快。\n明明硬件加速删除，怎么还需要 1.24s 呢? DC ZVA 并不是简单的“瞬间清零内存”，它的实际行为包括：\n缓存行操作： DC ZVA 会清零整个缓存行（通常 64 字节），但需要先加载缓存行到 CPU 缓存（如果未加载），再清零并写回内存。 如果目标内存尚未缓存，可能需要从主存加载，这会增加延迟。 内存访问模式的影响： 如果内存区域是非连续访问（例如跨多个缓存行），或者内存带宽受限，DC ZVA 的效率会下降。 对于大块内存，DC ZVA 可能需要多次操作，每次操作都有固定开销。 不用 clear 呢? 1 2 3 for i := range buf { buf[i] = 0 } 更慢了耶!! range 读取的副本，需要 copy 并加载到 cpu。\n总结 在性能上要更高要求的地方，对于大内存块，不执行清零操作，取指定长度的子切片直接覆盖使用即可。\n以上内容来源于开源项目 https://github.com/ixugo/bytepool\n这是带引用的计数内存池，基于 sync.Pool 实现，适用于多协程共享同一块内存，不知道何时放回内存池场景。(内存复制到各个协程会更安全，但共享会更高性能，建议选择前者，现在服务器基本内存管饱)\n自动引用计数 分层内存池 零拷贝设计 并发安全 内置统计数据 高性能 ","date":"2025-05-29T00:00:00Z","permalink":"https://blog.golang.space/p/golang-clear-%E5%BE%88%E6%B6%88%E8%80%97%E6%80%A7%E8%83%BD%E5%90%97/","title":"Golang clear 很消耗性能吗?"},{"content":"默认情况下，Go 在传递值时会复制它们。但有时这可能是不希望的。例如，如果你不小心复制了一个互斥锁，并且多个 goroutine 在不同的锁实例上工作，它们将无法正确同步。在这种情况下，传递锁的指针可以避免复制并按预期工作。\n以这个例子来说：通过值传递 sync.WaitGroup 会以微妙的方式破坏程序：\n1 2 3 4 5 6 7 8 func f(wg sync.WaitGroup) { // ... do something with the waitgroup } func main() { var wg sync.WaitGroup f(wg) // oops! wg is getting copied here! } sync.WaitGroup 让你可以等待多个 goroutine 完成一些工作。在幕后，它是一个包含 Add 、 Done 和 Wait 等方法的结构体，用于同步并发运行的 goroutine。\n这段代码可以编译，但由于我们在 f 函数中复制了锁而不是引用它，因此会导致错误行为。\n幸运的是， go vet 会捕获这个问题。如果你在代码上运行 vet，你会得到一个类似于这样的警告：\n1 2 f passes lock by value: sync.WaitGroup contains sync.noCopy call of f copies lock value: sync.WaitGroup contains sync.noCopy 这意味着当我们应该传递一个引用时，我们却通过值传递了 wg 。这是修复方法：\n1 2 3 4 5 6 7 8 func f(wg *sync.WaitGroup) { // pass by reference // ... do something with the waitgroup } func main() { var wg sync.WaitGroup f(\u0026amp;wg) // pass a pointer to wg } 由于这种不正确的复制不会抛出编译错误，如果你跳过了 go vet ，你可能永远也发现不了它。这也是始终审查代码的另一个原因。\n我很好奇 Go 工具链是如何强制执行这一点的。线索就在 vet 警告中：\n所以 sync.noCopy 结构体在 sync.WaitGroup 中做了些什么来提醒 go vet 当你通过值传递它时。\n查看 sync.WaitGroup 1 的实现，你会发现：\n1 2 3 4 5 6 type WaitGroup struct { noCopy noCopy state atomic.Uint64 sema uint32 } 然后我追踪了 noCopy 在 sync/cond.go 2 中的定义：\n1 2 3 4 5 6 7 8 9 // noCopy may be added to structs which must not be copied // after the first use. // Note that it must not be embedded, due to the Lock and Unlock methods. type noCopy struct{} // Lock is a no-op used by -copylocks checker from `go vet`. func (*noCopy) Lock() {} func (*noCopy) Unlock() {} 只需要在 noCopy 上定义那些空的 Lock 和 Unlock 方法。这实现了 Locker 3 接口。然后如果你将这个结构体嵌入到另一个结构体中， go vet 将会标记你在尝试复制外部结构体时出现的情况。\n另外，请注意注释：不要嵌入 noCopy 。显式包含它。嵌入会使 Lock 和 Unlock 在外部结构体中可见，这可能不是你想要的。\nGo 工具链通过 -copylocks 检查器来强制执行这一点。它是 go vet 的一部分。你可以单独使用 go vet -copylocks ./... 来调用它。它会查找任何包含 Lock 和 Unlock 方法的嵌套结构体的值拷贝。这些方法的具体功能并不重要，只要有这些方法就足够了。\n当 vet 运行时，它会遍历抽象语法树（AST），并在赋值、函数调用、返回值、结构体字面量、范围循环、通道发送等任何值被拷贝的地方应用检查器。如果它发现你拷贝了一个包含 noCopy 的结构体，它会发出警告。你可以在这里查看检查的实现 4 。\n有趣的是，如果你将 noCopy 定义为任何非结构体类型并实现 Locker 接口，vet 会忽略它。我在 Go 1.24 中进行了测试：\n1 2 3 type noCopy int // this is valid but vet doesn\u0026#39;t get triggered func (*noCopy) Lock() {} func (*noCopy) Unlock() {} 这不会触发 vet。只有当 noCopy 是结构体时才会生效。原因是 vet 在检查何时触发警告时采取了一条捷径 5 。目前，它明确查找满足 Locker 接口的结构体，并忽略任何其他类型，即使它们实现了该接口。\n你也会在 sync 包的其他部分看到这一点。 sync.Mutex 使用了同样的技巧：\n1 2 3 4 5 type Mutex struct { _ noCopy mu isync.Mutex } 同样适用于 sync.Once :\n1 2 3 4 5 type Once struct { done uint32 m Mutex noCopy noCopy } 这是一个使用 -copylocks 避免复制我们自己的结构体的完整示例：\n1 2 3 4 5 6 7 8 9 10 11 12 type Svc struct{ _ noCopy } type noCopy struct{} func (*noCopy) Lock() {} func (*noCopy) Unlock() {} // Use this func main() { var svc Svc _ = svc // go vet will complain about this copy op } 运行 go vet 得到：\n1 2 assignment copies lock value to s: play.Svc contains play.noCopy call of fmt.Println copies lock value: play.Svc contains play.noCopy 有人在 Reddit 上问我，是什么触发了 copylock 检查器在 go vet — 是结构体的字面名称 noCopy 还是它实现了 Locker 接口？\nnoCopy 这个名字不是特殊的。你可以想叫它什么就叫什么。只要它实现了 Locker 接口， go vet 会在周围结构体被复制时抱怨。参见这个 Go Playground 片段 6 。\n参考 本文翻译于 Preventing accidental struct copies in Go\n","date":"2025-04-26T00:00:00Z","permalink":"https://blog.golang.space/p/%E9%81%BF%E5%85%8D%E5%9C%A8-go-%E4%B8%AD%E6%84%8F%E5%A4%96%E5%9C%B0%E5%A4%8D%E5%88%B6%E7%BB%93%E6%9E%84%E4%BD%93/","title":"避免在 Go 中意外地复制结构体"},{"content":"上周，我遇到了一个棘手的问题：僵尸进程导致我的演示服务器崩溃 🧟‍♂️ 如果你有过在 Go 或 Docker 中处理进程管理的经验，你可能会对这段经历感同身受。下面是对这个问题的深入技术分析，以及我是如何追踪并解决它的。\n我们有一个功能，在 Stormkit 中可以根据自托管用户的需求启动 Node.js 服务器，使用动态端口分配在同一服务器上运行多个实例。它是用 Go 编写的，利用 os/exec 来管理进程。该系统一直非常稳定——没有宕机时间，用户也很满意。\n最近，我设置了一个用于托管 Next.js 和 Svelte 服务器端应用的演示服务器。一切看起来都正常，直到服务器开始随机出现 Redis 发布/订阅错误而崩溃。\n我将 Redis 升级到了 7.x 版本，检查了日志并尝试在本地重现问题——没有发现任何问题。崩溃是随机且难以捉摸的。然后，我禁用了 Next.js 应用，崩溃就停止了。我怀疑是 Next.js 本身的问题，于是深入研究了其运行时行为，但没有发现什么异常。\n查看服务器指标时，我发现内存使用率在崩溃前会激增。快速运行 ps aux 命令后，我发现有一堆遗留的 Next.js 进程没有被终止。我们的关机逻辑失败了，导致内存泄漏，最终耗尽了服务器资源。\n罪魁祸首在于我们的 Go 代码。我使用 os.Process.Kill 来终止进程，但没有杀死由 npm 启动的子进程（例如， npm run start 启动了 next start ）。这导致孤儿进程不断累积。这里有一个原始代码的简化版本：\n1 2 3 4 5 6 7 func stopProcess(cmd *exec.Cmd) error { if cmd.Process != nil { return cmd.Process.Kill() } return nil } 我通过启动一个带有子进程的 Node.js 进程并杀死父进程来本地重现了这个问题。果然，子进程还在运行。在 Go 中， os.Process.Kill 向进程发送信号，但不处理其子进程。\n解决尝试：进程组 要杀死子进程，我修改代码使用了进程组。通过使用 syscall.SysProcAttr 设置进程组 ID（PGID），我可以向整个组发送信号。这是更新后的代码（简化版）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 package main import ( \u0026#34;log\u0026#34; \u0026#34;os/exec\u0026#34; \u0026#34;syscall\u0026#34; ) func startProcess() (*exec.Cmd, error) { cmd := exec.Command(\u0026#34;npm\u0026#34;, \u0026#34;run\u0026#34; \u0026#34;start\u0026#34;) cmd.SysProcAttr = \u0026amp;syscall.SysProcAttr{Setpgid: true} // Assign PGID if err := cmd.Start(); err != nil { return nil, err } return cmd, nil } func stopProcess(cmd *exec.Cmd) error { if cmd.Process == nil { return nil } // Send SIGTERM to the process group pgid, err := syscall.Getpgid(cmd.Process.Pid) if err != nil { return err } return syscall.Kill(-pgid, syscall.SIGTERM) // Negative PGID targets group } 这在本地工作了：杀死父进程也终止了子进程。我将一个测试版本部署到我们的远程服务器上，期望胜利。但 ps aux 显示 \u0026lt;defunct\u0026gt; 接近进程旁边——僵尸进程！🧠\n僵尸进程 101 在 Linux 中，当一个子进程终止，但其父进程没有收集其退出状态（通过 wait 或 waitpid）时，就会出现僵尸进程。该进程会停留在进程表中，标记为 \u0026lt;defunct\u0026gt; 。少量的僵尸进程是无害的，但当它们积累时，会耗尽进程表，阻止新进程的启动。\n在本地，我的 Go 二进制文件可以正常回收进程。但在远程，僵尸进程仍然存在。关键区别在于远程服务器在 Docker 容器中运行了 Stormkit。\nDocker 的僵尸进程问题 Docker 将 PID 1 分配给容器的入口点（即我们的 Go 二进制文件）。在 Linux 中，PID 1（ init/systemd ）负责收养孤儿进程并回收其自身的僵尸子进程，包括它已经收养的前孤儿进程。如果 PID 1 没有处理 SIGCHLD 信号并调用 wait，僵尸进程就会累积。我们的 Go 程序并没有设计成一个初始化系统，所以它忽略了孤儿进程。\n解决方案：Tini 经过进一步调查，我发现回收僵尸进程是 Docker 长期存在的问题，所以市场上已经有了解决方案。最终我找到了 Tini，这是一个为容器设计的轻量级初始化系统。Tini 作为 PID 1 运行，通过处理 SIGCHLD 和 wait 所有进程来正确回收僵尸进程。我更新了我们的 Dockerfile：\n1 2 ENTRYPOINT [\u0026#34;/usr/bin/tini\u0026#34;, \u0026#34;--\u0026#34;] CMD [\u0026#34;/app/stormkit\u0026#34;] 或者，我可以使用 Docker 的 \u0026ndash;init 标志，该标志会自动添加 Tini。\n使用 Tini 部署后， ps aux 干净了——没有僵尸进程！🎉 服务器稳定了，Redis 错误消失了，因为它们是资源耗尽的副作用。\n总结 Go 进程管理：os.Process.Kill 不处理子进程。使用进程组或适当的信号处理以实现干净终止。 Docker PID 1：如果你的应用程序作为 PID 1 运行，它需要回收僵尸进程或委托给像 Tini 这样的初始化系统。 调试提示：处理崩溃时，请始终检查 ps aux 查看进程。 根本原因很重要：Redis 错误只是一个误导——僵尸进程导致的内存耗尽才是真正的问题。 参考 本文翻译于 Hunting Zombie Processes in Go and Docker ","date":"2025-04-25T00:00:00Z","permalink":"https://blog.golang.space/p/%E5%9C%A8-go-%E5%92%8C-docker-%E4%B8%AD%E6%90%9C%E5%AF%BB%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B/","title":"在 Go 和 Docker 中搜寻僵尸进程"},{"content":"什么是弱指针呢? 弱指针基本上是一种引用一块内存而不锁定它的方法，因此如果没有其他人主动持有它，垃圾收集器可以清理它。\n为什么还要为弱指针烦恼呢？ Go 有吗？\n嗯，是的，Go 确实有弱指针的概念。它是弱包的一部分，与 Go 运行时紧密相连。有趣的是，它曾经更多地是一个内部工具，但最近有人通过这个提案推动将其公开。\n很酷，对吧？\n弱指针的关键是它们是安全的。如果它们指向的内存被清理，弱指针会自动变为nil因此不存在意外指向已释放内存的风险。当您确实需要保留该内存时，可以将弱指针转换为强指针。这个强指针告诉垃圾收集器，“嘿，当我使用它时，请把它放开。”\n等等，它就自动变成 nil 了？这听起来……有风险\n是的，弱指针肯定会变成nil有时在你意想不到的时刻。\n它们比常规指针更难使用。在任何时候，如果弱指针指向的内存被清理，它就可以变成nil 。当没有强指针持有该内存时，就会发生这种情况。因此，始终检查刚刚从弱指针转换而来的强指针是否为nil非常重要。\n现在，关于清理何时发生——它不是立即发生的。即使没有人引用内存，清理时间也完全取决于垃圾收集器。\n现在，展示一些代码。\n在撰写本文时，弱包尚未正式发布。预计将在 Go 1.24 中落地。但我们可以偷看一下源代码并尝试一下。该软件包为您提供了两个主要的 API：\nweak.Make ：从强指针创建弱指针。 weak.Pointer[T].Strong ：将弱指针转换回强指针。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 type T struct { a int b int } func main() { a := new(string) println(\u0026#34;original:\u0026#34;, a) // make a weak pointer weakA := weak.Make(a) runtime.GC() // use weakA strongA := weakA.Strong() println(\u0026#34;strong:\u0026#34;, strongA, a) runtime.GC() // use weakA again strongA = weakA.Strong() println(\u0026#34;strong:\u0026#34;, strongA) } // Output: // original: 0x1400010c670 // strong: 0x1400010c670 0x1400010c670 // strong: 0x0 这是代码中发生的事情：\n在第一次垃圾回收（ runtime.GC() ）之后，弱指针weakA仍然指向内存，因为我们仍在使用变量a println(\u0026quot;strong:\u0026quot;, strongA, a) 线。由于内存正在使用中，因此还无法清理。 但是当第二次垃圾收集运行时，强引用（ a ）不再使用。这意味着垃圾收集器可以安全地清理内存，让weakA.Strong()返回nil 。 现在，如果您尝试使用string指针以外的其他内容（例如*int 、 *bool或其他类型）来尝试此代码，您可能会注意到不同的行为，最后一个strong输出可能不是nil 。\n这与 Go 如何处理int 、 bool 、 float32 、 float64等“微小对象”有关。这些类型被分配为微小对象，即使它们在技术上未使用，垃圾收集器也可能不会立即清理它们在垃圾收集期间。要了解更多信息，您可以更深入地研究Go Runtime Finalizer 和 Keep Alive中的微小对象分配。\n弱指针对于特定场景下的内存管理非常实用。\n例如，它们非常适合规范化映射 - 您只想保留一份数据的一份副本的情况。这与我们之前关于字符串驻留的讨论有关。 另一种情况是，当您希望某些内存的寿命与另一个对象的寿命相匹配时，类似于 JavaScript 的 WeakMap 的工作方式。 WeakMap 允许对象在不再使用时自动清理。 因此，弱指针的主要好处是它们可以让你告诉垃圾收集器， *“嘿，如果没有人使用这个资源，就可以删除它——我以后可以随时重新创建它。”*这对于占用大量内存但不需要保留的对象非常有效，除非它们正在被积极使用。\n弱指针如何工作？\n有趣的是，弱指针实际上并不直接指向它们引用的内存。相反，它们是包含“间接对象”的简单结构（使用泛型）。这个对象很小，只有 8 个字节，它指向实际的内存目标。\n1 2 3 type Pointer[T any] struct { u unsafe.Pointer } 为什么要这样设计呢？\n此设置使垃圾收集器可以高效地一次性清理指向特定对象的弱指针。当它决定应该释放内存时，收集器只需将间接对象中的指针设置为nil （或0x0 ）。它不必单独更新每个弱指针。\n最重要的是，这个设计支持相等检查（ == ）。从同一原始指针创建的弱指针将被视为“相等”，即使它们指向的对象已被垃圾回收。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func main() { a := new(string) // make a weak pointers weakA := weak.Make(a) weakA2 := weak.Make(a) println(\u0026#34;Before GC - Equality check:\u0026#34;, weakA == weakA2) runtime.GC() // Test their equality println(\u0026#34;After GC - Strong:\u0026#34;, weakA.Strong(), weakA2.Strong()) println(\u0026#34;After GC - Equality check:\u0026#34;, weakA == weakA2) } // Before GC - Equality check: true // After GC - Strong: 0x0 0x0 // After GC - Equality check: true 这是可行的，因为来自同一原始对象的弱指针共享相同的间接对象。当您调用weak.Make时，如果一个对象已经有一个与之关联的弱指针，则现有的间接对象将被重用，而不是创建一个新的。\n等等，使用 8 个字节作为间接对象不是有点浪费吗？\n看起来好像是这样，但作者会说，这并不是什么大问题。弱指针通常用于总体目标是节省内存的情况。例如，在规范化映射中（通过仅保留每个唯一数据的一份副本来消除重复项），您已经通过避免冗余节省了大量内存。\n也就是说，如果您存在大量唯一项和很少重复项的情况下使用弱指针，则最终可能会使用比预期更多的内存。因此，在决定弱指针是否是适合该工作的工具时，考虑具体用例非常重要。\n参考 本文翻译于 Weak Pointers in Go: Why They Matter Now\n","date":"2024-12-01T00:00:00Z","permalink":"https://blog.golang.space/p/go-%E4%B8%AD%E7%9A%84%E5%BC%B1%E6%8C%87%E9%92%88%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BB%96%E4%BB%AC%E7%8E%B0%E5%9C%A8%E5%BE%88%E9%87%8D%E8%A6%81/","title":"Go 中的弱指针:为什么他们现在很重要?"},{"content":"typora 在导出 HTML 文件时，其图片位置是根据写 markdown 时间定义的，比如在 markdown 中是网络图片，则导出 HTML 也是网络图片。\n图片在编辑者本地，或图片在网络但 HTML 使用在离线环境，此时图片是无法正确加载的。\n通过设置 typora 导出后执行命令，将图片替换成 base64 来解决以上问题。\n测试环境 typora 1.9.4\nMacbook Pro\n解决方案 在 typora 导出设置中，给 html 类型导出后执行自定义命令 ~/typora_format_html ${outputPath}，``~/typora_format_html是用于格式化 html 的可执行文件，${outputPath}` 是导出后的文件路径。 下载可执行文件 https://github.com/ixugo/typora_plugin/releases/tag/v0.0.1 此可执行文件由 Golang 编写，下载后存放路径要与第一步中填写路径名称相同。\n正常执行导出 HTML 操作，查看文件可以发现图片已经是 base64。\n","date":"2024-12-01T00:00:00Z","permalink":"https://blog.golang.space/p/typora-%E5%AF%BC%E5%87%BA%E5%B8%A6%E5%9B%BE%E7%89%87%E7%9A%84-html/","title":"typora 导出带图片的 html"},{"content":"HTTP/1.1 启动一个 HTTP 服务示例。\n1 2 3 4 5 m := http.NewServeMux() m.HandleFunc(\u0026#34;/proto\u0026#34;, func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(r.Proto)) }) go http.ListenAndServe(\u0026#34;:8080\u0026#34;, m) H2C h2c 是未加密的 http/2 协议，启动一个 h2c 服务示例。\n1 2 3 4 5 6 m := http.NewServeMux() m.HandleFunc(\u0026#34;/proto\u0026#34;, func(w http.ResponseWriter, r *http.Request) { w.Write([]byte(r.Proto)) }) h := h2c.NewHandler(m, \u0026amp;http2.Server{IdleTimeout: time.Minute}) go http.ListenAndServe(\u0026#34;:8080\u0026#34;, h) 客户端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 cli := \u0026amp;http.Client{ Timeout: 10 * time.Second, Transport: \u0026amp;http2.Transport{ AllowHTTP: true, DialTLSContext: func(ctx context.Context, network, addr string, cfg *tls.Config) (net.Conn, error) { var dialer net.Dialer return dialer.DialContext(ctx, network, addr) }, }, } { resp, err := cli.Get(\u0026#34;http://localhost:8080/proto\u0026#34;) if err != nil { t.Fatal(err) } defer resp.Body.Close() data, err := io.ReadAll(resp.Body) if err != nil { t.Fatal(err) } fmt.Println(\u0026#34;h2c\u0026#34;, string(data)) } h2c 客户端请求 h2c 服务端，可以从下面截图看出协议是 HTTP/2.0。\nh1 客户端请求 h2c 服务端，协议为 HTTP/1.1。\n那如果 h2c 客户端请求 h1 服务端呢? 将会收获以下错误。\nGet \u0026quot;http://localhost:8080/proto\u0026quot;: read tcp [::1]:61776-\u0026gt;[::1]:8080: read: connection reset by peer\n我们可以自己实现 RoundTrip 接口，当 h2c 连接不上时，降级到 h1 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // CustomTransport 实现 HTTP/2 回退到 HTTP/1.1 的逻辑 type CustomTransport struct { h2cTransport *http2.Transport h1Transport *http.Transport } func NewCustomTransport() *CustomTransport { return \u0026amp;CustomTransport{ h2cTransport: \u0026amp;http2.Transport{ AllowHTTP: true, DialTLSContext: func(ctx context.Context, network, addr string, _ *tls.Config) (net.Conn, error) { var dialer net.Dialer return dialer.DialContext(ctx, network, addr) }, IdleConnTimeout: time.Minute, }, h1Transport: \u0026amp;http.Transport{ IdleConnTimeout: time.Minute, }, } } func (f *CustomTransport) RoundTrip(req *http.Request) (*http.Response, error) { // 使用 HTTP/2 Transport 作为默认传输 resp, err := f.h2cTransport.RoundTrip(req) if err != nil { // 如果 HTTP/2 失败，回退到 HTTP/1.1 连接 return f.h1Transport.RoundTrip(req) } return resp, nil } 再尝试一次试试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 cli := \u0026amp;http.Client{ Timeout: 10 * time.Second, Transport: NewCustomTransport(), } { resp, err := cli.Get(\u0026#34;http://localhost:8080/proto\u0026#34;) if err != nil { t.Fatal(err) } defer resp.Body.Close() data, err := io.ReadAll(resp.Body) if err != nil { t.Fatal(err) } fmt.Println(\u0026#34;h2c\u0026#34;, string(data)) } ","date":"2024-10-25T00:00:00Z","permalink":"https://blog.golang.space/p/go-h2c/","title":"Go H2C"},{"content":"对于 Go 程序员来说，这是一个很快就会死记硬背的习惯用法：每当你想出一个实现io.Closer接口的值时，在检查错误后，你会立即defer其Close()方法。在发出 HTTP 请求时最常看到这种情况：\n1 2 3 4 5 resp, err := http.Get(\u0026#34;https://joeshaw.org\u0026#34;) if err != nil { return err } defer resp.Body.Close() 或打开文件：\n1 2 3 4 5 f, err := os.Open(\u0026#34;/home/joeshaw/notes.txt\u0026#34;) if err != nil { return err } defer f.Close() 但这种习惯用法实际上对可写文件有害，因为延迟函数调用会忽略其返回值，并且Close()方法可能会返回错误。对于可写文件，Go 程序员应该避免defer习惯用法，否则会出现非常罕见的令人抓狂的错误。\n为什么您会从Close()中收到错误，但在之前的Write()调用中却没有收到错误？为了回答这个问题，我们需要补充一下计算机体系结构领域知识。\n一般来说，当你从 CPU 向外移动时，操作的速度会变得慢几个数量级。写入 CPU 寄存器非常快。访问系统 RAM 相对较慢。进行磁盘或网络 I/O 则慢得多。\n如果每个Write()调用都将数据同步提交到磁盘，我们系统的性能将会慢得无法使用。虽然同步写入对于某些类型的软件（例如数据库）非常重要，但大多数时候它是多余的。\n最糟糕的情况是一次写入一个字节到文件中。硬盘驱动器——粗暴的机械设备——需要将磁头物理移动到盘片上的位置，并可能需要等待整盘的旋转才能将数据持久化。固态硬盘（SSD），它们以块的形式存储数据，并且每个块的写入周期是有限的，会因为块被反复写入和覆盖而迅速磨损。\n幸运的是，这种情况不会发生，因为硬件和软件的多个层次实现了缓存和写入缓冲。当你调用 Write() 时，数据不会立即被写入到介质上。操作系统、存储控制器和介质本身都在缓存数据，以便将较小的写入操作批量处理，优化数据在介质上的存储，并决定何时最佳地提交数据。这将我们的写入操作从缓慢的、阻塞的同步操作转变为快速的、异步的操作，这些操作不会直接触及更慢的 I/O 设备。一次写入一个字节从来不是最有效的做法，但至少我们不会因为这样做而耗损硬件。\n当然，这些字节最终必须被写入磁盘。操作系统知道当我们关闭一个文件时，我们已经完成了对它的操作，不会有后续的写入操作发生。它还知道关闭文件是它最后一次告诉我们是否出现了问题的机会。\n在 Linux 和 macOS 等 POSIX 系统上，关闭文件是通过close系统调用来处理的。 close(2)的 BSD 手册页讨论了它可能返回的错误：\n1 2 3 4 5 6 7 8 9 ERRORS The close() system call will fail if: [EBADF] fildes is not a valid, active file descriptor. [EINTR] Its execution was interrupted by a signal. [EIO] A previously-uncommitted write(2) encountered an input/output error. EIO 正是我们担心的错误。这意味着我们在尝试将数据保存到磁盘时丢失了数据，我们的 Go 程序在这种情况下绝对不应返回 nil 错误。\n解决这个问题最简单的方法就是在写入文件时不使用defer ：\n1 2 3 4 5 6 7 8 9 10 11 12 13 func helloNotes() error { f, err := os.Create(\u0026#34;/home/joeshaw/notes.txt\u0026#34;) if err != nil { return err } if err = io.WriteString(f, \u0026#34;hello world\u0026#34;); err != nil { f.Close() return err } return f.Close() } 这确实意味着在出现错误时需要对文件进行额外的记录：在io.WriteString()失败的情况下，我们必须显式关闭它（并忽略它的错误，因为写入错误优先）。但它很清晰、直接，并且可以正确检查f.Close()调用中的错误。\n有一种方法可以通过使用命名返回值和闭包defer处理这种情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func helloNotes() (err error) { var f *os.File f, err = os.Create(\u0026#34;/home/joeshaw/notes.txt\u0026#34;) if err != nil { return } defer func() { cerr := f.Close() if err == nil { err = cerr } }() err = io.WriteString(f, \u0026#34;hello world\u0026#34;) return } 此模式的主要好处是不可能忘记关闭文件，因为延迟关闭始终会执行。在具有更多if err != nil条件分支的较长函数中，此模式还可以减少代码行数和重复次数。\n尽管如此，我还是觉得这种模式有点魔法了。我不喜欢使用命名返回值，并且即使对于经验丰富的 Go 程序员来说，在核心函数完成后修改返回值也不是直观上清楚的。\n我愿意接受更具可读性和易于理解的代码的权衡，因为需要不断地审查代码以确保文件在所有情况下都已关闭，这就是我在向其他人提供的代码审查中推荐的方法。\n更新 1\nBen Johnson 在 Twitter 上建议，对文件多次运行Close()可能是安全的，如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 func doSomething() error { f, err := os.Create(\u0026#34;foo\u0026#34;) if err != nil { return err } defer f.Close() if _, err := f.Write([]byte(\u0026#34;bar\u0026#34;); err != nil { return err } return f.Close() } io.Closer上的 Go 文档明确指出，在第一次调用后的接口级别行为是未指定的，但特定的实现可能会记录其自己的行为。\n不幸的是， *os.File的文档并不清楚它的行为，只是说，“Close 关闭文件，使其无法用于 I/O。如果有的话，它会返回一个错误。”然而，从 1.8 开始的实现显示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func (f *File) Close() error { if f == nil { return ErrInvalid } return f.file.close() } func (file *file) close() error { if file == nil || file.fd == badFd { return syscall.EINVAL } var err error if e := syscall.Close(file.fd); e != nil { err = \u0026amp;PathError{\u0026#34;close\u0026#34;, file.name, e} } file.fd = -1 // so it can\u0026#39;t be closed again // no need for a finalizer anymore runtime.SetFinalizer(file, nil) return err } 为了清楚起见， badFd被定义为 -1 ，因此随后尝试关闭*os.File将不会执行任何操作并返回syscall.EINVAL 。但由于我们忽略了defer的错误，所以这并不重要。确切地说，它不是幂等的，但正如 Ben 后来在 Twitter 帖子中所说的那样， “won’t blow shit up if you call it twice.”\n更新 2\n关闭文件是操作系统告诉我们问题的最后机会，但关闭文件时缓冲区不一定会被刷新。关闭文件后完全有可能将写入缓冲区刷新到磁盘，并且无法捕获其中的故障。如果发生这种情况，通常意味着出现严重错误，例如磁盘出现故障。\n但是，您可以使用*os.File上的Sync()方法强制写入磁盘，该方法调用fsync系统调用。您应该检查该调用中的错误，但我认为忽略Close()中的错误是安全的。调用fsync对性能有严重影响：它将写入缓冲区刷新到速度较慢的磁盘。但如果您真的非常想要将数据存储在磁盘上，那么最好遵循的模式可能是：\n1 2 3 4 5 6 7 8 9 10 11 12 13 func helloNotes() error { f, err := os.Create(\u0026#34;/home/joeshaw/notes.txt\u0026#34;) if err != nil { return err } defer f.Close() if err = io.WriteString(f, \u0026#34;hello world\u0026#34;); err != nil { return err } return f.Sync() } ","date":"2024-09-17T00:00:00Z","permalink":"https://blog.golang.space/p/%E4%B8%8D%E8%A6%81%E5%9C%A8%E5%8F%AF%E5%86%99%E6%96%87%E4%BB%B6%E4%B8%8A%E5%BB%B6%E8%BF%9F-close/","title":"不要在可写文件上延迟 Close"},{"content":"蠢萌的死法: 指针中的随机值 最近有人提出「是否可以将非指针放入 unsafe.Pointer 变量」的问题。普遍的反应是「NO，这是一个坏主意」。我同意，但如果我们从不探索糟糕的想法，永远不会\u0026hellip;嗯，实际上，如果从不探索糟糕的想法，绝对不会出问题。\n让我们探讨一下这个 Bad idea\n为什么是坏主意? 主要是可能是会让 Go 的垃圾收集器崩溃。Go GC 会查看程序可见的每个指针，以查看哪些内存仍在使用，以及哪些内存可以释放。如果它跟随的指针未指向有效的内存地址，则可能会崩溃。\n让我们尝试一下，分配十亿个 unsafe.Pointers 并将他们全部设置为无效指针的值。\n1 2 3 4 5 6 7 8 9 10 11 func TestRandomUnsafePointers(t *testing.T) { x := make([]unsafe.Pointer, 1e9) for i := range x { // Possible misuse of unsafe.Pointer? Definite misuse of unsafe.Pointer! x[i] = unsafe.Pointer(uintptr(i * 8)) } runtime.GC() runtime.KeepAlive(x) } 此代码创建一个包含 10 亿个unsafe.Pointer的切片，然后强制 GC 运行。它不会崩溃。\n我们可以用真正的随机值再试一次，并且做一些傻事。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func TestRandomUnsafePointers2(t *testing.T) { x := make([]unsafe.Pointer, 1e9) for i := range x { // Possible misuse of unsafe.Pointer? Definite misuse of unsafe.Pointer! x[i] = unsafe.Pointer(uintptr(rand.Int64())) } runtime.GC() for range 10 { for i := range x { // Possible misuse of unsafe.Pointer? Definite misuse of unsafe.Pointer! x[i] = unsafe.Add(x[i], 3) } runtime.GC() } runtime.KeepAlive(x) } 仍旧未崩溃。\n如果我们不够聪明怎么办？\nGo 可能会查看这些值并思考「啊嘞」，然后忽略他。 Go 可以与 C 交互，因此它需要能够处理在其控制之外分配的内存。多年来，我还使用 Go 直接通过系统调用分配的内存，没有任何问题（祈祷）。\n如果指针的值看起来像它应该关心的内存，Go 可能会发现它更困难。如果我们存储的值曾经是 Go 本身分配的有效内存地址，但我们知道它不再有效怎么办？\n这里我们分配一个足够大的切片，以便始终分配在堆上。然后，我们获取支持该切片的数组的地址，并将其放入 uintptr 中。我们知道 Go 不会将 uintptr 视为指针，因此将值保存在 uintptr 中不应导致 Go 保留分配。\n如果我们随后删除对切片的引用并强制执行 GC，则应该释放内存。\n1 2 3 4 y := make([]int, 1e4) yptr := uintptr(unsafe.Pointer(unsafe.SliceData(y))) y = nil runtime.GC() 现在，如果我们将此值存储在unsafe.Pointer中并再次运行 GC，我们可能会遇到麻烦。这是完整的测试。\n1 2 3 4 5 6 7 8 9 10 11 12 func TestUnsafePointerBadNumber(t *testing.T) { y := make([]int, 1e4) yptr := uintptr(unsafe.Pointer(unsafe.SliceData(y))) y = nil runtime.GC() runtime.GC() x := unsafe.Pointer(yptr) runtime.GC() runtime.GC() runtime.KeepAlive(x) } 事实上，这确实引起了 panic 。\n1 2 3 4 5 6 7 runtime: pointer 0xc000162000 to unallocated span span.base()=0xc000288000 span.limit=0xc000290000 span.state=0 runtime: found in object at *(0xc00005ff58+0x0) object=0xc00005ff58 s.base()=0xc00005e000 s.limit=0xc000066000 s.spanclass=0 s.elemsize=2048 s.state=mSpanManual : : ... fatal error: found bad pointer in Go heap (incorrect use of unsafe or cgo?) 如果您想知道为什么要多次调用runtime.GC() ，我也是。这似乎使它更可靠地崩溃。\n这意味着什么？\nGo 的垃圾收集器非常强大，可以处理很多滥用情况。您可以将值存储在 GC 不知道的指针中，或者甚至不是有效的内存地址。\n但如果你存储了 GC 认为它能控制的内存地址，那么它就会发生 Panic。如果您将非指针值存储在unsafe.Pointer中，您可能不会立即看到问题。你的测试可能不会显示任何问题。但有一天，总会有异常甩你脸上，而你却不知道为什么。\n我的结论如下。\n除非确实必要，否则不要使用unsafe.Pointer 。 除非确实有必要，否则不要保留unsafe.Pointer指针值。大多数使用unsafe.Pointer的安全操作仅将其用作瞬态值，同时将某些内容转换为其他内容。 你可能不需要。 仅将内存地址存储在unsafe.Pointer中。 也许只有在 Go 运行时之外分配的内存地址（例如通过直接调用 mmap 系统调用）。 参考 本文翻译于Dumb ways to die: Random Values in Pointers\n","date":"2024-09-16T00:00:00Z","permalink":"https://blog.golang.space/p/%E6%8C%87%E9%92%88%E4%B8%AD%E7%9A%84%E9%9A%8F%E6%9C%BA%E5%80%BC/","title":"指针中的随机值"},{"content":"这几天，我开发了一个名为 \u0026ldquo;Horcux\u0026rdquo; 的程序，它允许将一个文件拆分为任意数量的魂器，然后可以重新组合以恢复原始文件。期间，我了解了很多有关 io.Reader 和 io.Writer 接口的知识，与大家分享。\n为什么使用 io.Reader 和 io.Writer? 在 Horcrux 的第一个版本中，做了类似以下的事情来加密文件。\n1 2 3 4 5 6 7 8 9 func main() { // plaintext: \u0026#34;this is my file\u0026#39;s content\u0026#34; content, _ := ioutil.ReadFile(\u0026#34;myfile\u0026#34;) encryptedContent := encrypt(content) // ciphertext: \u0026#34;uijt!jt!nz!gjmf(t!dpoufou\u0026#34; ioutil.WriteFile(\u0026#34;myfile.encryped\u0026#34;, encryptedContent, 0644) } 小文件超级快。当文件为 1GB 时超级慢。我的目的是加密源文件，而不是将整个文件加载到内存中。这就是 io.Reader 和 io.Writer 发挥作用的地方。\nio.Reader 从源读取数据。io.Writer 将内容写入目的地，两个接口是处理流信息的接口。\n流式方法有几个好处:\n用一个小的缓冲区读写数据，不需要将整个文件加载到内存 不需要等待整个文件加载好才开始加密，一旦数据读入缓冲区，即可开始写入目标文件。 io.Reader 什么是 io.Reader?\n1 2 3 type Reader interface { Read(p []byte) (n int, err error) } 常见的返回错误是 io.EOF，它代表读取结束。\n按照惯例，在 Go 中，当函数有多个返回值时，其中一个是 error，如果发生错误，其他值应为零值。但考虑如果读取中途发生错误，应该告诉调用者当前读取了多少字节。\n使用 io.Reader\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func main(){ reader := strings.NewReader(\u0026#34;this is the stuff i\u0026#39;m reading\u0026#34;) var result []byte buf := make([]byte,4) for { n,err := reader.Read(buf) result = append(result, buf[:n]...) if err != nil { if err == io.EOF { break } log.Fatal(err) } } fmt.Println(string(result)) } 在上面的代码中，创建缓冲区(大小为 4 字节) 并执行循环，在每次循环中调用读取器上的 Read 方法，并使用第一个返回值来查看已写入多少字节。最后将这些数据附加到结果中，如果出现 EOF 错误，跳出循环。\\\n注意有一个点是先处理数据，再处理错误。返回 (0,nil) 并不意味着没有更多内容可读，可能是正在等待底层源返回更多的数据。\n实现 io.Reader\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type myReader strcut{ content []byte position int } func (r *myReader) Read(buf []byte) (int,error) { remainingBytes := len(r.content) - r.position n := min(remainingBytes,len(buf)) if n == 0 { return 0, io.EOF } copy(buf[:n], r.content[r.position:r.position+n]) r.position += n return n,nil } 在这里，创建一个结构体，包含要读取的内容 content 字段，以及用于跟踪读取位置的 position 字段。 将源数据填充缓存区并防止溢出。\n注意，当没有更多内容可读取时，返回 (0,io.EOF) ，从而避免调用者对 Read 方法进行不必要的调用。\n编写 io.Readers\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 type augmentedReader struct{ innerReader io.Reader augmentFunc func([]byte) []byte } // replaces \u0026#39; \u0026#39; with \u0026#39;!\u0026#39; func bangify(buf []byte) []byte { return bytes.Replace(buf, []byte(\u0026#34; \u0026#34;), []byte(\u0026#34;!\u0026#34;), -1) } func (r *augmentedReader) Read(buf []byte) (int, error) { tmpBuf := make([]byte, len(buf)) n, err := r.innerReader.Read(tmpBuf) copy(buf[:n], r.augmentFunc(tmpBuf[:n])) return n, err } func BangReader(r io.Reader) io.Reader { return \u0026amp;augmentedReader{innerReader: r, augmentFunc: bangify} } func UpcaseReader(r io.Reader) io.Reader { return \u0026amp;augmentedReader{innerReader: r, augmentFunc: bytes.ToUpper} } ... package main import ( . \u0026#34;augment\u0026#34; ... ) func main() { originalReader := strings.NewReader(\u0026#34;this is the stuff I\u0026#39;m reading\u0026#34;) augmentedReader := UpcaseReader(BangReader(originalReader)) result, err := ioutil.ReadAll(augmentedReader) if err != nil { log.Fatal(err) } fmt.Println(string(result)) // THIS!IS!THE!STUFF!I\u0026#39;M!READING } 这一个增强包，它导出一些可组合的读取器函数。每个函数都接受一个 io.Reader，并返回一个 io.Reader。但内部 io.Reader 的输出由外部 IO 增强。在本例中，将 \u0026quot; \u0026quot; 与 ! 交换。\n使用 io.Writer\n1 2 3 4 func main() { writer := os.Stdout writer.Write([]byte(\u0026#34;hello there\\n\u0026#34;)) } 实现 io.Writer\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 type myWriter struct { content []byte } func (w *myWriter) Write(buf []byte) (int, error) { w.content = append(w.content, buf...) return len(buf), nil } func (w *myWriter) String() string { return string(w.content) } func main() { writer := \u0026amp;myWriter{} writer.Write([]byte(\u0026#34;hello there\\n\u0026#34;)) fmt.Println(writer.String()) // \u0026#34;hello there\\n\u0026#34; } 在 Write 方法中仅获取缓冲区并将其附加到其内部内容。我们还给它一个String方法来告诉我们到目前为止它写了什么。碰巧我们在这里实现了 bytes.Buffer 的精简编写器版本。\n参考 本文翻译于 Golang IO Cookbook\n","date":"2024-08-27T00:00:00Z","permalink":"https://blog.golang.space/p/golang-io-cookbook/","title":"Golang IO Cookbook"},{"content":"理解 maps 的真正工作原理有可能相当困难，举个例子: 你是否曾经设置过 map 的 hint，即 make(map,hint)，为什么它叫 hint ，而不是slice那样的 len?\n你可以已经注意到，当你在 map 上使用 for-range 时，顺序与插入顺序不匹配。如果在不同的时间循环同一个 map，每次的结果可能都不一样。奇怪的是，同一个时间循环，顺序通常保持不变。\n跟上，带你看看。\n本文基于 Go 1.23 版本。\n快速开始 Go 中的 map，是一种内置类型，充当键值存储， key 可以是任何可比较的类型。\n1 2 3 4 5 m := make(map[string]int) m[\u0026#34;a\u0026#34;] = 1 m[\u0026#34;b\u0026#34;] = 2 m // map[a:1 b:2] 在该示例中，使用 make() 创建了一个空 map，其中 key 是字符串，value 是整数。\n可以在声明 map 的同时赋值键值对。\n1 2 3 4 m := map[string]int{ \u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, } 删除的方法是 delete(m,\u0026quot;a\u0026quot;)\nmap 的零值是 nil，并且 nil map 在某些方面有点像 empty map，可以尝试在其中查找 key，golang 不会发生 panic 。\n如果搜索不存在的 key，Go 会提供该类型的零值。\n1 2 3 4 var m map[string]int println(m[\u0026#34;a\u0026#34;]) // 0 m[\u0026#34;a\u0026#34;] = 1 // panic: assignment to entry in nil map 警告: 但不能对 nil map 添加新的键值对!\n事实上， Go 处理 map 的方式与处理 slice 的方式非常相似，两者皆以 nil 开始，for-range 也不会发生 panic，Go 将任何类型的零值视为有用的东西，而不是导致程序崩溃的东西，除非当你做了一些非法的事情，例如尝试像 nil map 添加新的键值对，或者对 nil slice 越界索引。\n关于 Go 中的 map，应该了解以下几点:\nmap 的遍历是乱序的 map 非线程安全，并且数据竞争时会发生 panic 可以通过 ok 来检查 key 是否存在 _,ok := m[key] map 的 key 必须是可比较的 那么，可比较类型到底是什么?\n简单的很，如果可以使用 == 来判断相同类型的两个值，那么该类型被认为可以比较。\n1 2 3 4 5 6 7 8 9 func main() { var s map[int]string if s == s { println(\u0026#34;comparable\u0026#34;) } } // compile error: invalid operation: s == s (map can only be compared to nil) 显然，上面的代码无法通过编译，map 只能与 nil 比较。\n同样的规则适用于其他不可比较的类型，例如slice、函数或包含slice或map的结构等。\n但这里有个小技巧，接口是可以比较的，也可以是不可比较的。\n什么意思? 即可以定义一个空接口为键的 map ，而不会编译出错，但可以运行时出错。\n1 2 3 4 5 6 7 8 9 10 11 12 func main() { m := map[interface{}]int{ 1: 1, \u0026#34;a\u0026#34;: 2, } m[[]int{1, 2, 3}] = 3 m[func() {}] = 4 } // panic: runtime error: hash of unhashable type []int // panic: runtime error: hash of unhashable type func() 一切看起来都很好，直到尝试分配一个不可比较的类型作为 key 。这比编译错误更难处理，应当避免使用 interface{} 作为 map 的 key 。\nMap 剖析 让我们由浅入深，细品，别陷入 Go 源码的具体实现。\n实际上，键值对是一个抽象，底层是由许多称为 bucket 的较小单元阻塞。\n1 2 3 4 5 type hmap struct { ... buckets unsafe.Pointer ... } 注意看，这个 buckets 是指针，这就是为什么将 map 分配给变量或传递给函数时，在外部的修改也会影响到这个值。\n1 2 3 4 5 6 7 8 9 func changeMap(m2 map[string]int) { m2[\u0026#34;hello\u0026#34;] = 2 } func main() { m1 := map[string]int{\u0026#34;hello\u0026#34;: 1} changeMap(m1) println(m1[\u0026#34;hello\u0026#34;]) // 2 } map 是指向运行时 hmap 的指针，但它们不是引用类型，如果如下所示的更改，它不会反映到调用者中。\n1 2 3 4 5 6 7 8 9 func changeMap(m2 map[string]int) { m2 = map[string]int{\u0026#34;hello\u0026#34;: 2} } func main() { m1 := map[string]int{\u0026#34;hello\u0026#34;: 1} changeMap(m1) println(m1[\u0026#34;hello\u0026#34;]) // 1 } 在 Go 中，一切都是按值传递的。真正发生的情况有点不同，当你将 map m1 传递给 changeMap 函数时，Go 会创建 *hmap 结构的副本。因此，main() 中的 m1 和 changeMap() 函数中的 m2 从技术上讲是指向相同 hmap 不同的指针。\n每个存储桶最多只能容纳 8 个键值对，如下图所示。\n上面的map有2个bucket， len(map)是6。\n当添加键值对时，会根据 hash(key, seed) 将键值对放入其中一个存储桶中。\n看看以下场景: 有一个 nil map 并为其分配键值对\n它首先将“hello”散列到一个数字，然后获取该数字并按存储桶的数量对其进行修改。\n由于我们这里只有一个存储桶，任何数字 mod 1 都是 0，所以它会直接进入存储桶 0，当您添加另一个键值对时，也会发生相同的过程。它将尝试将其放入存储桶 0 中，如果第一个 bucket 已被占用或具有不同的密钥，它将移动到该存储桶中的下一个 bucket。\n看一下hash(key, seed) ，当您在具有相同键的两个map上使用 for-range 循环时，您可能会注意到键以不同的顺序出现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func main() { a := map[string]int{\u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, \u0026#34;c\u0026#34;: 3, \u0026#34;d\u0026#34;: 4, \u0026#34;e\u0026#34;: 5, \u0026#34;f\u0026#34;: 6} b := map[string]int{\u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, \u0026#34;c\u0026#34;: 3, \u0026#34;d\u0026#34;: 4, \u0026#34;e\u0026#34;: 5, \u0026#34;f\u0026#34;: 6} for i := range a { print(i, \u0026#34; \u0026#34;) } println() for i := range b { print(i, \u0026#34; \u0026#34;) } } // Output: // a b c d e f // c d e f a b 这怎么可能？map a 中的键“a”和map b 中的键“a”不是以相同的方式散列吗？\n但事情是这样的，虽然 Go 中用于 map 的哈希函数在具有相同键类型的所有 map 中是一致的，但该哈希函数使用的seed对于每个 map 实例是不同的。因此，当您创建新 map 时，Go 会专门为该 map 生成一个随机种子。\n一个 bucket 的长度最大是 8，那满了会怎样?\n当桶开始变满，甚至几乎满时，根据算法对“满”的定义，map 将触发扩容，这可能会使 main buckets 的数量增加一倍。\n有趣。\n当我说“ main buckets” 时，我正在设置另一个概念：“overflow buckets”。当遇到高碰撞的情况时，这些就会发挥作用。试想: 存在 4 个bucket，但其中一个由于高冲突而完全装满，另外 3 个则空着。\n是否真的需要将 map 翻倍扩容到 8 个 buckets? 仅仅是需要添加一个不幸也落到 bucket 0 的键值对?\nNo! 这样太浪费了。\nGo 通过创建链接到第一个 bucket 的 overflow bucket 来更有效处理这个问题。新的键值对存储在这个溢出桶中，而不是强制完全扩容。\n当满足两个条件之一时，Go 中的 map 就会扩容: 要么溢出桶太多，要么 map 过载(负载因子太高)。\n对应这两种条件，也有两种扩容方式:\n翻倍扩容(过载时) 保持相同大小，但重新分配 bucket 中的数据。(当溢出桶太多时) 目前，Go 的负载因子设置为 6.5，这意味着 map 设计为每个 bucket 平均维护 6,5 个，大约是 80%的容量，当负载因子超过此阈值，map 视为过载。此时，将通过分配一个新的 buckets 数组，该数组是大小是当前的两倍，然后元素重新散列到新的 buckets 中。\n我们通常认为在map中访问和赋值是 O(1)，对吧？但事情并不总是那么简单。\nbucket 中的元素越多，速度就越慢。\n当您想要添加另一个键值对时，不仅仅是检查存储桶是否有空间，而是将键与该存储桶中的每个现有键进行比较，以决定是添加新条目还是更新现有条目。\n当您有溢出桶时，情况会变得更糟，因为您还必须检查这些溢出桶中的每个插槽。这种速度减慢也会影响访问和删除操作。\n但 Go 团队强呀，他们为我们优化了这个比较。\n还记得我们对键“Hello”进行散列时得到的散列吗？ Go 不只是把它扔掉。它实际上将“Hello”的 tophash 作为uint8缓存在存储桶中，并使用它与任何新密钥的 tophash 进行快速比较。这使得初始检查超级快。\n比较tophash后，如果它们匹配，则意味着密钥“可能”相同。然后，Go 继续进行较慢的过程，检查密钥是否实际上相同。\n为什么使用 make(map,hint) 创建新 map 不提供确切的大小而只提供 hint？\nmake(map, hint)中的hint参数告诉Go您期望map保存的元素的初始数量。此 hint 有助于最大限度地减少添加元素时 map 需要扩容的次数。\n由于每个扩容操作都涉及分配新的存储桶数组并复制现有元素，因此这不是最有效的过程。从较大的初始容量开始可以帮助避免一些成本高昂的扩容操作。\n当您添加更多元素时，存储桶大小这样扩容：\nHint Range Bucket Count Capacity 0 - 8 1 8 9 - 13 2 16 14 - 26 4 32 27 - 52 8 64 53 - 104 16 128 105 - 208 32 256 209 - 416 64 512 417 - 832 128 1024 833 - 1664 256 2048 为什么 hint= 14 会产生 4 个桶？我们只需要 2 个桶就可以容纳 14 个元素。\n这就是负载因子发挥作用的地方，当 hint=13，有 2 个 buckets，负载因子为 13/2=6.5，达到阈值但未超过。因此，当 hint=14，负载因子超过 6.5，触发翻倍扩容。\nhint=26也是如此，26/4=6.5，当 hint\u0026gt;26，map 需要扩容以有效容纳更多元素。\n散列 为什么无法获取 map 元素的地址? 为什么不同时间不能保证范围内的顺序?\n当 map 增长时，会分配一个新的 buckets 数组，是旧 buckets 的两倍，旧 buckets 中所有元素都变得无效，需要移动到新内存地址的 buckets 中。\n如果 map 很大，一次性的移动想当昂贵，可能在相当长的时间内阻塞 goroutine。为了避免这种情况，Go 使用增量的方式，一次只重新哈希一部分元素。你的程序可以保持平稳运行，不会突然出现滞后。\n从旧 buckets 迁移到 新 buckets 什么时候发生?\n两种情况:\n添加新的键值对 从 map 中删除键值对 例如 map[\u0026quot;hello\u0026quot;]=2 时，实际第一件事是清空包含 hello 的旧 buckets。\n如果旧 buckets 有溢出桶， map 也会将这些 overflow buckets 的元素移动到新 buckets，移动所有元素后， map 通过在 tophash 字段将旧桶标记为 evacuated 。\n先这么多哈，Go map 确实比这更复杂，很多小细节先不细说。\n参考 本文翻译于 Go Maps Explained: How Key-Value Pairs Are Actually Stored\n","date":"2024-08-22T00:00:00Z","permalink":"https://blog.golang.space/p/go-maps-%E5%88%86%E6%9E%90-%E9%94%AE%E5%80%BC%E5%AF%B9%E5%AE%9E%E9%99%85%E4%B8%8A%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8%E7%9A%84/","title":"Go Maps 分析 键值对实际上是如何存储的?"},{"content":"迭代器 迭代器是将序列的连续元素传递给回调函数的函数。当序列完成或回调返回false时，该函数将停止，指示提前停止迭代。\n1.23 之前的 stdlib 中的迭代器的一个很好的例子是sync.Map.Range方法，它迭代并发安全映射：\n1 2 3 4 5 6 7 8 9 10 var m sync.Map m.Store(\u0026#34;alice\u0026#34;, 11) m.Store(\u0026#34;bob\u0026#34;, 12) m.Store(\u0026#34;cindy\u0026#34;, 13) m.Range(func(key, value any) bool { fmt.Println(key, value) return true }) 从 Go 1.23 开始，可以在 for-range 循环中使用迭代器。从显式调用变成了隐式调用。\n1 2 3 4 5 6 7 8 9 10 // go 1.22 m.Range(func(key, val any) bool { fmt.Println(key, val) return true }) // go 1.23 for key, val := range m.Range { fmt.Println(key, val) } for-range 循环中的range子句接受以下任意函数类型：\n1 2 3 func(func() bool) func(func(K) bool) func(func(K, V) bool) 迭代器类型 迭代器类型在新的iter包中正式定义：\n1 2 3 4 type ( Seq[V any] func(yield func(V) bool) Seq2[K, V any] func(yield func(K, V) bool) ) Seq产生单个值，而Seq2产生对（就像sync.Map.Range一样）。\nYield参数名称只是一个约定，您可以将其命名为foo或bar或其他任何名称 - 唯一重要的是函数签名\n使用Seq / Seq2类型使迭代器定义更加简洁。您可以定义一个返回迭代器的函数：\n1 2 3 4 5 6 7 8 9 10 // Reversed returns an iterator that loops over a slice in reverse order. func Reversed[V any](s []V) iter.Seq[V] { return func(yield func(V) bool) { for i := len(s) - 1; i \u0026gt;= 0; i-- { if !yield(s[i]) { return } } } } 还有一个使用迭代器的函数：\n1 2 3 4 5 6 7 // PrintAll prints all elements in a sequence. func PrintAll[V any](s iter.Seq[V]) { for v := range s { fmt.Print(v, \u0026#34; \u0026#34;) } fmt.Println() } 并以方便的方式组合它们：\n1 2 3 4 func main() { s := []int{1, 2, 3, 4, 5} PrintAll(Reversed(s)) } 拉迭代器 Seq和Seq2可以被认为是推送迭代器，将值推送到收益函数。\n有时，范围循环并不是使用序列值的首选方式。在这种情况下，您可以使用iter.Pull将推式迭代器转换为拉式迭代器：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func main() { s := []int{1, 2, 3, 4, 5} // uses the Reversed iterator defined previously next, stop := iter.Pull(Reversed(s)) defer stop() for { v, ok := next() if !ok { break } fmt.Print(v, \u0026#34; \u0026#34;) } } Pull启动一个迭代器并返回一对函数 - next和stop - 分别返回迭代器的下一个值并停止它。您调用next从迭代器中提取下一个值 - 因此得名。\n如果客户端不使用序列来完成，则它们必须调用stop ，这允许迭代器函数完成并返回。如示例所示，确保这一点的传统方法是使用defer 。\n切片迭代器 slices包添加了几个与迭代器一起使用的函数。\nAll返回切片索引和值的迭代器：\n1 2 3 4 5 s := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} for i, v := range slices.All(s) { fmt.Printf(\u0026#34;%d:%v \u0026#34;, i, v) } // 0:a 1:b 2:c Values返回切片元素上的迭代器：\n1 2 3 4 5 s := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} for v := range slices.Values(s) { fmt.Printf(\u0026#34;%v \u0026#34;, v) } // a b c Backward返回一个倒序切片的迭代器：\n1 2 3 4 5 s := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;} for i, v := range slices.Backward(s) { fmt.Printf(\u0026#34;%d:%v \u0026#34;, i, v) } // 2:c 1:b 0:a Collect将迭代器中的值收集到新切片中：\n1 2 3 4 s1 := []int{11, 12, 13} s2 := slices.Collect(slices.Values(s1)) fmt.Println(s2) // [11 12 13] AppendSeq将迭代器中的值追加到现有切片：\n1 2 3 4 5 s1 := []int{11, 12} s2 := []int{13, 14} s := slices.AppendSeq(s1, slices.Values(s2)) fmt.Println(s) // [11 12 13 14] Sorted将迭代器中的值收集到新切片中，然后对切片进行排序：\n1 2 3 4 s1 := []int{13, 11, 12} s2 := slices.Sorted(slices.Values(s1)) fmt.Println(s2) // [11 12 13] SortedFunc与 Sorted 类似，但具有比较函数：\n1 2 3 4 5 6 7 8 9 10 11 type person struct { name string age int } s1 := []person{{\u0026#34;cindy\u0026#34;, 20}, {\u0026#34;alice\u0026#34;, 25}, {\u0026#34;bob\u0026#34;, 30}} compare := func(p1, p2 person) int { return cmp.Compare(p1.name, p2.name) } s2 := slices.SortedFunc(slices.Values(s1), compare) fmt.Println(s2) // [{alice 25} {bob 30} {cindy 20}] SortedStableFunc与 SortFunc 类似，但使用稳定排序算法。\nChunk返回 s 的最多 n 个元素的连续子切片的迭代器。除最后一个子切片之外的所有子切片的大小均为 n。所有子切片都被剪裁，使其没有超出长度的容量。如果 s 为空，则序列为空：序列中不存在空切片。如果 n 小于 1，Chunk 会发生 panic。\n1 2 3 4 5 6 s := []int{1, 2, 3, 4, 5} chunked := slices.Chunk(s, 2) for v := range chunked { fmt.Printf(\u0026#34;%v \u0026#34;, v) } // [1 2]-2 [3 4]-2 [5 6]-2 [7]-1 map 迭代器 maps包添加了几个与迭代器一起使用的函数：\nAll返回映射中键值对的迭代器：\n1 2 3 4 5 m := map[string]int{\u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, \u0026#34;c\u0026#34;: 3} for k, v := range maps.All(m) { fmt.Printf(\u0026#34;%v:%v \u0026#34;, k, v) } // a:1 b:2 c:3 Keys返回映射中键的迭代器：\n1 2 3 4 5 6 m := map[string]int{\u0026#34;a\u0026#34;: 1, \u0026#34;b\u0026#34;: 2, \u0026#34;c\u0026#34;: 3} for k := range maps.Keys(m) { fmt.Printf(\u0026#34;%v \u0026#34;, k) } fmt.Println() // c a b ","date":"2024-08-12T00:00:00Z","permalink":"https://blog.golang.space/p/go-1.23/","title":"Go 1.23"},{"content":"Trace runtime/trace 包包含一个用于理解 Go 程序和排除故障的强大工具。其中的功能允许人们在一段时间内生成每个 goroutine 执行的跟踪。使用 go tool trace 命令或（或优秀的开源gotraceui 工具），用可视化的探索这些跟踪中的数据。\ntrace 的神奇之处在于，它可以轻松地揭示程序中难以通过其它方式看到的信息。例如，大量 goroutine 在同一个 channel 上阻塞的并发瓶颈可能很难在 CPU profile 中看到，因为没有可供采样的执行。但在 trace 中，将会清晰的显现出来，并且被阻塞的 goroutine 的堆栈跟踪将很快指出罪魁祸首。\nGo 开发人员甚至能够使用 tasks, regions 和 logs 来检测自己的程序，它们可以使用这些将更高级别的关注点和较低级别的执行细节相关联。\n问题 不幸的是，执行跟踪中的大量信息通常是遥不可及的。历史上有四个与 trace 有关的大问题困扰着我们。\ntrace 的开销很高。 trace 不能很好地扩展，并且可能会变的过大而无法分析。 通常不清楚何时开始 trace 以捕获特定的不良行为。 由于缺乏用于理解和解释执行跟踪的公共包，只要最具冒险精神的 gopher 才能以编程方式分析 trace 。 幸运的是，Go 在四个问题都取得了巨大的进展。\n低开销 trace 在 Go 1.21 之前，对于许多应用程序来说，trace 的运行时开销约为 10~20% cpu，这将 trace 限制情景使用情况，而不是像 cpu 分析那样的连续使用情况。事实证明，trace 大部分成本都归结为回溯。运行时产生的续跌事件都附加了堆栈跟踪，对于实际识别 goroutine 在执行的关键时刻正在做什么非常有价值。\n感谢 Felix Geisendörfer 和 Nick Ripley 在优化回溯效率方面所做的工作，执行 trace 的运行时 cpu 开销已大幅消减，对于许多应用程序而言，已将至 1~2%，您可以在Felix 关于该主题的精彩博客文章中阅读有关此处所做工作的更多信息。\n可缩放 traces trace 格式及其事件是围绕相对有效设计的，但需要工具来解析和保留整个 trace 的状态，几百 MiB 的 trace 可能需要几个 GiB 的 RAM 来分析。\n不幸的是，这个问题对于 trace 的生成方式至关重要。为了保持较低的运行时开销，所有事件都被写入相当于线程本地缓冲区的位置。但这意味着事件的出现不符合其真实顺序，并且 trace 工具需要承担起弄清楚到底发生了什么的责任。\n在保持低开销的同时使用 trace 扩展的关键是偶尔分割升生成的 trace。每个分割点的行为有点像一次性同时禁用和重新启用 trace。到目前为止，所有 trace 数据都将代表一个完整且独立的 trace，而新的 trace 数据将从其中断的位置无缝衔接。\n正如您可能想象的那样，解决这个问题需要重新思考和重写运行时中的 trace 实现的大量基础。很高兴地说这项工作已在 go 1.22 中发布并且现已普遍可用。重写带来了许多不错的改进，包括对 go tool trace 命令的一些改进。如果您好奇的话，详细信息都在设计文档中。\n飞行记录 假设您从事 Web 服务，并且 RPC 花费了很长时间。当您知道 RPC 已经花费了一段时间时，您无法开始跟踪，因为缓慢请求的根本原因已经发生并且没有记录。\n有一种技术可以帮助完成此任务，称为飞行记录，您可能已经在其他编程环境中熟悉了该技术。飞行记录的要点是持续跟踪并始终保留最新的跟踪数据，以防万一。然后，一旦发生有趣的事情，程序就可以写出它所拥有的一切！\n在 traces 被分割之前，这几乎是不可能的。但是，由于开销较低，连续trace 现在是可行的，而且运行时现在可以在需要时随时分割跟踪，因此事实证明，实现飞行记录非常简单。\n因此，我们很高兴地宣布进行飞行记录器实验，可在golang.org/x/exp/trace 包中找到。\n请尝试一下！下面是一个设置飞行记录以捕获长 HTTP 请求的示例，以帮助您入门。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 func main() { // Set up the flight recorder. fr := trace.NewFlightRecorder() fr.Start() // Set up and run an HTTP server. var once sync.Once var i int http.HandleFunc(\u0026#34;/test\u0026#34;, func(w http.ResponseWriter, r *http.Request) { start := time.Now() i++ // Do the work... // doWork(w, r) if i \u0026gt; 1000 { time.Sleep(5000 * time.Millisecond) } else { time.Sleep(200 * time.Millisecond) } // We saw a long request. Take a snapshot! if time.Since(start) \u0026gt; 300*time.Millisecond { // Do it only once for simplicity, but you can take more than one. once.Do(func() { // Grab the snapshot. var b bytes.Buffer _, err := fr.WriteTo(\u0026amp;b) if err != nil { log.Print(err) return } // Write it to a file. if err := os.WriteFile(\u0026#34;trace.out\u0026#34;, b.Bytes(), 0o755); err != nil { log.Print(err) return } }) } }) log.Fatal(http.ListenAndServe(\u0026#34;:8081\u0026#34;, nil)) } trace reader api 随着 traces 实现重写，我们还努力清理其他 trace 内部，例如go tool trace 。这催生了创建一个trace reader API 的尝试，该 API 足以共享并且可以使跟踪更容易访问。\n就像飞行记录器一样，我们很高兴地宣布，我们也有一个实验性的跟踪读取器 API，我们愿意与大家分享。它与飞行记录器位于同一包中，golang.org/x/exp/trace 。\n我们认为它足以开始在其上构建东西，所以请尝试一下！下面的示例测量了阻塞等待网络的 goroutine 阻塞事件的比例。\n","date":"2024-08-10T00:00:00Z","permalink":"https://blog.golang.space/p/go-traces/","title":"Go Traces"},{"content":"Etag 1 2 3 4 5 6 7 # 客户端请求 GET /api/data If-None-Match: \u0026#34;abc123\u0026#34; # 之前服务器返回的 ETag # 服务器响应（如果数据未变） HTTP/1.1 304 Not Modified # 不会返回响应体 ETag: \u0026#34;abc123\u0026#34; # 通常会重新确认 ETag ETag 是 HTTP 缓存机制的重要组成部分,可以有效减少不必要的数据传输。\n服务端携带响应头 ETag 时，下次浏览器请求时间将会携带此 ETag 值，可通过 If-None-Match 获取。服务识别到相同的 ETag 可直接返回 304 状态码。\n304 状态码响应很快，不需要返回 Body，该状态码表示 \u0026ldquo;Not Modified\u0026rdquo;，具体的含义为:\n请求的资源未修改 客户端可以继续使用本地缓存 响应体为空，节省带宽 通过上面的理论，以下是 Go/Gin 的 ETag 中间件实现，主要内容简略概括:\n自定义 EtagWriter，捕获响应内容 使用 SHA1 算法生成基于内容的 ETag 处理 If-None-Match 请求头 返回 304 Not Modified（如果内容未变） 返回 200 和 body (如果内容发生变化) 工作流程\n1 2 3 4 5 6 7 8 9 10 浏览器 ---GET---\u0026gt; 服务器 带 ETag 服务器 -----\u0026gt; 比对数据 -----\u0026gt; 发现未修改 服务器 ---304---\u0026gt; 浏览器 空响应体 浏览器 -----\u0026gt; 使用本地缓存 注意\n此实现适用于内容中小响应，中大型静态文件请参考下一章节的 Cache-Control ETag 的生成可以根据需求修改，可以基于时间或版本号 根据 RFC 9110（HTTP/1.1 规范），ETag 的值是一个“quoted-string”，即带引号的字符串。如果 ETag 值前有 W/ 前缀，则表示这是一个弱标签，表明资源内容大致相同，但不是完全相同。强 ETag 则表示资源内容完全相同。 强标签：ETag: \u0026quot;12345abc\u0026quot; 弱标签：ETag: W/\u0026quot;12345abc\u0026quot; SHA1 (160位) 比 MD5 (128位) 有更低的碰撞概率，SHA1 虽然比 MD5 慢一点，但差异极小，对 ETag 生成这种低频操作影响可以忽略。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 type EtagWriter struct { gin.ResponseWriter body bytes.Buffer } func (w *EtagWriter) Unwrap() http.ResponseWriter { return w.ResponseWriter } func (w *EtagWriter) Write(b []byte) (int, error) { return w.body.Write(b) } func EtagHandler() gin.HandlerFunc { return func(ctx *gin.Context) { bw := EtagWriter{ ResponseWriter: ctx.Writer, } ctx.Writer = \u0026amp;bw ctx.Next() hash := sha1.New() buf := bw.body.Bytes() hash.Write(buf) etag := `\u0026#34;` + hex.EncodeToString(hash.Sum(nil)) + `\u0026#34;` if match := ctx.GetHeader(\u0026#34;If-None-Match\u0026#34;); match != \u0026#34;\u0026#34; \u0026amp;\u0026amp; match == etag { ctx.Writer.WriteHeader(http.StatusNotModified) return } ctx.Header(\u0026#34;ETag\u0026#34;, etag) if _, err := bw.ResponseWriter.Write(buf); err != nil { slog.Error(\u0026#34;write err\u0026#34;, \u0026#34;err\u0026#34;, err) } } } Cache-Control Cache-Control 和 ETag 是两种不同的缓存机制，它们的作用和场景不同：\n1 2 3 4 5 Cache-Control: max-age=3600 # 缓存1小时 Cache-Control: no-cache # 每次都需要验证 Cache-Control: no-store # 完全不缓存 Cache-Control: private # 只允许浏览器缓存 Cache-Control: public # 允许中间代理缓存 其特点是:\n基于时间的缓存策略 完全不请求服务器（如果缓存未过期） 适合静态资源（图片、CSS、JS等） 配置简单，性能最好 下方是 Go/Gin 实现的缓存中间件，一般静态资源的获取(HTTP/CSS/JS 等)采用 GET 请求，根据传入的 millisecond 让浏览器缓存一定时间。\n1 2 3 4 5 6 7 8 9 func CacheControlMaxAge(millisecond int) gin.HandlerFunc { age := strconv.Itoa(millisecond) return func(ctx *gin.Context) { if ctx.Request.Method == \u0026#34;GET\u0026#34; { ctx.Header(\u0026#34;Cache-Control\u0026#34;, \u0026#34;max-age=\u0026#34;+age) } ctx.Next() } } 两者可组合使用\n1 2 Cache-Control: max-age=3600 ETag: \u0026#34;abc123\u0026#34; 1小时内直接使用缓存 超过1小时后用ETag验证 既节省资源又保证准确性 建议 建议对于不会变化的静态资源\n1 2 # 长期缓存 Cache-Control: max-age=31536000 # 1年 对于 API 数据\n1 2 3 # 短期缓存+ETag验证 Cache-Control: max-age=60 # 1分钟 ETag: \u0026#34;data-version\u0026#34; 对于时刻变化的内容\n1 2 3 # 只用ETag Cache-Control: no-cache ETag: \u0026#34;content-hash\u0026#34; Goweb 中最佳实践 此实践场景为 Go 提供静态 web 资源访问服务，以此类推，使用 nginx 等其它方式部署 web 静态资源，也可以使用以上的缓存控制方案。\n通过前缀将静态资源分组 对于该分组，使用 gzip 压缩，Cache-Control 缓存到客户端 代码示例里面是通过 embed 内嵌静态资源的，也可以读取磁盘文件 访问根路由时，跳转到静态资源首页 1 2 3 4 5 6 7 const publicPrefix = \u0026#34;/cloud\u0026#34; admin := router.Group(publicPrefix, gzip.Gzip(gzip.DefaultCompression), web.CacheControlMaxAge(7200)) admin.StaticFS(\u0026#34;/\u0026#34;, static.FileSystem()) g.GET(\u0026#34;/\u0026#34;, func(ctx *gin.Context) { ctx.Redirect(http.StatusPermanentRedirect, publicPrefix) }) ","date":"2024-08-01T00:00:00Z","permalink":"https://blog.golang.space/p/http-cache/","title":"HTTP Cache"},{"content":"介绍 Base64 是一种用于将二进制数据转换为文本格式的标准编码。 Base64 通常用于对 JSON、XML 和 HTML 等文本格式的二进制数据进行编码。 Base64 还用于对电子邮件附件中的二进制数据进行编码。\nGo 中的 Base64 编码 Encoding 是将数据从一种格式转换为另一种格式的过程。在本例中，我们将二进制数据转换为文本。 base64 包提供了 EncodeToString 函数，用于将二进制数据编码为 Base64。\n1 2 3 4 5 6 7 8 9 10 11 12 13 package main import ( \u0026#34;encoding/base64\u0026#34; \u0026#34;fmt\u0026#34; ) func main(){ data := []byte(\u0026#34;Hello World!\u0026#34;) encoded := base64.StdEncoding.EncodeToString(data) fmt.Println(encoded) } // SGVsbG8gV29ybGQh EncodeToString 函数将字节切片作为输入并返回字符串。 StdEncoding 变量是实现 Encoding 接口的 *Encoding 类型。 Encoding 接口提供 EncodeToString 功能。\nGo 中的 Base64 解码 Decoding 是将数据从一种格式转换为另一种格式的过程。在本例中，我们将文本转换为二进制数据。 base64 包提供了 DecodeString 函数，用于将 Base64 解码为二进制数据。\nDecodeString 函数将字符串作为输入并返回字节切片。 StdEncoding 变量是实现 Encoding 接口的 *Encoding 类型。 Encoding 接口提供 DecodeString 功能\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main import ( \u0026#34;encoding/base64\u0026#34; \u0026#34;fmt\u0026#34; ) func main(){ data := []byte(\u0026#34;SGVsbG8gV29ybGQh\u0026#34;) decoded, err := base64.StdEncoding.DecodeString(string(data)) if err != nil { fmt.Println(err) } fmt.Println(string(decoded)) } // Hello World! URL编码与解码 base64 包提供 URLEncoding 变量，用于使用 URL 和文件名安全字母表进行 Base64 编码和解码。 URLEncoding 变量是实现 Encoding 接口的 *Encoding 类型。 Encoding 接口提供 EncodeToString 和 DecodeString 功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import ( \u0026#34;encoding/base64\u0026#34; \u0026#34;fmt\u0026#34; ) func main(){ data := []byte(\u0026#34;Hello World!\u0026#34;) encoded := base64.URLEncoding.EncodeToString(data) fmt.Println(encoded) decoded, err := base64.URLEncoding.DecodeString(encoded) if err != nil { fmt.Println(err) } fmt.Println(string(decoded)) } // SGVsbG8gV29ybGQh // Hello World! 该程序的功能与前一个程序相同，但使用 URLEncoding 变量而不是 StdEncoding 变量。\n原始编码和解码 base64 包提供 RawStdEncoding 变量，用于使用标准原始、未填充的 Base64 格式对 Base64 进行编码和解码。 RawStdEncoding 变量是实现 Encoding 接口的 *Encoding 类型。 Encoding 接口提供 EncodeToString 和 DecodeString 功能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import ( \u0026#34;encoding/base64\u0026#34; \u0026#34;fmt\u0026#34; ) func main(){ data := []byte(\u0026#34;Hello World!\u0026#34;) encoded := base64.RawStdEncoding.EncodeToString(data) fmt.Println(encoded) decoded, err := base64.RawStdEncoding.DecodeString(encoded) if err != nil { fmt.Println(err) } fmt.Println(string(decoded)) } 当对需要以文本格式存储的二进制数据进行编码时，原始编码和解码非常有用。程序的输出是：\n1 2 SGVsbG8gV29ybGQh Hello World! 示例：编码和解码 JSON 对象 base64 包提供了 EncodeToString 和 DecodeString 函数用于base64编码和解码。 json 包提供了 Marshal 和 Unmarshal 函数来编码和解码 JSON。 json 包还提供了 MarshalIndent 函数，用于使用缩进编码 JSON。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 package main import ( \u0026#34;encoding/base64\u0026#34; \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; ) type Person struct { Name string Age int } func main(){ p := Person{ Name: \u0026#34;John Doe\u0026#34;, Age: 30, } data, err := json.MarshalIndent(p, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;) if err != nil { fmt.Println(err) } encoded := base64.StdEncoding.EncodeToString(data) fmt.Println(encoded) decoded, err := base64.StdEncoding.DecodeString(encoded) if err != nil { fmt.Println(err) } var p2 Person err = json.Unmarshal(decoded, \u0026amp;p2) if err != nil { fmt.Println(err) } fmt.Println(p2) } // eyJBY2UiOjMwLCJOYW1lIjoiSm9obiBEb2UifQ== // {30 John Doe} MarshalIndent 函数接受一个值并返回一个字节切片。 MarshalIndent 函数还采用前缀和缩进字符串。该前缀被添加到输出的每一行之前。缩进字符串用于缩进输出的每个级别。 MarshalIndent 函数对于使用缩进编码 JSON 非常有用。\nUnmarshal 函数采用一个字节切片和一个指向值的指针。 Unmarshal 函数对 JSON 编码数据进行解码，并将结果存储在 v 指向的值中。如果 JSON 编码数据不是有效表示， Unmarshal 函数将返回错误v 指向的值。\nBase64包中的其他函数 NewEncoder - 返回一个新的 Base64 流编码器。写入返回的 writer，将 base64 数据编码为 w。 NewDecoder - 返回一个新的 Base64 流解码器。从 r 读取解码 Base64 数据到 w。 NewEncoding - 返回由给定字母表定义的新自定义编码，该编码必须是不包含填充字符“=”的 64 字节字符串。 RawStdEncoding - 返回标准原始、未填充的 base64 编码。 Base64 包中的其他类型 Encoding - 表示 Base64 编码/解码方案，由 64 个字符的字母表定义。最常见的用法是通过标准预定义编码 StdEncoding 和 URLEncoding。 CorruptInputError - 报告输入不是有效的 Base64 数据的错误。 参考 本文翻译于 Golang Base64 Encoding and Decoding ","date":"2024-07-26T00:00:00Z","permalink":"https://blog.golang.space/p/base64-%E7%BC%96%E8%A7%A3%E7%A0%81/","title":"Base64 编解码"},{"content":"如果你在 Go 1.22 或更早版本中使用 Timer.Reset() ，你可能会做错。甚至《100 Go Mistakes》一书（关于 Go 的细微差别通常是正确的）也犯了错误。\n让我们看看问题可能是什么以及如何解决它。\ntime.After 在 Go ≤1.22 的循环中使用 time.After() 可能会导致大量内存使用。考虑这个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // go 1.22 type token struct{} func consumer(ctx context.Context, in \u0026lt;-chan token) { const timeout = time.Hour for { select { case \u0026lt;-in: // do stuff case \u0026lt;-time.After(timeout): // log warning case \u0026lt;-ctx.Done(): return } } } 消费者从输入通道读取令牌，如果一小时后通道中没有出现值，则会发出警报。\n让我们编写一个客户端来测量 100K 通道发送后的内存使用情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // go 1.22 func main() { ctx, cancel := context.WithCancel(context.Background()) defer cancel() tokens := make(chan token) go consumer(ctx, tokens) memBefore := getAlloc() for range 100000 { tokens \u0026lt;- token{} } memAfter := getAlloc() memUsed := memAfter - memBefore fmt.Printf(\u0026#34;Memory used: %d KB\\n\u0026#34;, memUsed/1024) // Memory used: 20379 KB } 什么是 getAlloc 1 2 3 4 5 6 7 8 // getAlloc returns the number of bytes of allocated // heap objects (after garbage collection). func getAlloc() uint64 { var m runtime.MemStats runtime.GC() runtime.ReadMemStats(\u0026amp;m) return m.Alloc } time.After 在幕后创建一个计时器，该计时器在到期之前不会被释放。由于我们使用了较长的超时（一小时），因此 for 循环本质上创建了无数尚未释放的计时器。这些计时器总共使用约 20 MB 的内存。这显然不是我们想要的。\n错误的解决方案 我们创建一个计时器并在每次循环迭代中重置它怎么样？看起来很合理。这是 100 Go Mistakes 建议的解决方案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // go 1.22 func consumer(ctx context.Context, in \u0026lt;-chan token) { const timeout = time.Hour timer := time.NewTimer(timeout) for { timer.Reset(timeout) select { case \u0026lt;-in: // do stuff case \u0026lt;-timer.C: // log warning case \u0026lt;-ctx.Done(): return } } } // Memory used: 0 KB 由于我们重复使用相同的计时器实例而不是创建新实例，因此内存使用问题得到解决。但问题是，这不是 Go ≤1.22 中使用 Reset 方法的方式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 // go 1.22 func main() { const timeout = 10 * time.Millisecond t := time.NewTimer(timeout) time.Sleep(20 * time.Millisecond) start := time.Now() t.Reset(timeout) \u0026lt;-t.C fmt.Printf(\u0026#34;Time elapsed: %dms\\n\u0026#34;,time.Since(start).Milliseconds()) // expected: Time elapsed: 10ms // actual: Time elapsed: 0ms } 计时器 t 的超时时间为 10 毫秒。所以我们等待了 20ms 后，它已经过期了，并向 t.C 通道发送了一个值。由于 Reset 不会排空通道，因此 \u0026lt;-t.C 不会阻塞并立即继续。另外，由于 Reset 重新启动了计时器，10 毫秒后我们将在 t.C 中看到另一个值。\n这不是一个小问题。让我们看看如果消费者中的“do stuff”分支花费的时间超过计时器超时时间会发生什么：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // go 1.22 func consumer(ctx context.Context, in \u0026lt;-chan token) { const timeout = 10 * time.Millisecond timer := time.NewTimer(timeout) for { timer.Reset(timeout) select { case \u0026lt;-in: // do stuff time.Sleep(20 * time.Millisecond) case \u0026lt;-timer.C: panic(\u0026#34;should not happen\u0026#34;) case \u0026lt;-ctx.Done(): return } } } 由于计时器通道未耗尽，因此无论 Reset 调用如何，都会执行计时器分支，从而导致恐慌。\n让我在这里引用 Go stdlib 文档：\nFor a Timer created with NewTimer, Reset should be invoked only on stopped or expired timers with drained channels.\n对于使用 NewTimer 创建的计时器，仅应在通道已耗尽的停止或过期计时器上调用 Reset。\n它可能不是很直观，但它是在 Go ≤1.22 中正确使用 Reset 的唯一方法。\n1.23 修复 Go 1.23 修复了重置问题。再次引用文档：\nThe timer channel associated with a Timer is now unbuffered, with capacity 0. The main effect of this change is that Go now guarantees that for any call to a Reset (or Stop) method, no stale values prepared before that call will be sent or received after the call.\n与 Timer 关联的计时器通道现在是无缓冲的，容量为 0。此更改的主要效果是，Go 现在保证对于任何对 Reset（或 Stop）方法的调用，不会发送该调用之前准备的过时值，或者通话后收到。\n但如果您查看代码，您会发现通道实际上仍在缓冲中：\n1 2 3 4 5 6 7 8 // As of Go 1.23, the channel is synchronous (unbuffered, capacity 0), // eliminating the possibility of those stale values. func NewTimer(d Duration) *Timer { c := make(chan Time, 1) t := (*Timer)(newTimer(when(d), 0, sendTime, c, syncTimer(c))) t.C = c return t } time/sleep.go\n根据提交消息，Go 团队将计时器通道保留为缓冲状态（与代码注释所述相反）。但他们还破解了 chan 类型本身，以返回计时器通道的零长度和容量：\nruntime/chan.go • commit message\n对我来说这似乎是一个肮脏的黑客方法，但我懂什么？\n1.23 之前的解决方案 虽然简单的 Reset 应该适用于 1.23+，但在早期版本中，我们必须确保计时器停止或过期，并且具有耗尽的通道。让我们编写一个辅助函数并在消费者中使用它：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // resetTimer stops, drains and resets the timer. func resetTimer(t *time.Timer, d time.Duration) { if !t.Stop() { select { case \u0026lt;-t.C: default: } } t.Reset(d) } // go 1.22 func consumer(ctx context.Context, in \u0026lt;-chan token) { const timeout = time.Hour timer := time.NewTimer(timeout) for { resetTimer(timer, timeout) select { case \u0026lt;-in: // do stuff case \u0026lt;-timer.C: // log warning case \u0026lt;-ctx.Done(): return } } } 现在，无论超时值和“do stuff”执行时间如何，消费者都可以保证正常工作。\n1 2 3 4 5 6 7 8 9 10 11 // go 1.22 func main() { const timeout = 10 * time.Millisecond t := time.NewTimer(timeout) time.Sleep(20 * time.Millisecond) start := time.Now() resetTimer(t, timeout) \u0026lt;-t.C fmt.Printf(\u0026#34;Time elapsed: %dms\\n\u0026#34;, time.Since(start).Milliseconds()) } 1.23 后的解决方案 从 Go 1.23 开始，垃圾收集器可以释放活动的（但未引用的）计时器。因此循环中的 time.After 不会堆积内存：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // go 1.23 func consumer(ctx context.Context, in \u0026lt;-chan token) { const timeout = time.Hour for { select { case \u0026lt;-in: // do stuff case \u0026lt;-time.After(timeout): // log warning case \u0026lt;-ctx.Done(): return } } } 当然，它仍然会进行大量分配。因此，您可能更喜欢 NewTimer + Reset 方法 - 它不会创建新的计时器，因此 GC 不需要收集它们。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // go 1.23 func consumer(ctx context.Context, in \u0026lt;-chan token) { const timeout = time.Hour timer := time.NewTimer(timeout) for { timer.Reset(timeout) select { case \u0026lt;-in: // do stuff case \u0026lt;-timer.C: // log warning case \u0026lt;-ctx.Done(): return } } } 以下两个选项（ time.After VS timer.Reset ）：\n1 2 BenchmarkAfter-8 24 49271620 ns/op 23201095 B/op 300012 allocs/op BenchmarkReset-8 40 29428138 ns/op 652 B/op 8 allocs/op 胜利者已经很明显了。\ntime.AfterFunc 更糟糕的是， time.AfterFunc 还创建了一个计时器，但是是一个非常不同的计时器。它有一个 nil C 通道，因此 Reset 方法的工作方式不同：\n如果计时器仍然处于活动状态（未停止，未过期）， Reset 会清除超时，从而有效地重新启动计时器。 如果计时器已停止或到期， Reset 会安排新的函数执行。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func main() { var start time.Time work := func() { fmt.Printf(\u0026#34;work done after %dms\\n\u0026#34;, time.Since(start).Milliseconds()) } // run work after 10 milliseconds timeout := 10 * time.Millisecond start = time.Now() // ignore the data race for simplicity t := time.AfterFunc(timeout, work) // wait for 5 to 15 milliseconds delay := time.Duration(5+rand.Intn(11)) * time.Millisecond time.Sleep(delay) fmt.Printf(\u0026#34;%dms has passed...\\n\u0026#34;, delay.Milliseconds()) // Reset behavior depends on whether the timer has expired t.Reset(timeout) start = time.Now() time.Sleep(50*time.Millisecond) } 如果计时器尚未到期， Reset 会清除超时：\n1 2 8ms has passed... work done after 10ms 如果计时器已过期，Reset 会安排新的函数调用：\n1 2 3 work done after 10ms 13ms has passed... work done after 10ms 最后 重申一下：\nGo ≤ 1.22：对于使用 NewTimer 创建的 Timer ， Reset 只能在通道耗尽的计时器停止或过期时调用。 Go ≥ 1.23：对于使用 NewTimer 创建的 Timer ，在任何状态（活动、停止或过期）的计时器上调用 Reset 都是安全的。不需要通道耗尽，因为计时器通道（某种程度上）不再被缓冲。 对于使用 AfterFunc 创建的 Timer ， Reset 要么重新安排该函数（如果计时器仍然处于活动状态），要么安排该函数再次运行（如果计时器已已停止或已过期）。 [Documentation pre-1.23] • [Documentation 1.23+] • 100 Go Mistakes\n定时器并不是 Go 中最明显的东西，不是吗？\n参考 本文翻译于 Resetting timers in Go\n","date":"2024-07-18T00:00:00Z","permalink":"https://blog.golang.space/p/%E5%9C%A8-go-%E4%B8%AD%E9%87%8D%E7%BD%AE%E8%AE%A1%E6%97%B6%E5%99%A8/","title":"在 Go 中重置计时器"},{"content":"2023 年，Go 1.21 引入了配置文件引导优化（PGO）。使用 PGO，您可以在运行时向 Go 编译器提供应用程序的配置文件，然后 Go 编译器使用该配置文件就如何在下一个构建中优化代码做出更明智的决策。\nGoogle 和 Uber 的团队从 2021 年开始合作构建 PGO。我们一起尝试了各种优化，以提高计算效率并降低成本。如今，Uber 已在整个车队范围内推出了 PGO，降低了许多服务的 CPU 利用率。阅读更多内容，了解如何在 Go 应用程序中使用 PGO。\n什么是PGO？ 当您构建 Go 二进制文件时，Go 编译器会执行优化，尝试生成性能最佳的二进制文件。但这并不总是一件容易的事：在许多情况下，过度激进的优化实际上可能会损害性能或导致构建时间过长，需要权衡取舍。在不知道代码在运行时如何使用的情况下，编译器使用静态启发式方法来对代码最常调用的路径进行最佳猜测，然后进行相应的优化。\n但是，如果您可以准确地告诉编译器您的代码在运行时如何使用呢？有了 PGO，您就可以做到。如果您在生产中收集应用程序的配置文件，然后在下一个构建中使用此配置文件，编译器可以做出更明智的决策，例如更积极地优化最常用的函数，或更准确地选择函数内的常见情况。\n在 Go 应用程序中使用 PGO 使用 PGO 非常简单。只需在运行时收集应用程序的配置文件，然后在下一次构建时向编译器提供配置文件即可。具体做法如下：\n导入并启用分析：在 main 包中，导入 net/http/pprof 包。这会自动将 /debug/pprof/profile 端点添加到服务器以获取 CPU 配置文件。\n收集配置文件：照常构建您的项目，然后在代表性环境（例如生产、登台）或实际测试条件下运行您的应用程序。当您的应用程序正在运行并经历典型负载时，从您在上一步中创建的服务器端点下载配置文件。例如，如果您的应用程序在本地运行：\n1 curl -o cpu.pprof \u0026#34;http://localhost:8080/debug/pprof/profile?seconds=30\u0026#34; 使用配置文件优化您的下一个构建：现在您有了配置文件，您可以在下一个构建中使用它。当 Go 工具链在主包目录中找到名为 default.pgo 的配置文件时，它会自动启用 PGO。或者， go build 的 -pgo 标志采用用于 PGO 的配置文件的路径。我们建议将 default.pgo 文件提交到您的存储库，以便用户自动访问该配置文件，并且您的构建保持可重现（并且高性能！）：\n1 2 $ mv cpu.pprof default.pgo $ go build 衡量改进：如果您能够复制创建第一个配置文件的条件（例如，使用每秒提供恒定数量查询的负载测试），那么您可以使用优化的构建和收集新的配置文件使用 go tool pprof 命令将其与第一个进行比较，以测量 CPU 使用率的减少情况：\n1 $ go tool pprof -diff_base nopgo.pprof yespgo.pprof 有关如何对性能改进进行基准测试的详细示例以及更多信息，请务必查看 Go 博客中的这篇文章 。您还可以了解 PGO 在幕后的工作原理以及如何在 Go docs 中生成更强大的分析策略。\n参考 本文翻译于 Boost performance of Go applications with profile-guided optimization\n","date":"2024-07-12T00:00:00Z","permalink":"https://blog.golang.space/p/%E9%80%9A%E8%BF%87%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%BC%95%E5%AF%BC%E4%BC%98%E5%8C%96%E6%8F%90%E5%8D%87-go-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%80%A7%E8%83%BD/","title":"通过配置文件引导优化提升 Go 应用程序的性能"},{"content":"SOLID 原则是一组设计指南，可帮助开发人员编写更可维护、可扩展和可测试的代码。\n构建软件是一个不断变化的挑战。为了应对这种复杂性，开发人员依靠经过验证的设计原则来编写健壮、适应性强且易于管理的代码。其中一组原则是 SOLID（由 Robert C. Martin 首先提出）。\nSOLID 代表：单一职责、开闭式、里氏替换、接口隔离和依赖倒置。每条原则在提高程序的可维护性、可扩展性和可测试性方面都发挥着至关重要的作用。\n尽管Golang不是纯粹的面向对象语言，但我们仍然可以应用SOLID原则来改进我们的Go代码。在这篇文章中，我们将深入研究每个原则，探索其含义，并发现如何在 Go 中有效地利用它。\nS - 单一责任原则 单一职责原则 (Single Responsibility Principle) 规定结构/包应专注于单个明确定义的功能区域。将每个结构想象成具有特定专业知识的专家。这可以使您的代码保持井井有条并降低复杂性。对结构功能的更改是隔离的，使维护和未来的更新变得轻而易举。\nA class should have one, and only one, reason to change.\nRobert C. Martin\nGo 擅长结构体，而不是类。但不用担心，SRP 建议在这里仍然适用。将每个结构想象为一个紧密结合的模块，负责一个明确定义的任务。这种模块化方法可以保持代码整洁、降低复杂性并提高可维护性。\nSRP 的魔力也延伸到了 Go 包中。理想情况下，包应该专注于单一功能领域。这可以最大限度地减少依赖性并使事情井井有条。通过在结构和包中采用 SRP，您可以为干净、可维护和可扩展的 Go 应用程序奠定基础。\n一些好的包的例子：\ncoding/json - 提供 JSON 的编码/解码。 net/url - 解析 URL。 不太好的例子：\nutils - 杂项垃圾场？ 让我们看一个 Go 中的示例，其中有一个 struct Survey，其中包含一些属性和几个方法：GetTitle()、Validate() 和 Save()：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package survey type Survey struct { Title string Questions []string } func (s *Survey) GetTitle() string { return s.Title } func (s *Survey) Validate() bool { return len(s.Questions) \u0026gt; 0 } func (s *Survey) Save() error { // saves the survey to the database return nil } 我们当前的 Survey 结构似乎设计得很好，除了 Save() 方法之外。它的存在违反了 SRP。由于数据存储和调查逻辑位于同一结构中，维护、测试和扩展变得更具挑战性。\n为了遵守 SRP，我们应该区分这些问题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 package survey type Survey struct { Title string Questions []string } func (s *Survey) GetTitle() string { return s.Title } func (s *Survey) Validate() bool { return len(s.Questions) \u0026gt; 0 } type Repository interface { Save(survey *Survey) error } // One of many possible implementations type InMemoryRepository struct { surveys []*Survey } func (r *InMemoryRepository) Save(survey *Survey) error { r.surveys = append(r.surveys, survey) return nil } func SaveSurvey(survey *Survey, repo Repository) error { return repo.Save(survey) } 现在，Survey 结构只负责管理调查数据，而 Repository 接口和 InMemoryRepository 结构则处理数据库操作。\nO——开闭原则 开闭原则 (Open-Closed Principle) 是良好软件设计的基石。它规定软件实体（类、模块、功能等）的设计应考虑到未来的增长。这意味着它们应该开放扩展，允许添加新特性和功能，同时保持关闭修改。修改现有代码来适应新的需求是有风险的，因为它可能会引入错误并使未来的维护成为一场噩梦。\nA module should be open for extension but closed for modification.\nRobert C. Martin\n回到我们的调查示例。让我们向结构体添加一个新方法 - Export()，它可以将调查数据导出到某些外部服务/存储中。由于可能有多个导出目标，因此 Export() 方法有一个 switch 块。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package survey // ... func ExportSurvey(s *Survey, dst string) error { switch dst { case \u0026#34;s3\u0026#34;: // export to s3 return nil case \u0026#34;gcs\u0026#34;: // export to gcs return nil default: return nil } } 如果我们需要添加对其他服务的支持，则当前的实现需要修改，这违反了 OCP。\n为了遵守 OCP，我们可以定义一个 Exporter 接口，这样我们就可以为不同的目标添加新的导出器，而无需修改现有的代码库。\n这遵循 OCP，提高了代码的灵活性和可维护性。我们的代码对扩展开放（我们可以添加新的导出器），但对修改关闭（我们不需要更改 Export() 函数）。\nL - 里氏替换原理 里氏替换原则 (Liskov Substitution Principle) 确保可以在不破坏程序的情况下交换对象。虽然 Go 缺乏传统的继承，但接口实现了这一点。任何类型都可以通过具有与其签名相匹配的方法来“实现”接口。这提高了灵活性——使用接口的代码可以与各种类型一起工作，只要它们履行合同。\nIf S is a subtype of T, then objects of type T may be replaced with objects of type S, without breaking the program\nB. Liskov\n在 Go 中，LSP 的一个很好的例子是 io.Writer 接口：\n1 2 3 type Writer interface { Write(buf []byte) (n int, err error) } io.Writer 的神奇之处在于它能够将字节切片写入任何流：文件、HTTP 响应等。\n现在回到我们的 Survey 结构，我们可以添加一个方法 Write() 来将调查对象写入某处。我们可以简单地让它接受 io.Writer，这样实现就可以决定将其写入何处。\n这个函数的用户现在有很大的灵活性，因为他们只需要使用一些实现 io.Writer 的结构，例如：\n1 2 3 4 5 6 7 file, err := os.Open(\u0026#34;file.go\u0026#34;) if err != nil { log.Fatal(err) } survey := \u0026amp;Survey{Title: \u0026#34;Feedback Form\u0026#34;} WriteSurvey(\u0026amp;Survey, file) I——接口隔离原则 接口隔离原则 (Interface Segregation Principle) 规定客户端不应被迫依赖于他们不使用的接口。这一原则鼓励创建更小、更集中的界面，而不是大型、单一的界面。\nClients should not be forced to depend on methods they do not use.\nRobert C. Martin\n同样，Go 的 io 包就是一个很好的例子。它有多个小接口及其组合，例如 io.Reader、io.ReadWriter、io.ReadCloser、io.ReadWriteCloser 等。\n在我们的调查示例中，假设我们有多种问题类型：文本和下拉列表。我们可以定义一个通用的 Question 接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 type Question interface { SetTitle() AddOption() } type TextQuestion struct { Title string } func (q *TextQuestion) SetTitle(title string) { q.Title = title } func (q *TextQuestion) AddOption(option string) { // not supported as text fields don\u0026#39;t have options } type DropdownQuestion struct { Title string Options []string } func (q *DropdownQuestion) SetTitle(title string) { q.Title = title } func (q *DropdownQuestion) AddOption(option string) { q.Options = append(q.Options, option) } Question 界面中的 AddOption() 方法很突出。这对于 TextQuestion 来说没有意义并且违反了 ISP。以下是我们如何遵循 ISP 并改进设计：将问题界面拆分为更小、更集中的界面：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 type Question interface { SetTitle() } type QuestionWithOptions interface { Question AddOption() } type TextQuestion struct { Title string } func (q *TextQuestion) SetTitle(title string) { q.Title = title } type DropdownQuestion struct { Title string Options []string } func (q *DropdownQuestion) SetTitle(title string) { q.Title = title } func (q *DropdownQuestion) AddOption(option string) { q.Options = append(q.Options, option) } D - 依赖倒置原则 依赖倒置原则 (Dependency Inversion Principle) 规定高级模块不应依赖于低级模块。两者都应该依赖于抽象。\n简单来说，DIP 建议您的代码应该依赖于接口或抽象类，而不是具体的类或函数。这种控制反转减少了软件不同部分之间的耦合，使其更加模块化、可扩展且易于测试。\nAbstractions should not depend on details. Details should depend on abstractions.\nRobert C. Martin\n作为示例，我们可以引入一个处理调查创建的 SurveyManager 结构，您可以想象它依赖于数据库。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type InMemoryRepository struct { surveys []*Survey } type SurveyManager struct { store InMemoryRepository } func NewSurveyManager() *SurveyManager { return \u0026amp;SurveyManager{ store: InMemoryRepository{}, } } func (m *SurveyManager) Save(survey *Survey) error { return m.store.Save(survey) } 这里糟糕的设计是它严重依赖InMemoryRepository，违反了高层模块不应该依赖低层模块的原则。\n同样，接口和构造函数可以帮助我们解耦事物：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type Repository interface { Save(survey *Survey) error } type SurveyManager struct { store Repository } func NewSurveyManager(store Repository) *SurveyManager { return \u0026amp;SurveyManager{ store: store, } } func (m *SurveyManager) Save(survey *Survey) error { return m.store.Save(survey) } 结论 SOLID 原则是构建干净、可维护和可扩展软件的基石。虽然具体的实现细节可能会因编程语言的不同而有所不同（例如在 Go 中使用接口组合而不是继承），但 SOLID 的核心原则仍然普遍适用。通过遵循这些原则，开发人员可以编写更具适应性、更容易测试并最终更能适应变化的代码，无论他们选择哪种语言。\n参考 本文翻译于 Mastering SOLID Principles with Go Examples ","date":"2024-07-10T00:00:00Z","permalink":"https://blog.golang.space/p/%E9%80%9A%E8%BF%87-go-%E7%A4%BA%E4%BE%8B%E6%8E%8C%E6%8F%A1-solid-%E5%8E%9F%E5%88%99/","title":"通过 Go 示例掌握 SOLID 原则"},{"content":"这些可能是您在尝试使用 Go 的 HTTP 客户端时看到的第一组代码片段。\n1 2 3 4 resp, err := http.Get(\u0026#34;http://example.com/\u0026#34;) ... resp, err := http.Post(\u0026#34;http://example.com/upload\u0026#34;, \u0026#34;image/jpeg\u0026#34;, \u0026amp;buf) ... 类似的代码可能导致你的第一次生产中断。这是非常好的代码，当将以下内容引入其中时，事情开始变得复杂。\n当程序开始大量 HTTP 调用时。 当程序对多个服务主机进行 HTTP 调用时。 其背后的原因是 net/http 包中声明的这个变量。\n认识 DefaultClient DefaultClient 的类型是 *http.Client，http.Client 是包含执行 HTTP 调用的所有方法结构。DefaultClient 是一个 HTTP 客户端，所有底层设置都指向默认值。\n当您尝试调用这些包级 HTTP 方法（例如 http.Get 、 http.Post 、 http.Do 等）时，将使用 DefaultClient 变量。 http.Client 结构中的两个字段可能会将 http.DefaultClient 的“默认”和“共享”行为转化为潜在问题：\n1 2 3 4 type Client struct { Transport RoundTripper Timeout time.Duration } Timeout 的默认值为零，因此 http.DefaultClient 默认情况下不会超时，并且只要连接处于活动状态，就会尝试保留本地端口/套接字。如果请求太多怎么办？答案是发生了生产中断，你将耗尽端口，并且不会有可用的端口进行进一步的 HTTP 调用。\n接下来是 http.Client 中的 Transport 字段。默认情况下，以下 DefaultTransport 将在 DefaultClient 中使用。\n1 2 3 4 5 6 7 8 9 10 11 12 var DefaultTransport RoundTripper = \u0026amp;Transport{ Proxy: ProxyFromEnvironment, DialContext: defaultTransportDialContext(\u0026amp;net.Dialer{ Timeout: 30 * time.Second, KeepAlive: 30 * time.Second, }), ForceAttemptHTTP2: true, MaxIdleConns: 100, IdleConnTimeout: 90 * time.Second, TLSHandshakeTimeout: 10 * time.Second, ExpectContinueTimeout: 1 * time.Second, } （里面有很多东西，但是把你的注意力转向 MaxIdleConns ）\n这是关于它的作用的文档：\n1 2 3 // MaxIdleConns controls the maximum number of idle (keep-alive) // connections across all hosts. Zero means no limit. MaxIdleConns int 由于 DefaultClient 是共享的，因此您最终可能会从中调用多个服务（主机名）。在这种情况下，默认客户端为给定主机集维护的 MaxIdleConns 可能存在不公平的分配。\n一个小例子 让我们在这里举个栗子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type LoanAPIClient struct {} func (l *LoanAPIClient) List() ([]Loan, error) { // .... err := http.Get(\u0026#34;https://loan.api.example.com/v1/loans\u0026#34;) // .... } type PaymentAPIClient struct {} func (p *PaymentAPIClient) Pay(amount int) (error) { // .... err := http.Post(\u0026#34;https://payment.api.example.com/v1/card\u0026#34;, \u0026#34;application/json\u0026#34;, \u0026amp;req) // .... } LoanAPIClient 和 PaymentAPIClient 都通过调用 http.Get 和 http.Post 来使用 http.DefaultClient 。假设我们的程序最初从 LoanAPIClient 进行 80 次调用，然后从 PaymentAPIClient 进行 200 次调用。默认情况下 DefaultClient 仅维护最大100个空闲连接。因此， LoadAPIClient 将占领这 100 个位置中的 80 个位置，而 PaymentAPIClient 将仅获得 20 个剩余位置。这意味着对于来自 PaymentAPIClient 的其余 60 个调用，需要打开和关闭一个新连接。这会对支付API服务器造成不必要的压力。这些 MaxIdleConns 的分配很快就会脱离你的掌控！ （相信我😅）\n我们该如何解决这个问题？ 增加 MaxIdleConns ？是的，您可以，但如果客户端仍然在 LoanAPIClient 和 PaymentAPIClient 之间共享，那么这也会在某种程度上失控。\n我发现了 MaxIdleConns 的兄弟，那就是 MaxIdleConnsPerHost 。\n这有助于为每个端点（主机名）维护可预测数量的空闲连接。\n好吧，我会如何修复它? 如果您的程序正在调用多个 HTTP 服务，那么您很可能还想调整客户端的其他设置。因此，为这些服务提供单独的 http.Client 可能会有所帮助。这样我们就可以在将来需要时对它们进行微调。\n1 2 3 4 5 6 7 type LoanAPIClient struct { client *http.Client } type PaymentAPIClient struct { client *http.Client } 别担心 结论是这样的：使用 http.DefaultClient 开始是可以的。但如果您认为您将拥有更多客户端并且会进行更多 API 调用，请避免这样做。\n提醒：如果您正在编写具有 API 客户端的库，请为您的用户提供一个帮助：提供一种自定义用于进行 API 调用的 http.Client 的方法。这样，您的用户就可以完全控制他们在使用您的客户端时想要实现的目标。\nHTTP 服务器内的 HTTP 客户端与另一个具有 HTTP 客户端的 HTTP 服务器进行通信，所有这些都由您编写。那将是你的提示。\n参考 本文翻译于Know when to break up with Go\u0026rsquo;s http.DefaultClient\n","date":"2024-07-09T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%9F%A5%E9%81%93%E4%BD%95%E6%97%B6-go-%E7%9A%84-http.defaultclient-%E6%96%AD%E5%BC%80/","title":"知道何时 Go 的 http.DefaultClient 断开"},{"content":"日志记录对于任何野蛮生长的应用必不可少。通常，我们会回顾性的查阅日志以了解过去，但在某些情况下，实时访问有关特定用户操作的详细流程是识别问题的最佳(有时是唯一)方法。让我们看看如何使用 Go 及 Slog 包实现这种日志记录功能。\n当用户开始抱怨应用中的特定功能不起作用时，该怎么办？首先，你可能会评估症状并验证用户是否存在意料之外的行为。然后，你可以检查你的错误跟踪服务（这里没什么可看的）、正常运行时间和重要指标（一切正常）。最后，任何潜在有用信息的最后一个来源都隐藏在日志中的某个地方。但是，默认生产日志级别为“INFO”（对吗？），因此，尽管可能存在一些警告和错误，但这些日志不太可能包含有关问题的足够信息。下一步该怎么做？\n在这篇文章中，我想探讨不同的选项，包括如何临时启用详细（通常是选择性）日志记录以进行故障排除，以及如何使这些类型的日志能够随时随地实时轻松访问。这种日志记录有时称为诊断日志记录。\n在本文中，我们将探讨一些不同的策略，用于将诊断日志记录引入由 slog 包支持的 Go 应用程序，并涵盖该过程中的以下主题：\n更新全局日志级别 (无论是否重启) Slog 是大道，大道至简 多 handler Slogging 提高性能的方法 更新全局日志级别 (无论是否重启) 让我们从一些简单明了且适用于任何应用程序的东西开始，而不仅仅是那些用 Go 编写的应用程序。\n你可以暂时将应用程序日志级别更新为“DEBUG”并重新启动它。现在，你已经记录了大量日志，并且（我希望）有一个不错的日志收集和查看服务（即不是普通文件）来搜索相关事件。问题解决了，牛逼。\n对吗? 但是，如果您不能仅仅为了调试而重新启动应用程序怎么办? 这正是 AnyCable 或任何其他服务于数千个持久连接的应用程序（例如，在线活动平台）的情况。在这种情况下，重新启动服务器将需要重新初始化所有活动客户端（重新建立连接并恢复状态）。从用户体验的角度来看，这并不好，从服务器的角度来看也不好，而且大规模的重新连接（也称为连接雪崩）可能会导致严重的负载峰值。\n因此，重新启动服务器不是一种选择。因此我们更改日志记录设置的唯一方法是向应用程序添加一些自定义逻辑。所以，让我们开始写一些 Go。\nSlog 是大道，大道至简 让我们注意 slog 包的两个主要概念：\nslog.Logger 是日志记录入口点，是调用 Info() 、 Debug() 等函数的结构。 slog.Handler 是一个接口，负责处理日志条目（或记录）并执行对日志记录设备的写入、级别过滤、格式化等。 下面是一个使用的基本示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 package main import \u0026#34;log/slog\u0026#34; func main() { opts := \u0026amp;slog.HandlerOptions{ Level: slog.LevelInfo, } logger := slog.New( slog.NewTextHandler(os.Stdout, opts), ) // ... } 请注意，日志记录级别是 handler 的特征，而不是 logger 实例的特征。没有 logger.SetLogLevel(lvl) 函数或任何类似的机制（如在许多日志记录库中）来更改日志级别。那么，我们如何动态地更改日志级别呢？\n有很多解决方法，但我更喜欢的一种如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import \u0026#34;log/slog\u0026#34; var LOG_LEVEL = new(slog.LevelVar) func main() { LOG_LEVEL.Set(slog.LevelInfo) opts := \u0026amp;slog.HandlerOptions{ Level: LOG_LEVEL, } logger := slog.New( slog.NewTextHandler(os.Stdout, opts), ) // ... } // SetLogLevel updates the application log level func SetLogLevel(lvl slog.Level) { LOG_LEVEL.Set(lvl) } 在这里，我们使用特殊 slog.LevelVar 变量作为当前日志记录级别的容器。现在，如果我们想在不中断应用程序的情况下更改日志记录级别，我们可以调用该 SetLogLevel 函数。为了演示，我们可以设置一个 SIGQUIT 信号处理程序来在“DEBUG”和“INFO”之间切换日志值（您可以在此 this gist 找到一个完整的工作示例）。\n如果我们能够轻松访问日志，并且能够满足不断大海捞针的需要，那么这种方法就足够好了，因为在全局范围内启用详细日志记录会产生大量日志。\n我们在开发故障排除日志功能时考虑了两个用例：\n为用户提供轻松的日志访问。 通过后台管理 UI 访问日志。 在这两种情况下，都无法对日志的收集方式做出任何假设。因此，我们需要一种独立于基础设施的方式来按需流式传输详细日志。因此，我们开始寻找同时将日志写入多个输出的方法。\n让我们看看如何使用 slog 实现多输出日志记录。\n多 handler Slogging 我们可以使用扇出模式构建一个多输出记录器。让我们看一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 package main import \u0026#34;log/slog\u0026#34; type MultiHandler struct { left slog.Handler right slog.Handler } func (t *MultiHandler) Enabled(ctx context.Context, level slog.Level) bool { return left.Enabled() || right.Enabled() } func (t *MultiHandler) Handle(ctx context.Context, r slog.Record) (err error) { if t.left.Enabled(ctx, r.Level) { err = t.left.Handle(ctx, r) } if t.right.Enabled(ctx, r.Level) { err = t.right.Handle(ctx, r) } return } func (t *MultiHandler) WithAttrs(attrs []slog.Attr) slog.Handler { return \u0026amp;MultiHandler{t.left.WithAttrs(attrs), t.right.WithAttrs(attrs)} } func (t *MultiHandler) WithGroup(name string) slog.Handler { return \u0026amp;MultiHandler{t.left.WithGroup(name), t.right.WithGroup(name)} } func main() { jsonHandler := slog.NewJSONHandler( os.Stdout, \u0026amp;slog.HandlerOptions{ Level: slog.LevelInfo, }, ) textErrorHandler := slog.NewTextHandler( os.Stderr, \u0026amp;slog.HandlerOptions{ Level: slog.LevelError, }, ) logger := slog.New( \u0026amp;MultiHandler{ jsonHandler, textErrorHandler, }, ) // ... } 我们的 MultiHandler 必须实现以下 slog.Handler 接口：该 Enabled() 函数是记录器用来决定处理程序是否要处理此条目的保护; 如果是，则生成 slog.Record 结构并将其传递给 Handle() 函数。\nWithAttrs() and WithGroup() 函数用于创建附加了给定上下文的处理程序的副本。\n现在，我们只需要创建一个自定义处理程序，即 spy handler ，当且仅当至少有一个用户请求日志时，它将使用所有日志。由于诊断日志记录可以在生产和高峰时段使用，因此存在与性能相关的重要注意事项：\n将 spy handler 附加到记录器时，当它处于非活动状态时，不得产生明显的性能开销（即，它不应该向用户发送消息） 一旦激活， spy handler 不得导致性能下降。 spy handler 必须是非阻塞的（可以跳过一些消息来实现这一点）。 让我们分享一下我们为获得令人满意的效果而采取的步骤！\n提高性能的方法 非阻塞的要求，意味着在单独的 Go 协程中处理日志条目，并使用通道作为传输。我们还需要跟踪处理程序状态，无论是活动还是非活动。因此，我们提出了这个 spy handler 的初始实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 type SpyHandler struct { active bool ch chan *slog.Record } func NewSpyHandler(callback func(*slog.Record)) *SpyHandler { h := \u0026amp;SpyHandler{ ch: make(chan *slog.Record, 2048), } go func() { for r := range h.ch { callback(r) } } return h } func (h *SpyHandler) Enabled(ctx context.Context, level slog.Level) bool { return true } func (h *SpyHandler) Handle(ctx context.Context, r slog.Record) error { if h.active { h.enqueueRecord(\u0026amp;r) } return nil } func (h *SpyHandler) enqueueRecord(r *slog.Record) { select { case h.ch \u0026lt;- r: default: } } 上面代码段中的重要部分如下：\n该 select { ... default:} 模式的使用避免了可能阻塞通道写入操作（如果通道的缓冲区已满，则默认子句只会删除记录）。\nEnabled() 函数中 return true ，我们的处理程序应该消费所有日志，对吧？ 在我们继续完善此实现之前，我们最好运行一些性能测试并检查这种方法是否可行。幸运的是，在 Go 中编写性能测试（或基准测试）是一件轻而易举的事：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 func BenchmarkSpy(b *testing.B) { handler := slog.NewTextHandler(os.Stderr, \u0026amp;slog.HandlerOptions{Level: slog.LevelError}) callback: = func(r *slog.Record) { // Immitate some work to ensure that the spy is not blocking the logger time.Sleep(10 * time.Millisecond) } spy := NewSpyHandler(callback) configs := []struct { spy *SpyHandler active bool }{ {spy, true}, {spy, false}, {nil, false}, } for _, config := range configs { desc := \u0026#34;no spy\u0026#34; if config.spy != nil { desc = \u0026#34;active spy\u0026#34; if !config.active { desc = \u0026#34;inactive spy\u0026#34; } } b.Run(desc, func(b *testing.B) { var logger slog.Logger if config.spy != nil { config.spy.active = config.active logger = slog.New(\u0026amp;MultiHandler{handler, config.spy}) } else { logger := slog.New(handler) } b.ResetTimer() for i := 0; i \u0026lt; b.N; i++ { logger.Debug(\u0026#34;test\u0026#34;, \u0026#34;key\u0026#34;, 1, \u0026#34;key2\u0026#34;, \u0026#34;value2\u0026#34;, \u0026#34;key3\u0026#34;, 3.14) } }) } } 我们得到的结果如下：\n1 2 3 4 BenchmarkSpy BenchmarkSpy/active_spy 401.4 ns/op BenchmarkSpy/inactive_spy 266.0 ns/op BenchmarkSpy/no_spy 8.142 ns/op 哇！监视调试日志比没有监视慢 40 倍。但这并不奇怪：如果我们将基本处理程序的日志级别设置为“DEBUG”，我们将在“无监视”场景中看到类似（甚至更高）的数字。换句话说，在我们的例子中，附加一个活跃的监视大致等于全局启用详细日志。更有趣的是，即使监视处于非活动状态，我们仍然可以观察到明显的开销：数百纳秒 vs 约十几纳秒。\n虽然当有人读取诊断日志时，有一些开销是可以的，但总是有开销是不可接受的。\n我决定仔细研究一下 slog 是如何工作的，以便弄清楚这种开销可能来自哪里。下面是由 Info() 、 Debug() 等函数调用的 slog.Logger.log() 函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func (l *Logger) log(ctx context.Context, level Level, msg string, args ...any) { if !l.Enabled(ctx, level) { return } var pc uintptr if !internal.IgnorePC { var pcs [1]uintptr // skip [runtime.Callers, this function, this function\u0026#39;s caller] runtime.Callers(3, pcs[:]) pc = pcs[0] } r := NewRecord(time.Now(), level, msg, pc) r.Add(args...) if ctx == nil { ctx = context.Background() } _ = l.Handler().Handle(ctx, r) } 你可以看到，它做的第一件事是调用 Enabled() 函数，它依赖于与处理程序相同的函数。然后，如果处理程序响应“是，我已启用”，我们将分多个阶段生成日志条目记录。看完这段代码后，我意识到了什么？我知道有两个函数（特别是 Enabled() 和 Handle() ）的存在是有原因的：构建日志记录不是一个免费操作;从性能的角度来看，首先构建记录，然后才检查日志级别（如果我们只有函数 Handle() ）将不是最佳的。\n您可能已经意识到我们需要应用的快速修复程序，以避免在非活动状态期间进行间谍开销：\n1 2 3 4 func (h *SpyHandler) Enabled(ctx context.Context, level slog.Level) bool { - return true + return h.active } 而这个变化之后的基准测试结果要好得多：\n我们可以看到，开销现在在误差范围内。\n当我们将这个概念验证转变为更强大的解决方案时，让我跳过这一部分（通过用原子替换布尔活动字段以实现安全的并发，并在输出中引入缓冲区）。相反，我想谈谈我们在查看 slog 源代码时发现的另一个优化。\n嘿，您可以在 GitHub 上找到完整版的 SpyHandler：palkan/slog-spy. 。它是从 AnyCable+ 中提取的，并且是开源的，尽情享受吧！\nIgnorePC的故事 你有没有注意到这个内部配置参数， internal.IgnorePC ？它负责将调用方指针附加到日志记录，因此我们可以将该 AddSource: true 选项与内置处理程序一起使用。\n在开发中向日志添加源代码行是一个不错的功能，但在生产中不需要。因此，我决定看看禁用此功能是否会带来任何性能提升。为此，我调整了 slog 源代码，将 IgnorePC var 设置为 true，然后再次运行基准测试：\nThe effect of removing the caller information from the log record turned out to be quite good. I wondered why there wasn’t an option to disable this feature (or why we don’t automatically disable it when the AddSource option is set to false). There was an opportunity for a pull request and a contribution here but… this fairy tale had no happy ending: this situation is already known to the Go team (and actually, there’s a benchmark in the slog package) and they decided not to overoptimize. Maybe, that will change in the future. We’ll see.\n现在，您可以使用一些编译器级别的 hacky 来更改项目中的值 IgnorePC ，如下所示：\n1 2 //go:linkname IgnorePC log/slog/internal.IgnorePC var IgnorePC = true 如果你想让日志记录更快，请将这个咒语放在代码中的某个位置。（不过，对于大多数应用程序来说，slog 肯定已经足够快了——投入其中的工作和想法非常出色。\n参考 本文翻译于 Realtime diagnostic logging, or how to really spy on your Go web apps\n","date":"2024-07-04T00:00:00Z","permalink":"https://blog.golang.space/p/%E5%AE%9E%E6%97%B6%E8%AF%8A%E6%96%AD%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95%E5%A6%82%E4%BD%95%E7%9B%91%E8%A7%86-go-web-%E5%BA%94%E7%94%A8/","title":"实时诊断日志记录，如何监视 Go Web 应用"},{"content":"Go 仍然是一门新语言，如果你正在使用它，它很可能不是你的第一门编程语言。\n不同的语言，既为你带来了经验，也带来了偏见。你用以前的任何语言做的事情，在 Go 中用相同的方法可能不是一个好主意。\n学习 Go 不仅仅是学习一种新的语法。这也是学习一种新的思维方式来思考你的程序：\nGo is a language for writing Go programs, not Java programs or Haskell programs or any other language’s programs. You need to think a different way to write good Go programs. But that takes time and effort, more than most will invest. So the usual story is to translate one program from another language into Go and see how it turns out. But translation misses idiom. A first attempt to write, for example, some Java construct in Go will likely fail, while a different Go-specific approach might succeed and illuminate. After 10 years of Java programming and 10 minutes of Go programming, any comparison of the language’s capabilities is unlikely to generate insight, yet here come the results, because that’s a modern programmer’s job.\nRob Pike — Esmerelda’s Imagination\n正如 Rob Pike 所建议的那样，如果你想提高围棋技能，需要投入时间和精力来学习这门语言的习语。\nGo 在几件事上与其他传统语言不同，在本文中，我将重点介绍其中之一：接口。\n下面列出了人们在编写 Go 接口时常犯的错误。这些在其他语言中可能不是错误，但在 Go 中，你需要忘记它们。或者至少，给一个机会，暂时不和他们一起工作，看看这会把你引向何方。\n但在这之前 以下是阅读本文时要记住的事项列表。如果你已经熟悉它们，请随意跳过。\n接口隔离原则：不应强制客户端实现它不使用的接口，也不应强制客户端依赖于它们不使用的方法。\n多态性：一段代码根据它收到的具体数据改变其行为。\nLiskov 替换原则：如果你的代码依赖于抽象，那么一个实现可以被另一个实现替换，而无需更改你的代码。\n抽象的目的不是模糊不清，而是创造一个新的语义层次，在这个层次上可以绝对精确。— E.W.迪克斯特拉\n接口是精确包含用于编写程序的想法的概念。\n以正确的方式使用接口可以带来简单性、可读性和 organic code 设计。\norganic code 是代码会根据你在某个时间点所需的行为而增长。它不会强迫你提前考虑你的类型以及它们之间的关系，因为你很可能无法正确理解它们。\n这就是为什么说 Go 偏爱组合而不是继承。你有一小组行为，你可以从中编写任何你想要的，而不是预定义由其他类型继承的类型并希望它们适合问题域。\nRob Pike 在 golang-nuts 论坛上解释了这种方法：\nGo 的接口不是 Java 或 C# 接口的变体，它们远不止于此。它们是大规模编程和适应性强的演进设计的关键。\n无论如何，理论已经足够了，让我们来看看最常见的错误：\n1. 你创建了太多的接口 接口过多的术语称为接口污染 interface pollution.。当你在编写具体类型之前开始抽象时，就会发生这种情况。由于你无法预见你需要什么抽象，所以很容易写出太多的接口，这些接口在以后要么是错误的，要么是无用的。\nRob Pike 有一个很好的指南，可以帮助我们避免界面污染：\nDon’t design with interfaces, discover them.\nRob Pike\nRob 在这里指出的是，你不需要提前考虑你需要什么抽象。你可以使用具体结构开始设计，并仅在设计需要时创建接口。通过这样做，你的代码会顺其自然的增长到预期的设计。\n我仍然看到人们提前创建接口，因为他们认为他们将来可能需要多个实现。\n我对他们说：\n以一种好的方式懒惰。创建接口的最佳时机是你真正需要它的时候，而不是你预测需要它的时候。下面是一个通过提前思考创建接口的示例，以及它导致了什么。\n无用的接口往往只有一个实现。它们只是增加了一个额外的间接级别，迫使程序员在真正想要实现时总是通过它们。\n接口是有代价的：这是您在推理代码时需要记住的一个新概念。正如 Djikstra 所说，理想的界面必须是“a new semantic level in which one can be absolutely precise.”。\n如果你的代码需要 Box 的概念，仅由 Box 实现的名为 Container 的额外接口没有带来任何好处，除了混淆。\n因此，在创建接口之前，先问问自己：接口有多个实现吗？我强调使用了‘有’，因为‘将会有’假设了你能预测未来，而你不能。\n2. 你有太多的方法 在 PHP 项目中，看到 10 种方法接口是很常见的。在 Go 中，接口很小，标准库中所有接口上的平均方法数为 2。\nThe bigger the interface the weaker the abstraction，这是 Go 谚语之一。正如 Rob Pike 所说，这是接口最重要的一点，这意味着接口越小，它就越有用。\n接口可以拥有的实现越多，它的通用性就越强。如果你有一个包含大量方法的接口，则很难有它的多个实现。您拥有的方法越多，接口就越具体。它越具体，不同类型显示相同行为的可能性就越低。\n有用接口的一个很好的例子是 io.Reader 和 io.Writer，它们具有数百个实现。或者 error 接口，它非常强大，可以在 Go 中实现整个错误处理。\n请记住，你可以稍后用其他接口组合接口。例如， ReadWriteCloser 下面是由 3 个较小的接口组成的：\n1 2 3 4 5 type ReadWriteCloser interface { Reader Writer Closer } 3. 你不编写行为驱动的接口 在传统语言中，名词接口如 User、Request、等等都是很常见的。在 Go 中，大多数接口都有一个 er 后缀： Reader Writer Closer 等。这是因为，在 Go 中，接口公开了行为，它们的名称指向了该行为。\n正如我之前在 IO 基础中所写的，在 Go 中定义接口时，你定义的不是某物是什么，而是它提供了什么——行为，而不是事物！这就是为什么 Go 中没有 File 接口，而是 Reader 和 Writer ： 这些是行为，并且是 File 实现 Reader 和 Writer 的东西。\n在官方指南《Effective Go》中也提到了同样的想法：\nGo 中的接口提供了一种指定对象行为的方法：如果某些东西可以做到这一点，那么它可以在这里使用。\n在编写接口时，请尝试考虑操作或行为。如果你定义了一个名为的 Thing 接口，问问自己为什么 Thing 不是一个结构。\n4. 你在生产者端编写接口 我经常在代码审查中看到这一点：人们在编写具体实现的同一包中定义接口。\n但是，也许客户端不想使用生产者界面中的所有方法。请记住，从接口隔离原则中，“不应强迫客户端实现它不使用的方法”。下面是一个示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main // ====== producer side // This interface is not needed type UsersRepository interface { GetAllUsers() GetUser(id string) } type UserRepository struct { } func (UserRepository) GetAllUsers() {} func (UserRepository) GetUser(id string) {} // ====== client side // Client only needs GetUser and // can create this interface implicitly implemented // by concrete UserRepository on his side type UserGetter interface { GetUser(id string) } 如果客户想使用 producer 的所有方法，他可以使用具体结构。该行为已通过 struct 方法提供。\n即使客户端想要解耦其代码并使用多个实现，他仍然可以创建一个包含他这边所有方法的接口：\n这些东西是通过 Go 中的接口隐式满足这一事实来实现的。客户端代码不再需要导入某些接口并写入 implements ，因为 Go 中没有这样的关键字。如果 Implementation 具有与 Interface 相同的方法，则 Implementation 已满足该接口，并且可以在客户端代码中使用。\n5. 你的方法返回接口 如果方法返回接口而不是具体结构，则调用该方法的所有客户端都将强制使用相同的抽象。你需要让客户决定他们需要什么抽象，因为代码是他们的庭院。\n当你想使用结构中的某些内容但不能使用时，这很烦人，因为接口没有公开它。这种限制可能有原因，但并非总是如此。这里有一个人为的例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package main import \u0026#34;math\u0026#34; type Shape interface { Area() float64 Perimeter() float64 } type Circle struct { Radius float64 } func (c Circle) Area() float64 { return math.Pi * c.Radius * c.Radius } func (c Circle) Perimeter() float64 { return 2 * math.Pi * c.Radius } // NewCircle returns an interface instead of struct func NewCircle(radius float64) Shape { return Circle{Radius: radius} } func main() { circle := NewCircle(5) // we lose access to circle.Radius } 在上面的例子中，我们不仅失去了对 circle.Radius 的访问权限，而且每次我们想要访问它时，我们都需要用类型断言填充我们的代码：\n1 2 3 4 5 shape := NewCircle(5) if circle, ok := shape.(Circle); ok { fmt.Println(circle.Radius) } 要遵循波斯特尔定律，“你接受什么是自由的，而你发送什么是保守的”，从你的方法中返回具体的结构，并选择用接口接收。\n在 Dave Cheney 的 Practical Go 中，有一篇很好的文章 a nice write-up 解释了为什么以下代码：\n1 2 // Save writes the contents of doc to the file f. func Save(f *os.File, doc *Document) error 通过接受接口进行改进：\n1 2 3 // Save writes the contents of doc to the supplied // Writer. func Save(w io.Writer, doc *Document) error 6. 你创建接口纯粹是为了测试 这是接口污染的另一个原因：创建一个只有一个实现的接口，只是因为你想模拟这个实现。\n如果通过创建许多模拟来滥用接口，则最终会测试从未在生产中使用过的模拟，而不是应用程序的实际逻辑。在你的实际代码中，你现在有 2 个概念（正如 Djikstra 所说，语义级别）可以在其中执行。这只是为了你想要测试的东西。你想在每次创建新测试时将语义级别提高一倍吗？\n例如，你始终可以使用 testcontainers 而不是模拟你的数据库。或者，如果 testcontainers 尚不支持，则只需拥有自己的容器。\n或者，也许你需要 mock 一些东西，但不是整个事情。例如，如果你有一个包含 10 种方法的结构，也许你不需要模拟整个结构。也许你只能模拟一小部分，你可以在测试中使用你的具体结构。模拟整个结构体是一种非常懒惰的测试解决方案。\n如果你编写一个 API，你不需要向你的客户端提供一个接口，这样他们就可以用它来模拟。如果他们想编写模拟，他们可以通过指定自己的接口来自己完成（参见第 4 点）\n7. 您不验证接口合规性 假设你有一个包，该包导出了名为 User 的类型，并且n你实现了该 Stringer 接口，因为出于某种原因，当你打印它时，你不希望显示电子邮件：\n1 2 3 4 5 6 7 8 9 10 package users type User struct { Name string Email string } func (u User) String() string { return u.Name } 客户端具有以下代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;pkg/users\u0026#34; ) func main() { u := users.User{ Name: \u0026#34;John Doe\u0026#34;, Email: \u0026#34;john.doe@gmail.com\u0026#34;, } fmt.Printf(\u0026#34;%s\u0026#34;, u) } 这将正确输出： John Doe 。\n现在，假设您重构，并且错误地删除或注释了 String() 实现，并且您的代码如下所示：\n1 2 3 4 5 6 package users type User struct { Name string Email string } 在这种情况下，代码仍将编译并运行，但输出现在将为 {John Doe john.doe@gmail.com} “没有反馈强制执行之前的意图”。\n当您有接受 User 的方法时，编译器会为您提供帮助，但在上述情况下，编译器不会。\n为了强制执行某个类型实现接口的事实，我们可以执行以下操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package users import \u0026#34;fmt\u0026#34; type User struct { Name string Email string } var _ fmt.Stringer = User{} // User implements the fmt.Stringer func (u User) String() string { return u.Name } 现在，如果我们删除该 String() 方法，我们将在构建时得到以下内容：\n1 cannot use User{} (value of type User) as fmt.Stringer value in variable declaration: User does not implement fmt.Stringer (missing method String) 我们在那一行中所做的是，尝试将一个空 User{} 分配给类型 fmt.Stringer 。由于停止实现 fmt.Stringer ， User{} 收到了投诉。我们使用 _ 作为变量名称，我们并没有真正使用它所以不会执行任何分配。\n上面我们有 User 实现接口。 User 并且是 *User 不同的类型。因此，如果你想实现它， *User 你可以做这样的事情：\n1 var _ fmt.Stringer = (*User)(nil) // *User implements the fmt.Stringer 我也喜欢在这样做时，我的Goland IDE会向我显示一个“实现缺少的方法”选项：\n如需了解详情，请查看 article from Mat Ryer 或 Uber Go Style 的指南。\n虽然这是一个很酷的技巧，但你不需要对每个实现接口的类型都这样做，如果我们有需要接口的函数，如果你尝试使用不实现它们的类型，编译器已经抱怨了。我自己不得不思考一段时间才能为本文想出一个例子，所以真的，这是一个罕见的案例。\n正如我们在 Effective Go 中被警告的那样：\nThe appearance of the blank identifier in this construct indicates that the declaration exists only for the type checking, not to create a variable. Don’t do this for every type that satisfies an interface, though. By convention, such declarations are only used when there are no static conversions already present in the code, which is a rare event.\n就这些了!\n参考 本文翻译于 \u0026lt;7 Common Interface Mistakes in Go\u0026gt;\n","date":"2024-07-01T00:00:00Z","permalink":"https://blog.golang.space/p/go-%E4%B8%AD%E7%9A%84-7-%E4%B8%AA%E5%B8%B8%E8%A7%81%E6%8E%A5%E5%8F%A3%E9%94%99%E8%AF%AF/","title":"Go 中的 7 个常见接口错误"},{"content":"类似以下代码，执行提示失败了，但是转码结果有输出。\n错误是 ERROR exec: \u0026quot;ffmpeg\u0026quot;: executable file not found in $PATH\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func ffmpegPipeExec(ctx context.Context, in io.Reader, out io.Writer, args ...string) error { argsData := append(append([]string{\u0026#34;-y\u0026#34;, \u0026#34;-hide_banner\u0026#34;, \u0026#34;-loglevel\u0026#34;, \u0026#34;error\u0026#34;, \u0026#34;-i\u0026#34;, \u0026#34;pipe:0\u0026#34;}, args...), \u0026#34;pipe:1\u0026#34;) cmd := exec.CommandContext(ctx, \u0026#34;ffmpeg\u0026#34;, argsData...) // nolint cmd.Stdin = in cmd.Stdout = out errOut := bytes.NewBuffer(nil) cmd.Stderr = errOut if err := cmd.Run(); err != nil { slog.Error(err.Error()) } if err := errOut.String(); len(err) \u0026gt; 0 \u0026amp;\u0026amp; strings.Contains(err, \u0026#34;Error\u0026#34;) { return fmt.Errorf(err) } return nil } 问题分析 通过断点检测 Go 基础库，在这里遇到错误。\n1 2 3 4 5 6 7 8 9 10 11 12 if filepath.Base(name) == name { lp, err := LookPath(name) if lp != \u0026#34;\u0026#34; { // Update cmd.Path even if err is non-nil. // If err is ErrDot (especially on Windows), lp may include a resolved // extension (like .exe or .bat) that should be preserved. cmd.Path = lp } if err != nil { cmd.Err = err } } 继续深入\n1 path := os.Getenv(\u0026#34;PATH\u0026#34;) exec.Command 会从环境变量中判断可执行文件是否存在。我通过 brew 安装的 ffmpeg，路径在 /opt/homebrew/bin 目录下，shell 是有写入 PATH 的。\n在终端执行 echo $PATH ，可输出详细环境变量，是正常的，那么可能是 vscode 加载环境变量时出现异常。\n解决方法在 vscode 的 settings 增加，vscode 可以通过 ${env:Name} 的语法引用环境变量。\n1 2 3 \u0026#34;go.toolsEnvVars\u0026#34;: { \u0026#34;PATH\u0026#34;: \u0026#34;${env:PATH}:/opt/homebrew/bin\u0026#34; } 为什么都找不到可执行文件，程序却执行成功输出结果了呢?\n1 2 3 if err := cmd.Run(); err != nil { slog.Error(err.Error()) } 在这一行中，没有返回错误，上层执行认为没有错误，写了一个空文件。\n这里避免返回的原因是认为 ffmpeg 的错误信息会提供更多详情用于分析，但不应该忽略这个错误，可以将此错误放到最后判断。\n参考 Vscode 官方文档\n","date":"2024-05-26T00:00:00Z","permalink":"https://blog.golang.space/p/exec-%E6%89%A7%E8%A1%8C%E6%88%90%E5%8A%9F%E4%BD%86%E5%A4%B1%E8%B4%A5/","title":"Exec 执行成功但失败!"},{"content":"Gitea Actions 下载文件 1 2 3 4 wget https://gitea.com/gitea/act_runner/releases/download/v0.2.10/act_runner-0.2.10-linux-amd64 -O act_runner chmod +x ./act_runner ./act_runner --version 最新版本点这里\n注册到 Gitea 1 ./act_runner register --no-interactive --instance \u0026lt;instance\u0026gt; --token \u0026lt;token\u0026gt; instance 就是 Gitea 的访问地址，例如 https://gitea.com\ntoken 可以在 Gitea 实例的 [管理后台] - [Actions] 获取。\n启动 1 ./act_runner daemon 也可以使用 docker-compose 来启动\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 version: \u0026#34;3.8\u0026#34; services: runner: image: gitea/act_runner:nightly environment: CONFIG_FILE: /config.yaml GITEA_INSTANCE_URL: \u0026#34;${INSTANCE_URL}\u0026#34; GITEA_RUNNER_REGISTRATION_TOKEN: \u0026#34;${REGISTRATION_TOKEN}\u0026#34; GITEA_RUNNER_NAME: \u0026#34;${RUNNER_NAME}\u0026#34; GITEA_RUNNER_LABELS: \u0026#34;${RUNNER_LABELS}\u0026#34; volumes: - ./config.yaml:/config.yaml - ./data:/data - /var/run/docker.sock:/var/run/docker.sock 在存储库设置页面启用 actions 参考 act_runner gitea 仓库\n","date":"2024-04-28T00:00:00Z","permalink":"https://blog.golang.space/p/%E8%AE%BE%E7%BD%AE-gitea-actions/","title":"设置 Gitea Actions"},{"content":"证书自动续签方案 安装 acme.sh 1 2 3 4 git clone --depth 1 https://gitee.com/neilpang/acme.sh.git cd acme.sh ./acme.sh --install -m my@example.com alias acme.sh=~/.acme.sh/acme.sh my@example.com 可以指定自己的邮箱。\n修改默认 CA 服务商，默认的是 zerossl\n1 ./acme.sh --set-default-ca --server letsencrypt 主域名，子域名签发证书 可以使用 HTTP/DNSAPI 两种方式\n1 acme.sh --issue -d example.com -w ./nginx/site/ --issue 表示要签发证书\n-d 指定要签发的域名，签发之前要先设计好 DNS 解析到当前主机哦。\n-w 指定网站的根目录。\n--key-file 指定 key 文件写入哪里\n--fullchain-file 指定 cer 文件写入哪里\n泛域名签发证书 1. 设置 DNS API 必须使用 DNS API 的方式\n如果是阿里云的证书，可以使用以下方式。(其它参考)\n1 2 export Ali_Key=\u0026#34;\u0026lt;key\u0026gt;\u0026#34; export Ali_Secret=\u0026#34;\u0026lt;secret\u0026gt;\u0026#34; 2. 签发泛域名证书 1 acme.sh --issue -d example.com -d \u0026#39;*.example.com\u0026#39; --dns dns_ali 将签发的证书安装到指定目录下 程序将会每 60 天重新签发\n1 2 3 4 5 6 7 acme.sh --install-cert -d example.com \\ --key-file /path/to/keyfile/in/nginx/key.pem \\ --fullchain-file /path/to/fullchain/nginx/cert.pem \\ --reloadcmd \u0026#34;service nginx force-reload\u0026#34; acme.sh --install-cert -d puff.golang.space --key-file /home/apps/gb/nginx/certs/key.pem --fullchain-file /home/apps/gb/nginx/certs/cert.pem --reloadcmd \u0026#34;/home/apps/gb \u0026amp;\u0026amp; docker compose exec -it nginx nginx -s reload\u0026#34; 其它 1 2 3 4 # 升级并保持自动更新 acme.sh --upgrade --auto-upgrade # 关闭自动更新 acme.sh --upgrade --auto-upgrade 0 参考: https://github.com/acmesh-official/acme.sh\nhttps://www.orcy.net.cn/1337.html\nhttps://developers.weixin.qq.com/community/develop/article/doc/0008ae40ca0af83d0d7e3bb6b56013\nhttps://cloud.tencent.com/developer/article/2218945?areaSource=102001.10\u0026traceId=XFvJArbxeBBM3HvlN8MOV\nhttps://www.jianshu.com/p/387dcb9566f7\n","date":"2024-04-01T00:00:00Z","permalink":"https://blog.golang.space/p/%E8%AF%81%E4%B9%A6%E8%87%AA%E5%8A%A8%E7%BB%AD%E7%AD%BE%E6%96%B9%E6%A1%88/","title":"证书自动续签方案"},{"content":"约定 结构体名 RequestQuery 表示请求的 query 参数，实际业务应该名为 业务名+Input。\n结构体名为 RequestBody 表示请求的 body 参数。\n结构体名为 ResponseBody 表示响应的 body 参数。\n设计原则 命名\n名字的寿命可能比项目的生命周期还要长。从变量命名，结构体命名，包名，函数名，到业务名，无处不在，如果变量叫 Channel，业务名叫通道，销售经理叫管道，函数名叫 Pipe，这种割裂感，每位项目参与者真的能明白对方想表达的是什么东西吗?\n代码内的命名还好，一旦是开放的 API ，就不能轻易的更名，所以选择一个清晰简洁通俗易懂的名称，是非常必要的。\n数据请求/响应参数的命名，有大驼峰/小驼峰/蛇形，重点不在于选择哪种方式，而在于统一。看看以下 JSON，你会觉得很享受吗? 每次填写参数的时候，你是否要考虑一下，这个参数是小驼峰还是蛇形来着?\n跟着公司旧项目的命名方式走即可，如果没有旧项目? 可以参考你喜欢的公司用怎样的命名方式，例如看看 ChatGPT ，Twitter(X)，百度等等，选一个作为参考即可。\n1 2 3 4 { \u0026#34;page_number\u0026#34;:1, \u0026#34;maxPageLimit\u0026#34; 2 } 量词命名应当结尾带上单位，例如开始时间 startAtMs 开始时间戳毫秒，StartAtS 开始时间戳秒。文件大小 sizeBytes，这种明细的单位不用查询文档即可知道其含义。当接口发生变更时(例如更换单位)，新增一个变量名即可，例如 SizeMbypes 。\n简单性\n好的 API 应该非常简单的调用，不应该为了一些隐藏或兼容功能，提高调用复杂度。API 不应试图过度减少接口数量，而应该尽可能以最直接的方式公开用户想实现业务的功能。\n可预测性\n在某些 API 中使用了 page 作为分页，那么在相同查询列表的接口中，也应该使用相同的单词，所有接口使用一致的命名规则能够使 API 的参数可以被预测。如果有些接口中叫 page，有些接口叫 page_num，有些接口叫 page_size ，另外的接口用 pageSize，调用者会很混乱，同一个东西为什么要起这么多名字? 是有什么特殊性吗?\n个人编写代码可能会出现这种情况，但更多是因为团队开发才出现这种情况，团队开发者如果明确知道这个模型已经定义了，应当先去了解已定义的模型，而不是自己想当然的创建新模型。\n1 2 3 4 5 6 // 以下函数都是为了分页查询消息。 func findMessages(page,size int) ([]Message,error){} func findMessagesByUserID(pageNum,maxSize int) ([]Message,error){} func findMessagesByUsername(pageSize,max_limit int) ([]Message,error){} func findInformatiI( size,limit int) ([]Message,error){} // What Fuck? 富有表现力\n接口能够清楚的表达他们想做的事情。例如，将文本转换成另外一种语言，用户可能会频繁的调用接口去判断字符串属于哪个语言? 这属于业务上的需求，如果直接提供一个 detectLanguage 接口而不是让用户调用大量接口去猜测，情况会好得多。\n标识符 通过标识符来区分资源。好的标识符应该有以下优点:\n易于使用，不应该含有特殊符号和保留关键字 全局唯一 永久生命周期 生成快速，简单 不可预测，可预测的标识符更容易定位和利用潜在的漏洞 可读，可共享，可验证，应当避免 1，|，L，l，i，I 这些容易混淆，以下字符串中去掉了 容易与 数组 0 混淆的字母 O，去掉了容易与数字 1 混淆的字母I 和 L 。 1 0123456789ABCDEFGHJKMNPQRSTUVWXYZabcdefghjkmnpqrstuvwxyz 在标识符前面应当增加资源，例如设备 /devices/5B82KZMO，那如果想查询分页设备呢? 一般来说，API 仅当一种资源对另外一种资源拥有所有权时，才应依赖于层次关系。例如分页，分页属于资源的属性，并且经常变动不会持久化存储，不应该存在 /page/1 或 /devices/5B82KZMO/page/1 的情况，使用 /devices/5B82KZMO?page=1 更合理。\n那想查询属于该设备的通道列表呢? 子资源是仅存在于父资源的上下文中的，否则会引出一个问题: 哪个设备的通道呢? 使用 /devices/5B82KZMO/channels 比较合理。\n有一个较为矛盾的地方，当随着业务发展，可能会出现只想查询通道，并不关心通道属于谁。这时用 /channels 比较合理，当 device_id 作为查询条件时，此资源查询已包含 /devices/5B82KZMO/channels 的相同功能。\n所以，层级划分时，必须明确子资源是仅存在于父资源的上下文中的。分层不宜过深，建议最大 2 层，例如 /users/1/messages/1，用户和消息两层。当层数过多时，应该考虑是否应该将子资源剥离出来作为顶层资源。\n请求方法 删除资源，正确删除时返回 200，如果资源不存在呢? 有人认为最终结果是正确的所以应该返回 200 结果。有人认为应该区分结果，尝试删除不存在应当返回 404。如果资源存在，尝试访问没有权限的资源怎么办呢? 返回 404 但实际资源是存在，返回 403 无权限但这会被恶意攻击者明确资源存在，可能会被探测并作为攻击目标。\n在设计 API 时，经常会遇到这些选择题，接下来我们将讨论标准 API 应该如何设计，仅供参考，不应该所有实际业务都用标准 API 套用，遇到业务复杂的情况呢? 要灵活。以下内容不是解决问题的金手指，而在于引起一些思考。\nGET (查询资源)\n资源检索，一般通过唯一标识符检索资源，或通过关键信息过滤查找资源。\n此方法应该是幂等的，假设没有发生其它更改的情况，则每次结果都应该相同。\n访问控制，如果某些资源只能被特定用户访问，可以确保资源有单独的父级，例如 /users/:id/messages。\n在分布式项目中，计数很难获取精确的结果，提供这种查询容易给使用者误导，应当用估计值而非精确计数;\n假设对分布在 100 个后端的 1 亿数据做排序，这种查询很容易导致服务器过载。这类微小的功能往往会在未来增加大量的复杂性，且对 API 使用者来说价值相对较小。为了实现一个价值相对较小的业务功能，而增加服务的复杂度，代码的维护复杂性，内存倍增，是值得的吗?\n查询部分资源，大多数情况下，查询部分资源只会有 2 个版本，完整数据版和基础数据版。可以通过 query 参数来指定基础版 field=base，当情况更复杂时，可以指定具体要哪些数据，两种方式应该是二选一实现。fields=name,remark,age，注意当使用后者时，服务端应当小心的对待这些参数，避免 SQL 注入，或不存在的字段输入了 SQL 。\nPOST (创建资源)\n资源创建，请求体包含资源创建信息，并生成对应的资源响应。目标要么是父资源，要么是顶级集合。例如 /users，/devices 。\n资源一旦创建成功，意味着应该允许查询或删除/修改等操作，要保证资源一致性。\nDelete (删除资源)\n通常使用资源唯一标识符删除，例如 DELETE /users/6n12312m 。\n重复删除相同的资源，应当返回正确的结果，无论资源是否存在，其最终达到了删除的目的。可以响应被删除的数据，如果资源不存在时，可能只有资源标识符，资源属性为零值。\nPATCH (部分更新)\n在业务实际使用过程中，并不太需要明确部分更新还是全量更新的区别，建议使用 PUT 替代。\nPUT (替换资源)\n如果使用 PUT 包含 PATCH 的内容，会出现部分更新的状况，此时应该使用 query 参数 fields 来表示哪些参数需要更新，例如 PUT /users/n1i24km?fields=name ，此时表示只更新用户名。\n自定义方法\nREST ful API 是将 API 视为资源的设计方案，在实际业务中，有些行为是动作，比如导入导出，比如设备重启/格式化。有些动作并不一定会对资源属性发生更改。这些自定义的方法几乎都应该使用 POST HTTP Method，当然使用其它 Method 也有应用场景，不明确用什么时，那就应该用 POST 。\n为了避免对资源造成混淆，应当避免使用 / ，可以使用 : 加动词来指示资源的操作，这可能看起来有点奇怪，但避免歧义很重要。冒号是 URL 中保留特殊字符，会被转码为 %3A 。例如导出设备通道 /devices/1/channels:export，导入设备信息 /devices:import。\n如果对多个不同父级的一组资源操作应该怎么处理呢? 例如 /users/1/messages 并不关心用户是谁，而关心操作的子资源，此时可以将父标识替换为通配符，如/users/-/messages，服务端不会去处理父资源，使用通配符从语义上更容易懂。\n通常自定义方法不是幂等的，会有副作用，比如连续 2 次重启设备，第二次执行时设备已经离线了。使用 :\u0026lt;动词\u0026gt;能够区分标准的资源，应当谨慎的对待这些接口。\n分页模式 大量数据被同时查询，会增加接口耗时，对于用户体验不是很好，每次打开客户端，都要等几秒才能看到结果? 正确使用分页模式，将消息分片，每次返回一部分。\n例如用户的消息。\nGET /users/:id/messages?page=1\u0026amp;size=10\n1 2 3 4 type RequestQuery struct{ Page int // page 用来表示请求的哪一页 Size int // size 表示最大取多少条数据 } 响应\n1 { \u0026#34;items\u0026#34;:[], \u0026#34;total\u0026#34;: 200, \u0026#34;next\u0026#34;:\u0026#34;\u0026#34;} items 表示内容列表，total 和 next 一般是二选一存在，当遇到支持跳页时，应该返回 total 表示消息总数，前端可以通过 total 来计算分多少页。 当遇到顺序翻页时( 滚动翻页 )，应当返回 next ，此值是获取下一页的方法。\n导入/导出模式 通常导入导出涉及到查询进度，查询状态，历史记录，下载位置等问题。\n以导出用户信息为例:\nPOST /users/:id/messages:export\n导入/导出是一个行为动作，所以此处应用 POST 动词加上特殊语法来区分，这不是标准 REST API操作。\n1 2 3 4 type RequestBody struct{ Compression int // 指定文件压缩级别 \u0026lt;=0 不压缩，1-9 压缩级别 Filters string // 过滤导出哪些字段 } 导入/导出模式应该持续响应进度，可以返回具体的量值，由前端根据需要是计算百分比，还是显示实际的量值。\n1 2 3 4 5 6 7 type ResponseMetadata struct{ Total int // 总任务量 Current int // 当前执行到第一个任务? Success int // 顺利完成任务总量 Failure int // 操作失败的任务总量 Err string // 如果当前任务执行失败时存在此信息，否则为 undefined } 最终任务完成时，返回文件信息。\n1 2 3 4 type ResponseBody struct{ Path string // 文件地址(如果是本地文件应当返回 path 路径，若是 s3 存储应当返回完整 url 路径) Compression int // 压缩信息 } 其中导出模式，应当另外提供获取文件的接口。\n","date":"2024-03-30T00:00:00Z","permalink":"https://blog.golang.space/p/api-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","title":"API 设计模式"},{"content":"什么是 Context? context 是 Go 标准库中的\n参考 本篇文章翻译于 The Complete Guide to Context in Golang: Efficient Concurrency Management\n","date":"2023-12-02T00:00:00Z","permalink":"https://blog.golang.space/p/golang-context-%E5%AE%8C%E6%95%B4%E6%8C%87%E5%8D%97/","title":"Golang Context 完整指南"},{"content":"什么是 WHIP 和 WHEP ? WHIP 表示 WebRTC-HTTP 入口协议，WHEP 表示 WebRTC-HTTP 出口协议。\nWebRTC 明确决定不适用任何信令协议，以便开发人员能够选择任何现有信令协议。对于流媒体行业来说不是一件好事，大家需要一个众所周知的协议和现成的实现，于是乎产生了 WHIP 和 WHEP。\n在直播例子中，主播将本地媒体传到媒体服务器，就是 WHIP 的用武之地，另一端用户可以在媒体服务器出口端获取流。\n在视频会议中，WebRTC 消除了很多复杂性，对于用户来说可能仅仅是加载网页就能开始会议。\n流媒体行业不同，它依赖 3 个组件，这 3 个组件可能来源于不同的提供者。\n媒体服务器 媒体源，通常是网络摄像机 观众 WHIP 和 WHEP 正是连接三者的答案，WHIP 将媒体源连接到媒体服务器，WHEP 将媒体服务器连接观众。\n在流媒体行业，WebRTC 可能是临时方案，未来更可能是 WebTransport+WebCodecs+WebAssembly 的替代方案。\n参考 翻译 WHIP \u0026amp; WHEP: Is WebRTC the future of live streaming?\n","date":"2023-11-21T00:00:00Z","permalink":"https://blog.golang.space/p/%E4%BB%80%E4%B9%88%E6%98%AF-whip-%E5%92%8C-whep/","title":"什么是 WHIP 和 WHEP"},{"content":"WebRTC 是 Web 实时通信（Real-Time Communication）的缩写，它既是 API 也是协议。WebRTC 协议是两个 WebRTC Agent 协商双向安全实时通信的一组规则。\n可以用 HTTP 和 Fetch API 之间的关系作为类比。WebRTC 协议就是 HTTP，而 WebRTC API 就是 Fetch API。\nWebRTC 协议是一组其他技术的集合体 信令：peer 如何在 WebRTC 中找到彼此 当 WebRTC Agent 启动时，它不知道与谁通信以及他们将要通信的内容。信令解决了这个问题！信令用于引导呼叫，以便两个 WebRTC Agent 可以开始通信。\n信令使用一种现有的协议 SDP（会话描述协议）。SDP 是一种纯文本协议。每个 SDP 消息均由键 / 值对组成，并包含“media sections（媒体部分）”列表。\n任何适合发送消息的架构均可被用于传递 SDP 信息，许多应用程序都使用其现有的基础设施（例如 REST 端点，WebSocket 连接或身份验证代理）来解决适当客户端之间的 SDP 传递问题。\n使用 STUN/TURN 进行连接和 NAT 穿透 ICE（交互式连接建立）是 WebRTC 前现有的协议。ICE 允许在两个 Agent 之间建立连接。这些 Agent 可以在同一网络上，也可以在世界的另一端。ICE 是无需中央服务器即可建立直接连接的解决方案。\n使用 DTLS 和 SRTP 加密传输层 第一个协议是 DTLS（数据报传输层安全性），即基于 UDP 的 TLS。\n第二种协议是 SRTP（安全实时传输协议）。\n首先，WebRTC 通过在 ICE 建立的连接上进行 DTLS 握手来进行连接。与 HTTPS 不同，WebRTC 不使用中央授权来颁发证书。相反，WebRTC 只是判断通过 DTLS 交换的证书是否与通过信令共享的签名相符。\n接下来，WebRTC 使用 RTP 协议进行音频 / 视频的传输。我们使用 SRTP 来保护我们的 RTP 数据包。我们从协商的 DTLS 会话中提取密钥，用来初始化 SRTP 会话。\n通过 RTP 和 SCTP 进行点对点通信 RTP（实时传输协议）和 SCTP（流控制传输协议）。我们使用 RTP 来交换用 SRTP 加密过的媒体数据，使用 SCTP 发送和接收那些用 DTLS 加密过的 DataChannel 消息。\n","date":"2023-11-12T00:00:00Z","permalink":"https://blog.golang.space/p/webrtc-%E5%85%A5%E9%97%A8/","title":"WebRTC 入门"},{"content":"部署 端口\ngrafana 3000 prometheus 9090 node_exporter 9100 创建配置文件\nvim prometheus.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 # prometheus.yml global: scrape_interval: 15s # 每15秒抓取一次指标 evaluation_interval: 15s # 每15秒评估一次规则 scrape_configs: # 可选：也让 Prometheus 监控自己 - job_name: \u0026#39;prometheus\u0026#39; static_configs: - targets: [ \u0026#39;localhost:9090\u0026#39; ] - job_name: \u0026#39;node\u0026#39; static_configs: - targets: [\u0026#39;localhost:9100\u0026#39;] 创建 docker-compose.yml 文件\nvim docker-compose.yml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 services: grafana: image: registry.cn-shanghai.aliyuncs.com/lnton/grafana:latest user: \u0026#34;root:root\u0026#34; container_name: grafana restart: unless-stopped volumes: - ./grafana/datasource:/etc/grafana/provisioning/datasources - ./grafana/data:/var/lib/grafana environment: - GF_PATHS_PROVISIONING=/etc/grafana/provisioning - GF_AUTH_ANONYMOUS_ENABLED=false # 禁止匿名访问，必须登录 # - GF_SERVER_ROOT_URL=http://ip:port # - GF_SERVER_SERVE_FROM_SUB_PATH=true network_mode: host # ports: # - \u0026#39;3000:3000\u0026#39; prometheus: image: registry.cn-shanghai.aliyuncs.com/lnton/prometheus:latest container_name: prometheus volumes: # 将宿主机当前目录下的 prometheus.yml 挂载到容器内 - ./prometheus.yml:/etc/prometheus/prometheus.yml command: - \u0026#39;--config.file=/etc/prometheus/prometheus.yml\u0026#39; restart: unless-stopped network_mode: host #networks: #- monitoring node_exporter: image: quay.io/prometheus/node-exporter:latest command: - \u0026#39;--path.rootfs=/host\u0026#39; network_mode: host pid: host restart: unless-stopped volumes: - \u0026#39;/:/host:ro,rslave\u0026#39; Grafana 配置 SMTP 编辑 docker-compose 文件，给 grafana 增加环境变量\n注意 GF_SMTP_HOST 必须携带端口号\n1 2 3 4 5 6 - GF_SMTP_ENABLED=true - GF_SMTP_HOST=smtp.qiye.163.com:465 - GF_SMTP_USER=xxxxxxx@163.com - GF_SMTP_PASSWORD=password - GF_SMTP_FROM_ADDRESS=xxxxxx@163.com - GF_SMTP_FROM_NAME=name 更新后，按照以下流程测试能否收到邮件\n模板 在仪表板导入模板\nnode_exporter ，可以看看 16098\nlivekit，可以看看 15237\n","date":"2023-11-07T00:00:00Z","permalink":"https://blog.golang.space/p/%E4%BD%BF%E7%94%A8-grafana-%E5%85%A8%E5%AE%B6%E6%A1%B6%E8%BF%9B%E8%A1%8C%E4%B8%BB%E6%9C%BA%E7%9B%91%E6%8E%A7/","title":"使用 Grafana 全家桶进行主机监控"},{"content":"使用 TraceQL 查询 受 PromQL 和 LogQL 的启发，TraceQL 是一种查询语言，设计用于在 Tempo 中选择跟踪。目前，TraceQL 查询可以根据以下内容选择跟踪：\nSpan and resource attributes, timing, and duration 基本聚合， count(), avg(),min(),max(),sum() 构建查询 在 TraceQL 中，查询是一次对一个追踪求值的表达式。查询的结构为一组链式表达式（管道）。管道中的每个表达式都会选择或放弃包含在结果集中的范围集。例如：\n1 { span.http.status_code \u0026gt;= 200 \u0026amp;\u0026amp; span.http.status_code \u0026lt; 300 } | count() \u0026gt; 2 大括号 {} 始终从当前追踪中选择一组范围。自定义属性以 .，span.，resource. 为前缀，内在函数可直接键入。\n关键字\n","date":"2023-10-15T00:00:00Z","permalink":"https://blog.golang.space/p/%E4%BD%BF%E7%94%A8-traceql-%E6%9F%A5%E8%AF%A2/","title":"使用 TraceQL 查询"},{"content":"OpenTelemetry OpenTelemetry 是一个可观察性框架和工具包，用于创建和管理链路，指标和日志等遥测数据。\n它不像 Jaeger，Prometheus 那样的可观察性后端，它专注于遥测数据的生成，收集，管理和导出。数据的存储和可视化由其它工具提供。\n可观察性 什么是可观察性?\n从外部了解应用系统内正发生什么。\n可靠性和指标\n遥测是指从系统发出的有关其行为的数据，数据可以是链路，指标，日志的形式。\n服务是否按照用户期望的运行? 如果用户将一条黑色裤子添加到购物车，但系统显示红色的裤子，显然被认为是不可靠。\n指标是一段时间内，有关基础设置和应用程序的数字数据的聚合。包括 CPU ，错误率 ，调用频率，连接数，请求次数等等。\nSLI ( Service Level Indicator )，表示服务的衡量标准，例如网页加载的速度。\nSLO ( Service Level Objective )，向组织传达可靠性的方式。\n了解分布式追踪 日志\n日志是由服务或其它组件发出的带有时间戳的消息，过去开发人员和运维人员非常依赖它们来帮助理解系统行为。\n但日志对于追踪代码执行并不是非常有用，因为通常缺乏上下文信息，例如它们是从哪里调用的。\n当它们与追踪相关时，会变得更加有用。\nSpans\nSpan 代表一个工作或操作单元。它追踪请求进行的特定操作，描绘执行该操作期间发生的情况。\n包含名称，时间，结构化日志消息或其它元数据。\n分布式追踪\n分布式追踪，记录请求在微服务架构中传播时所采用的路径。\n如果没有追踪，就很难查明分布式系统中性能问题的原因。\n它提高了应用程序或系统运行状况的可见性，并让我们能够调试难以在本地重现的行为。\n信号 Traces 提供了应用程序发出请求时发生的情况。\n通过三个工作单元，用 Spans 表示:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # hello span # 注意，它有一个指示追踪的 trace_id { \u0026#34;name\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;context\u0026#34;: { \u0026#34;trace_id\u0026#34;: \u0026#34;0x5b8aa5a2d2c872e8321cf37308d69df2\u0026#34;, \u0026#34;span_id\u0026#34;: \u0026#34;0x051581bf3cb55c13\u0026#34; }, \u0026#34;parent_id\u0026#34;: null, \u0026#34;start_time\u0026#34;: \u0026#34;2022-04-29T18:52:58.114201Z\u0026#34;, \u0026#34;end_time\u0026#34;: \u0026#34;2022-04-29T18:52:58.114687Z\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;http.route\u0026#34;: \u0026#34;some_route1\u0026#34; }, \u0026#34;events\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Guten Tag!\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2022-04-29T18:52:58.114561Z\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;event_attributes\u0026#34;: 1 } } ] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # hello-greetings span # 这个 span 封装了特定的任务，它与 hello 共享 trace_id，并有 parent_id 指示调用关系。 { \u0026#34;name\u0026#34;: \u0026#34;hello-greetings\u0026#34;, \u0026#34;context\u0026#34;: { \u0026#34;trace_id\u0026#34;: \u0026#34;0x5b8aa5a2d2c872e8321cf37308d69df2\u0026#34;, \u0026#34;span_id\u0026#34;: \u0026#34;0x5fb397be34d26b51\u0026#34; }, \u0026#34;parent_id\u0026#34;: \u0026#34;0x051581bf3cb55c13\u0026#34;, \u0026#34;start_time\u0026#34;: \u0026#34;2022-04-29T18:52:58.114304Z\u0026#34;, \u0026#34;end_time\u0026#34;: \u0026#34;2022-04-29T22:52:58.114561Z\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;http.route\u0026#34;: \u0026#34;some_route2\u0026#34; }, \u0026#34;events\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;hey there!\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2022-04-29T18:52:58.114561Z\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;event_attributes\u0026#34;: 1 } }, { \u0026#34;name\u0026#34;: \u0026#34;bye now!\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2022-04-29T18:52:58.114585Z\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;event_attributes\u0026#34;: 1 } } ] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # hello-salutations # 该 span 代表此跟踪中的第三个操作，它是 `hello` span 的子级，与 `hello-greetings` 同级。 { \u0026#34;name\u0026#34;: \u0026#34;hello-salutations\u0026#34;, \u0026#34;context\u0026#34;: { \u0026#34;trace_id\u0026#34;: \u0026#34;0x5b8aa5a2d2c872e8321cf37308d69df2\u0026#34;, \u0026#34;span_id\u0026#34;: \u0026#34;0x93564f51e1abe1c2\u0026#34; }, \u0026#34;parent_id\u0026#34;: \u0026#34;0x051581bf3cb55c13\u0026#34;, \u0026#34;start_time\u0026#34;: \u0026#34;2022-04-29T18:52:58.114492Z\u0026#34;, \u0026#34;end_time\u0026#34;: \u0026#34;2022-04-29T18:52:58.114631Z\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;http.route\u0026#34;: \u0026#34;some_route3\u0026#34; }, \u0026#34;events\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;hey there!\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2022-04-29T18:52:58.114561Z\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;event_attributes\u0026#34;: 1 } } ] } 在三个 JSON 块，有相同的 trace_id，有 parent_id 来表示层次结构，具有上下文，相关信息，层次结构。\nTracer Provider\n这是 Tracer 的工厂，在大多数应用程序中，Provider 会初始化一次，还包括 Resource 和 Exporter 初始化。\nTracer\ntracer 创建的 span 包含有关给定操作锁发生情况的更多信息，由 Tracer Provider 创建。\nTrace Exporters\n追踪导出器将数据发送给消费者。可以是 OpenTelemetry Collector 或其它后端。\nContext Propagation\n上下文传播是实现分布式跟踪的核心概念。通过上下文传播，Span 可以互相关联并组装成 Tracer。\nContext 是一个对象，其中包含发送和接收服务的信息，用于将一个 Span 与 另一个 Span 关联起来。\nPropagation 是在服务和进程之间移动上下文的机制，它序列化或反序列化上下文对象。OpenTelemetry 支持多种不同的上下文格式。 OpenTelemetry 跟踪中使用的默认格式称为 W3C TraceContext。\nSpans\nSpan 是 Traces 的构建模块。包含以下信息:\nName Parent span ID (empty for root spans) Start and End Timestamps Span Context，每个 Span 不可变对象，包含 trace_id，span_id，state Attributes，包含元数据的键值对，描述追踪操作的信息 Span Events，可以被认为是结构化日志，通常表示持续时间内有意义的单一时间点 Span links，关联多个 span，因果关系。 Span Status，当代码中出现错误时，可以设置 span 状态。 Unset，由处理 span 的后端分配 OK，一切正常 ``Error`，代码中出现错误 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 { \u0026#34;trace_id\u0026#34;: \u0026#34;7bba9f33312b3dbb8b2c2c62bb7abe2d\u0026#34;, \u0026#34;parent_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;span_id\u0026#34;: \u0026#34;086e83747d0e381e\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;/v1/sys/health\u0026#34;, \u0026#34;start_time\u0026#34;: \u0026#34;2021-10-22 16:04:01.209458162 +0000 UTC\u0026#34;, \u0026#34;end_time\u0026#34;: \u0026#34;2021-10-22 16:04:01.209514132 +0000 UTC\u0026#34;, \u0026#34;status_code\u0026#34;: \u0026#34;STATUS_CODE_OK\u0026#34;, \u0026#34;status_message\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;attributes\u0026#34;: { \u0026#34;net.transport\u0026#34;: \u0026#34;IP.TCP\u0026#34;, \u0026#34;net.peer.ip\u0026#34;: \u0026#34;172.17.0.1\u0026#34;, \u0026#34;net.peer.port\u0026#34;: \u0026#34;51820\u0026#34;, \u0026#34;net.host.ip\u0026#34;: \u0026#34;10.177.2.152\u0026#34;, \u0026#34;net.host.port\u0026#34;: \u0026#34;26040\u0026#34;, \u0026#34;http.method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;http.target\u0026#34;: \u0026#34;/v1/sys/health\u0026#34;, \u0026#34;http.server_name\u0026#34;: \u0026#34;mortar-gateway\u0026#34;, \u0026#34;http.route\u0026#34;: \u0026#34;/v1/sys/health\u0026#34;, \u0026#34;http.user_agent\u0026#34;: \u0026#34;Consul Health Check\u0026#34;, \u0026#34;http.scheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;http.host\u0026#34;: \u0026#34;10.177.2.152:26040\u0026#34;, \u0026#34;http.flavor\u0026#34;: \u0026#34;1.1\u0026#34; }, \u0026#34;events\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;OK\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2021-10-22 16:04:01.209512872 +0000 UTC\u0026#34; } ] } Span Kind\nSpan 有以下类型:\nclient，子级通常是 server span，表示同步传出远程调用。 server，父级通常是 client span，表示远程过程调用。 internal，未提供类型，则默认为此类型，表示不跨越 span 的操作。 producer，子级通常是 consumer span，表示创建一个稍后可能会异步处理的作业。 consumer，父级通常是 producer span，表示对 producer 创建的作业的处理，可能再很久之后才开始。 Metrics 对运行时捕获的测量，捕获测量的时刻称为度量事件，不仅包括测量本身，还包括捕获的时间和关联的元数据。\n应用程序和请求指标是可用性和性能的重要指标，自定义指标可以深入了解其如何影响用户体验或业务。收集的数据可用于发出警报或调度决策，以根据高需求自动扩展部署。\nMeter Provider\n是 Metrics 的工厂，它会初始化一次，还包括 Resource 和 Exporter 初始。\nMeter\n创建度量工具，在运行时捕获有关服务的测量结果。\nMetric Exporter\n将数据发送给消费者，可以是标准输出OpenTelemetry Collector 或其它后端。\nMetric Instruments\n测量结果由它捕获，定义如下:\nName Kind Unit Description instrument 的 kind 有:\ncounter，计数器，只会上涨 asynchronous counter，异步计数器，与计数器相同，但每次导出只会收集一次。如果无法访问连续增量，而只能访问聚合值，则可以使用。 UpDownCounter，随着时间积累的值，可以下降。 asynchronous UpDownCounter，与 UpDownCounter 相同，但每次导出时收集一次。 Gauge ，仪表，测量读取时的当前值，例如汽车的功率表。 Histogram ，直方图，值的聚合，例如请求延迟，例如有多少个请求花费的时间大于 1 秒。 Aggregation\n将大量结果组合成有关窗口期发生的度量事件。\n例如:\n系统调用持续时间 请求数量趋势 CPU 或 内存使用情况 账号的平均余额 当前正在处理的活动请求 View\n视图为用户提供自定义输出指标的灵活性。\nLogs Go 版本截止 2023-10-14 尚未实现，略。\nBaggage 是在 Span 之间传递的 Context 信息，它是一个键值对存。\n假设希望追踪中的每个范围都有一个 CustomerID 属性，涉及多个服务，但是 CustomerID 仅一项特定服务可用，为了实现目标，可以使用 Baggage 在整个系统中传播此值。\n通常将 账号标识，用户 ID，产品 ID等等内容，附加到下游服务中的 Span ，以便于搜索时过滤。\n参考 OpenTelemetry-Go Github\nGo 语言实现的 Otel 文档\nOtel 概念\n","date":"2023-10-10T00:00:00Z","permalink":"https://blog.golang.space/p/opentelemetry/","title":"OpenTelemetry"},{"content":"介绍 NSQ 是一个实时分布式消息平台。\n特性:\n支持无单点故障的分布式拓扑 水平可扩展 低延迟，高性能的消息传递 负载均衡和消息多播路由 擅长流式(高吞吐)处理和面向作业(低吞吐)的工作负载 主要在内存中，超过限制将透明的保存在磁盘上。 提供消费者查找生产者的服务发现 等等\u0026hellip; 说明 NSQ 主要是内存消息传递平台，默认情况下，消息会在内存中，这也意味着当服务崩溃时会发生丢失，可以通过 --mem-queue-size=0 来控制将每条消息都持久化到硬盘上。 消息至少传递一次。这意味着由于各种原因(超时/断开连接/重新排队)，消息可以多次传递。执行幂等操作或重复数据删除是用户的责任。 收到消息是无序的，不能依赖消息的顺序。 消费者最终找到所有主题生产者，发现服务被设计最终一致。 设计 单个 nsqd 实例支持同时处理多个数据流，流称为 \u0026ldquo;主题\u0026rdquo;，一个主题有1 个或多个\u0026quot;通道\u0026quot;，每个通道都会主题的所有消息的副本。一个通道通常可以连接多个客户端，假设这些客户端都处于接收消息状态，则消息会随机传递过去。\n首次发布到指定主题时，创建主题，首次订阅指定主题时，创建通道。\n内部设计 NSQ 由 3 个守护进程组成\nnsqd，接收消息，排队消息，传递消息给客户端的进程 nsqlookupd 管理拓扑信息并提供最终一致的服务发现 nsqadmin，是一个 Web UI，用于实时检查集群 参考 NSQ 官方文档\n","date":"2023-09-10T00:00:00Z","permalink":"https://blog.golang.space/p/nsq/","title":"NSQ"},{"content":"减小 Go 二进制文件大小 在未进行任何优化的情况下，由此创建的二进制文件较为庞大。这会浪费存储空间，传送流量。因此，在开发过程中，我们需要考虑对二进制文件进行优化处理，以尽可能地减小其体积，同时保证程序的正常运行。\n使用 go build 构建二进制文件，此时的大小是 19.1 MB，这也太大了。\n使用 go build --ldflags \u0026quot;-s -w\u0026quot; 构建，减少了 5.7 MB。\n经过使用UPX进行压缩，文件大小从19.1MB成功减小至5.4MB。\n总结 使用-ldflags=\u0026quot;-s -w\u0026quot;进行静态链接优化，这将删除二进制文件中的调试信息和符号表，从而减小二进制文件大小。 使用类似于upx的工具进行压缩，进一步减小二进制文件大小。 如果程序中包含网页，请尽可能避免使用框架，而应该使用原生的HTML/CSS/JS来完成。若网页大小大概只有几百KB，则可以直接将其嵌套到二进制文件中。 1 2 # macbook 使用 brew 安装 upx brew install --build-from-source upx ","date":"2023-05-18T00:00:00Z","permalink":"https://blog.golang.space/p/%E5%87%8F%E5%B0%8F-go-%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F/","title":"减小 Go 二进制文件大小"},{"content":"Go 项目的思考与架构设计 读完《Domain-Driven Design with Golang》这本书后，我有了一些感悟。\n领域驱动设计广泛应用于解决大型复杂项目的问题。然而，将 DDD 应用于 CURD 程序可能会过度设计，并且会使交付速度变缓且更加繁琐。在实际开发中，我们面临更多中小型项目快速落地的情景，因此需要寻求开发效率和架构设计之间的平衡点。\n同时，在保证高效率开发和可扩展性的前提下，应避免过度设计，确保代码具有良好的可读性、稳定性和可测试性。\n如果您想深入了解领域驱动设计，可以阅读相关的专业书籍。对我而言，将其中的优点应用于我所遇到的项目，不会完全按照DDD规范去设计和开发，有时可能还会采用反模式。\n从分层架构到分模型架构 通常，编写的应用程序中最多的是 CRUD。在这类项目中，分层架构得到了广泛应用。无论怎样变化，它大致都被分为 API/Service/DAO 三层。随着业务的发展，可能会出现一层内有 20 或 30 个文件，并且一个结构体的方法可能分布在不同的文件中。因此，组件也很难被复用于其他项目。\n那么，为什么架构设计需要分层呢？分层架构的优点在于关注点分离、分而治之、低耦合和高内聚。\n同样具备这些优点的是分模型架构，所谓分模型架构，基于模型驱动设计的思想，将复杂系统拆分为几个相关的模型。每个模型具有独立的职责，并且负责处理特定的功能，这种架构需要架构师对业务领域非常熟悉。\n相比分层架构，它对行为上下文进行了更加明确的界限，使开发者可以专注于自己的领域模型。\n领域就像积木，有简单的基层子域，也有依赖子域实现的更复杂领域。领域和子域几乎可以互换使用，这取决于对话上下文。\n考虑到并不完全采用 DDD，但基于模型驱动设计，接下来将以“DDD lite”的方式称之，因 DDD 一语双关，D 可以是 Domain，可以是 Data。\nDDD lite Golang 有许多谚语，例如 不要通过共享内存来进行通信，而是通过通信来共享内存。 遵循这样的谚语可以提高编程体验和代码质量。\n以下是与 DDD lite 相关的谚语，这些谚语甚至本身就是设计模式。它将帮助我们实现更好的架构设计。在设计时，应考虑到未来可能的需求变化，具备高度的可扩展性和灵活性；而在开发过程中，则需要根据当前的需求和限制，注重实现和可维护性，以达成交付可靠代码的目标。\n通用语言 团队应该使用统一的术语表，这样在针对业务的讨论中就可以更加精准，不会出现词不达意、两个人说的不是同一件事的情况。\n开发者应该在代码中使用这些术语、函数名和变量名，例如用“宝箱的开关”代替“设置属性为 true”。\n有些人思维敏捷，可能会在上一秒谈论这个问题，下一秒谈论另一个问题。对于相似行为的页面，使用同一术语很容易造成误解，甚至在没有图片的情况下很难理解对方在说什么。\n构建一种健壮、无处不在的语言，需要花费时间，没有捷径可走。在沟通和设计阶段，应记录任何术语，并将其添加到术语表中与其他同事分享。\n尽管尝试在多个项目、团队甚至整个公司应用一种共通的语言可能很诱人，但这样做会导致术语失去严谨性，可能会造成混乱。因此，应谨慎考虑并选择最适合特定团队和项目的共通术语。\n依赖倒置 以存储库为例，核心业务依赖于具体存储库的实现，则需要考虑到难以进行扩展，例如从 MySQL 迁移到 PostgreSQL。\n为了方便解耦和测试，可以使核心业务与数据库无关，核心业务依赖抽象接口，实现一个简单的 mockStore 即可进行测试。\n再举一个例子，当数据库成为瓶颈时，可以引入 Redis 缓存。由于核心业务依赖于抽象接口，因此可以扩展缓存实现接口来优化性能。\n实战 REST ful 我们按照以下的方式组织代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 . ├── config # 配置相关代码 ├── config.toml # 配置文件 ├── go.mod ├── go.sum ├── internal # 项目业务 │ ├── api │ │ ├── api.go │ │ ├── message.go │ │ └── user.go │ └── core # 核心业务 │ ├── message # 消息领域 │ │ ├── message.go │ │ ├── model.go │ │ └── store │ │ └── messagedb │ │ └── db.go │ └── user # 用户领域 │ ├── model.go │ ├── store │ │ └── userdb │ │ ├── db.go │ │ ├── db_test.go │ │ ├── record.go │ │ └── user.go │ ├── user.go │ └── user_test.go ├── main.go └── pkg # 工具包 代码的组织方式有很多种，这种较为简单，如果有多个 main 函数，即多个程序时，建议创建 cmd 文件夹，或更改目录结构以符合最适合业务的方式。\ninternal 是一个特殊的目录，它将限制包的导入范围，我们将业务所需全部放在该目录下。\n底下包含两个主要目录，api 和 core。\napi 是 REST ful Web 的具体实现。 core 是核心业务，包含的每个文件夹即是一个领域。 store 是数据存储，使用依赖倒置原则，领域行为依赖于抽象接口，存储库依赖于领域模型。 领域模型与数据库模型如果拆分，将需要写许多转换函数，通过依赖倒置原则，store 直接依赖领域模型。\n接下来会涉及 Go 代码，写这篇文章时，我的安装的版本是 Go1.20.3。\n案例: 查询两个用户对话的历史消息。\n在 [core] - [message] 文件夹下，创建 model.go 文件，写入模型。\n1 2 3 4 5 6 7 8 9 10 11 12 type Message struct { orm.Model SenderID int `gorm:\u0026#34;notNull;default:0;index;comment:发送者\u0026#34;` ReceiverID int `gorm:\u0026#34;notNull;default:0;index;comment:接收者\u0026#34;` Type string `gorm:\u0026#34;type:text;notNull;default:\u0026#39;\u0026#39;;comment:类型\u0026#34;` SessionID int `gorm:\u0026#34;notNull;default:0;index;comment:会话id\u0026#34;` Content []byte `gorm:\u0026#34;type:bytea; notNull; comment:消息\u0026#34;` } func (*Message) TableName() string { return \u0026#34;messages\u0026#34; } 在 [core]-[message] 文件夹下，创建 message.go 文件，写入行为。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // 数据存储抽象 type Storer interface{ InsertOne(b orm.Tabler) error FindMessages(ms []Message, uid,sessionID,limit int) } type Core struct{ ctx context.Context // 我非常确定，整个项目周期不会更换日志组件，这里直接依赖实现 Log *zap.SugaredLogger // 数据交互 store Storer } // 使用值对象的优势是不用担心副作用 func NewCore(log *zap.SugaredLogger, store Storer) Core { return Core { ctx: context.Background(), Log: log, store: store, } } // 每次访问，我们将使用 with 创建一个新的对象 // 拥有当前访问的下上文，以及记录追踪 ID 的日志 // 通过日志追踪，可以详细了解用户的操作行为 func (c Core) With(ctx context.Context, log *zap.SugaredLogger) Core { c.ctx = ctx c.Log = log return c } func (c Core) FindMessages(ms *[]*Message, uid,sessionID,limit int) error { if uid == 0 { return fmt.Errorf(\u0026#34;uid 不能为空\u0026#34;) } return c.store.FindMessages( ms, uid, sessionID, limit, ) } 在 [api]-[message.go] 文件中实现 REST ful\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 type Message struct{ core message.Core } func messageAPI(g *gin.Engine, cfg Config) error { store := messagedb.NewDB(cfg.DB) if err := store.AutoMigrate();err!=nil { return err } core := message.NewCore(zap.S(), store) m := Message{core:core} chat := g.Group(\u0026#34;/chat\u0026#34;, mid.AuthMiddleware(cfg.JWTSecret)) chat.Get(\u0026#34;/messages\u0026#34;, m.FindMessages) } func (m Message) FindMessages(ctx *gin.Context) { core := m.core.With( ctx.Request.Context(), m.core.Log.With(\u0026#34;traceid\u0026#34;, mid.TraceID(ctx)) ) var input struct { SessionID int `form:\u0026#34;session_id\u0026#34;` } if err:=ctx.ShouldBindQuery(\u0026amp;input);err!=nil{ web.Fail(ctx, err) return } // .... } 实战 gRPC 未完结，欲知后事如何，请听下回分解。\n","date":"2023-05-15T00:00:00Z","permalink":"https://blog.golang.space/p/go-%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%80%9D%E8%80%83%E4%B8%8E%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","title":"Go 项目的思考与架构设计"},{"content":"ChatGPT 编写明确和具体的指令。 使用分隔符清楚地指示输入的不同部分。\n使模型清楚的知道，这是独立的部分。就像是人物说话的内容放在双引号内。\n这可以避免造成歧义，例如某些文字并不是对 gpt 的指令。\n三引号 三个反引号 三个破折号 尖括号 要求结构化输出\n可以请求 HTML 或 JSON 输出。\nProvide them in JSON format with the following keys: title,author\n分步骤执行任务\n**给出明确而具体的指示，出示结果模板\n1 2 3 你的任务是以一致的风格回答问题。 \u0026lt;child\u0026gt;:.... \u0026lt;grandparent\u0026gt;:.... 给模型时间去思考，因犯了推理错误，在模型提供最终答案前请求一系列相关的推理 如果给模型一个任务，这个任务太复杂了，它不能在短时间内或用少量的单词完成，它可能会做出一个可能不正确的猜测。\n因此，可以指示模型更长时间地思考问题。\n就像和伙伴交流那样，也可以给出自己推理的解决方案供模型参考，这样模型会给出更接近正确的答复。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 你的认为是确定学生的解决方案是否正确。要解决问题，请执行以下操作: - 首先制定出自己的解决思路。 - 然后将自己的解题思路与学生解题思路进行对比，评估学生解题思路正确与否。在你自己做题之前，不要决定学生的答案是否正确。 使用以下格式: 问题: \u0026lt;问题\u0026gt; 学生: \u0026lt;学生的解题思路\u0026gt; 参考答案: \u0026lt;正确的解题思路及步骤\u0026gt; 结果: \u0026lt;如果学生的解题思路是正确的，此处写 YES，否则写 NO\u0026gt; 问题: ``` 13-8=? ``` 学生的解题思路: ``` 13-(3+5)=13-3-5=10-5=5，结果为 5 ``` 模型的限制 尽管语言模型在训练过程中接触了大量知识，但它并没有完美的记住它所看到的信息。模型对于晦涩难懂的问题通常会给出捏造的想法，通常成为模型的幻觉。\n减少幻觉的策略是使用以上建议的方法，另一个策略是要求模型首先从文本中找到相关的内容。然后要求它使用这些引用内容来回答问题。\n将答案追溯到源文档的方法通常对减少模型幻觉很有帮助。\n参考 ChatGPT 提示工程师\n","date":"2023-05-09T00:00:00Z","permalink":"https://blog.golang.space/p/chatgpt-%E5%A6%82%E4%BD%95%E5%86%99%E5%A5%BD%E6%8F%90%E7%A4%BA%E8%AF%8D/","title":"ChatGPT 如何写好提示词?"},{"content":"适配器模式 适配器模式是一种设计模式，其将一个类的接口转换成另一个指定的接口，以实现原本由于接口不兼容而无法协同工作的类之间的协同工作。\n通常，在完成某些任务时需要与其他程序进行通信，如访问数据库、访问开发接口、第三方授权登录或短信通知等。\n代码中任何外部依赖性都会带来设计和测试方面的问题。此时，可以使用适配器模式，同时解决这两个问题。\n简单地说，如果程序需要接入 MySQL、PostgreSQL、SQLite 等数据库，直接针对每种数据库编写 CURD 操作将导致设计难度加大，不便于测试。使用适配器模式，则只需了解增删改查操作，具体实现由包含依赖关系的组件负责实现。\n将特定于依赖关系的内容封装在一个组件中，进行核心流程测试时，可替换为 mock 组件，模拟完成依赖对象的操作。\n代码示例 场景 目前，该程序已接入微信支付功能，现欲加入 PayPal 支付功能。\n1 2 3 4 5 6 // 微信支付 type WeChatPay struct{} func (w *WeChatPay) Pay(money int64) { fmt.Println(\u0026#34;微信支付\u0026#34;) } 1 2 3 4 5 6 7 type Payer struct{ Pay(int64) } func main(){ var payer Payer = new(WeChatPay) payer.Pay() } 1 2 3 4 5 6 // 等待接入的 PayPal 支付 type PayPal struct{} func (w *PayPal) Consume(money float64,message string){ fmt.Println(\u0026#34;PayPal 支付\u0026#34;) } 不使用设计模式 将会在代码块里，直接依赖第三方库，没有解耦，难以测试，切代码块读起来复杂。\n1 2 3 4 5 6 7 8 9 10 11 12 13 func main(){ payType := \u0026#34;PayPal\u0026#34; switch payType{ case \u0026#34;PayPal\u0026#34;: var payer Payer = new(WeChatPay) payer.Pay(12) case \u0026#34;Wechat\u0026#34;: pp := new(PayPal) pp.Consume(12.0, \u0026#34;购买会员\u0026#34;) default: fmt.Println(\u0026#34;不支持的支付方式\u0026#34;) } } 使用适配器模式 当 PayPal 的支付组件由别人提供时，不能修改代码。此时由我们定义一个适配器实现接口，内部实现调用 PayPal。\n1 2 3 4 5 6 7 8 // 定义 PayPal 对 Payer 的适配器 type PayPalAdopter struct{ payPal *PayPal } func (p *PayPalAdopter) Pay(money int64) { p.payPal.Consume(float64(money),\u0026#34;购买会员\u0026#34;) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 func main() { payType := \u0026#34;PayPal\u0026#34; var payer Payer switch payType{ case \u0026#34;PayPal\u0026#34;: payer = new(WeChatPay) case \u0026#34;Wechat\u0026#34;: payer = new(PayPalAdopter{ new(PayPal)}) default: fmt.Println(\u0026#34;不支持的支付方式\u0026#34;) } payer.Pay(12) } 通过以上的方式使测试更容易，因为它更容易推理，不必担心两个不同且不相关的行为会互相干扰。\n其他结构型模式 适配器模式通常在已有程序中使用，让互相不兼容的类友好合作，先有两端的东西，才有适配器。桥接模式，通常开发前期进行设计，使各个部分独立开发便于开发，先有桥才有两端的东西。 参考 The adapter pattern in Go\n适配器模式\n","date":"2023-05-03T00:00:00Z","permalink":"https://blog.golang.space/p/%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F/","title":"适配器模式"},{"content":"HTTP 读写超时 服务端超时\n对于暴露在互联网上的 HTTP 服务器来说，强制客户端连接超时非常重要。\n非常慢或消息的客户端可能会导致文件描述符泄露，出现以下错误:\n1 http: Accept error: accept tcp [::]:80: accept4: too many open files; retrying in 5ms ReadTimeout 涵盖从接受连接到完全读取请求正文（如果您确实读取了正文，否则到标头末尾）的时间。它是通过在 Accept 之后立即调用 SetReadDeadline 在 net/http 中实现的。\nWriteTimeout 通常通过在 readRequest 末尾调用 SetWriteDeadline 来覆盖从请求标头读取结束到响应写入结束的时间（也称为 ServeHTTP 的生命周期）。\nhttp.TimeoutHandler 。它不是服务器参数，而是限制 ServeHTTP 调用最大持续时间的 Handler 包装器。它的工作原理是缓冲响应，并在超过截止时间时发送 504 网关超时。\n客户端超时\n最容易使用的是 http.Client 的 Timeout 字段。它涵盖了整个流程。\nhttp.Get 等包级函数使用没有超时的客户端，因此在开放的 Internet 上使用是危险的。\nnet.Dialer.Timeout 限制建立 TCP 连接所花费的时间（如果需要新连接） http.Transport.TLSHandshakeTimeout 限制执行 TLS 握手所花费的时间。 http.Transport.ResponseHeaderTimeout 限制读取响应标头所花费的时间。 1 2 3 4 5 6 http.Server{ Addr: defaultAddr, Handler: handler, ReadTimeout: defaultReadTimeout, WriteTimeout: defaultWriteTimeout, } 如上面代码所示，可以使用 http.Server 定义读写超时时间，通常在 5~30 秒之间，这有助于防止应用程序无限期地阻塞在HTTP响应的读取或写入操作上，从而导致应用程序失去响应并影响整体性能。\nReadTimeout 是从 accept 到 request.Body 被完全读取的时间，如果不读 body 则时间截止到读完 header 为止。\nWriteTimeout 是从 request header 的读取结束开始，到 response write 结束为止。\n使用以上定义的代码，在上传文件功能中，如果文件的大小不确定，大文件读取用时超过预定义的 ReadTimeout，则会出现超时错误，类似于 read tcp [::1]:1133-\u0026gt;[::1]:57471: i/o timeout。\n在 Go 1.20 中新增加了 http.ResponseController 类型，使用该包可以单独控制每个 Handler 的读写超时时间。\n参考 Github issue net/http: ResponseController to manipulate per-request timeouts (and other behaviors) #54136。\n它有以下优点:\n根据每个请求设置读写超时时间。 http.Flusher 和 http.Hijacker 使用更轻松。 使创建和使用自定义的 http.ResponseWrite 实现变得更容易和更安全。 使用 1 2 3 4 5 func ServeHTTPx(w http.ResponseWriter, req *http.Request) { rc := http.NewResponseController(w) _ = rc.SetReadDeadline(time.Now().Add(30 * time.Second)) _ = rc.SetWriteDeadline(time.Now().Add(30 * time.Second)) } 参考 http timeouts\n","date":"2023-05-01T00:00:00Z","permalink":"https://blog.golang.space/p/http-%E8%AF%BB%E5%86%99%E8%B6%85%E6%97%B6/","title":"HTTP 读写超时"},{"content":"HTTP SSE SSE 指的是 Server-sent events，使用服务器发送事件。\n在 Go 服务端设置响应头信息。\n1 2 3 w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/event-stream\u0026#34;) w.Header().Set(\u0026#34;Cache-Control\u0026#34;, \u0026#34;no-cache\u0026#34;) w.Header().Set(\u0026#34;Connection\u0026#34;, \u0026#34;keep-alive\u0026#34;) 客户端代码类似这样\n1 2 3 4 5 6 7 8 const evtSource = new EventSource(\u0026#34;/ssedemo\u0026#34;); // 监听事件 evtSource.onmessage = function(event) { const newElement = document.createElement(\u0026#34;li\u0026#34;); const eventList = document.getElementById(\u0026#34;list\u0026#34;); newElement.innerHTML = \u0026#34;message: \u0026#34; + event.data; eventList.appendChild(newElement); } HTTP 流式传输 Transfer-Encoding 出现在 HTTP Response Header 中。\n该消息指明将消息体传递给请求端的编码形式。\n1 2 3 4 5 6 7 8 9 # 语法 Transfer-Encoding: chunked Transfer-Encoding: compress Transfer-Encoding: deflate Transfer-Encoding: gzip Transfer-Encoding: identity // 可以多个值，以逗号隔开 Transfer-Encoding: gzip, chunked chunked 指数据以一系列分块的形式进行发送，Content-Length 在这种情况下不被发送，在每一个分块的开头需要添加当前分块的长度，以十六进制的形式表示，后面紧跟着 \u0026lsquo;\\r\\n\u0026rsquo;。\n分块的应用场景是要传输大量的数据，但是在请求没有被处理完之前响应的长度是无法获得的。\n接下来演示一个 demo，假设客户端有一个进度条，向用户告知服务端处理进度。\n网页效果展示\n服务端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 package main import ( \u0026#34;encoding/json\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) // 流式传输 func main() { http.HandleFunc(\u0026#34;/aaa\u0026#34;, func(w http.ResponseWriter, r *http.Request) { w.WriteHeader(200) w.Header().Set(\u0026#34;Transfer-Encoding\u0026#34;, \u0026#34;chunked\u0026#34;) w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain\u0026#34;) ch := make(chan Resp, 10) defer close(ch) go func() { // 此处 defer... recover()... tick := time.NewTicker(40 * time.Millisecond) defer tick.Stop() var zeroValue Resp var last *Resp fn := func(v Resp, w io.Writer) error { b, _ := json.Marshal(v) if _, err := w.Write(b); err != nil { return err } w.(http.Flusher).Flush() return nil } for { select { case \u0026lt;-tick.C: if last != nil { _ = fn(*last, w) last = nil } case v := \u0026lt;-ch: if v != zeroValue { last = \u0026amp;v continue } if last != nil { _ = fn(*last, w) } return } } }() var resp Resp resp.All = 300 ok := rand.Intn(10) == 5 for i := 0; i \u0026lt;= resp.All; i++ { time.Sleep(10 * time.Millisecond) fmt.Println(i) if ok { resp.Err = fmt.Errorf(\u0026#34;err\u0026#34;).Error() } resp.CUR = i ch \u0026lt;- resp if ok { break } } time.Sleep(30 * time.Second) }) http.Handle(\u0026#34;/\u0026#34;, http.FileServer(http.Dir(\u0026#34;./\u0026#34;))) // 展示网页 _ = http.ListenAndServe(\u0026#34;:8888\u0026#34;, nil) } type Resp struct { All int `json:\u0026#34;all\u0026#34;` CUR int `json:\u0026#34;cur\u0026#34;` Err string `json:\u0026#34;err\u0026#34;` } 网页端 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34; /\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;test\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;response\u0026lt;/p\u0026gt; \u0026lt;h1 id=\u0026#34;output\u0026#34;\u0026gt;...\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; // 参考: https://web.dev/i18n/zh/fetch-upload-streaming/ const { readable, writable } = new TransformStream(); document.addEventListener(\u0026#34;DOMContentLoaded\u0026#34;, async function () { const response = await fetch(\u0026#34;/aaa\u0026#34;); const reader = response.body.getReader(); while (true) { const { value, done } = await reader.read(); if (done) break; const decoder = new TextDecoder(\u0026#34;utf-8\u0026#34;); const str = decoder.decode(value); document.getElementById(\u0026#34;output\u0026#34;).innerHTML = str; } }); \u0026lt;/script\u0026gt; \u0026lt;/html\u0026gt; 参考 使用 fetch API 流式处理请求\nTransfer-Encoding\n使用服务器发送事件\n","date":"2023-02-15T00:00:00Z","permalink":"https://blog.golang.space/p/http-%E6%B5%81%E5%BC%8F%E4%BC%A0%E8%BE%93/","title":"HTTP 流式传输"},{"content":"持续集成(CI)/持续交付(CD) 持续集成: 自动构建和自动化测试 持续交付: 自动推送到发布系统 持续部署: 自动将更改推送到生产中 不同环境，就有不同问题。如果应用在不同的操作系统上运行，或者操作系统的不同版本，就需要测试所有的操作系统。\n使用持续集成工具，在每一种支持的平台和环境中运行单元测试，要积极的寻找问题，而不是等问题来找你。\nCaddy Server Caddy 2 是一个强大的、企业级、**开源的 Web 服务器，**具有用 Go 编写的 自动 HTTPS\n在服务器上安装 1 2 3 4 5 sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https curl -1sLf \u0026#39;https://dl.cloudsmith.io/public/caddy/stable/gpg.key\u0026#39; | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg curl -1sLf \u0026#39;https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt\u0026#39; | sudo tee /etc/apt/sources.list.d/caddy-stable.list sudo apt update sudo apt install caddy 查看 caddy 运行状态\n1 2 3 systemctl status caddy # 如果你还没有运行，执行 caddy start 此时访问 ip 将会看到 caddy 的默认页面\ncaddy 的常用命令如下\n1 2 3 4 # 停止 caddy stop # 重载当前目录的配置 caddy reload 在部署 Drone 之前，我们先用 caddy 作为网关，反向代理。\n在 /etc/caddy/Caddyfile 增加几行\n1 2 3 drone.example.com:80 { reverse_proxy 127.0.0.1:8000 } 此处 127.0.0.1:8000 是 drone 的服务\nDrone Drone 是为繁忙的开发团队提供的自助式持续集成平台。\n在 Git 仓库平台创建第三方应用 此处以官网文档的图片示例，关于如何创建，官方文档非常详细。\n回调地址大概是 应用主页/login\n在服务器下，创建 drone 文件夹，编辑 docker-compose.yml 文件\n1 2 mkdir /home/app/drone \u0026amp;\u0026amp; cd /home/app/drone vim docker-compose.yml 使用 docker-compose 部署 drone\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 version: \u0026#39;3\u0026#39; services: drone-server: image: drone/drone:latest ports: - 8000:80 # - 9000:443 networks: - drone_network volumes: - $PWD/data:/data:rw - /var/run/docker.sock:/var/run/docker.sock - /etc/localtime:/etc/localtime restart: always environment: - TZ=Asia/Shanghai - DRONE_RPC_SECRET=\u0026lt;随机秘钥，试试 openssl rand -hex 16\u0026gt; - DRONE_GITEE_CLIENT_ID=\u0026lt;创建第三方应用时得到的 id\u0026gt; - DRONE_GITEE_CLIENT_SECRET=\u0026lt;创建第三方应用时得到的 secret\u0026gt; - DRONE_SERVER_HOST=\u0026lt;公网 IP:port 或域名\u0026gt; - DRONE_SERVER_PROTO=http - DRONE_TLS_AUTOCERT=false - DRONE_USER_CREATE=username:ixugo,admin:true - DRONE_NETRC_CLONE_ONLY=true # 如果部署后遇到问题，追踪日志依次处理 # 部署成功后，建议注释 - DRONE_TRACE=true - DRONE_DEBUG=true - DRONE_LOGS_DEBUG=true drone-runner: image: drone/drone-runner-docker:latest command: agent restart: always ports: - 3000:3000 depends_on: - drone-server networks: - drone_network volumes: - /var/run/docker.sock:/var/run/docker.sock - /etc/localtime:/etc/localtime dns: 114.114.114.114 environment: - TZ=Asia/Shanghai - DRONE_RPC_HOST=drone-server - DRONE_RPC_PROTO=http - DRONE_RPC_SECRET=\u0026lt;随机秘钥，跟上面的配置相同\u0026gt; - DRONE_RUNNER_CAPACITY=2 - DRONE_RUNNER_NETWORKS=drone_network # 开启日志 - DRONE_TRACE=true - DRONE_DEBUG=true - DRONE_LOGS_DEBUG=true networks: drone_network: name: drone_network 执行 docker-compose up -d 即可，如果发现意外，检查日志查看发生的问题。\n使用 CI/CD 进入 Drone 控制面板，将会同步你的所有仓库。\n如果你不是仓库的管理员，是没有权限激活的。\n如果仓库的名称有问题，打开后会提示 404。\n成功激活后的页面是这样\n同时，你在对应仓库的 webhook 中将会看到多出的配置。\n在项目中创建文件 .drone.yml，如下所示:\n这里使用 plugins/docker 来构建镜像并推送到远程仓库，默认会识别当前目录下的 Dockerfile 文件。这里使用的是免费的阿里云个人镜像仓库，如果认为这一步麻烦可以跳过。将构建的应用程序放到主机上，远程执行命令在主机上构建。\n避免秘钥泄露在公共仓库中，请使用 from_secret，该参数在 drone settings 中配置。\n使用 appleboy/drone-ssh 对远程主机通信，可用来执行部署操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 --- kind: pipeline type: docker name: build platform: os: linux arch: amd64 steps: - name: test and build image: golang:1.19.5-alpine3.17 # privileged: true # volumes: # - name: deps # path: /tmp/cache commands: - go test ./... - go build -o start - name: build Docker image and push image: plugins/docker settings: registry: registry.cn-hangzhou.aliyuncs.com repo: \u0026lt;名字\u0026gt; use_cache: true username: from_secret: registry_username password: from_secret: registry_password auto_tag: true # 自动打tag - name: ssh commands image: appleboy/drone-ssh environment: DEBUG_STR: asdasd settings: host: from_secret: debug_host username: from_secret: debug_username key: from_secret: debug_password port: from_secret: debug_port script: - echo start - docker pull \u0026lt;镜像名\u0026gt; environment: CGO_ENABLED: 0 GOOS: linux GOARCH: amd64 # volumes: # - name: deps # host: # path: /home/app/test/build trigger: branch: - main event: - push 当你在 main 分支推送代码后，drone 将会自动执行工作流。\n参考 Caddy 2 官方文档\nDrone 官方文档\nDrone 插件 ssh\nDrone 插件 docker\n博客 使用 Drone Pipeline 构建 Docker 镜像\n私有化轻量级持续集成部署方案\u0026ndash;05-持续部署服务-Drone（下）\n私有存储库注入身份验证权限\n","date":"2023-02-14T00:00:00Z","image":"http://img.golang.space/img-1676339073254.png","permalink":"https://blog.golang.space/p/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90ci/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98cd/","title":"持续集成(CI)/持续交付(CD)"},{"content":"敏捷之道 \u0026lt;高效程序员的 45 个习惯\u0026gt; 读书笔记\n任何一个愚者都能够让事情变得越来越笨重，越来越复杂，越来越极端，需要旁观者的指点以及极大的勇气，才能得到豁然开朗的局面。\n新项目刚开始，代码很容易理解和上手，随着开发过程的推进，项目不知不觉演变成一个庞然怪物。\n是为什么让它最终变得难以掌控? 开发人员在完成任务时，可能会难挡诱惑为节省时间而走「捷径」。这些「捷径」往往只会推迟问题的爆发时间，而不是把它彻底解决掉。\n最简单的解决方式，就是开发过程中每天付出一点小的努力，避免代码「腐烂」。\n代码要清晰地表达意图 代码阅读的次数要远远超过编写的次数，所以在编写的时候值得花点功夫让它读起来更加简单。\n例如:\n默认参数或可选参数会影响代码可读性，使其难以理解和调试，最好明确地指明参数。 改动代码以修复 bug 或添加新功能时，应有条不紊，先理解代码做了什么，如何做的。 看看代码例子\n1 coffeeShop.PlaceOrder(2) 这个大概可以理解是在咖啡店下了订单，2 是什么意思呢?\n不仿添加一些注释。\n1 coffeeShop.PlaceOrder(2) // 2: large cup 有时候，注释是为了帮写的不好的代码补漏，不仿考虑用枚举值来表达概念。\n1 2 3 4 5 6 7 const ( Small = iota Medium Large ) coffeeShop.PlaceOrder(Large) 这段代码就很明白，是要一个大杯的咖啡。\n作为一个优雅的开发者，应该时长提醒自己是否有版本啊让写出的代码更容易理解。\n1 result := val \u0026lt;\u0026lt; 1 如果你擅长位运算，就会明白只是把 val 的值乘以 2。但对于没有类似背景的人来说，他们能明白吗? 对于团队中的新人，可能会挠头不已，抓耳挠腮，百思不得「琪姐」。\n1 result := val*2 用位移做乘法是在堆代码进行不必要且危险的性能优化，直接乘法看起来更清晰，不要表现得好像很聪明似的。\n有意图的编程并不是意味着创建更多的类和类型，这不是进行过分抽象的理由。\n增量式编程 开车进行长图旅行时，两手把我方向盘，固定在一个位置，两眼直盯前方，油门一踩到底几个小时，这样可能吗?\n如果不对自己编写的代码进行测试，并且保证没有问题，就不要连续长时间进行编程。\n相反，应该采用增量式的编程方式，增量式编程可以精简并结构化你的代码。所开发的代码基于即使的反馈，这些反馈来自小步幅方式编写代码和测试的过程。\n采取增量式编程和测试，会倾向于创建更小的方法和更具内聚性的类，在编写代码时，要经常留心可以改进的微小方面，这可能会改善代码的可读性。将长函数拆分成短函数，使其变得更易于测试。\n中庸之道\n如果构建和测试循环花费的时间过长，你就不会希望经常运行它们了。要保证测试可以快速运行。 在编译和测试运行中，停下来想一想，并暂时远离代码细节，这是保证不会偏离正确方向的好方法。 要休息的话，就要好好休息，休息时远离键盘 要像重构业务代码那样，重构测试，而且要经常重构测试 保持简单 也许你看到一篇文章，其中提到了一个设计想法，放下文章，眼前的代码似乎马上就可以用到这样的模式。\n你真的需要用它吗?\n是不是特定的问题强迫你使用这个解决方案 ? 不要让过度设计，也不要将代码过度复杂化。\n开发人员更应该为自己能够创建出一套简单并可用的设计而骄傲。\n简单不是简陋! 相比一个过度复杂，拙劣的解决方案，简单的方案 通常更难以获得。\n优雅的代码第一眼看上去，就知道它的用处，而且很简洁。这样的解决方案不是那么容易想出来的。优雅是易于理解和辨识的。\n中庸之道\n代码几乎总是可以进一步精炼，但到了某个点之后，再作改进就不会带来任何实质性的好处了。 简单，可读性高的代码。强行让代码变得优雅与过早优化类似，同样会产生恶劣的影响。 简单的解决方案必须满足功能需求，为了简单而在功能上妥协，就是过度简化。 一个人认为简单的东西，可能对另一个人意味着复杂。 开发可以工作，最简单的解决方案。除非有不可辩驳的原因，否则不要乱用设计模式，高难度技术之类的东西，造成一大锅黏糊糊，乱七八糟。 编写高内聚，低耦合的代码 内聚程序高，表明各个成员共同完成了一个功能特性或是一组功能特性。\n假定把所有衣服都扔到一个衣柜，当需要找一双袜子时，得翻遍里面所有的衣服。\n如果每个页面包含展示逻辑，业务逻辑和访问数据的代码，臃肿的堆积在一起，如果要对数据库的表结构进行一次微调，这个微小的变化会导致应用中所有的页面发生变化。\n假设有这样一个类，实现了 5 种完全不相干的功能，当 5 个功能的需求或细节发生了变化，这个类也必须跟着改变。如果一个类变化得过于频繁，这样的改变会对整个系统产生涟漪效应，导致更多的维护和成本。推书「敏捷软件开发: 原则,模式与实战」。\n中庸之道\n一些东西拆分成很多微小的部分，可能会失去使用价值，当你需要袜子的时候，一盒毛线是不够用的。 告知，而非询问 有个「送报男孩和钱包的故事」，男孩将报纸送到你的门前，要求付报酬，你转过身让男孩从你的后屁股兜掏出钱包，并且从中拿到两美元，再把钱包放回去。\n当男孩拿到钱包的时候，他拿走的数额不是你能控制的。送报男孩作为调用者，应该告诉客户需要付多少钱，男孩不能探寻客户的财务状况，也不能代替做任何决策。\n告知，不要询问是一个很有用的技术，将功能和方法分为「命令」和「查询」两类，一个常规的命令可能会改变对象的状态，一个查询仅仅提供状态，不提供修改。\n敏捷调试 即使是运作得最好的敏捷项目，也会发生错误。bug，错误，缺陷\u0026mdash;不管被称作什么，它们总会发生。\n要想更加有效地重用你的知识和努力，记录问题解决日志是很有用的。\n不要在同一处跌倒两次，可以选择符合需求的任何格式，如下:\n问题发生日期 问题简述 解决方案详细描述 引用文章或网址 任何代码片段，设置或对话框截屏 助记标签 如\n1 2 3 2023/02/15 golang 更新 1.20 后，golangci-lint 在终端提示了很多错误。 在 github 的 golangci-lint 搜索相关 issus，发现 brew/vscode-go 发行的 golangci-lint 都是旧版 1.50.1，而此工具已更新至 1.51 修复了相关问题，直接下载替换即可。 如果面临的问题无法在日志中找到解决方案，在问题解决之后，要记得马上更新细节记录到日志中。\n解决方案日志应该作为思考的一个来源，可以在其中发现某些特定问题的细节，对于某些类似但是有差异的问题，也能从中获得修复的指引。\n中庸之道\n记录问题的时间不能超过在解决问题上花费的事情，要保持轻量级和简单，不必达到对外发布式的质量 找到以前的解决方法非常关键，使用足够的关键字，以帮助查找 如果通过 web 搜索，发现没人曾经遇到同样的问题，也许是搜索的方式有问题 要记录发生问题时应用程序，应用框架或平台的特定版本 记录团队做出重要决策的原因，否则 6-9 个月之后，想再重新回顾决策过程，这些细节就很难再记得，容易发生互相指责的情形。 对问题各个击破 单元测试带来的积极效应之一，就是它会强迫形成代码的分层，要保证代码可测试，就必须把它从周边代码中解脱出来，如果代码依赖其它模块，就应该使用 mock 对象。\n识别复杂问题的第一步，是将他们分离出来。不可能在半空中试图修复飞机引擎，将其取出来放在工作台上之后更容易修复。\n中庸之道\n将代码中其运行环境中分离后，问题消失不见了，有助于隔离问题，相反也有助于隔离问题 以二分查找的方式定位问题很有用，将问题空间分成两半，看哪一半包含问题，再将包含问题的进行二分，并不断重复这个过程，直到发现问题本质。 在处理问题之前，先查找问题解决日志。 报告所有的异常 编程，不仅要考虑正常状态下如何运作，更要考虑异常情况下会发生什么。\n有些开发人员会采用临时的做法，捕捉到异常后，为了不看到编译器的提示，就把异常忽略掉。\n必须处理或向上传播所有的异常，不要将它们压制不管，就算是临时做也不行。\n中庸之道\n不是所有的问题都应该抛出异常。 报告的异常应该在代码的上下文中有实际意义。 如果代码中会记录运行时调试日志，当捕获或是抛出异常时，都要记录日志信息，这样做对以后的跟踪工作很有帮助。 检查异常处理起来很麻烦，没人愿意调用抛出 31 种不同检查异常的方法。这是设计上的问题。 要传播不能处理的异常。 提供有用的错误信息 发生错误时，显示通用的信息告诉用户发生了问题，要好过于系统崩溃造成应用执行错误的动作。然而类似「出错了」这样的消息，无法帮助团队针对问题做出诊断。\n用户在给支持团队打电话报告问题时，我们希望他们提供足够多且好的信息，以帮助尽快识别问题所在。\n记录日志 客户端展示包装的错误，将错误细节隐藏在「详情」按钮中，点击按钮可以将错误细节以邮件发给技术支持，或直接展示错误。 日志中记录的信息可能应该包含当时的系统状态，版本等快照 区分错误类型:\n程序缺陷: 这是真正的 bug，用户或技术支持对此束手无策，只能研发处理。 环境问题: 如果能提供足够详细的错误，技术支持可以解决。 用户错误: 由用户的输入造成的问题，用户可以重试。通过追踪记录报告的错误类型，可以为受众提供更佳合适的建议，为研发提供程序优化等。 中庸之道\n像无法找到文件这样的错误，本身而言无助于问题的解决。 「无法找到 /home/app/main.yaml 文件 」这样的信息更有效。 在提供更多信息的同时，不要泄露安全信息，个人隐私，商业机密。 提供给用户的信息可以包含一个主键，以便于在日志文件或是审核记录中定位相关内容。 敏捷协作 高效的协作是敏捷开发的基石。\n团队中一个人的知识，经常可以解决另外一名成员的问题。只要允许大家自己想办法，就可以帮助团队不断成长。\n准备好再共享代码 code review 不断完成旧任务，领取新任务，及时通报进展与问题 定时安排会面时间，要保证会议议题不会发散，每个人都应该只回答 3 个问题，如果要详细讨论某些问题，可以在会议结束后，再专门召集相关人员私聊。\n昨天有什么收获? 今天计划做哪些工作? 面临哪些障碍? 成为指导者 好的想法不会因为被许多人了解而削弱，好主意就像火，可以引领这个世界。\n与别人共事，激励他们变得更出色，同时可以提升团队的整体实力。\n成为指导者，并不意味着要手把手教成员怎么做，也不是在白板前讲座。多数时候，成为指导者，是指在帮助团队成员提升水平的同时也提高自己。\n成为指导者意味着要分享，而不是固守。\n中庸之道\n如果总是被一些懒于自己寻找答案的人打扰\u0026hellip; 为团队成员在寻求帮助之前，设定一个陷入时间，1 小时应该不错 做 code review 代码刚刚完成时，是寻找问题的最佳时机。\n中庸之道\n不进行思考的 code review 没有任何价值 代码复杂需要积极评估代码的设计和清晰程序，带着问题去复查 走向敏捷 一灯能除千年暗，一智能灭万年愚。 \u0026mdash;- 慧能，中国禅宗第六代祖师\n","date":"2023-02-10T00:00:00Z","permalink":"https://blog.golang.space/p/%E6%95%8F%E6%8D%B7%E4%B9%8B%E9%81%93-%E4%B8%8B/","title":"敏捷之道 (下)"},{"content":"敏捷之道(上) \u0026lt;高效程序员的 45 个习惯\u0026gt; 读书笔记\n态度决定一切 发生问题后，最高的优先级是找出罪魁祸首对吗?\n肯定的答案是: 优先解决问题!\n如果说出来的话只是让事态更复杂，或一味地抱怨，或者伤害他人的感情，无意中在给问题火上浇油。\n为了解决或缓解这个问题，我们能够做些什么?\n敏捷开发团队中每个人都应该抱着这样的观点，咱们可以从自己做起。例如一个开发者带着抱怨或问题来过来，咱们要了解具体的问题，询问他需要什么样的帮助。这样一个简单的行为表明目的是解决问题，而不是追究责任。\n相反咱们找人帮忙，却没人积极响应，那么应该主动引导对话，解释清楚想要什么。\n一个重大的错误应该被当做是一次学习，而不是指责他人的机会。\n指责不能修复问题.\nVlame doesn\u0026rsquo;t fix bugs.\n中庸之道\n「这不是我的错」这句话不对，「这都是你/他的错」这句话更不对 如果没有犯过任何错误，说明可能没有努力去工作 如果一个团队成员误解了需求/API/会议决策，那么，意味着其他成员也有相同的误解，要确保整个团队尽快消除误解。 如果某个团队成员不是在帮助团队解决问题的方向前进，则应该要求他离开当前项目上的主要工作。 欲速则不达 拙劣的码农会不假思索的改完代码，快速转向下一个问题。\n卓越的码农会挖掘更深一层，去理解这个函数的意义，思考修改函数的影响。\n否则，在经年累月的屎山中添加新功能或修复 bug，难逃脱发的厄运。\n千里之堤溃于蚁穴。快速修复的诱惑很容易令人把持不住，治标不治本啊!\n防微杜渐.\nBeware of land mines.\n很可能在公司里，有人告诉你:\u0026ldquo;无论如何千万不能碰那个函数，写代码那哥们早就不在了，没有人能看懂他的代码\u0026rdquo;\n建议:\n不要孤立地编码.\n团队成员应该花时间阅读其他同时的代码，确保代码是可读可理解的。\nDon\u0026rsquo;t code in isolation.\n单元测试.\n单元测试很自然就会帮助你把代码分层，解耦成小的模块。\nUse unit tests.\n中庸之道\n必须理解代码是如何工作的，但不一定要成为专家，能够使用它进行有效工作即可。 如果有一块代码其他人很难看懂，意味着任何人包括原作者都很难维护它 所有的大型系统都非常复杂，没有一个人能够完全明白所有代码。咱们除了深入开发的部分代码之外，还需要从更高层面了解系统架构，各个功能模块是如何交互的。 不要急于修复一段没能理解的代码。 对事不对人 \u0026ldquo;那样很蠢!\u0026rdquo; 这句话想表达设计上的问题，但无意中却重伤了他人，有明示设计者很蠢之意。\n更有效优雅的方式应该是: 「感谢，我想知道，如果两个用户同时登录会发生什么情况?」\n通常对一个明显错误有哪些反应?\n否定个人能力 指出缺点，否则其观点 问询并提出顾虑 第三种方法，没有谴责，没有批判，由此由浅入深的交谈，而非面红耳赤的争辩。\n尝试引导性的提出问题。\n我们每个人都有一些极好的创新想法，同样也会萌生一些很愚蠢的想法。好的作品和设计都需要大量的创造力和洞察力，分享并融合各种不同的想法和观点，远胜于单个想法为项目带来的价值。\n重点要放在解决问题上，而不是极力证明谁的主意更好。团队中一个人的智商高是没有用的，如何很顽固并且拒绝合作，那就更糟糕。\n每个人都都会有好的想法，也会有不对的想法，每个人都需要自由表达观点。你不需要很出色才能起步，但是你必须起步才能变得很出色。\n有关于团队决策的有效方法论:\n设定最终期限，以防止陷入无休止的理论争辩。\n逆向思维，先积极看到它的正面，然后努力从反面认识它。目的是找出优点最多缺点最少的方案。\n设立仲裁人，选一个仲裁人作为本次会议的决策者。仲裁人应该专注于调停，而不是发表自己的观点，理想情况下不应在项目中有既得利益。\n支持已经做出的决定，一旦方案被确定，团队成员必须通力合作。目标是让项目成功满足用户需求，客户并不关心这是谁的主意，只关心产品是否符合他们的期望。\n设计充满了妥协，工作者不感情用事是需要克制力的，若咱们能展现出成熟大度来，大家一定不会视而不见，这需要有人带头，身体力行，去感染另一部分人。\n中庸之道\n尽力贡献自己的好想法，没有被采纳也无需过多情绪，不要因为表现自己的想法而画蛇添足。\n脱离实际的反方观点会使争论变味，你很容易提出一堆不太可能发生的情形去批驳它，这时需要扪心自问: 类型问题以前发生过吗? 是否经常发生呢?\n「我们不能采用这个方案，万一数据库厂商倒闭.」「甲方绝不对接收这个方案」，不能凭空想象。\n排除万能，奋勇前进 谁去给猫系铃铛?\n老鼠们打算在猫的脖子上系一个铃销，这样猫巡逻靠近的时候，就能预先得到警报。每只老鼠都点头，认为这是一个绝妙的想法。这时一只年老的老鼠问道：“那么，谁愿意挺身而出去系铃铛呢？”毫无疑问，没有一只老鼠站出来。当然，计划也就这样泡汤了。\n有时，绝妙的计划会因为勇气不足而最终失败。尽管前方很危险—不管是真的鱼雷或者只是一个比喻——你必须有勇气向前冲锋，做你认为对的事情。\n假如要修复其他人编写的代码，很脏乱，很难理解，这时怎么办?\n也许会跳起来告诉周围人，代码是多么糟糕，但那只是抱怨和发泄，并不能解决问题。\n相反，咱们应该重写这些代码，并比较重写前后的优缺点，动手证明是最有效的方式。\n中庸之道\n设计或代码中出现了奇怪的问题，花时间去理解为什么，如果清晰明朗需要重构代码就去做。但如果没有马上理解那段代码，不要轻易地否定和重写它们，那不是勇气是鲁莽。 「更清晰的代码」是无法打动生意人的，节约资金，获得更好的投资回报等会让论点更有说服力。 学无止境 逆水行舟，不进则退。\n许多新技术都基于现有的技术和思想，它们会加入一些新的东西，这些新东西是逐步加的量，如果跟踪技术变化，那么学习这些新东西就是增量变化。\n敏捷的根本之一是拥抱变化，曾经非常有用的东西往往会靠边站，还会降低效率。\n在学习新的东西，要丢弃阻止你前进的旧习惯。\n如何才能跟上技术变化的步伐呢?\n迭代和增量式的学习，每天计划用一点时间来学习新技术。听到不熟悉的术语或短语，记录下来，在计划时间深入研究。 通过邮件/技术博客/社区了解行情 阅读 中庸之道\n你不可能精通每一项技术，没有必要去做这样的尝试，只要在某些方面成为专家，就能用同样的方法，很容易成为新领域的专家。 你要明白为什么需要这项新技术，它试图解决什么样的问题? 避免一时冲动的情况下，只是因为想学习而将应用切换到新的技术。在决策时，必须评估新技术的优势，开发一个小的原型系统是对付技术狂热者的一剂良药。 打破砂锅问到底 在计算机世界，很多问题会影响应用，为了解决问题，需要知道许多影响的因素。当找人询问任何相关问题时，让他们耐心回答，这是你的职责。\n你的问题甚至会帮助他们理清思路，从一个新人的角度提出的问题，给他们提供了一个新的视角，也许就帮助他们解决了一直令人困扰的问题。\n「哎呀，只要每周重启一次系统，就没问题了」\n「你必须依次执行 3 次构建才能完成构建」\n「我们的用户根本不想要那个功能」\n真的吗? 为什么呀? 不能只满足于别人告诉你的表面现象，要不停地提问直到你明白问题的根源。\n中庸之道\n咱们可能跑题，问一些与主题无关的问题，要问到点子上。 当问为什么的时候，也许会被反问，「为什么你问这个问题」，在提问之前，想好提问的理由，也许有助于问出恰当的问题。 「这个，我不知道」是一个好的起点。 把握开发节奏 在许多不成功的项目中，基本都是随意安排工作计划，那样随机安排很难处理，根本不知道明天将会发生什么。\n中庸之道\n每天结束的时候，测试代码，提交代码，没有残留的代码 不要搞得经常加班 如果开发节奏过于密集，会精疲力竭 有规律的开发节奏会暴露很多问题 交付用户想要的软件 让客户做决定。\n开发者能做的一个最重要的决定就是，判断哪些是自己决定不了的。\n应该让业主做决定，你不需要自己给业务上的关键问题做决定。毕竟，那不是你的事情。\n中庸之道\n记录客户做出的决定，并注明原因，好记性不如烂笔头 不要用低级别和没有价值的问题打扰繁忙的业务人员 不要假设低级别的问题不会影响他们的业务 如果业务负责人回答我不知道，尽你所能提供建议 保持可以发布 在团队工作，修改一些东西的时候必须很谨慎，时刻警惕，每次改动都会影响系统的状态和整个团队的工作效率。\n在办公室不能容忍任何人乱丢垃圾，为什么就可以容忍一些人给项目带来垃圾代码呢?\n下面是一个简单的工作流程，可以防止你提交破坏系统的代码。\n在本地运行测试 检出最新的代码 git pull 提交代码 提早集成，频繁集成 绝不要做大爆炸式的集成。越早解决它们，工作量就越小。如果推迟集成的时间，解决这些问题就会变得很难，需要大量和大范围地修改代码。\n固定的价格就是保证要背叛承诺 软件项目天生就是变化无常的，如果要提前给出一个固定的开发时间，就几乎肯定不能遵守开发上的承诺。\n那如何做到更精确的评估呢? 可以试试这样的方法:\n主动提议先构建系统最初，有用的部分，这时候不是要完成所有的功能，而是足够一次交付，并能让用户真正使用，通常在 6~8 周。 第一次迭代结束，客户有两个选择，可以新增功能继续下一个交付，要么取消合同，仅需支付第一个迭代的费用。 如何继续前进，这时根据提出的增量功能，应该就可以很好预测下一个迭代工作。 敏捷反馈 编写能产生反馈的代码，通过单元测试来获取反馈。\n确保测试是可重复的，使用当前时间/机器固定 IP 等都是使其依赖运行时的机器 测试边界条件，比如日期 11:59:59/0:00:00，比如月份 0 / 13 / -1 不要放过任何失败的测试 一旦单元测试到位，采用这样的回归测试，就可以随意重构代码。单元测试会确保你不会意外地破坏任何功能。\n如果你仍然在寻找开始单元测试的理由，下面有很多:\n单元测试能及时提供反馈 单元测试让你的代码更佳健壮 单元测试是有用的设计工具 单元测试是让你自信的后台 单元测试是解决问题时的探测器 单元测试是可信的文档 单元测试是学习工具 先用它再实现它 在说服他人使用它之前，先得让自己切实的使用产品。\n先写测试，你就会站在代码用户的角度来思考，而不仅仅是单纯的实现。\n你会发现因为你自己要使用它们，所以能设计一个更有用，更一致的接口。\n先写测试有助于消除复杂的设计，让你可以专注于真正需要完成的工作。\n举一个编程例子，这是一个可以两个人玩的「井字旗」 游戏:\n开始，会思考如何为这个游戏做代码设计，也许会考虑到需要这些类，棋盘/行列/用户/规则/等。\n首先写棋盘的测试，类似于这样\n1 2 3 4 5 func TestBoard(t *testint.T) { s := NewBoard() request.NoNil(t,s) request.IsFalse(t,s.GameOver) } 此时执行测试应该是失败的，因为结构体 board 还不存在，需要实现这个结构体。\n1 2 3 4 5 6 7 type Board struct{ GameOver bool } func NewBoard() *Board{ return \u0026amp;Board{} } 此时再执行测试，以保证测试通过，不通过话的修改直到通过。\n下一步，必须决定谁先开始走第一步棋，需要设第一个比赛者，写下相关测试\n1 2 3 func TestSetFirstPlayer(){ // test content } 这时，测试会迫使你决定如何在代码中表示比赛者，并分配到棋盘上。\n可能是这样的\n1 2 # 玩家 mark 使用 X board.SetFirstPlayer(new Player(\u0026#34;Mark\u0026#34;), \u0026#34;X\u0026#34;) 但真的需要 player 这个结构体吗? 或者需要玩家的名字吗? 此时还没有实现 SetFirstPlayer 方法，初期让我们的测试更简单一些，比如\n1 board.SetFirstPlayer(\u0026#34;X\u0026#34;) 这个版本隐藏着风险，可以传递任何字母给 SetFirstPlayer，意味着需要添加代码来检查参数的正确性。因此我们可以进一步简化，用一个 bool 来表示第一个玩家是 O 还是 x。\n例如这样\n1 2 3 4 func TestSetFirstPlayer(){ board.FirstPlayerPegIsX = true; requests.IsTrue(board.FirstPlayerPegIsX) } 我们的思考是从 player 类开始，最后实现只用了简单的布尔类型属性，我们不是要扔掉好的设计，仅仅用大量的布尔类型来编码所有东西，而是成功地实现特定功能的最低成本。程序员很容易走向另一个极端，一些不必要过于复杂的事情。\n消除还没有编写好的类，这会很容易简化代码，相反，一旦已经编写了代码，也许会强迫自己保留这些代码，并继续使用它。\n好的设计并不意味着需要更多的类\n添加无用的代码总是不好的想法，不管他们是否真的需要，TDD 有机会让你编写代码之前，可以深思熟虑将如何使用它。这会迫使你去思考它的可用性和便利性，让你的设计更注重实效。\n设计并不是开始编码的时候就结束了，需要在产品的生命周期中持续添加测试，添加代码，重新设计。\n中庸之道\n不要把测试代码和提交代码之前的测试等同，单元测试可以保证代码的健壮性，提交代码前的功能测试可以保证产品的稳定性。 任何一个设计都可以被改进 单纯的单元测试无法保证好的设计，但他们回到设计有所帮助，使设计更佳简单。 不同环境，就有不同问题 你的应用程序要在不同的操作系统上运行，或者一个操作系统的不同版本，就需要测试所有的操作系统。\n不同环境就有不同的问题，使用持续集成工具，在每一种支持的平台和环境中运行单元测试。要积极地寻找问题，而不是等问题来找你。\n","date":"2023-01-19T00:00:00Z","permalink":"https://blog.golang.space/p/%E6%95%8F%E6%8D%B7%E4%B9%8B%E9%81%93-%E4%B8%8A/","title":"敏捷之道 (上)"},{"content":"JSON JSON charset web 响应要指定 Content-Type，你可能见过 Content-Type: application/json; charset=utf-8\n在 RFC 中指出:\nJSON text exchanged between systems that are not part of a closed ecosystem MUST be encoded using UTF-8.\n面向公众的应用程序必须始终采用 UTF-8 编码，所以不需要标注字符集，Content-Type: application/json 即可\nJSON encode time.Time 值将会被编码为 RFC 3339 格式的字符串，例如\u0026quot;2020-11-08T06:27:59+01:00\u0026quot; []byte 切片将被编码为 base64 字符串 无法对 channel/function/complex 进行编码，如果这样做，在运行时将会得到 json.UnsupportedTypeError的错误 任意指针都编码为指向的值 如果你有一个 io.Writer ，可以使用 err := json.NewEncoder(w).Encode(data) 直接写入。\njson.Encoder 和 json.Marshal() 性能差异 json.Marshal() 比 json.Encoder 多一次堆内存分配。\n嵌套结构体序列化不会 omitempty 1 2 3 4 5 type A struct{ b struct{ Bar string `json:\u0026#34;,omitempty\u0026#34;` } `json:\u0026#34;,omitempty\u0026#34;` } 结构体为值类型，不存在 nil 的情况，所以不会 omitempty。\n如果需要省略，建议替换成 pointer。\n转义字符 如果字符串中包含 \u0026lt;\u0026gt;\u0026amp; 字符，将会转义成 unicode，这是为了防止某些 web 浏览器意外解释 JSON 响应为 HTML，如果不需要转义，使用 json.Encoder SetEscapeHTML(false) 执行编码。\n转义字符 unicode \u0026lt; \\u003c \u0026gt; \\u003e \u0026amp; \\u0026 删除 float 小数点末尾的 0 1 2 3 4 5 s := []float64{ 123.0, 456.100, 789.990, } 编码后将得到\n1 [123,456.1,789.99] 预编码 JSON 如果你有一个包含预编码的 string 或者 []byte，使用 JSON tag 将会被转义并编码为 json 字符串\n1 2 3 4 5 m := struct { Person string }{ Person: `{\u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;age\u0026#34;: 21}`, } 编码后得到\n1 {\u0026#34;Person\u0026#34;:\u0026#34;{\\\u0026#34;name\\\u0026#34;: \\\u0026#34;Alice\\\u0026#34;, \\\u0026#34;age\\\u0026#34;: 21}\u0026#34;} 如果想插入 JSON 而非 JSON 字符串，可以使用 json.RawMessage\n1 2 3 4 5 m := struct { Person json.RawMessage }{ Person: json.RawMessage(`{\u0026#34;name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;age\u0026#34;: 21}`), } 编码后得到\n1 {\u0026#34;Person\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;Alice\u0026#34;,\u0026#34;age\u0026#34;:21}} 使用 json.RawMessage 要确保预编码的值是有效的 JSON，否则会出错。如果需要在运行时检查 JSON 是否有效，可以使用 json.Valid() 函数\nMarshalText 如果类型有没有 MarshalJSON() 方法，但是有 MarshalText() 方法，以实现 encoding.TextMarshaler 接口，使用 JSON 编码将会显示 json 字符串。\n1 2 3 4 5 6 7 8 9 10 11 12 type myFloat float64 func (f myFloat) MarshalText() ([]byte, error) { return []byte(fmt.Sprintf(\u0026#34;%.2f\u0026#34;, f)), nil } func main() { f := myFloat(1.0/3.0) js, err := json.Marshal(f) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;%s\u0026#34;, js) } 它将会打印由 MarshalText() 函数返回的 JSON 字符串\n1 0.33 MarshalJSON 的接收器 当自定义类型实现了 MarshalJSON()，并使用 pointer 接收器时，仅传递指针时函数有效。\n关于接收器的指针与值的规则是:\n值方法可以用指针或值调用，但指针方法只能在指针上调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 type myFloat float64 // This has a pointer receiver. func (f *myFloat) MarshalJSON() ([]byte, error) { return []byte(fmt.Sprintf(\u0026#34;%.2f\u0026#34;, *f)), nil } func main() { f := myFloat(1.0 / 3.0) // When encoding a value, the MarshalJSON method is used. // 得到 0.33 js, err := json.Marshal(\u0026amp;f) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;%s\\n\u0026#34;, js) // When encoding a value, the MarshalJSON method is ignored. // 得到默认的 0.3333333333333333 js, err = json.Marshal(f) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;%s\u0026#34;, js) } 部分 JSON 解码 如果你只需要处理 JSON 中的一小部分\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // Let\u0026#39;s say that the only thing we\u0026#39;re interested in is processing the \u0026#34;genres\u0026#34; array in // the following JSON object js := `{\u0026#34;title\u0026#34;: \u0026#34;Top Gun\u0026#34;, \u0026#34;genres\u0026#34;: [\u0026#34;action\u0026#34;, \u0026#34;romance\u0026#34;], \u0026#34;year\u0026#34;: 1986}` // Decode the JSON object to a map[string]json.RawMessage type. The json.RawMessage // values in the map will retain their original, un-decoded, JSON values. var m map[string]json.RawMessage err := json.NewDecoder(strings.NewReader(js)).Decode(\u0026amp;m) if err != nil { log.Fatal(err) } // We can then access the JSON \u0026#34;genres\u0026#34; value from the map and decode it as normal using // the json.Unmarshal() function. var genres []string err = json.Unmarshal(m[\u0026#34;genres\u0026#34;], \u0026amp;genres) if err != nil { log.Fatal(err) } fmt.Printf(\u0026#34;genres: %v\\n\u0026#34;, genres) 解码后得到\n1 genres: [action romance] 解码成任意类型 解码成任意类型在以下情况很有用\n事先不知道解码的是什么 需要解码包含不同类型的的 array/map 数字解码到任意类型时，为 float64 ，即使它是整数。\n如果想获得整数形式(而非 float64)，应该在 json.Decoder 实例使用 UseNumber() 方法，将会导致解码为 json.Number 类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 js := `10` var n any dec := json.NewDecoder(strings.NewReader(js)) dec.UseNumber() // Call the UseNumber() method on the decoder before using it. err := dec.Decode(\u0026amp;n) if err != nil { log.Fatal(err) } // Type assert the any value to a json.Number, and then call the Int64() method // to get the number as a Go int64. nInt64, err := n.(json.Number).Int64() if err != nil { log.Fatal(err) } // Likewise, you can use the String() method to get the number as a Go string. nString := n.(json.Number).String() fmt.Printf(\u0026#34;type: %T; value: %v\\n\u0026#34;, n, n) fmt.Printf(\u0026#34;type: %T; value: %v\\n\u0026#34;, nInt64, nInt64) fmt.Printf(\u0026#34;type: %T; value: %v\\n\u0026#34;, nString, nString) out:\n1 2 3 type: json.Number; value: 10 type: int64; value: 10 type: string; value: 10 struct tag 指令 指令 说明 备注 json:\u0026quot;-\u0026quot; 编解码时忽略( 属性名首字母小写也可以忽略 ) json:\u0026quot;,omitempty\u0026quot; 解码时为零值则忽略 嵌套结构体无效 json:\u0026quot;,omitempty,string\u0026quot; 以字符串类型编解码 适用于数字/布尔/数字指针类型 自定义编码 方法一\n在 MarshalJSON 中定义个新的结构体，对其编码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 // Note that there are no struct tags on the Movie struct itself. type Movie struct { ID int64 CreatedAt time.Time Title string Year int32 Runtime int32 Genres []string Version int32 } // Implement a MarshalJSON() method on the Movie struct, so that it satisfies the // json.Marshaler interface. func (m Movie) MarshalJSON() ([]byte, error) { // Declare a variable to hold the custom runtime string (this will be the empty // string \u0026#34;\u0026#34; by default). var runtime string // If the value of the Runtime field is not zero, set the runtime variable to be a // string in the format \u0026#34;\u0026lt;runtime\u0026gt; mins\u0026#34;. if m.Runtime != 0 { runtime = fmt.Sprintf(\u0026#34;%d mins\u0026#34;, m.Runtime) } // Create an anonymous struct to hold the data for JSON encoding. This has exactly // the same fields, types and tags as our Movie struct, except that the Runtime // field here is a string, instead of an int32. Also notice that we don\u0026#39;t include // a CreatedAt field at all (there\u0026#39;s no point including one, because we don\u0026#39;t want // it to appear in the JSON output). aux := struct { ID int64 `json:\u0026#34;id\u0026#34;` Title string `json:\u0026#34;title\u0026#34;` Year int32 `json:\u0026#34;year,omitempty\u0026#34;` Runtime string `json:\u0026#34;runtime,omitempty\u0026#34;` // This is a string. Genres []string `json:\u0026#34;genres,omitempty\u0026#34;` Version int32 `json:\u0026#34;version\u0026#34;` }{ // Set the values for the anonymous struct. ID: m.ID, Title: m.Title, Year: m.Year, Runtime: runtime, // Note that we assign the value from the runtime variable here. Genres: m.Genres, Version: m.Version, } return json.Marshal(aux) } 方法二\n嵌入别名，为结构体设置别名，以避免序列化死循环。\n用一个新的结构体，匿名嵌套上面的别名，并在新结构体里设置同名参数以覆盖。\n缺点:\n将失去编码后的顺序，如果你的应用场景需要固定顺序，如对 JSON 求 MD5。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 // Notice that we use the - directive on the Runtime field, so that it never appears // in the JSON output. type Movie struct { ID int64 `json:\u0026#34;id\u0026#34;` CreatedAt time.Time `json:\u0026#34;-\u0026#34;` Title string `json:\u0026#34;title\u0026#34;` Year int32 `json:\u0026#34;year,omitempty\u0026#34;` Runtime int32 `json:\u0026#34;-\u0026#34;` Genres []string `json:\u0026#34;genres,omitempty\u0026#34;` Version int32 `json:\u0026#34;version\u0026#34;` } func (m Movie) MarshalJSON() ([]byte, error) { // Create a variable holding the custom runtime string, just like before. var runtime string if m.Runtime != 0 { runtime = fmt.Sprintf(\u0026#34;%d mins\u0026#34;, m.Runtime) } // Define a MovieAlias type which has the underlying type Movie. Due to the way that // Go handles type definitions (https://golang.org/ref/spec#Type_definitions) the // MovieAlias type will contain all the fields that our Movie struct has but, // importantly, none of the methods. type MovieAlias Movie // Embed the MovieAlias type inside the anonymous struct, along with a Runtime field // that has the type string and the necessary struct tags. It\u0026#39;s important that we // embed the MovieAlias type here, rather than the Movie type directly, to avoid // inheriting the MarshalJSON() method of the Movie type (which would result in an // infinite loop during encoding). aux := struct { MovieAlias Runtime string `json:\u0026#34;runtime,omitempty\u0026#34;` }{ MovieAlias: MovieAlias(m), Runtime: runtime, } return json.Marshal(aux) } 解码类型 JSON type Supported Go types boolean bool string string number int*,uint*,float*,rune array array,slice object struct, map JSON 错误分类 对于面向公众的 API，错误消息本身并不理想。有些令人困惑且难以理解，或暴露了底层 API 细节信息。\nDecode 方法，可能会返回 5 种类型的错误\nError types 原因 json.SyntaxError json 语法存在问题 io.ErrUnexpectedEOF json 语法存在问题 json.UnmarshalTypeError JSON 值不适用于目标 Go 类型。 json.InvalidUnmarshalError 解码目标无效，通常因为它不是指针，这实际上是程序代码的问题 io.EOF json 为空 反序列时想对部分字段不赋值 客户端传递的 json 是无法控制的。\n你可以在反序列化后对指定字段置零，但这显得有点笨拙，如果结构体增加了字段但忘记反序列化后置零，这样的写法会给未来留下技术栈。\n建议新建一个结构体用于序列化，时候赋值给指定结构体。如:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 type User struct{ Name string Age int } func main(){ var input struct{ Name string } s := `{\u0026#34;name\u0026#34;:\u0026#34;Nacy\u0026#34;}` if err := json.UnmarshalJSON([]byte(s), \u0026amp;input);err!=nil{ panic(err) } user := User{ Name: input.Name, } _ = user } 参考 此文章内容为 Let\u0026rsquo;s Go Further 读书笔记\n","date":"2023-01-12T16:11:45Z","permalink":"https://blog.golang.space/p/json/","title":"JSON"},{"content":"FFmpeg 基础知识 ffmpeg 处理流程 从一种编码转换到另一种编码。\n基本信息查询命令 命令 说明 命令 说明 -version 版本 -formats 显示可用的格式 -demuxers 显示可用的 demuxers -protocols 显示可用的协议 -muxers 显示可用的 muxers -filters 显示可用的过滤器 -devices 显示可用的设备 -pix_fmts 显示可用的像素格式 -decoders 显示可用的解码器 -layouts 显示 channel 名称 -encoders 显示所有编码器 -colors 显示识别的颜色名称 -bsfs 显示比特率 filter D 表示解码器 E 表示编码器 录制命令 使用 ffmpeg 录制屏幕\n1 ffmpeg -f avfoundation -r 30 -i 2 out.yuv -f: 指定使用 avfoundation 采集数据，mac 下专用于音视频处理 -i: 指定从哪儿采集输入，是一个文件索引号 -r: 指定帧率 使用 ffplay 播放视频\n1 ffplay -video_size 2560x1440 -pixel_format uyvy422 out.yuv -video_size: yuv 中不包含视频大小，需要指定尺寸，在上面录制时就已给定。 -pixel_format: 播放帧格式与录制的格式必须相同，才能真确播放 上面提到 -i 指定采集输入，如何查看索引号呢?\n1 ffmpeg -f avfoundation -list_devices true -i \u0026#34;\u0026#34; 使用 ffmpeg 录制音频\n1 2 3 ffmpeg -f avfoundation -i :2 out.wav # 播放音频 ffplay out.wav 注意这次序号前面加了:，冒号前面表示视频设备，冒号后面表示音频设备。 分解/复用命令 将 mp4 转成 flv\n1 ffmpeg -i out.mp4 -vcodec copy -acodec copy out.flv -vcodec: 视频编码处理方式，copy 表示使用原始格式q -acodec: 音频编码处理方式 抽取视频\n1 ffmpeg -i video.MP4 -an -vcodec copy out.h264 抽取音频\n1 ffmpeg -i video.MP4 -vn -acodec copy out.aac -an: audio null，表示过滤掉音频 -vn: video null，表示过滤掉视频 处理原始数据命令 提前 YUV 数据\n1 ffmpeg -i video.MP4 -an -c:v rawvideo -pixel_format yuv420p out.yuv -c: 指定编解码器 -c:v: 限定只处理视频画面，例如 -c:v libx264表示转换为 h264，-c:v rawvideo表是提取 YUV 数据，也可以-c:v h264 直接操作。 -c:a: 限定只处理音频声音，例如 -c:a libmp3lame，表示转换 mp3，也可以-c:a mp3直接操作。 -c:s: 限定只处理字幕 提取 PCM 数据\n1 ffmpeg -i video.MP4 -vn -ar 44100 -ac2 -f s16le out.pcm -ar: audio rate，指定音频采样率 -ac: audio channel，指定声道，2 表示双声道 -f: 指定格式，s有符号，16表示每个数值是 16 位 播放 PCM 数据\n跟提取时一样，也要指定相关参数\n1 ffplay -ar 44100 -ac 2 -f s16le out.pcm 裁剪与合并命令 视频裁剪\n1 ffmpeg -i video.MP4 -c copy -ss 00:00:00 -t 10 out.ts -ss: 开始裁剪时间，指定时分秒 -t: 裁剪市场，单位秒 视频合并\n在合并之前，需要创建包含所有切片的文件\n1 2 3 # input.txt file \u0026#39;1.ts\u0026#39; file \u0026#39;2.ts\u0026#39; 1 ffmpeg -f concat -i input.txt out.mp4 -f concat: 指定合并 图片/视频互转命令 视频转图片\n配合视频裁剪有奇效。\n1 2 3 ffmpeg -i video.MP4 -r 1 -f image2 image-%3d.jpeg ffmpeg -i video.MP4 -ss 00:00:00 -t 5 -r 1 -f image2 image-%2d.jpeg -r: 指定转换图片的帧率，1 表示每秒转出一张图片 -f image2: 指定 jpeg 编码器 %3d.jpeg: 这是一个动态增长的文件名，最大 3 位数，不足补 0。 图片转视频\n1 ffmpeg -i image-%2d.jpeg out.mp4 直播推/拉流 直播推流\n1 ffmpeg -re -i video.mp4 -c copy -f flv \u0026#34;rtmp://server/live/streamName\u0026#34; -re: 减慢帧率速度，对于直播流来说，让帧率与声音保持同步 -c copy: 不做音视频编码 直播拉流\n1 ffmpeg -i \u0026#34;rtmp://server/live/streamName\u0026#34; -c copy dump.flv 滤镜命令 倍速，画中画，修改长宽等。\n调整宽高\n1 ffmpeg -i video.MP4 -vf crop=in_w-200:in_h-200 -c:v libx264 -c:a copy out.mp4 -vf: 指定滤镜 crop=in_w-200:in_h-200: 修改宽高 -c:v: 视频编码 ","date":"2022-11-25T00:00:00Z","permalink":"https://blog.golang.space/p/ffmpeg-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/","title":"FFmpeg 基础知识"},{"content":"编译器 在 mac 平台下，编译器是 GCC/CLANG。\n1 gcc/clang -g -O2 -o test test.c -I... -L... -l... -g: 输出文件增加调试信息 -O: 指令优化级别，-O1 不优化，-O2 代表第二个级别优化。 -o: 可执行程序输出的名字 test.c: 在这里是源代码文件 -I: 指定头文件 -L: 指定库文件位置 -l: 指定使用哪个库 编译过程 预编译，将头文件与源代码合在一起，会形成一个新的文件 编译，生成 .o 文件，这是中间文件，是可执行程序的一部分 链接，将 .o 文件与第三方库/系统库链接到一起 1 2 3 4 5 6 // vim add.c #include \u0026lt;stdio.h\u0026gt; void add(int a,int b){ printf(\u0026#34;%d\\n\u0026#34;,a+b); } 1 2 3 clang -g -c add.c # 链接 libtool -static -o libadd.a add.o 1 2 // 创建 add.h 文件 void add(int a,int b); 调用文件\n1 2 3 4 5 6 7 #include \u0026lt;stdio.h\u0026gt; // 引号表示优先在本地目录搜索，也可以用尖括号指定位置 #include \u0026#34;add.h\u0026#34; int main(){ add(5,3); return 0; } 编译\n1 gcc -g -o test main.c -I . -L . -l add 调试 Mac 下是 lldb\nLinux 下是 gdb\n说明 命令 英文 设置断点 b break 运行程序 r run 单步执行 n next 跳入函数 s step 跳出函数 finish 打印内容 p print 退出 q quit 查看所有断点 break l break list 使用 -g 加入调试信息，在目录下也会生成 test.dSYM 目录\n1 dwarfdump test ","date":"2022-11-25T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E5%8D%81%E5%85%AD%E8%AF%BE-%E7%BC%96%E8%AF%91%E5%99%A8/","title":"第十六课 编译器"},{"content":"音视频基础 媒体基础知识 图像 「图像」是「像素」的集合，有宽度和高度，每个像素块是单一的颜色。\n「图像分辨率」表示图像的质量和像素数，由 x 轴乘以 Y 轴的像素个数得出，常见分辨率:\nHD( 1920 * 1080 ) UHD ( 3840*2160 ) 4K ( 4096*2160 ) 图像的纵横比是宽高比，常见的有\n16:9 4:3 常见分辨率\n格式 分辨率 360P(流畅) 640x360 480P(标清) 854x480 720P(高清) 1280*720 1080P(高清) 1920*1080 2160P(4K) 3840*2160 4320P(8K) 7860*4320 视频 视频是一系列的图像，在视频上下文中，每个图像称为「帧」，「帧率」(fps)表示每秒有多少帧，常见的帧率:\n15 (实时通信) 25 (动画) 30 (实时通信) 60 (电影/游戏) 未编码视频的 RGB 码流计算方法 = 分辨率 * 3 * 帧率\n例如1280*720*3*25，约等于每秒 69MB。\nYUV Y 明亮度 UV 色彩及饱和度 主要的采样格式有:\nYUV4:2:0，应用最广泛的格式， YUV4:2:2，每一个横行隔一个含有一个 uv YUV4:4:4 RGB 用于屏幕图像的展示，YUV 用于采集和编码\n生成 YUV\n1 2 3 4 5 ffmpeg -i input.mp4 \\ -an \\ -c:v rawvideo \\ -pix_fmt yuv420p \\ out.yuv -i 输入 -an，audio null，表示过滤掉音频 -c，指定视频编码器为 rawvideo 视频编解码 H.264，在今天互联网上使用最多，与 YUV 的压缩比是百分之一。\nH.265 是前者的继承者，提供了更好的压缩效果\nVP9，起源于 Google\nGOP，强相关的一组帧，强相关的帧放在一起压缩，压缩率更高\n编码帧的分类\nI (interframe frame) 帧，关键帧，采用帧内压缩技术 P (forward predicted frame)，向前参考帧，压缩时只参考前面已经处理的帧，采用帧间压缩技术，占 I 帧一半大小。 B (Bidirectionally predicted frame)，双向参考帧，压缩时即参考前面已处理的帧，也参考后面的帧，帧间压缩技术，占 I 帧 ¼ 大小。B 帧越多，延迟越大，占用 CPU，空间最小。 IDR 帧是解码器立即刷新帧，解码器遇到 IDR 帧会清空 buffer 中的数据，防止错误的传播，每个 GOP 中的第一帧就是 IDR 帧。IDR 帧是一种特殊的 I 帧。\n在每个 IDR 帧前面都有 SPS 与 PPS。\nSPS (Sequence Parameter Set): 约束，参考帧的数量，解码图像尺寸，编码模式 PPS (Picture Parameter set): 图像参数集。 H264压缩技术\n帧内压缩，解决的是空域数据冗余问题 (有损) 帧间压缩，解决的是时域数据冗余问题 (有损) 整数离散余弦变化(DCT)，将空间上的相关性变为频域上无关数据然后进行量化 CABAC 压缩 宏块\n宏块是视频压缩操作的基本单元，无论是帧内压缩还是帧间压缩，他们都以宏块为单位。\n视频花屏原因\nGOP 分组中的帧丢失，造成解码端的图像发生错误，会出现花屏。\n视频卡顿原因\n为了避免花屏问题发生，发现有帧丢失时，就丢弃 GOP 内的所有帧，直到下一个 IDR 帧重新刷新图像。\nI 帧有一个比较长的周期，在下一个 I 帧来之前不显示后面的图像，视频就静止不动了，即出现卡顿现象。\n视频压缩 它的工作原理是从原始图像或视频帧中去除冗余信息，有两种冗余信息\n图像或帧存在冗余 同一场景的每两个连续帧之间存在冗余 H264 Profile，对视频压缩特性的描述。\nH264 Level 是对视频的描述，Level 越高，视频的码率，分辨率，fps 越高。\n音频 音频样本通常存储为 8 位，16 位，24 位，甚至是 32 位的值，位数越多，意味着音频质量越高。采样率表示每秒有多少个样本，可以对 44.1kHZ \u0026hellip;.采样，频率越高意味着更高的质量。\n音频 channel 表示单个采样序列，channels 可以组成不同的布局，单个 channel 称为单声道，两个 channel 称为立体声(左声道/右声道)。\n音轨(track) 表示 channel 的集合，单个媒体文件中可以有多个音轨。不同的音轨用于组织与同一时间线相关的不同声音\n编解码\nPCM，最流行的格式，但不压缩 AAC MP3 container 通常表示一种文件格式，媒体数据在文件中的组织方式。比如文件有多少流，哪里可以找到音轨等等。\nMP4，最受欢迎的 MXF，大多数高质量的专业摄像机记录 QT/MOV MKV 音频\nWAV，用于存储高质量和压缩的 PCM 音频 M4A，用于存储压缩的 AAC 音频 架构模型 流媒体服务器 推流工具( ffmepg / obs ) 拉流 (ffplay / vlc / iina) 示例\n1 2 3 4 5 # 推流 ffmpeg -i video.mp4 -f flv -rtmp_playpath \u0026#34;BSWMSId4g?sign=BSZaSIO4gz\u0026#34; rtmp://localhost/live # 拉流 ffplay rtmp://localhost/live/BSWMSId4g -i 表示输入 -f 表示输出格式 -rtmp_playpath 指定路径 简单尝试一下，会发现推流失败或清晰度不高的问题。\n-re 让媒体以原来音视频同步的速度播放，增加此参数可以避免推流失败 使用 -f 指定输出格式，会将原格式编解码到新格式，将损失一定的质量，所以清晰度不高。\n-c copy 不重新编码，使用原来的音视频方式，将会是原视频的清晰度。 音频处理流程 音频数据流\n原始数据 PCM =\u0026gt; 压缩数据 AAC/MP3 =\u0026gt; 多媒体包 MP4/FLV\nHZ ，声音在一秒内震动的次数，人类听觉范围是 20HZ ~ 20KHZ。\n声音三要素:\n音调，音频的快慢 音量，振动的幅度 音色，谐波 模数转换，对声音进行量化，将十进制转换为二进制。\n音频原始数据有两种，原始数据是 PCM，封装成格式后为 WAV。WAV 是在 PCM 的基础上套了一个 Header，增加了描述信息，如通道数，采样率，采样大小，字节对齐，采样率的字节数，\n采样大小，一个采样用多少 bit 存放，常用是 16bit。 采样率，8K，16K，32K，44.1K，48K，通常打电话是 8K 有一定的失真。 声道数，单声道，双声道，多声道。比如在电影院感受到的声音就很震撼，有很多喇叭围绕在四周。 码率计算\nPCM 音频流的码率 = 采样率 * 采样大小 * 声道数\n例如: 采样率=44.1KHz，采样大小为 16bit，双声道的 PCM 编码文件，44.1K * 16*2 = 1411.2KB/s。\nAAC 规格 AAC LC:(Low Complexity)低复杂度规格，码流是 128K，音质好。 AAC HE:等于 AAC LC + SBR，核心思想是按频谱分保存。码流是 64K。 AAC HE v2:等于 AAC LC + SBR + PS，双声道的声音存在某种相似性，只需存储一个声道，并花很少字节描述另一个声道不同的地方。 AAC 格式 ADIF (audio date interchange format)，可以确定的找到音频数据的开始，只能从头开始解码。\nADTS (audio data transport stream)，每一帧都有一个同步字，可以在音频任意位置解码，适用性更广，更适合流媒体传输。\n由 7/9 个字节组成，\n通过 ffmpeg 生成 AAC 文件 1 2 3 4 5 6 7 ffmpeg -i xxx.mp4 \\ -vn \\ -c:a aac \\ -ar 44100 \\ -channels 2 \\ -profile:a aac_he_v2 \\ xxx.aac -vn: video null，用于过滤掉视频 -c: 指定编码器，a 表示 audio，libfdk_aac 相对而言，这个性能是最好的编码器 -ar: audio rate 采样率 -channels: 通道数 -profile:指定参数 音频重采样? 什么是音频重采样?\n将音频三元组转换成另外一组值，例如将 44100/16/2 =\u0026gt; 48000/16/2\n为什么要重采样?\n采样的音频数据与编码器要求的数据不一致 扬声器要求的音频数据与要播放的音频数据不一致 方便运算，比如回音消除，需要将其转成单声道处理 如何知道是否需要进行重采样?\n了解音频设备的参数 查看 ffmpeg 源码 重采样的步骤\n创建重采样上下文 设置参数 初始化重采样 进行重采样 流媒体 RTMP 创建流的基本流程 tcp 连接 rtmp 握手 建立 rtmp 连接 创建 rtmp 流 参考 ffmpeg 推流 rtmp 的参数设置\n码流参考值\n","date":"2022-11-24T00:00:00Z","permalink":"https://blog.golang.space/p/%E9%9F%B3%E8%A7%86%E9%A2%91%E5%9F%BA%E7%A1%80/","title":"音视频基础"},{"content":"Certified Kubernetes Application Developer (CKAD)，认证 Kubernetes 应用开发人员。该考试由云原生计算基金会（CNCF）联合Linux基金会推出，旨在考察相关从业者对 Kubernetes 的运维和开发知识了解程度的认证考试。\nCKAD 考试是一个完全动手的考试，需要您在多个Kubernetes集群中解决问题。您需要理解、使用和配置与应用程序开发人员相关的Kubernetes原语。 以官方说法，通过CKAD考试后，持证者即被认可能够为Kubernetes设计、构建、配置和部署云原生应用，在Kubernetes中能够定义应用程序资源，使用核心功能构建、监控和诊断可伸缩的应用程序。\n这是我的证书。\n考试 我在 Linux Foundation 购买的认证考试。原价是 2498，建议折扣活动期间购买，我是在黑色星期五买的。\n购买后在 \u0026ldquo;个人中心\u0026rdquo; - \u0026ldquo;我的考试\u0026rdquo; 可以看到考试券，需要去英文官网激活。\n在这里 预约考试，需要提前一天预约。具体步骤和相关说明官方文档都写的很清楚，建议查看 官方文档。\n有两次模拟考的机会，一次是 36 个小时，模拟考试比正常考试更难，模拟考的题目始终是一样的，建议多刷几遍模拟考。\n建议提前半个小时，点击启动考试，此时会跳转到相关页面，下载考试软件。我保留了下载地址分享给你 考试软件 PSI 下载。\n如果你的网络不好，软件会弹窗提示你，并只有一个退出选项 ! 我因为网络原因崩了 3 次。\n打开软件后，跟着相关步骤操作，允许使用视频和声音，拍摄自己的身份证及考试房间的环境。等待了 10 分钟，会弹出与考官的会话窗口。如果前面的哪些步骤没有达到要求，考官会提示进一步操作。\n考试时间是 2 个小时。因为做模拟考的时候感觉时间不是很充裕，所以真实考试时，我先迅速做题，不检查结果。实际上我还有足够的时间再检查一遍。打好基础，不用担心时间不够用。\n考试环境的浏览器比较卡顿，页面内文字搜索点击没反应，总结有点不方便在 kubernets 官方寻找 yaml 配置。\n注意复制和粘贴功能，windows 电脑需要多按一个 SHEFT， CTRL + SHEFT +c/v，Mac 电脑改成前面的操作，注意使用 command +c/v 是无效的，建议提前练习快捷键。\n在考试结束后 24 小时内将会收到邮件，通知你的成绩。\n学习资料 CKAD-exercises\nKubernets 官方文档\n","date":"2022-07-04T00:00:00Z","image":"http://img.golang.space/shot-1656933075470.png","permalink":"https://blog.golang.space/p/kubernetes-%E5%BC%80%E5%8F%91%E8%AE%A4%E8%AF%81ckad%E8%80%83%E8%AF%95%E5%BF%83%E5%BE%97/","title":"Kubernetes 开发认证(CKAD)考试心得"},{"content":"基于 docker-compose 模拟 PostgreSQL 12.2 主从 主服务器和后备服务器一起工作来提供高可用集群能力。主服务器在连续归档模式下操作，每一个后备服务器在连续恢复模式下操作并且持续从主服务器读取 WAL 文件。要启用这种能力不需要对数据库表做任何改动，因此它相对于其他复制方案降低了管理开销。这种配置对主服务器的性能影响也相对较低。\nPostgreSQL通过一次一文件（WAL 段）的 WAL 记录传输实现了基于文件的日志传送。日志传送是异步的，即 WAL 记录是在事务提交后才被传送。正因为如此，在一个窗口期内如果主服务器发生灾难性的失效则会导致数据丢失，还没有被传送的事务将会被丢失。基于文件的日志传送中这个数据丢失窗口的尺寸可以通过使用参数archive_timeout进行限制，它可以被设置成低至数秒。但是这样低的设置大体上会增加文件传送所需的带宽。\n参考 高可用、负载均衡和复制\ndocker-compose 配置文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 services: pg_master: restart: always image: postgres:12.2 environment: - POSTGRES_PASSWORD=123456789 - TZ=Asia/Shanghai volumes: - $PWD/master:/var/lib/postgresql/data:rw ports: - \u0026#34;1556:5432\u0026#34; extra_hosts: - \u0026#34;postgres_master:172.22.0.2\u0026#34; - \u0026#34;postgres_standby:172.22.0.3\u0026#34; networks: localnet: ipv4_address: 172.22.0.2 pg_standby: restart: always image: postgres:12.2 environment: - POSTGRES_PASSWORD=123456789 - TZ=Asia/Shanghai volumes: - $PWD/standby:/var/lib/postgresql/data:rw ports: - \u0026#34;1557:5432\u0026#34; extra_hosts: - \u0026#34;postgres_master:172.22.0.2\u0026#34; - \u0026#34;postgres_standby:172.22.0.3\u0026#34; networks: localnet: ipv4_address: 172.22.0.3 networks: localnet: driver: bridge ipam: config: - subnet: \u0026#34;172.22.0.0/16\u0026#34; gateway: \u0026#34;172.22.0.1\u0026#34; 具体操作 如果是在多台服务器上部署，建议所有设备上修改 /etc/hosts 文件，增加相关配置\n1 2 postgres_master 172.22.0.2 postgres_standby 172.22.0.3 主库 创建含有相关权限的用户，专用于流复制。 1 2 3 CREATE ROLE replica login replication encrypted password \u0026#39;xxxxxxxxxxx\u0026#39;; \\du # 查看用户列表 修改 data/pg_hba.conf 文件，该文件用于配置是否允许其它主机访问。\n参考文档\n格式: host replication 同步用的用户名 备库IP地址或域名/24 trust\n从库可以加上主库的，便于以后主从切换\n1 2 3 4 host replication replica postgres_two trust # 如果某个网段都可以允许 host replication replica 192.168.0.0/24 trust 配置主库的配置文件 data/postgres,conf，为了方便以后做主从切换，建议所有从库配置相同参数\n修改完成后重启\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 监听所有地址的客户端连接 listen_addresses = \u0026#39;*\u0026#39; # 来自客户端并发连接的最大数量，后备服务器必须 \u0026gt;= 该值 max_connections = 500 # 设置 WAL 归档 archive_mode = on archive_command = \u0026#39;cp %p /var/lib/postgresql/data/pg_archive/%f\u0026#39; restore_command = \u0026#39;cp /var/lib/postgresql/data/pg_archive/%f %p\u0026#39; recovery_target_timeline = latest # 日志格式 wal_level = replica # 设置流复制保留的最多段数目 wal_keep_segments = 64 # 中断那些停止活动超过这个时间量的复制连接 wal_sender_timeout = 30s # 来自后备服务器并发连接的最大数量，官方文档建议 \u0026gt; max_connections max_wal_senders=50 # 开启日志 logging_collector = on log_directory = \u0026#39;/var/lib/postgresql/data/log\u0026#39; log_filename = \u0026#39;pg-%Y-%m-%d_%H%M%S.log\u0026#39; log_file_mode = 0600 log_rotation_age = 72h # 恢复期间，允许连接并查询 hot_standby = on # 流复制最大延迟，默认 30s max_standby_streaming_delay = 30s # 向主报告状态，默认 10s wal_receiver_status_interval = 10s 备库设置 1 2 3 4 5 6 7 8 9 # 备份之前的数据 cp data ../data_back # 删除数据 rm -rf data/* # 进入容器，切换 postgres 用户，拉取主库的数据 docker exec -it 5123123 sh su postgres pg_basebackup -h postgres_one -U replica -Fp -P -R -D /var/lib/postgresql/data 参数 说明 -h host -U 用户名 -F p 是默认输出格式，t 表示 tar 格式 -P 显示进度 -D 输出到指定目录 -R 建立 standby.signal 并附加连接设置到postgresql.auto.conf 来简化设置一个后备服务器 检查是否成功\n进入主库查询，如显示备库表示成功\n1 2 psql select client_addr,sync_state from pg_stat_replication; ","date":"2022-05-25T00:00:00Z","image":"http://img.golang.space/img-1669079318266.png","permalink":"https://blog.golang.space/p/%E5%9F%BA%E4%BA%8E-docker-compose-%E6%A8%A1%E6%8B%9F-postgresql-12.2-%E4%B8%BB%E4%BB%8E/","title":"基于 docker-compose 模拟 PostgreSQL 12.2 主从"},{"content":"单体服务的演进过程 最初业务刚开始\n上面没有容灾的方案，服务端挂了，就直接挂了。\n当业务有点发展以后，使用 nginx 做负载均衡，横向扩展服务，数据库升级一下。\n在 DNS 上加负载均衡，使用 K8S 管理服务，使用 redis 增加缓存。\n这个架构足以支持大部分初创项目。\n优点 开发简单 测试简单 部署简单 缺点 难以理解和扩展 小改动也得全量更新 小问题容易触发大故障 能够支持的业务规模有限 微服务 单体能够承载的业务规模有限，当规模扩大的时候，就需要升级到微服务。\n每个微服务都单独连接一个数据库。\n优点 边界清晰的业务拆分 易开发，易理解，易维护 技术栈可相对独立 持续集成，持续部署更容易 按需对服务进行治理 稳定性更容易保障 缺点 增量了系统复杂度 数据拆分复杂度 难调试，难测试 跨服务修改麻烦 难部署 什么信号表明该考虑单体转微服务了 单体系统过度复杂 当前架构不能满意业务发展需要 研发效率低下，提交代码冲突 持续集成，持续交付比较困难，不太敢更新，小版本要等大版本，要死一起死 团队人员较多 如何启动? 开着飞机换引擎\n在转型的过程中，很难零故障的完全转换。\n需要公司或部门领导的支持，要有一个敢于扛责任的领导，在改造期间，要管理好预期收益，实际在转换期间是很难看到成果的。\n建立服务迁移核心团队，需要经验，执行力强，自驱力强的队员。从一个小的服务开始，遇到问题不能跳过，一定要解决，完成这个服务形成最佳实践后，可以推广到整个团队。\n微服务改造策略 由外向内，由边缘到核心 数据拆分，迁移和验证，可回滚 (要保证当微服务挂掉后，可以回滚到旧的服务) fork 请求，proxy 验证 定期复盘过程，总结可复制套路 汇报成果，让领导看到收益 微服务数据库拆分 数据不能乱，规则先确定 定义数据边界，避免数据冗余 数据库互相隔离，避免故障传递 接口聚类收敛 按功能聚类接口 避免微服务过微 避免调用链路过深 fork 请求 将老的服务上面的请求 fork 到新的服务上，比较结果是否一致。\n循序渐进可回滚 fork 请求，验证正确性 灰度逐步迁移 监控有无漏网请求 保证回滚可能性 单体到微服务改造案例 单体应用，有通知和打卡两个模块，一个 DB 读存数据\n第一步，才代码上拆分，服务部署的方式没有改变。只是将 打卡 模块的代码抽出来。\n第二步，数据库的拆分。依然还是一个单体，但连接两个数据库。\n增加一个 DB 用来存储打开相关内容。\n第三步，将打卡服务单独部署。承载 fork 的请求，然后比较新旧服务返回的结果是否一致。\n注意同一个 DB 读取没有什么影响，但是写入需要做隔离。\n第四步，通过一段时间的测试，确保服务测试通过后，就可以上线。\n加一个 api_getway，将请求全部发到新服务上。这里要保留旧的服务，如果出现问题，随时回滚。\n第五步，老的服务确实没有流量了，新服务完全稳定了，将老的服务删除。\n参考 七牛云架构师实践课\n","date":"2022-03-27T00:00:00Z","image":"http://img.golang.space/shot-1649475285445.png","permalink":"https://blog.golang.space/p/%E5%8D%95%E4%BD%93%E5%A6%82%E4%BD%95%E5%8D%87%E7%BA%A7%E5%88%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1/","title":"单体如何升级到微服务"},{"content":"泛型 简单尝试泛型函数 1 2 3 4 5 6 7 func SumIntsOrFloats[K comparable, V int64 | float64](m map[K]V) V { var s V for _, v := range m { s += v } return s } comparable 允许其值可用作比较运算符的任何类型，这里作为 map 的 key 是必要的。\n参数 V 是两种类型的联合，使用 | 指定，意味着此约束允许任何一种类型。\n调用方法。指定类型参数，以便清楚地了解在调用的函数中替换类型参数的类型。通常可以省略，如果 Go 编译器可以从代码中推断出它们。(调用没有参数的泛型函数，无法推断)\n1 2 3 4 fmt.Printf(\u0026#34;Generic Sums: %v and %v\\n\u0026#34;, SumIntsOrFloats[string, int64](ints), SumIntsOrFloats[string, float64](floats), ) 声明类型约束 当您希望将类型参数约束为 int64或 float64时，可以使用这个 Number 类型约束，而不是写出 int64 | float64。\n1 2 3 type Number interface { int64 | float64 } 1 2 3 4 5 6 7 func SumNumbers[K comparable, V Number](m map[K]V) V { var s V for _, v := range m { s += v } return s } 参考 Go 官方泛型教程\n泛型设计\n","date":"2022-03-18T18:00:00Z","permalink":"https://blog.golang.space/p/25.%E6%B3%9B%E5%9E%8B/","title":"25.泛型"},{"content":"分析与追踪 这里主要关注两种性能分型。针对阻塞和互斥锁所做的性能分析价值不是特别大，那是针对程序中很小的一部分，例如阻塞情况而做的，所以不太能够看出程序的整体的情况，当然，接下来说明的技巧也可以用在这个上面。\nCPU 层面的 内存层面的 通过追踪不仅能程序里发生了什么，还能知道哪些事情没有发生。\n从 CPU 层面，我们要关注的是程序把大部分时间都耗在哪些函数上面 从内存层面，要关注两项指标 程序要给堆上面放多少个值，如果这样的值比较多且有效期比较短，那么垃圾收集工作就得花费很长时间才能完成。 堆的总大小，能不能少用一些空间 栈追踪 程序发生 panic 时，终端会输出栈调用信息。\n微观优化 关注单个函数，让这个函数运行更快，可能要查看 CPU 的使用情况，或堆内存的使用情况分析。\n使用 -memprofile 对基准测试生成内存报告\n1 go test -run none -bench . -benchtime 3s -benchmem -memprofile m.out go tool pprof 可以查看涉及 CPU，内存，以及阻塞的分析文件。\n1 2 3 go tool pprof -alloc_space m.out # 通过 list 命令查看分析 list \u0026lt;函数名\u0026gt; -alloc_space 查看内存分配情况 -alloc_objects 查看各种内容的数量 -inuse_sapce 默认选项 如下图所示，红框有两栏。第一栏 flat 表示该行的内存分配，假如查看的 Profile 是针对 CPU 生成的，则该栏是 CPU 的用量。第二栏 cum 表示从这一行算起，一直沿着调用栈往下累计，看看它本身及调用的代码总共分配了多少内存。\n比如下图中的意思是，26 行本身没有分配内存，但是它调用栈往下累计，发生了分配 512.05kb 内存。\n也可以使用网页版\nFlat 该函数本次运行耗费资源 Flat% 占总资源的比例 Sum% 该数据累计耗费资源比例 Cum 该函数及调用栈总耗费资源 Cum% 比例 Name 函数名 资源 - inuse_spce 已分配尚未释放的内存 inuse_objects 已分配但尚未释放的对象数量 alloc_space 分配的内存总量 alloc_objects 分配的对象总数 1 2 3 4 5 6 # 安装图形工具, 用于绘制图形 brew install graphviz # 生成 cpu.out 文件 go test -bench . -cpuprofile cpu.out # 见图2, 输入 web 后生成 图3 go tool pprof -http :3333 cpu.out 根据图中显示, 哪一块最消耗性能, 针对修改, 使用 pprof 继续进行测试, 以完成性能优化\n宏观优化 查看程序调度信息 每 1000 毫秒生成一份调度信息\n1 GODEBUG=schedtrace=1000 ./main \u0026gt; /dev/null 终端会输出正在运行的跟可运行的 goroutine。\n第一栏是追踪信息的时刻 第二栏是有多少个 procs可以使用 第三栏闲置的 procs 数量 第四栏有多少操作系统级别的线程 第五栏 spinningthreads ，指的是某个 procs 发现自己一直没事做，所以纵向从别处拿一点儿任务过来，或者就是想让自己在这里空转，防止系统把自己给切换掉 第六栏是闲置的系统级线程 第七栏是全局运行队列 最后是本地运行队列，方括号的每个数字都表示一个逻辑处理器(procs) 给系统增加负载做测试\n1 hey -m GET -c 100 -n 10000 \u0026#34;http://localhost:1323/app\u0026#34; 如果发生了 goroutine 泄露，那么这些 goroutine 就会进入 waiting 状态，于是我们可以看到全局运行队列与局部队列里的数字就会不断增长。相反如果任务完成，这些数字都会降到 0，说明服务器是很健康的，并没有泄露什么。\n查看程序垃圾收集信息 每次垃圾收集打打印一条追踪信息\n1 GODEBUG=gctrace=1 ./main \u0026gt; /dev/null gc 1 和 gc 2\u0026hellip; 分别表示第几次垃圾收集 第二栏表示在生成这条信息时，程序已经运行了多长时间 第三栏表示为了完成这次垃圾收集工作，使用了多少 CPU 资源，图中为 0%，说明任务完成的相当快 第四栏显示了垃圾收集的三个阶段所花的时间，比如0.022+0.75+0.035 是 STW + Concurrent +STW，两个 STW 加起来不应该超过 100 微秒(0.1 毫秒)，如果堆正在膨胀，那么偶尔可能会超过这个值，但不应该频繁发生。我们要关注的是 Concurrent 实际经过时间。 第四栏是 CPU 所花的时间，最左边和最右边和上面一样，也是 STW 所花的时间，但它将中间 Concurrent 分成了三个小的部分，这里重点是检查两个 STW 所花的时间。 第五栏，如果你怀疑程序有内存泄露问题，那只能通过这个地方来判断。4-\u0026gt;5-\u0026gt;1 MB，收集垃圾之前的堆大小，完成收集垃圾后的堆大小，最后是活跃堆的大小。 web 应用引入 pprof 监测性能 1 2 // 引入包，仅仅执行初始化逻辑 _ \u0026#34;net/http/pprof\u0026#34; allocs 对过去所有的内存分配行为采样，性能调优查看重点此项。 block 导致阻塞的堆栈跟踪 cmdline 当前程序通过什么样命令调用的 goroutine 所有当前 goroutine 的堆栈痕迹 heap 活跃对象内存分配情况，heap 是以前的老路径，allocs 是1.11 加进来了新路径。 pprof 会注册到net/http 包默认的服务上，建议单独开一个专门 pprof 的服务，端口不要暴露到公网。\n分析正在运行的 Go 程序 CPU 这跟 heap 方面的数据有点区别，那个只需要根据以往的堆数据就能统计出来。但 CPU 方面的不同，要想得到有效的报告，必须给程序增加负载，默认的标准中，在生成 CPU 报告时，需要让程序运行 30 秒，以便收集足够量的数据。\n如果你想自定义时间\n1 http://localhost:6060/debug/pprof/profile?seconds=5 分析 CPU\n1 go tool pprof -http :5050 \u0026#34;http://localhost:6060/debug/pprof/profile\u0026#34; 另一种办法做性能分析 除了命令行 go tool pprof ，还有另一种办法做性能分析。\n程序会向标准输出端输出一份分析报告。 注意: 与没有做性能分析时相比，这次的程序花的时间会长一些。\n1 2 3 4 5 6 7 import \u0026#34;runtime/pprof\u0026#34; func main() { pprof.StartCPUProfile(os.Stdout) defer pprof.StopCPUProfile() // ... } 1 2 3 main \u0026gt; cpu.out go tool pprof cpu.out 有时，你会发现大部分性能消耗在操作系统调用上，profile 没能发挥作用，试试 trace。\n用 Tracer 追踪程序运行情况 做 trace 也有很多种办法:\n在命令行里执行 benchmark 的时候增加 -trace 选项 标准库里的函数 有时候我们要看的不是程序发生了什么，而是还没有发生的事情。\n1 2 3 4 5 6 7 import \u0026#34;runtime/trace\u0026#34; func main() { trace.Start(os.Stdout) defer trace.Stop() // ... } 追踪和性能测试不同，它不要求程序必须停下来，只是会把每次函数调用都记录下来，而且会精确到微秒级别。\n1 2 main \u0026gt; cpu.out go tool trace c.out ","date":"2022-03-01T00:00:00Z","permalink":"https://blog.golang.space/p/%E5%88%86%E6%9E%90%E4%B8%8E%E8%BF%BD%E8%B8%AA/","title":"分析与追踪"},{"content":"新的思维方式 代码行数，确实会影响项目的健康程序，团队的健康程序。\n如果将 Linux 视为一个开源项目，那么今天该项目中约有 2400 万行代码，这非常庞大，需要一个庞大的团队来处理。\n成为质量，效率和简单性的拥护者。\n是什么推动了我做出的工程决策? 作为开发人员，我在进步吗?\n采用新技术总是很容易，但是采用新的思维方式却很难。\n少即是多 如果你的工作做得很好，没人应该知道你的名字。\n如果有人知道你的名字，可能意味着你的软件出现故障或导致问题。\n你想让别人知道你的名字吗? 成为前端开发者。那你会花两周的时间在屏幕上工作，会有人看着你的页面指出了他们不喜欢的东西。啊，这曾经让我发疯。\n不管是什么行业，不管软件是否正确，人们的生活，他们的幸福，一切都依赖于你正在构建的技术。我们必须认真对待，保持软件的完整性。\n完整性有两个地方，一个微观层面和一个宏观层面。\n在微观层面，需要明白你写的每一行代码。每一行代码要么做三件事之一，它分配内存，读取内存，写入内存。使用 Go 语言，我们在代码中所需要做的只是读取并写入内存，所有这些读取和写入都会导致我们周围的一切发生: 灯亮了。你正在阅读这篇文章。\n上面提到过，一般开发者面对超过 10000 行代码，会产生严重的心智负担。而且平均每 100 行代码有可能会产生 10-20 个错误。当代码比预估需要的多时，就会有更多的地方可以隐藏错误，这也意味着有更多不完整的测试。\n除了编写更少的代码之外，完整性的另一个重要部分是错误处理。你的软件必须保持稳定，而不是增加危机，应该试图从错误中恢复。\nless is always more\n完整性是首要的，次要的是可读性。要以一种易于理解的方式构建我们的软件。\n抽象的目的不是模糊，而是创造一个新的语义层次，一个可以绝对精确的层次。\n封装不仅仅是可测试的，要确保它们提供了一种语义精确的层次，而不是隐藏复杂性。\n性能 软件的性能不足，有可能来自四个地方。\n延迟，网络，IO，磁盘 IO 等类型的延迟 垃圾回收和内存分配 访问数据的方式，效率 算法效率，是否可以优化算法以采取更少的步骤而不是更多的步骤 让它正确，让它清晰，让它简洁，让它快速\n面向数据的设计 Go 语言的特性，它要求你必须把自己的思维方式，从 面向对象的设计 到 面向数据的设计。\n怎么才能将代码和有可能改变的数据相解耦呢? 如何可以解耦，那就可以尽量降低由于数据改动造成的连锁反应。\n总是在做抽象，在抽象上面做另一层抽象，那么就会离上面说的解耦越来越远，而且很难保证代码准确无误，清晰易读，因为这样写出来的代码太过抽象，让我们很难理解其中的思路。\n代码要针对当下来写，架构要面向未来设计。不要写出目前根本用不到的代码，那样写只会产生更多的 bug。因为代码越多，越容易出 bug。\n面向数据的设计，是要求必须将数据搞懂，要求我们只编写必须用到的代码和算法，要对算法解耦，以降低数据发生变化时整个项目受到的影响。我们要做是，怎样做到数量最少写法最清晰的代码把问题解决。\n数据应该在特定的情况下才有行为，如果你是从面向对象的编程语言切换到 Go，那可能不太容易接受这种理念。因为 OOP 总是要求你考虑数据的状态，以及数据会有怎样的行为。面向对象并不是 Go 语言里面最好的编程思路，Go 语言在大多数情况下追求的其实是把状态跟行为分开，做到这点可以少写一点代码，并且可以简化编程工作。\n首先应该考虑函数，只有在不该用或不方便使用函数的情况下，才可以考虑方法。\n遗留代码 我们认为糟糕的代码是由糟糕的开发人员编写的，但实际上，它是由合适的开发人员在\u0026rsquo;糟糕的情况下\u0026rsquo;编写的。\n总会有人请你帮他看代码，你可能会觉得写代码的人是不是出了什么问题，怎么会写出这样的东西呢?\n其实这背后是有原因的，他们没有办法告诉你，遇到这种代码的时候千万别急。先冷静下来，别急着去责怪写它的那个人，我们应该问问自己，这种代码是在什么样的环境或什么样的情况下写出来的。\n现在既然交给自己来维护，那有没有什么办法能把它改的好一些呢?\n无论面对什么事都应该有同理心，因为做那件事的人所处的情况可能和你现在不一样，现在是把别人写过的代码交给你来维护，反过来你的代码也有可能交给别人来维护。如果能够换位思考，那么跟遗留代码有关的许多问题或许就能够解决。\n如果你想一开始就把代码写好，而不想写出那种留有很有问题的代码，那么首先要注意的，就是提醒自己，这套代码优采用什么样的方式来写，写代码的思路特别关键，每天重构代码，其实都是按这样的思路进行修改的。\n在开发者脑子里，通常没办法容下超过 10000 行代码，这里的容下不是指将每行代码都背下来。而是如果有人问你某个函数在什么地方，或是某项功能的实现代码在哪里，你可以很快的找出来。也就是说，你能够弄清代码的流程，对代码非常的熟悉。如果程序发生错误，很快就能知道自己应该从哪块代码入手。\n我们要关注代码行数，把它降低，这样才能保证团队合作顺利。每位程序员所需要把控的代码不应超过 10000 行，这种认知方面的负担必须引起重视。\n最难对付的 bug 是思路上的 bug，因为你根本看不出问题在哪。\n不应该第一时间使用调试器，如果正式的软件产品里面出现了错误，那你只应该通过整理思路，或者查看日志来解决问题，如果这些方法还是不能帮你找到 bug，那就说明这段代码的写法出了问题。如果需要调试器才能解决问题，可能这段代码需要重构。因为根本问题在于修正思路上的错误。要在日志里面多记录一些有用的信息，帮助我们还原当时出错的过程。\nGo 是我见过的力量和表现力之间的最佳平衡，通过简单直接的编程，你几乎可以做任何你想做的事情。并且，对机器上将要发生的事情有一个良好的心理模型\n","date":"2022-02-25T00:00:00Z","permalink":"https://blog.golang.space/p/%E5%BA%94%E8%AF%A5%E6%9C%89%E7%9A%84-go-%E8%AF%AD%E8%A8%80%E6%80%9D%E7%BB%B4/","title":"应该有的 Go 语言思维"},{"content":"\u0026lt;Redis 核心技术与实战\u0026gt;读书笔记 基础 简单来说，底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下图所示：\n为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对。\n哈希表的最大好处很明显，就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对\n为什么哈希表操作变慢了？\n当你往哈希表中写入更多数据时，哈希冲突是不可避免的问题。这里的哈希冲突，也就是指，两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。\nRedis 解决哈希冲突的方式，就是链式哈希。就是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。\n哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率降低。\n对于 String 类型来说，找到哈希桶就能直接增删改查了，所以，哈希表的 O(1) 操作复杂度也就是它的复杂度了。\n对于集合类型来说，即使找到哈希桶了，还要在集合中再进一步操作。\n单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定，例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以它们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM、SRANDMEMBER 复杂度也是 O(1)。\n范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。\n统计操作，是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。\n例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。\n宕机了，如何避免数据丢失 一旦服务器宕机，内存中的数据将全部丢失。\nRedis 的持久化主要有两种方式:\nAOF（Append Only File）日志 RDB (Redis DataBase) 快照 AOF Redis 是先执行命令，把数据写入内存，然后才记录日志。\n传统数据库( 如 Mysql )的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。\n我们以 Redis 收到“set testkey ”命令后记录的日志为例，看看 AOF 日志的内容。\n“*3”表示当前命令有三个部分，每部分都是由“$+数字”开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，“$3 set”表示这部分有 3 个字节，也就是“set”命令。\n但是，为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。\n而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的一大好处是，可以避免出现记录错误命令的情况。\n不过，AOF 也有两个潜在的风险。\n首先，如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有丢失的风险。如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记入日志，所以就无法用日志进行恢复了。\n其次，AOF 虽然避免了对当前命令的阻塞，但可能会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而导致后续的操作也无法执行了。\n这两个风险都是和 AOF 写回磁盘的时机相关的。这也就意味着，如果我们能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就解除了。\n- 优点 风险 AOF 避免额外的检查开销，避免出现记录错误命令的情况 会出现没有来得及记日志就宕机的情况，可能会给下一个操作带来阻塞风险 三种写回策略 AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选值。\n- - 可靠性 高性能 Always 同步写回 高 低 Everysec 每秒写回，先放缓冲区 中 中 No 操作系统控制的写回，先放缓冲区 低 高 我们一定要小心 AOF 文件过大带来的性能问题。这里的“性能问题”，主要在于以下三个方面：一是，文件系统本身对文件大小有限制，无法保存过大的文件；二是，如果文件太大，之后再往里面追加命令记录的话，效率也会变低；三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，这就会影响到 Redis 的正常使用。\n日志文件太大了怎么办？ AOF 重写机制，在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件。\n重写机制具有“多变一”功能。所谓的“多变一”，也就是说，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。\n当一个键值对被多条写命令反复修改时，AOF 文件会记录相应的多条命令。但是，在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用一条命令就行了，而且，在日志恢复时，只用执行这条命令，就可以直接完成这个键值对的写入了。\nAOF 重写会阻塞吗? 不会! 和 AOF 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。\nfork子进程时，子进程是会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。\n因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了。\nRDB 快照 所谓内存快照，就是指内存中的数据在某一个时刻的状态记录。\n全量数据越多，RDB 文件就越大，往磁盘上写数据的时间开销就越大。\n对于 Redis 而言，它的单线程模型就决定了，我们要尽量避免所有会阻塞主线程的操作，所以，针对任何操作，我们都会提一个灵魂之问：“它会阻塞主线程吗?”RDB 文件的生成是否会阻塞主线程，这就关系到是否会降低 Redis 的性能。\nRedis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。\n- - save 主线程执行，会导致阻塞 bgsave(默认) 创建一个子进程，专门用于写入 RDB 文件，避免主线程阻塞 快照时数据能修改吗? 给别人拍照时，一旦对方动了，那么这张照片就拍糊了，我们就需要重拍，所以我们当然希望对方保持不动。对于内存快照而言，我们也不希望数据“动”。\n为了快照而暂停写操作，肯定是不能接受的。所以这个时候，Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。\n如果主线程要修改一块数据，那么，这块数据就会被复制一份，生成该数据的副本。然后，主线程在这个数据副本上进行修改。同时，bgsave 子进程可以继续把原来的数据写入 RDB 文件。\n混合 AOF/RDB Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。\n这个方法既能享受到 RDB 文件快速恢复的好处，又能享受到 AOF 只记录操作命令的简单优势，颇有点“鱼和熊掌可以兼得”的感觉，建议你在实践中用起来。\n关于 AOF 和 RDB 的选择问题，我想再给你提三点建议：\n数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择； 如果允许分钟级别的数据丢失，可以只使用 RDB； 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。 注意: 写比读多时，RDB 的性能问题。\n1 2 3 4 5 6 7 8 9 # 开启 RDB 持久化 save 60 10000 # 60 秒内执行 1000 次操作，持久化 save 300 10 # 300 秒内执行 10 次操操作，持久化 save 600 1 # 600 秒内执行 1 次操作，持久化 # 开启 AOF 持久化 appendonly yes appendfilename \u0026#34;appendonly.aof\u0026#34; appenddirname \u0026#34;appendonlydir\u0026#34; appendfsync everysec 主从库实现数据一致 现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们在实例 2 上执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据：\n1 replicaof 172.16.19.3 6379 第一阶段，从库向主库发送 psync 命令，其中包含 runID (主库唯一标识) 和 offset (复制进度) 两个参数，首次同步，runID=?，offset=-1。主库返回正确的 runID 和 offset。\n第二阶段，主库执行 bgsave 生成 RDB 文件，发给从库。从库收到后清空当前数据库，加载 RDB 文件。\n第三阶段，主库在同步过程中新增的命令，专门记录到 replication buffer，此时发给从库。从库执行这些操作完成数据同步。\n一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。\n主从级联模式分担全量复制时的主库压力 一主多从模式中，同步数据，主库生成 RDB 和 发送 RDB 会消耗性能和带宽。可以通过级联，将压力分担到从库上。\n主从库间网络断了怎么办？ 基于长连接的命令传播这个过程中存在着风险点，最常见的就是网络断连或阻塞。\n从 Redis 2.8 开始，网络断了之后，主从库会采用增量复制的方式继续同步。当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。\nrepl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。\n网络断了后，将主库写位置和从库读位置的之间的命令同步给从库。\n因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖掉之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。\n因此，我们要想办法避免这一情况，一般而言，我们可以调整 repl_backlog_size 这个参数。\n一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。\n哨兵机制: 主库挂了，不间断服务 基本流程 哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。\n监控是指哨兵进程在运行时，周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行。如果从库没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”；同样，如果主库也没有在规定时间内响应哨兵的 PING 命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。\n主库挂了以后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，现在的集群里就有了新主库。\n最后，哨兵会执行最后一个任务：通知。在执行通知任务时，哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。\n哨兵机制通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。\n“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。\n如何选定新主库？ 首先过滤掉不符合条件的，如果在选主时，一个从库正常运行，我们把它选为新主库开始使用了。可是，很快它的网络出了故障，此时，我们就得重新选主了。这显然不是我们期望的结果。\n如果从库总是和主库断连，而且断连次数超出了一定的阈值，我们就有理由相信，这个从库的网络状况并不是太好，就可以把这个从库筛掉了。\n接下来就要给剩余的从库打分。我们可以分别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。\n第一轮：优先级最高的从库得分高。用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。如果从库的优先级都一样，那么哨兵开始第二轮打分。\n第二轮：和旧主库同步程度最接近的从库得分高。如果从库的优先级都一样，那么哨兵开始第三轮打分。\n第三轮：ID 号小的从库得分高。\n如果有哨兵实例在运行时发生了故障，主从库还能正常切换吗？ 在配置哨兵的信息时，我们只需要用到下面的这个配置项，设置主库的 IP 和端口，并没有配置其他哨兵的连接信息。\n1 sentinel monitor \u0026lt;master-name\u0026gt; \u0026lt;ip\u0026gt; \u0026lt;redis-port\u0026gt; \u0026lt;quorum\u0026gt; 这些哨兵实例既然都不知道彼此的地址，又是怎么组成集群的呢？要弄明白这个问题，我们就需要学习一下哨兵集群的组成和运行机制了。\n基于 pub/sub 机制的哨兵集群 哨兵实例之间可以相互发现，要归功于 Redis 提供的 pub/sub 机制，也就是发布 / 订阅机制。\n哨兵只要和主库建立起了连接，就可以在主库上发布消息了，比如说发布它自己的连接信息（IP 和端口）。同时，它也可以从主库上订阅消息，获得其他哨兵发布的连接信息。当多个哨兵实例都在主库上做了发布和订阅操作后，它们之间就能知道彼此的 IP 地址和端口。\n在主从集群中，主库上有一个名为“sentinel:hello”的频道，不同哨兵就是通过它来相互发现，实现互相通信的。\n实战篇 Redis 在消息队列上的应用 消息队列在存取消息时，必须要满足三个需求，分别是消息保序、处理重复的消息和保证消息可靠性。\n消息保序\n假设有 3 个消息\n减库存 5 读库存 减库存 2 如果发生乱序处理任务，优先执行了 321，此时 2 读到的库存是错误的。\n重复消息处理\n因为网络堵塞而出现消息重传的情况，可能到收到多条重复消息。\n一个任务扣 1 个库存，因为重复消息，却扣了 5 次就不对了。\n消息可靠性保证\n因为故障或宕机导致消息没有处理完成。当消费者重启后，可以重新读取消息处理\nRedis 的 List 和 Streams 两种数据类型，就可以满足消息队列的这三个需求\n基于 List 的消息队列解决方案 List 本身就是按先进先出的顺序对数据进行存取的，所以，如果使用 List 作为消息队列保存消息的话，就已经能满足消息保序的需求了。\n当 List 中没有值，RPOP 命令会读到空值。为了解决这个问题，Redis 提供了 BRPOP 命令，BRPOP 命令也称为阻塞式读取，客户端在没有读到队列数据时，自动阻塞，直到有新的数据写入队列，再开始读取新数据。\nList 本身是不会为每个消息生成 ID 号的，所以，消息的全局唯一 ID 号就需要生产者程序在发送消息前自行生成。生成之后，我们在用 LPUSH 命令把消息插入 List 时，需要在消息中包含这个全局唯一 ID。\n当消费者程序从 List 中读取一条消息后，List 就不会再留存这条消息了。所以，如果消费者程序在处理消息的过程出现了故障或宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就没法再次从 List 中读取消息了。为了留存消息，List 类型提供了 BRPOPLPUSH 命令，这个命令的作用是让消费者程序从一个 List 中读取消息，同时，Redis 会把这个消息再插入到另一个 List（可以叫作备份 List）留存。这样一来，如果消费者程序读了消息但没能正常处理，等它重启后，就可以从备份 List 中重新读取消息并进行处理了。\n基于 List 类型，我们可以满足分布式组件对消息队列的三大需求。但是，在用 List 做消息队列时，我们还可能遇到过一个问题：生产者消息发送很快，而消费者处理消息的速度比较慢，这就导致 List 中的消息越积越多，给 Redis 的内存带来很大压力。\n我们希望启动多个消费者程序组成一个消费组，一起分担处理 List 中的消息。但是，List 类型并不支持消费组的实现。那么，还有没有更合适的解决方案呢？这就要说到 Redis 从 5.0 版本开始提供的 Streams 数据类型了。\n基于 Streams 的消息队列解决方案 1 2 3 # 往 mqstream 队列插入 {resp:5} # 星号表示自动生成全局唯一的 ID XADD mqstream * resp 5 参考 Redis 核心技术与实战\n","date":"2022-01-22T15:00:00Z","permalink":"https://blog.golang.space/p/redis-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","title":"\u003cRedis 核心技术与实战\u003e读书笔记"},{"content":"分布式事务 在一个系统内部，我们可以使用数据库事务来保证数据一致性。\n那如果一笔交易，涉及到跨多个系统、多个数据库的时候，用单一的数据库事务就没办法解决了。\n如何来解决这种跨系统、跨数据库的数据一致性问题呢？答案就是咱们要讨论的主题，分布式事务。\n分布式事务也是事务，也需要遵从 ACID 四个特性，但实际情况是，在分布式系统中，因为必须兼顾性能和高可用，所以是不可能完全满足 ACID 的。我们常用的几种分布式事务的实现方法，都是“残血版”的事务，而且相比数据库事务，更加的“残血”。\n分布式事务的解决方案有很多，比如：2PC、3PC、TCC、Saga 和本地消息表等等。这些方法，它的强项和弱项都不一样，适用的场景也不一样，所以最好这些分布式事务你都能够掌握，这样才能在面临实际问题的时候选择合适的方法。这里面，2PC 和本地消息表这两种分布式事务的解决方案，比较贴近于我们日常开发的业务系统。\n事务消息 在快餐店点餐并付钱后，并不会直接给你餐点，往往是给你一张小票或序号，然后让你拿着凭证到出货区排队取。\n为什么要将付钱和取货两个动作分开呢? 一个很重要的原因是为了使他们接待能力增强。只要凭证能可靠保存，依靠凭证(消息)能完成最终一致性。\n分布式事务方法 强一致性 高并发 可用性 应用场景 2PC 优 差 差 订单系统完成，促销系统销毁优惠券 本地消息表 优 良 良 订单系统完成，购物车系统清空物品 事务收件箱 ( Transactional outbox ) 轮询发布 ( Polling publisher ) ( Transaction log tailing ) 两阶段提交 ( 2PC ) mysql的事务就是通过**「日志系统」**来完成两阶段提交的。由一个全局的事务管理器协调各个子系统的局部事务管理器完成两阶段提交。\n在我们购物下单时，如果使用了优惠券，订单系统和优惠券系统都要更新自己的数据，才能完成“在订单中使用优惠券”这个操作。\n订单系统内两个操作的一致性问题可以直接使用数据库事务来解决。促销系统需要操作就比较简单，把刚刚使用的那张优惠券的状态更新成“已使用”就可以了。我们需要这两个系统的数据更新操作保持一致，要么都更新成功，要么都更新失败。\n接下来我们来看 2PC 是怎么解决这个问题的。2PC 引入了一个事务协调者的角色，来协调订单系统和促销系统，协调者对客户端提供一个完整的“使用优惠券下单”的服务，在这个服务的内部，协调者再分别调用订单和促销的相应服务。\n二阶段指的是准备阶段和提交阶段。在准备阶段，协调者分别给订单系统和促销系统发送“准备”命令，订单和促销系统收到准备命令之后，开始执行准备操作。准备阶段都需要做哪些事儿呢？你可以理解为，除了提交数据库事务以外的所有工作，都要在准备阶段完成。比如说订单系统在准备阶段需要完成：\n在订单库开启一个数据库事务； 在“订单优惠券表”写入这条订单的优惠券记录； 在“订单表”中写入订单数据。 注意，到这里我们没有提交订单数据库的事务，最后给事务协调者返回“准备成功”。类似的，促销服务在准备阶段，需要在促销库开启一个数据库事务，更新优惠券状态，但是暂时不要提交这个数据库事务，给协调者返回“准备成功”。协调者在收到两个系统“准备成功”的响应之后，开始进入第二阶段。\n等两个系统都准备好了之后，进入提交阶段。提交阶段就比较简单了，协调者再给这两个系统发送“提交”命令，每个系统提交自己的数据库事务，然后给协调者返回“提交成功”响应，协调者收到所有响应之后，给客户端返回成功响应，整个分布式事务就结束了。\n这是正常情况，接下来才是重点：异常情况下怎么办？我们还是分两个阶段来说明。在准备阶段，如果任何一步出现错误或者是超时，协调者就会给两个系统发送“回滚事务”请求。每个系统在收到请求之后，回滚自己的数据库事务，分布式事务执行失败，两个系统的数据库事务都回滚了，相关的所有数据回滚到分布式事务执行之前的状态，就像这个分布式事务没有执行一样。以下是异常情况的时序图：\n在实现 2PC 的时候，没必要单独启动一个事务协调服务，这个协调服务的工作最好和订单服务或者优惠券服务放在同一个进程里面，这样做有两个好处：\n参与分布式事务的进程更少，故障点也就更少，稳定性更好； 减少了一些远程调用，性能也更好一些。 2PC 是一种强一致的设计，它可以保证原子性和隔离性。只要 2PC 事务完成，订单库和促销库中的数据一定是一致的状态。\n所以 2PC 比较适合那些对数据一致性要求比较高的场景，比如我们这个订单优惠券的场景，如果一致性保证不好，有可能会被黑产利用，一张优惠券反复使用，那样我们的损失就大了。\n2PC 也有很明显的缺陷，整个事务的执行过程需要阻塞服务端的线程和数据库的会话，所以，2PC 在并发场景下的性能不会很高。\n可能出现的问题:\n单点故障，一旦事务管理器出现故障，整个系统不可用 数据不一致，阶段二如果事务管理器只发送 响应时间较长，消息链路串行，要等待响应结果，不适合高并发场景 不确定性，当事务管理器发送 commit 之后，并且此时只有一个参与者收到了 commit，那么当该参与者与事务管理器同时宕机之后，重新选举的事务管理器无法确定该条消息是否提交成功。 本地消息表 2PC 它的适用场景其实是很窄的，更多的情况下，只要保证数据最终一致就可以了。比如说，在购物流程中，用户在购物车界面选好商品后，点击“去结算”按钮进入订单页面创建一个新订单。这个过程我们的系统其实做了两件事儿。\n第一，订单系统需要创建一个新订单，订单关联的商品就是购物车中选择的那些商品。 第二，创建订单成功后，购物车系统需要把订单中的这些商品从购物车里删掉。 这也是一个分布式事务问题，创建订单和清空购物车这两个数据更新操作需要保证，要么都成功，要么都失败。但是，清空购物车这个操作，它对一致性要求就没有扣减优惠券那么高，订单创建成功后，晚几秒钟再清空购物车，完全是可以接受的。只要保证经过一个小的延迟时间后，最终订单数据和购物车数据保持一致就可以了。\n本地消息表的实现思路是这样的，订单服务在收到下单请求后，正常使用订单库的事务去更新订单的数据，并且，在执行这个数据库事务过程中，在本地记录一条消息。这个消息就是一个日志，内容就是“清空购物车”这个操作。因为这个日志是记录在本地的，这里面没有分布式的问题，那这就是一个普通的单机事务，那我们就可以让订单库的事务，来保证记录本地消息和订单库的一致性。完成这一步之后，就可以给客户端返回成功响应了。\n然后，我们再用一个异步的服务，去读取刚刚记录的清空购物车的本地消息，调用购物车系统的服务清空购物车。购物车清空之后，把本地消息的状态更新成已完成就可以了。异步清空购物车这个过程中，如果操作失败了，可以通过重试来解决。最终，可以保证订单系统和购物车系统它们的数据是一致的。\n消息队列 RocketMQ 提供一种事务消息的功能，其实就是本地消息表思想的一个实现。使用事务消息可以达到和本地消息表一样的最终一致性，相比我们自己来实现本地消息表，使用起来更加简单，你也可以考虑使用。\n如果看事务的 ACID 四个特性，本地消息表这种方法，它只能满足 D（持久性），A（原子性）C（一致性）、I（隔离性）都比较差，但是，它的优点非常突出。\n首先，实现简单，在单机事务的基础上稍加改造就可以实现分布式事务，另外，本地消息表的性能非常好，和单机事务的性能几乎没有差别。在这个基础上，还提供了大部分情况下都能接受的“数据最终一致性”的保证，所以，本地消息表是更加实用的分布式事务实现方法。\n当然，即使能接受数据最终一致，本地消息表也不是什么场景都可以适用的。它有一个前提条件就是，异步执行的那部分操作，不能有依赖的资源。比如说，我们下单的时候，除了要清空购物车以外，还需要锁定库存。\n三阶段提交 ( 3PC ) 相对于2PC来说增加了CanCommit阶段和超时机制。如果段时间内没有收到协调者的commit请求，那么就会自动进行commit，解决了2PC单点故障的问题。\n但是性能问题和不一致问题仍然没有根本解决。下面我们还是一起看下三阶段流程的是什么样的？\n第一阶段，协调者询问事务参与者，你是否有能力完成此次事务。 都返回 yes，进入第二阶段 有一个返回 no 或 等待响应超时，则中断事务，并向参与者发送 abort 请求 第二阶段，协调者会向所有的参与者发送PreCommit请求，参与者收到后开始执行事务操作，并将Undo和Redo信息记录到事务日志中。参与者执行完事务操作后（此时属于未提交事务的状态），就会向协调者反馈“Ack”表示我已经准备好提交了，并等待协调者的下一步指令。 第三阶段，在阶段二中如果所有的参与者节点都可以进行PreCommit提交，那么协调者就会从“预提交状态”转变为“提交状态”。然后向所有的参与者节点发送\u0026quot;doCommit\u0026quot;请求，参与者节点在收到提交请求后就会各自执行事务提交操作，并向协调者节点反馈“Ack”消息，协调者收到所有参与者的Ack消息后完成事务。相反，如果有一个参与者节点未完成PreCommit的反馈或者反馈超时，那么协调者都会向所有的参与者节点发送abort请求，从而中断事务。 ","date":"2022-01-22T00:00:00Z","permalink":"https://blog.golang.space/p/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","title":"分布式事务"},{"content":"Pods 官方文档\nPod 是 k8s 抽象出来的，表示一组一个或多个应用程序容器。以及这些容器的一些共享资源。\n共享存储，当做卷 网络，唯一的集群 IP 地址 有关每个容器如何运行的信息 工作节点\n一个 Pod 总是运行在工作节点，工作节点是 k8s 中的参与计算的机器。\n每个 k8s 工作节点至少运行:\nkubelet，负责 k8s 主节点和工作节点之间通信的过程，它管理 Pod 和机器上运行的容器 容器运行时 (如 docker) 负责从仓库中提取容器镜像，解压容器和运行应用程序 kubectl get - 列出资源 kubectl describe - 显示有关资源的详细信息 kubectl logs - 打印 pod 和其中容器的日志 kubectl exec - 在 pod 中的容器上执行命令 1 2 3 4 5 6 7 8 # 查看所有 pod kubectl get pods -owide # 获取 Pod 信息 kubectl describe pods # 查看标签 kubectl get po --show-labels # 通过标签批量删除 pod， -l 是 --selector 的短命令 kubectl delete po -l name=busybox-pod 通过文件创建 pod\n1 2 3 4 5 # 创建 yaml 文件 # 你可以使用 --dry-run=client 参数来预览而不真正提交即将下发到集群的对象实例 kubectl run redis --image=redis12 --dry-run=client -oyaml \u0026gt; redis-definition.yaml # 通过文件创建 pod kubectl create -f redis-definition.yaml 更新配置\nreplace ，使用新的配置文件中的 API 对象，替换原有对象 apply，执行一个对原有 API 对象的 PATCH 操作 1 2 3 4 5 # 修改 配置文件 kubectl apply xxx.yaml # 或者 kubectl edit pod redis kubectl replace -f redis.yaml --force 使用代理\n1 kubectl proxy 1 curl http://localhost:8001/api/v1/namespaces/default/pods/$POD_NAME/proxy/ 查看日志\n1 kubectl logs $POD_NAME 一旦 pod 启动并运行，可以直接在容器上执行命令\n1 2 3 4 # 列出容器环境变量 kubectl exec $POD_NAME -- env # 启动一个 bash 会话 kubectl exec -ti $POD_NAME -- bash 删除 pod\n1 kubectl delete po/webapp ReplicaSet 官方文档\n目的是维护一组任何时候都处于运行状态的 Pod 副本的稳定集合。\n1 2 3 4 5 6 7 8 # 查看系统上运行了多少 replicaSet kc get rs # 查看描述 kc describe rs/new-replica-set # 查看解释 kc explain replicaset # 批量删除 kc delete rs/replicaset-1 rs/replicaset-2 缩放 pod 的数量\n1 kc scale rs/new-replica-set --replicas=5 获取编辑文件，修改参数\n1 kc edit rs/new-replica-set Deployment 官方文档\n一个 Deployment 为 Pods 和 ReplicaSets 提供声明式的更新能力。\n常用命令\n1 2 3 4 5 6 # 查看部署 kc get deploy # 查看镜像 kc describe deploy/frontend-deployment | grep -i image # 创建文件 kc create deploy httpd-frontend --image=httpd:2.4-alpine --replicas=3 --dry-run=client -oyaml \u0026gt; httpd-frontend.yaml Namespace 官方文档\n1 2 3 4 5 6 7 8 9 10 # 创建名字空间 kc create ns dev-ns # 查看有多少名字空间 kc get ns --no-headers | wc -l # 查看 research 空间下有多少 Pods kc get po -n research # 在 finance 空间创建镜像 kc run redis --image=redis -n finance # 查看哪个 pod 属于 blue 空间 kc get po -A | grep blue 通过配置文件来创建或修改名字空间\n通过 DNS 名称来访问\n1 2 db-service.dev.svc.cluster.local # \u0026lt;svc 名称\u0026gt;.\u0026lt;名字空间\u0026gt;.svc.cluster.local 重要的命令 创建 Pods ，加上 tier=db 标签\n1 kc run redis --image=redis:alpine -l tier=db 在配置文件编写标签\n设置端口\n1 kc expose po/redis --name=redis-service --port=6379 port 服务端口 target-port 容器端口 type 有四种 ClusterIP(默认)，NodePort, LoadBalancer, ExternalName 创建 Pod 的同时暴露端口\n1 kubectl run httpd --image=httpd:alpine --port=80 --expose 执行命令和参数 官方文档\nPod 创建文件中 comamnd 与 Dockerfile 中 ENTRYPOINT [\u0026quot;python\u0026quot;, \u0026quot;app.py\u0026quot;] 对应\nPod 创建文件中 args: [\u0026quot;--color\u0026quot;, \u0026quot;pink\u0026quot;] 与 Dockerfile 中CMD [\u0026quot;--color\u0026quot;, \u0026quot;red\u0026quot;] 对应\n1 2 # 创建容器时，修改参数 kc run webapp-green --image=kodekloud/webapp-color -- \u0026#34;--color=green\u0026#34; ConfigMaps 官方文档\nConfigMap 是一种 API 对象，用来将非机密性的数据保存到键值对中。\nConfigMap 将环境配置信息和 容器镜像 解耦，便于应用配置的修改。\n设置环境变量\n1 2 3 4 5 6 7 8 apiVersion: v1 kind: Pod metadata: spec: containers: - env: - name: APP_COLOR value: green 常用命令\n1 2 3 4 5 6 # 查看有多少 configmap kc get cm # 查看详情 kc describe cm/db-config # 通过命令创建 configmap kc create cm webapp-config-map --from-literal=APP_COLOR=darkblue 通过配置文件创建 configmap\n1 APP_COLOR=darkblue 1 kc create cm webapp-config-map --from-file=webapp-config-map.toml 为 Pod 配置 configmap\n1 2 3 4 5 6 7 8 apiVersion: v1 kind: Pod metadata: spec: containers: - envFrom: - configMapRef: name: webapp-config-map Secret 官方文档\nSecret 是一种包含少量敏感信息例如密码、令牌或密钥的对象。使用 Secret 意味着你不需要在应用程序代码中包含机密数据。Secret 类似于 ConfigMap 但专门用于保存机密数据。\n1 2 3 4 5 # 创建 通用类型 secret kc create secret generic \u0026lt;名称\u0026gt; --from-literal=DB_Host=sql01 # 例子 kc create secret generic db-secret --from-literal=DB_Host=sql01 --from-literal=DB_User=root --from-literal=DB_Password=password123 为 Pod 配置 secret 环境变量\n1 2 3 4 5 6 7 8 apiVersion: v1 kind: Pod metadata: spec: containers: - envFrom: - secretRef: name: db-secret Security Context 官方文档\n安全上下文定义 Pod 或 Container 的特权与访问控制设置。\n1 2 # 在容器内执行命令，查看当前是哪个用户 kubectl exec \u0026lt;Pod 名称\u0026gt; -- whoami 配置系统用户\n1 2 3 4 5 6 7 apiVersion: v1 kind: Pod metadata: spec: securityContext: runAsUser: 1010 containers: Resource Limits 官方文档\nOOMKILLED 错误表示内存不足\n修改配置\nrequests 资源设定请求值 limit 约束值 K，M，G，T，P，E #通常是以1000为换算标准的。\nKi，Mi，Gi，Ti，Pi，Ei #通常是以1024为换算标准的。\nK8S 的 1000 = CPU 一个核。四核表示 4*1000\n1 2 3 4 5 6 7 8 9 10 11 12 apiVersion: v1 kind: Pod metadata: spec: containers: - resources: limits: memory: 20Mi cpu: requests: memory: 5Mi cpu: Service-Accounts 官方文档\nKubernetes 区分用户账号和服务账号的概念\n用户账号是针对人而言的。 服务账号是针对运行在 Pod 中的进程而言的。 用户账号是全局性的。其名称跨集群中名字空间唯一的。服务账号是名字空间作用域的。 通用命令\n1 2 3 4 # 查看有多少 service account kc get sa # 创建 kc create sa \u0026lt;名称\u0026gt; 配置文件自动读取服务账号\n1 2 3 4 5 6 apiVersion: v1 kind: Pod metadata: spec: serviceAccountName: dashboard-sa containers: Taints And Tolerations 官方文档\n污点和容忍度相互配合，可以用来避免 Pod 被分配到不合适的节点上。 如果你需要某个节点仅会运行某一类 Pod。\n通用命令\n效果\nNoSchedule，Kubernetes 不会将 Pod 分配到该节点。 PreferNoSchedule，Kubernetes 会 尝试 不将 Pod 分配到该节点 NoExecute， Kubernetes 不会将 Pod 分配到该节点，已经存在会驱逐。 1 2 3 4 5 6 # 查看节点上的污点 kubectl describe node node01 | grep -A2 -i taints # 为 node01 节点创建污点 kc taint node node01 spray=mortein:NoSchedule # 删除污点，默认加 - 号 kc taint node node01 spray=mortein:NoSchedule- 通过对 Pods 设置容忍，将 Pods 分配到指定污点的节点\n1 2 3 4 5 6 7 8 9 10 apiVersion: kind: metadata: spec: tolerations: - key: \u0026#34;spray\u0026#34; operator: \u0026#34;Equal\u0026#34; value: \u0026#34;mortein\u0026#34; effect: \u0026#34;NoSchedule\u0026#34; containers: Node Affinity 节点亲和性 官方文档\n有两种类型\nrequiredDuringSchedulingIgnoredDuringExecution 硬需求，调度到一个节点必须满足的规则 preferredDuringSchedulingIgnoredDuringExecution 软需求，调度器尝试执行，但不能保证达到 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/e2e-az-name operator: In values: - e2e-az1 - e2e-az2 preferredDuringSchedulingIgnoredDuringExecution: - weight: 1 preference: matchExpressions: - key: another-node-label-key operator: In values: - another-node-label-value 规则表示: Pod 只能放置在具有标签键kubernetes.io/e2e-az-name且值为e2e-az1或e2e-az2的节点上。\n另外，在满足这些标准的节点中，具有标签 another-node-label-key=another-node-label-value 的节点优先使用。\noperator 的可选参数:\nIn NotIn Exists DoesNotExist Gt Lt 依据强制的节点亲和性调度 Pod，下方的配置意味着 Pod 只会被调度到具有 color=blue 标签的节点上。如果你需要 Pod 优先或强制调度到某个节点。\n已经部署的 Pod 不会处理。\n1 2 3 4 5 6 # 查看所有节点的标签 kubectl get nodes --show-labels # 为节点添加标签 kubectl label node node01 color=blue # 删除标签 kc label node node01 color- 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 apiVersion: kind: metadata: spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: color operator: In values: - blue containers: 将 Pod 部署到 master 节点上\n1 2 3 4 5 6 7 8 9 10 11 12 apiVersion: kind: metadata: spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: node-role.kubernetes.io/master operator: Exists containers: 存活/就绪/启动探测器 官方文档\nlivenessProbe 存活探测器可以探测到应用死锁，如果应用发生崩溃，Pod 会重启 readinessProbe 就绪探测器可以知道容器何时准备好接受请求流量，当一个 Pod 内的所有容器都就绪时，才能认为该 Pod 就绪。 这种信号的一个用途就是控制哪个 Pod 作为 Service 的后端。 若 Pod 尚未就绪，会被从 Service 的负载均衡器中剔除。当应用程序崩溃时，容器会重新启动。在此期间，服务将用户引导至可用的 POD。 启动探测器来了解应用容器何时启动。启动探测器可以用于对慢启动容器进行存活性检测，避免它们在启动运行之前就被杀掉。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 apiVersion: v1 kind: Pod metadata: spec: containers: - name: liveness # http 存活探测 livenessProbe: httpGet: path: /healthz port: 8080 httpHeaders: - name: Custom-Header value: Awesome # 执行第一次探测前应该等待 5 秒 initialDelaySeconds: 3 # 每隔 3 秒执行一次存活探测 periodSeconds: 3 使用启动探测器保护慢启动容器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 apiVersion: v1 kind: Pod metadata: spec: containers: - name: liveness ports: - name: liveness-port containerPort: 8080 hostPort: 8080 livenessProbe: httpGet: path: /healthz port: liveness-port failureThreshold: 1 # 探测失败时，重试次数，默认值 3 periodSeconds: 10 startupProbe: httpGet: path: /healthz port: liveness-port failureThreshold: 30 periodSeconds: 10 多容器 Pod 1 2 # 查看 webapp-2 Pod 中的 simple-webapp 容器 kubectl logs webapp-2 -c simple-webapp 性能检查 1 kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml 1 2 3 4 # 查看各个 node 性能 kubectl top node # 查看各个 pod 性能 kc top po 更新 1 2 # 查看更新策略 kc describe deploy/frontend | grep StrategyType 重建更新 Recreate 重建更新，会立即停止所有容器，重新创建。\n滚动更新 用户希望应用程序始终可用，而开发人员则需要每天多次部署它们的新版本。在 Kubernetes 中，这些是通过滚动更新（Rolling Updates）完成的。 滚动更新 允许通过使用新的实例逐步更新 Pod 实例，零停机进行 Deployment 更新。新的 Pod 将在具有可用资源的节点上进行调度。\n默认情况下，更新期间不可用的 pod 的最大值和可以创建的新 pod 数都是 1。这两个选项都可以配置为（pod）数字或百分比。 在 Kubernetes 中，更新是经过版本控制的，任何 Deployment 更新都可以恢复到以前的（稳定）版本。\n与应用程序扩展类似，如果公开了 Deployment，服务将在更新期间仅对可用的 pod 进行负载均衡。可用 Pod 是应用程序用户可用的实例。\n滚动更新允许以下操作：\n将应用程序从一个环境提升到另一个环境（通过容器镜像更新） 回滚到以前的版本 持续集成和持续交付应用程序，无需停机 kubectl set image 更新镜像\n1 kubectl set image deployments/kubernetes-bootcamp kubernetes-bootcamp=jocatalin/kubernetes-bootcamp:v2 获取端口并设置成环境变量\n1 export NODE_PORT=$(kubectl get services/kubernetes-bootcamp -o go-template=\u0026#39;{{(index .spec.ports 0).nodePort}}\u0026#39;) 检查\n1 2 3 4 5 6 7 8 9 kubectl rollout status deployments/kubernetes-bootcamp # 回滚 kubectl rollout undo deployments/kubernetes-bootcamp # 重新部署 kubectl rollout restart deployments/kubernetes-bootcamp # 查看历史版本 kubectl rollout history deployments/kubernetes-bootcamp # 回到指定的历史版本 kubectl rollout undo deploy/frontend --to-revision=2 RollingUpdate 滚动更新，设置 maxUnavailable 和 maxSurge 控制更新容器幅度。\n1 2 3 4 5 strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate 修改 strategy type ，使用 kubectl edit 可以直接修改。\nJobs And CronJob 如何列出隶属某 job 的所有 pods ?\n1 kubectl get pods --selector=job-name=pi --output=jsonpath=\u0026#39;{.items[*].metadata.name}\u0026#39; 模板关键字\n1 2 3 4 5 6 7 8 spec: template: # 最大失败次数，达到次数后视为 job 失败 backoffLimit: 4 # 控制并行数量(非负整数)，默认为 1，设置为 0 时间相当于暂停任务 parallelism: 3 # 需要完成的数量 completions: 1 Service 网络服务 1 2 3 4 5 6 # 查看，第一个 kubernetes 是 k8s 启动默认创建的服务 kubectl get svc # 创建模板 kc create svc nodeport webapp-service --tcp 8080:8080 --node-port 30080 --dry-run=client -oyaml \u0026gt; s.yaml # 对现有的部署创建 svc kubectl expose -n ingress-space deployment ingress-controller --type=NodePort --port=80 --name=ingress --dry-run=client -o yaml \u0026gt; ingress.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 --- apiVersion: v1 kind: Service metadata: name: webapp-service spec: type: NodePort ports: - targetPort: 8080 # 容器接收流量的端口 port: 8080\t# 主机上其他 Pod 通过该端口访问 Service nodePort: 30080 # 外部流量访问K8s的一种方式，即nodeIP:nodePort selector: name: simple-webapp Network Policy 网络策略 如果你希望在 IP 地址或端口层面（OSI 第 3 层或第 4 层）控制网络流量， 则你可以考虑为集群中特定应用使用 Kubernetes 网络策略（NetworkPolicy）。\n前置条件 网络策略通过网络插件 来实现。要使用网络策略，你必须使用支持 NetworkPolicy 的网络解决方案。 创建一个 NetworkPolicy 资源对象而没有控制器来使它生效的话，是没有任何作用的。\nIngress 官方文档\n可以提供负载均衡、SSL 终结和基于名称的虚拟托管\n需要安装控制器\n1 2 3 4 # 安装 ingress 控制器 kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.0/deploy/static/provider/cloud/deploy.yaml # 检查 kubectl get pods --namespace=ingress-nginx Volume 持久化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 --- apiVersion: v1 kind: metadata: spec: containers: - name: nginx # 容器内挂载的文件夹 volumeMounts: - mountPath: /log name: log-volume volumes: # 主机上的文件夹 - name: log-volume hostPath: path: /var/log/webapp type: Directory PersistentVolume 1 2 3 4 5 6 7 8 9 10 11 12 apiVersion: v1 kind: PersistentVolume metadata: spec: accessModes: - ReadWriteOnce capacity: storage: 100Mi # 使用节点本地目录存储，生成环境不要使用 hostPath: path: /tmp/data accessModes 说明 ReadOnlyMany 只读 ReaedWriteOnce 读写一次 ReadWriteMany 读写多次 Helm ubuntu 安装 helm\n1 2 3 4 5 curl https://baltocdn.com/helm/signing.asc | sudo apt-key add - sudo apt-get install apt-transport-https --yes echo \u0026#34;deb https://baltocdn.com/helm/stable/debian/ all main\u0026#34; | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list sudo apt-get update sudo apt-get install helm 参考 kubectl 官方文档 kubernets 官方入门教程 ","date":"2022-01-11T11:00:00Z","permalink":"https://blog.golang.space/p/kubernets-%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5/","title":"Kubernets 核心概念"},{"content":"Hey hey 是一个轻量级向 web 发送负载的工具。\n参数 说明 -n 请求数，默认 200 -c 并发数，默认 50，不能小于请求数量 -q 速率限制，以每个工作者的每秒查询数 (QPS) 为单位 -z 请求时间，指定后将忽略请求数。例如 : -z 10s -z 3m -o 输出类型，仅支持 cvs -m 请求方法 GET/POST/\u0026hellip;. -H 自定义 HTTP header，可重用。例如: -H \u0026ldquo;Content-Type: application/json\u0026rdquo; -H \u0026ldquo;Accept: text/html\u0026rdquo; -t 每个请求的超时时间，默认 20 -A HTTP accept header -a 基本身份验证 -D 来自文件的 HTTP request body ，例如 -D ./file.txt -d HTTP request body -T Content-type ，默认 \u0026ldquo;text/html\u0026rdquo; -x HTTP proxy -h2 启用 HTTP/2 -host HTTP Host header 更多见 github README.md 例如\n1 2 # GET 请求，并发100，请求 5 秒 hey -m GET -c 100 -z 5s \u0026#34;http://localhost:1323\u0026#34; web 网站的几个并发量级 来源于网络，仅供参考\nQPS 级别 一般举措 \u0026lt;50 \u0026lt;10k 人 正常开发 50~100 \u0026lt;30k 人 优化 DB 优化性能 300~800 \u0026lt;100k 人 负载均衡 / 异地缓存 ","date":"2022-01-05T00:00:00Z","permalink":"https://blog.golang.space/p/%E8%BD%BB%E9%87%8F%E7%BA%A7%E5%8E%8B%E6%B5%8B%E5%B7%A5%E5%85%B7/","title":"轻量级压测工具"},{"content":"测试 在包目录内，所有以_test.go为后缀名的源文件在执行go build时不会被构建成包的一部分，它们是go test测试的一部分。\n测试文件可以放其它源文件同一个目录。\n如果测试针对的是未导出的 API，那么测试文件和其它源代码文件放在同一个包 package exam 如果测试是用户使用这套 API 的方式，可以对测试文件的包名加后缀 package exam_test 在*_test.go文件中，有三种类型的函数\n测试函数 (Test) 基准测试函数（Bench） 示例函数 (Example) 测试函数 用于测试程序的一些逻辑行为是否正确，go test 命令会调用这些测试函数并报告测试结果。\n1 2 3 import \u0026#34;testing\u0026#34; func TestFuncName(t *testing.T) { } 参考上面的格式， 以 Test 为函数名前缀，后面的FuncName首字母必须大写，参数类型必须是 *testing.T。\n1 2 3 4 5 6 7 8 9 10 11 12 # 测试全部文件 go test -v # 测试单个文件 go test -v cal_test.go cal.go # 测试单个方法 go test -v \u0026lt;file_name.go\u0026gt; -run TestAddUpper # 测试以 French 和 Canal 为前缀的函数 go test -v -run=\u0026#34;French|Canal\u0026#34; # === RUN TestFrenchPalindrome # === RUN TestCanalPalindrome # 测试所有子目录 go test -v ./... -v 用于打印每个测试函数的名字和运行时间 -run对应一个正则表达式，只有测试函数名被它正确匹配的测试函数才会执行 -cover 覆盖率 -coverprofile 生成覆盖详情 1 2 go test -coverprofile c.out go tool cover -html c.out [命令行工具参考官网文档][https://pkg.go.dev/cmd/go]\n表格测试 将输入和输出写成表格。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 func TestIsPalindrome(t *testing.T) { var tests = []struct { input string want bool }{ {\u0026#34;\u0026#34;, true}, {\u0026#34;a\u0026#34;, true}, {\u0026#34;aa\u0026#34;, true}, {\u0026#34;ab\u0026#34;, false}, {\u0026#34;kayak\u0026#34;, true}, {\u0026#34;detartrated\u0026#34;, true}, {\u0026#34;A man, a plan, a canal: Panama\u0026#34;, true}, {\u0026#34;Evil I did dwell; lewd did I live.\u0026#34;, true}, {\u0026#34;Able was I ere I saw Elba\u0026#34;, true}, {\u0026#34;été\u0026#34;, true}, {\u0026#34;Et se resservir, ivresse reste.\u0026#34;, true}, {\u0026#34;palindrome\u0026#34;, false}, // non-palindrome {\u0026#34;desserts\u0026#34;, false}, // semi-palindrome } for _, test := range tests { if got := IsPalindrome(test.input); got != test.want { t.Errorf(\u0026#34;IsPalindrome(%q) = %v\u0026#34;, test.input, got) } } } func IsPalindrome(str string) bool { // ... } 模拟 webserver 应答 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // mockServer 模拟服务器 func mockServer() *httptest.Server { var f http.HandlerFunc f = func(w http.ResponseWriter, r *http.Request) { w.WriteHeader(200) w.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;) fmt.Fprint(w, \u0026#34;welcome\u0026#34;) } return httptest.NewServer(f) } // TestNewRequest 模拟发起请求 func TestNewRequest(t *testing.T) { server := mockServer() defer server.Close() req := httptest.NewRequest(\u0026#34;GET\u0026#34;, server.URL, nil) w := httptest.NewRecorder() server.Config.Handler.ServeHTTP(w, req) require.EqualValues(t, w.Result().StatusCode, http.StatusOK) require.EqualValues(t, \u0026#34;welcome\u0026#34;, w.Body.String()) } 示例函数 属于通过 godoc 生成文档的一部分。\n以Example为函数名前缀的函数，提供一个由编译器保证正确性的示例文档。和普通测试的区别，示例函数没有函数参数和返回值。\n示例函数有三个用处。\n作为文档, 根据示例函数的后缀名部分，godoc这个web文档服务器会将示例函数关联到某个具体函数或包本身 在go test执行测试的时候也会运行示例函数测试。如果示例函数内含有类似上面例子中的// Output:格式的注释，那么测试工具会执行这个示例函数，然后检查示例函数的标准输出与注释是否匹配。 提供一个真实的演练场, 在线编辑和运行示例函数 1 2 3 4 5 6 7 func ExampleIsPalindrome() { fmt.Println(IsPalindrome(\u0026#34;A man, a plan, a canal: Panama\u0026#34;)) fmt.Println(IsPalindrome(\u0026#34;palindrome\u0026#34;)) // Output: // true // false } 1 2 # 安装文档 go get -u golang.org/x/tools/cmd/godoc 子测试及平行执行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func TestSubTest(t *testing.T) { data := []struct { name string result bool }{ {\u0026#34;123\u0026#34;, true}, {\u0026#34;246\u0026#34;, false}, } for _, v := range data { tf := func(t *testing.T) { t.Parallel() t.Log(v) } t.Run(v.name, tf) } } 1 2 # 仅仅想执行名为 246 的子测试 go test -v -run SubTest/246 默认情况下，go test 在不同包之间是并行执行，在每个包内部是串行执行。使用 t.Parallel()让当前函数开启并行。\n基准测试 fmt.Sprint 和 fmt.Sprintf 哪个性能更佳呢?\n为了保证测试结果准确，必须保证电脑没有执行其它事务。如果要执行长时间的测试，一定不要打开浏览器上网，或去看在线视频。\nGo 语言做 benchmark 的时候，会让编译器重新编译代码，编译器会把没有用处的死代码拿掉。也就是说，如果编译器发现某个函数并没有修改任何内容，或虽然返回了某个值，却没有保存起来，编译器就会认证没必要浪费时间去调用这个函数，因为它对程序的结果不会产生任何影响。\n通过下面的命令执行测试， -run可以是正则表达式，这里写 none 表示不执行任何 Test 函数，仅执行 benchmark 函数。-bench 标志的正则表达式写出 . 表示匹配所有。通过-benchtime 设置测试时间为 3 秒。\nbenchmark 也有子测试，子测试的主要意义并不在于并行，而在于可以更加细致地测评。\n1 2 # none 没有特殊的意义，仅仅用来确保没有任何函数与它匹配 go test -run none -bench . -benchtime 3s -banchmem 测试结果大概长这样，分别表示\n测试函数名-CPU 核心数 执行次数 执行时间(纳秒)，看图中，将小数点左移6 位，该测试大概 245 毫秒一次 内存 分配次数 验证测评结果 测评的结果，总是应该在自己所能理解的范围之内，如果跟自己想的差太远，那一定要把其中的道理弄清楚。这并不意味着代码写错了，但还是应该尽量想办法拿到准确的测评结果。\n测试驱动开发 测试驱动开发需要你做一些小步骤，每一个实现都会感觉微不足道。真正的价值不在于步骤本身，而在于最终产品，即使做了一个微不足道的更改，这肯定会起作用。\n三个步骤\n红色，通常终端会红色提示错误。先编写测试代码，然后实现业务函数，期间可能无法通过测试。 绿色，通过终端会绿色表示成功。当业务函数通过测试代码。 重构，再不添加任何功能的情况下改进其结构，如果没有这一步，您的代码将很快退化为经过充分测试但难以理解的混乱。 如何在不改变功能的情况下使这段代码更好地表达其意图 ( 可理解性 ) ？ 许多重构不仅涉及被测代码，还涉及测试本身。您需要花费更多的时间来修复测试而不是改进代码。 如果您的被测单元提供多个分支，则值得考虑拆分成多个单元。 go test命令会遍历所有的*_test.go文件中符合上述命名规则的函数，生成一个临时的main包用于调用相应的测试函数，接着构建并运行、报告测试结果，最后清理测试中生成的临时文件。\n避免脆弱测试代码的方法是只检测你真正关心的属性。保持测试代码的简洁和内部结构的稳定。特别是对断言部分要有所选择。不要对字符串进行全字匹配，而是针对那些在项目的发展中是比较稳定不变的子串。很多时候值得花力气来编写一个从复杂输出中提取用于断言的必要信息的函数，虽然这可能会带来很多前期的工作，但是它可以帮助迅速及时修复因为项目演化而导致的不合逻辑的失败测试。\n","date":"2021-11-25T15:00:00Z","permalink":"https://blog.golang.space/p/22.%E6%B5%8B%E8%AF%95/","title":"22.测试"},{"content":"公网部署 K8s 环境\n一台腾讯云轻量应用服务器 2 核 4G\n一台阿里云共享型服务器 1 核 2G\nubuntu 18.04 ( CKA 认证环境的系统 )\n趁着双十二活动，花了 74 入手腾讯云轻量应用服务器，用于搭建 k8s 集群环境\n环境准备 1 2 3 4 5 6 7 8 # 永久关闭交换区 sudo sed -i \u0026#39;s/.*swap.*/#\u0026amp;/\u0026#39; /etc/fstab # 修改主机名 # master 节点执行 hostnamectl set-hostname master1 # node 节点执行 hostnamectl set-hostname node1 允许 iptables 检查桥接流量\n1 2 3 4 5 6 7 8 9 10 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/modules-load.d/k8s.conf br_netfilter EOF cat \u0026lt;\u0026lt;EOF | sudo tee /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sudo sysctl --system 如下图所示，开放相应端口，如果使用 flannel 网络插件，需要开放 upd/8472 端口\n安装工具 安装 docker，国内建议自行使用镜像安装，以下为docker官网提供的安装方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 sudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install -f docker-ce docker-ce-cli containerd.io 配置 docker 的 cgroup，要跟 kubelet 使用的保持一致，否则 kubelet 进程会失败。\nsystemd 是 k8s 默认驱动。\n1 2 3 4 5 6 7 cat \u0026gt; /etc/docker/daemon.json \u0026lt;\u0026lt;EOF { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], } EOF systemctl restart docker 安装 kubeadm\n国内安装\n1 2 3 4 5 6 7 8 9 10 11 12 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb http://mirrors.tuna.tsinghua.edu.cn/kubernetes/apt/ kubernetes-xenial main EOF sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys FEEA9169307EA071 sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 8B57C5C2836F4BEB sudo apt-get update # 若遇到秘钥问题，参考 https://www.cnblogs.com/reatual/p/14304675.html sudo apt-get install -y kubelet kubeadm kubectl systemctl enable --now kubelet 为 ip 配置别名\n1 2 3 #echo \u0026#34;${ip} ${主机名}\u0026#34; \u0026gt;\u0026gt; /etc/hosts echo \u0026#34;${master1_ip} master1\u0026#34; \u0026gt;\u0026gt; /etc/hosts echo \u0026#34;${node1_ip} master2\u0026#34; \u0026gt;\u0026gt; /etc/hosts 提前拉取镜像，避免在初始化时过久等待\n1 kubeadm config images pull --image-repository=registry.aliyuncs.com/google_containers 创建虚拟网卡\n1 sudo apt install ifupdown 临时生效\n1 2 # sudo ifconfig eth0:1 ${公网 IP} sudo ifconfig eth0:1 44.44.44.44 永久生效\n1 2 3 4 5 6 7 8 9 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/network/interfaces auto eth0:1 iface eth0:1 inet static # address ${公网 IP} address 44.44.44.44 netmask 255.255.255.0 EOF 150.158.141.120 1 sudo /etc/init.d/networking restart 修改 kubelet 启动参数\n添加 kubelet 的启动参数--node-ip=公网IP， 每个主机都要添加并指定对应的公网 ip\n1 sudo vi /etc/systemd/system/kubelet.service.d/10-kubeadm.conf master 初始化，如果初始化失败，可以重置\n1 2 3 4 5 6 7 8 9 10 11 12 kubeadm init \\ --kubernetes-version v1.27.3 \\ --apiserver-advertise-address=192.168.0.58 \\ --image-repository=registry.aliyuncs.com/google_containers \\ --service-cidr=10.96.0.0/16 \\ --pod-network-cidr=10.244.0.0/16 # 重置 kubeadm reset -f rm -rf /etc/cni/net.d rm -rf $HOME/.kube 1 2 3 4 5 6 7 8 9 10 # 当你看到如下信息时，初始化成功 Your Kubernetes control-plane has initialized successfully! ... # 按提示，执行以下三行 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config ... # 用于 worker 节点加入集群 kubeadm join master1:6443 --token zqmjvh.5wij6n8j......... 修改 kube-apiserver 参数\n- --bind-address=0.0.0.0\n1 sudo vi /etc/kubernetes/manifests/kube-apiserver.yaml 安装 flannel 网络 下载 flannel 的 的 yaml 配置文件\n1 wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 修改配置文件\n1 vim kube-flannel.yml 在 200 行左右\n1 2 3 4 5 6 7 8 9 args: - --public-ip=$(PUBLIC_IP) - --iface=eth0 env: - name: PUBLIC_IP valueFrom: fieldRef: fieldPath: status.podIP 开始安装网络插件\n1 kubectl apply -f kube-flannel.yml K8s 启用 ipvs 安装工具，方便检查配置\n1 sudo apt-get install ipvsadm ubuntu 永久启用 ipvs 模块\n1 ls /lib/modules/$(uname -r)/kernel/net/netfilter/ipvs|grep -o \u0026#34;^[^.]*\u0026#34; \u0026gt;\u0026gt; /etc/modules 修改配置文件，找到 mode，后面参数修改为 ipvs\n1 kubectl edit configmap kube-proxy -n kube-system 删除所有的 kube-proxy 的 pod，并等待自愈恢复\n1 $ kubectl delete pods `kubectl get pods -n kube-system | grep kube-proxy | awk \u0026#39;{print $1}\u0026#39;` -n kube-system 通过 kubectl logs 来查看启用 ipvs 的日志，检查是否正常启用\nworker 节点加入集群 如果 token 过期，可以使用以下命令创建新的加入命令\n1 kubeadm token create --print-join-command 在 worker 节点执行，等待执行结束\n1 kubeadm join........ 在 master 节点检查\n1 kubectl get nodes 部署 nginx 测试 1 vim nginx.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.21.4 ports: - containerPort: 80 1 kubectl apply -f nginx.yaml 开启服务\n1 vim nginx-svc.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 apiVersion: v1 kind: Service metadata: name: nginx-service spec: selector: app: nginx ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30080 type: NodePort 1 kubectl apply -f nginx-svc.yaml 访问任意节点公网 IP:30080，查看是否能够请求到 nginx 主页\n部署 dashboard 国内可能无法访问此链接\n1 wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.3.1/aio/deploy/recommended.yaml 1 kubectl apply -f recommended.yaml 设置访问端口\n1 kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard 查看端口\n1 kubectl get svc -A |grep kubernetes-dashboard 参考 k8s 官方安装文档\n公网环境搭建 k8s 集群\nflannel\n","date":"2021-11-05T15:00:00Z","permalink":"https://blog.golang.space/p/%E5%85%AC%E7%BD%91%E9%83%A8%E7%BD%B2-k8s/","title":"公网部署 k8s"},{"content":"保证接口数据安全的方案 数据加密，防止明文传输 不需要解密，只需要验证是否相同的\n比如登录时的密码，可以在前端编码成 MD5 传输。MD5具有不可逆的性质，非常适合用来存储这些。\n为了防止数据库泄露暴露 MD5 密码，或者希望更安全，可以对 MD5 加盐。\n比如 MD5( password + salt )，salt 可以是每个用户唯一的，防止如果某个用户的密码被穷举破解出来了，不能使用现有的成果来类推其它用户的密码。\n需要解密，使用原来的参数\n使用 AES 对称加密算法，这个需要服务端和客户端都存储秘钥，如果不用暴露客户端，这种方案很合适。\n使用 RSA 非对称加密，会生成私钥和公钥。\n数据加签验签 加签\n它可以保证数据在传输过程中不被篡改。\n使用 MD5/ShA-256 对原始请求报文生成摘要，使用私钥对摘要加密，就得到了报文对应的数字签名。\n将 报文原文和签名 一起发到接收方。\n验签\n接收方对原始数据以相同方法处理，得到摘要，使用对方提供的公钥对数字签名解密，判断两个摘要是否相同。就可以得知报文有没有被篡改过。\ntoken 授权认证 非登录接口如何识别用户的身份?\n可以在用户名密码登录接口中返回唯一 token。请求其它需要权限的接口必须带上此 token，服务端解析 token 验证身份，并检查 token 是否 过期。\n此方式也可用于唯一设备登录，每个用户最后一次登录生成的 token 记录到 redis 缓存中，每次登陆都会覆盖掉旧的。接口请求时，服务端验证其 token 是否与服务端的一致，如果不一致，就提示用户重新登录。\n另外关于身份验证错误的状态码参考网址\ntoken 不存在或解析失败，token 过期等返回 401 错误\ntoken 验证通过，但对资源没有访问的权限，返回 403 错误\n时间戳 timestamp 超时 有些攻击者，不关心真实的数据，而是抓包后进行恶意请求，如 DOS 攻击。\n可以引入时间戳 ，来保证接口安全，客户端每次请求都带上当前时间，求服务端时间与请求时间的时间差，大于一定时间如 2 分钟，则认为请求无效。\n只加时间，很容易破解，无非每次请求时更新一下时间，可以在时间戳的基础上，与「数据加签验签」结合。\ntimestamp+nonce 防止重放攻击 nonce 指唯一的随机字符串，在客户端维护一个随机字符串 set，每次请求使用 timestamp+nonce，nonce 不能重复。\n服务端也维护一个相同的 set，如果发现重复的 nonce 就是重复请求。 因为有 timestamp 仅接收 2分钟内的请求，所以服务端和客户端可以都只维护 2分钟内的 nonce ，以节省内存。\n限流 可以从以下方面考虑\n每分钟可以接收多少次请求 服务端最大能同时处理多少请求 每个 IP， 1 分钟内最多请求次数 黑名单 对于黑名单的 IP，返回错误码\n建议黑名单加上时间限制，对于明知是恶意的攻击，多长时间都可以\n对于不确定，模棱两可，或只是小小的警告惩罚，可以设定有限的时间。\n白名单 仅允许白名单内的 IP 访问\n参数合法性效验 如手机号和身份证检测长度等是否合法。\n枚举参数是否合法。\n","date":"2021-10-22T00:00:00Z","permalink":"https://blog.golang.space/p/%E4%BF%9D%E8%AF%81%E6%8E%A5%E5%8F%A3%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E7%9A%84%E6%96%B9%E6%A1%88/","title":"保证接口数据安全的方案"},{"content":"通道模式 不能仅通过增加缓存区来提升性能，不要认为把缓冲区设置的非常大就可以解决性能问题。应该将缓冲区尽量设置的小一些，尽量把延迟降低。\n缓冲区大小不能胡乱设置成 10000，缓冲区不一定能够提升性能!!不要指望缓冲区大小来提升程序性能，我们要做的是降低发送与接收操作可能产生的延迟，\noption open close send ok no recive ok ok 面对并发代码时，凭借打印语句，没办法判断哪个发生在前。因为打印不是原子操作。\n通道模式 waitForTask - 三个基本模式之一 经理指派任务给员工，经理去做别的事情，同时随时可以叫停或修正员工的任务。\n可以实现 Pooling 模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func waitForTask() { ch := make(chan string) go func() { p := \u0026lt;-ch fmt.Println(\u0026#34;recv\u0026#39;d signal : \u0026#34;, p) }() time.Sleep(500 * time.Millisecond) ch \u0026lt;- \u0026#34;paper\u0026#34; fmt.Println(\u0026#34;manager : sent signal\u0026#34;) time.Sleep(time.Second) fmt.Println(\u0026#34;-------------end-------------\u0026#34;) } waitForResult - 三个基本模式之一 经理等待员工完成他的工作任务，再继续往下走。\n可以实现 Drop 模式和 FanOut 模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 func waitForResult() { ch := make(chan string) go func() { time.Sleep(500 * time.Millisecond) ch \u0026lt;- \u0026#34;paper\u0026#34; fmt.Println(\u0026#34;employee : sned signal\u0026#34;) }() p := \u0026lt;-ch fmt.Println(\u0026#34;manage : recv\u0026#39;d signal : \u0026#34;, p) time.Sleep(1 * time.Second) fmt.Println(\u0026#34;-------------end-------------\u0026#34;) } waitForFinished - 三个基本模式之一 其实用 waitGroup 更好，通过它对 goroutine 编组会更加清晰。\n经理请员工做事，员工已经知道自己的任务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func waitForFinished() { ch := make(chan struct{}) go func() { time.Sleep(500 * time.Millisecond) close(ch) fmt.Println(\u0026#34;employee : sned signal\u0026#34;) }() _, ok := \u0026lt;-ch fmt.Println(\u0026#34;manage : recv\u0026#39;d signal : \u0026#34;, ok) time.Sleep(1 * time.Second) fmt.Println(\u0026#34;-------------end-------------\u0026#34;) } Pooling 模式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func pooling() { ch := make(chan string) const emps = 2 for i := 0; i \u0026lt; emps; i++ { go func(emp int) { for p := range ch { fmt.Printf(\u0026#34;employee %d : recv\u0026#39;d signal : %s\\n\u0026#34;, emp, p) } fmt.Printf(\u0026#34;employee %d : recv\u0026#39;d signal\\n\u0026#34;, emp) }(i) } const work = 10 for i := 0; i \u0026lt; work; i++ { ch \u0026lt;- \u0026#34;paper\u0026#34; + strconv.Itoa(i) fmt.Println(\u0026#34;manager : sent signal : \u0026#34;, i) } close(ch) fmt.Println(\u0026#34;manage : recv\u0026#39;d signal end \u0026#34;) time.Sleep(1 * time.Second) fmt.Println(\u0026#34;-------------end-------------\u0026#34;) } Fan out 模式 很危险，可能会导致程序中的 goroutine 迅速增长\n对于隔一段时间执行的定时任务，和命令行工具来说，这种模式很合适。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 允许任意数量的 goroutine 执行 func fanOut() { emps := 20 ch := make(chan string, emps) for i := 0; i \u0026lt; emps; i++ { go func(i int) { time.Sleep(200 * time.Millisecond) ch \u0026lt;- \u0026#34;paper\u0026#34; + strconv.Itoa(i) fmt.Println(\u0026#34;manager : sent signal : \u0026#34;, i) }(i) } for emps \u0026gt; 0 { p := \u0026lt;-ch fmt.Println(p) fmt.Println(\u0026#34;manage : recv\u0026#39;d signal : \u0026#34;, emps) emps-- } time.Sleep(2 * time.Second) fmt.Println(\u0026#34;-------------end-------------\u0026#34;) } fanoutSemaphore 模式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // 限制同时执行的 goroutine 数量 func fanoutSemaphore() { emps := 20 ch := make(chan string, emps) const cap = 5 sem := make(chan struct{}, cap) for i := 0; i \u0026lt; emps; i++ { go func(i int) { sem \u0026lt;- struct{}{} { time.Sleep(200 * time.Millisecond) ch \u0026lt;- \u0026#34;paper\u0026#34; + strconv.Itoa(i) fmt.Println(\u0026#34;manager : sent signal : \u0026#34;, i) } \u0026lt;-sem }(i) } for emps \u0026gt; 0 { p := \u0026lt;-ch fmt.Println(p) fmt.Println(\u0026#34;manage : recv\u0026#39;d signal : \u0026#34;, emps) emps-- } } drop 模式 drop 尽快发现有问题的地方，并且防止恶化 抽象点就是往水杯注水，满了后，就让后来的水溢出去 这个模式可以用来测试性能的瓶颈\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func drop() { const cap = 5 ch := make(chan string, cap) go func() { for p := range ch { fmt.Println(\u0026#34;employee : recv\u0026#39;d signal : \u0026#34;, p) } }() const work = 20 for i := 0; i \u0026lt; work; i++ { select { case ch \u0026lt;- \u0026#34;paper\u0026#34;: fmt.Println(\u0026#34;manager : sent signal : \u0026#34;, i) default: fmt.Println(\u0026#34;manager : dropped data : \u0026#34;, i) } } close(ch) fmt.Println(\u0026#34;manager sent shutdown signal\u0026#34;) } cancellation 模式 超时机制，如果有这样的需求，应该使用 context 包来完成。\n注意，在这个例子中要使用 有缓冲通道 否则有可能会泄露，假设现在使用无缓冲通道，而任务超时，主任务结束。 而子任务还卡在那，等待 channel 发送过去。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func cancellation() { ch := make(chan string, 1) go func() { time.Sleep(time.Duration(rand.Intn(150)) * time.Millisecond) ch \u0026lt;- \u0026#34;paper\u0026#34; fmt.Println(\u0026#34;manager : sent signal \u0026#34;) }() tc := time.After(100 * time.Millisecond) select { case p := \u0026lt;-ch: fmt.Println(\u0026#34;manage : recv\u0026#39;d signal : \u0026#34;, p) case t := \u0026lt;-tc: fmt.Println(\u0026#34;manager : timedout :\u0026#34;, t) } time.Sleep(1 * time.Second) fmt.Println(\u0026#34;-------------end-------------\u0026#34;) } 代码案例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 同时最多运行 3 个 goroutine // 需要启动大量 goroutine 执行任务 func m(){ data := make([]int,50) // 假设要处理的数据 ch := make(chan struct{},3) var wg sync.Wait for i:=0; i\u0026lt;len(data); i++{ wg.Add(1) ch \u0026lt;- struct{}{} go func(){ \u0026lt;- ch defer wg.Done() }() // ... } wg.Wait() close(ch) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 同时最多运行 3 个 goroutine // 仅用 3 个来执行任务，不需要创建更多 goroutine func m(){ data := make([]int,50) // 假设要处理的数据 ch := make(chan int,len(data)) for _, v:= range data{ ch \u0026lt;- v } close(ch) var wg sync.Wait for i:=0; i\u0026lt;3; i++{ go func(){ defer wg.Done() for v := ch { } }() } wg.Wait() } ","date":"2021-09-21T00:00:00Z","permalink":"https://blog.golang.space/p/channels-%E6%A8%A1%E5%BC%8F/","title":"Channels 模式"},{"content":"栈帧 GMP 中的 G 和 M 非常像，也有一个内存栈。( M 的内存栈是操作系统层面的，大小是 1M )\n一个 G 的栈大小是 2KB，goroutine 进行函数调用，它会从栈中取出一些内存，我们称为栈帧内存。\n1 2 3 4 5 6 7 8 9 10 func main{ a := 10 incr(a) fmt.Println(a) } func incr(i int) int { i++ return i } goroutine 只对它所操作的栈帧的内存有直接的访问权，意味者所有的数据都必须在这里，比如声明一个 int 类型的变量，会有 4 个字节的内存就在这个栈帧内。它必须在这个栈帧内，否则 goroutine 就不能访问它。这个栈帧一个非常重要的目的，它在创造一个沙盒，一个隔离层。\n参考上面的代码进行一次函数调用，我想让你想到的是，每当进行一次函数调用，真正在做的是跨域了一个程序边界。跨域这个程序边界，意味着将离开当前的栈帧并进入一个新的栈帧，我们需要在新的栈帧内获取数据，如上面程序将变量 a 的值传递给 incr 函数，因为 Go 中的一切都是通过值传递，所以要在数据穿过程序边界时复制一个数据的副本。\n你会听到三个术语\n数据，这是我们工作的对象，数据包含两种类型 值，比如变量 a 的整数值 10 值地址，指针 在函数 incr 中做出的改变，并没有影响到 main 函数的变量 a，这是函数的隔离性。\n优点是不会产生副作用，变量在\u0026quot;\u0026ldquo;沙盒\u0026quot;中改变，不影响执行环境之外的任何东西，这非常重要!\n缺点是在程序中有多个数据副本，值传递是没有效率的，可能会导致代码更加复杂，甚至性能问题。\n1 2 3 4 5 incr(\u0026amp;a) func incr(a *int) { // ... } 记住这句话，在 Go 中一切都是值传递。有人说上面的代码是引用传递，其实不是的。\n按值传递意味着跨域程序边界时，会对数据进行复制。在上面的代码中，我们正在复制和传递的数据，不是一个值，而是一个地址。为了让程序能够访问\u0026quot;沙盒\u0026quot;之外的东西，它必须执行对地址的读取。goroutine 只有对栈帧的直接内存访问，如果你想让 goroutine 能够访问其它内存，必须将该内存位置的地址分享给它。\n如果多个 goroutine 同时通过指针去访问/修改变量 a，会造成数据竞争。函数式编程试图通过完全不给你指针语义来减少副作用，但是值语义的代价是数据的低效率。后面我们将讨论什么时候使用指针语义，什么时候使用值语义。\n优点是解决了效率问题，每个人都可以改变它。代价是副作用和更多的工作 ，需要确保我们没有破坏数据，或者事情不会在幕后被改变。\n我们要充分利用语言的各个方面，有助于减轻内存管理的认知负担。\n注意 : 当 main 函数进行另一个函数调用时，会发生什么? 它需要另一个栈帧，它会清理掉活动帧以下的内存，重复使用。\n逃逸 我们通常会有一些工厂函数，用来创建结构体对象。注意，在 Go 中没有构造函数，它隐藏了成本，我们所拥有的是我称之为工厂函数的东西，工厂函数是一个可以创建一个值的函数。初始化它，并返回给调用者。这对于可读性来说是很好的，它没有隐藏成本。我们可以读懂它，并且在结构上有助于简化。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func createUseV1() User { u := user{ name:\u0026#34;Bill\u0026#34;, } return u } func createUserV2() *User { u := user{ name:\u0026#34;Bill\u0026#34;, } return \u0026amp;u } 在上面的示例中，有两个版本的创建用户，注意它们的返回类型。\ncreateUseV1 是值语义的，它返回数据的副本，不会有任何副作用。\ncreateUserV2 是指针语义的，这次不是在制作一个值的副本，要做的是拷贝值的地址。要知道栈帧是复用的，这块内存用完就会丢掉。我们好像引用了一个会被销毁的地址，这非常可怕。但实际上，编译器非常强大，它能够进行静态代码分析，将确定一个值是否被放在栈上，还是逃逸到堆中。\n充分利用栈是非常非常快的，栈是自我清洁的。这意味着，垃圾处理器甚至不会介入，直到一个值逃出栈，并在堆上结束。\n为什么栈是自我清洁的? 参考上面绘图，从栈帧返回到上面时，内存会被单独留在栈中，并在下行时进行清理，所以垃圾处理器并不需要参与。栈可以为我们提供大量的性能，因为内存是已经分配好的，而且它可以自我清理。\n我们应该尽力利用值语义，并将值保留在栈中，不仅仅是因为隔离和不变性的带来减少副作用的好处，而且在很多情况下还能带来更好的性能，因为一旦有东西被分配到堆上，垃圾处理器就必须参与进来。\n另外，指针在可读性上，有一个指导原则。\n在构造过程中使用指针语义，现在我们使这段代码更难读了。在构造过程中，不要使用指针语义，希望你在构造过程中使用值语义，仅在调用处使用指针语义。除非你想直接返回(return \u0026amp;user{})。\n再次提醒，如果你将一个变量的生命作为一个指针开始，你就会失去可读性。\n1 2 3 4 5 6 7 func createUserV2() *User { u := \u0026amp;user{ name:\u0026#34;Bill\u0026#34;, } return u } 生成逃逸分析报告 1 go build -gcflags \u0026#34;-m -m\u0026#34; 当你在 go build 中使用 gcflags 时，你将得到的不是一个二进制文件，而是逃逸分析报告。\n内存分配 如果在编译时，编译器不知道一个值的大小，它必须立即在堆上构建，因为栈帧不是动态的，都是在编译时确定尺寸，所以编译时不知道值的大小，就不能放在栈里。\n我们知道 Go 中的栈是非常非常小的，操作系统的栈大约是 1MB，而 Go 栈是 2KB。如果有一个 goroutine 进行大量的函数调用，并最终耗尽了栈空间，会发生什么呢? Go 所做的是它有连续栈，它会分配一个更大的栈，比原来的栈大 25%，然后，把所有的栈帧复过来。\n垃圾处理器 一旦在堆上进行了内存分配，它就会停留在那里，直到被回收。\n我们想要的是最小的堆，减少内存使用。那么怎样才能得到最小的堆?\n","date":"2021-08-05T00:00:00Z","permalink":"https://blog.golang.space/p/%E6%A0%88%E5%B8%A7%E4%B8%8E%E9%80%83%E9%80%B8/","title":"栈帧与逃逸"},{"content":"Postgres 表分区 当一个表非常大时，划分所带来的好处是非常值得的。一个表何种情况下会从划分获益取决于应用，一个经验法则是当表的尺寸超过了数据库服务器物理内存时，划分会为表带来好处。\nPostgreSQL对下列分区形式提供了内建支持：\n范围划分，根据一个关键列或一组列划分为“范围”，例如日期 列表划分，显式地列出每一个分区中出现的键值来划分表 哈希分区，为每个分区指定模数和余数来对表进行分区 无法把一个常规表转换成分区表，反之亦然。不过，可以把一个包含数据的常规表或者分区表作为分区加入到另一个分区表，或者从分区表中移走一个分区并且把它变成一个独立的表。\n声明式分区 在 v10 中，引入了新的专用分区语法。\n假定我们正在为一个大型的冰激凌公司构建数据库。该公司每天测量最高温度以及每个区域的冰激凌销售情况。\n1 2 3 4 5 6 CREATE TABLE measurement ( city_id int not null, logdate date not null, peaktemp int, unitsales int ); 我们知道大部分查询只会访问上周的、上月的或者上季度的数据，因为这个表的主要用途是为管理层准备在线报告。为了减少需要被存放的旧数据量，我们决定只保留最近3年的数据。在每个月的开始我们将去除掉最早的那个月的数据。在这种情况下我们可以使用分区技术来帮助我们满足对measurement表的所有不同需求。\n要在这种情况下使用声明式分区，可采用下面的步骤：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 -- 创建表 CREATE TABLE measurement ( city_id int not null, logdate date not null, peaktemp int, unitsales int ) PARTITION BY RANGE (logdate); -- 创建分区 CREATE TABLE measurement_y2022m04 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2022-04-01\u0026#39;) TO (\u0026#39;2022-05-01\u0026#39;); CREATE TABLE measurement_y2022m05 PARTITION OF measurement FOR VALUES FROM (\u0026#39;2022-05-01\u0026#39;) TO (\u0026#39;2022-06-01\u0026#39;); -- 为分区表键列创建索引 -- 这会自动在每个分区上创建一个索引，并且后来创建或者附着的任何分区也将会包含索引 CREATE INDEX ON measurement (logdate); -- 测试添加 INSERT INTO measurement VALUES(1,now(),27,99999); INSERT INTO measurement VALUES(2,\u0026#39;2022-05-13 20:26:42\u0026#39;,23,11111); INSERT INTO measurement VALUES(3,\u0026#39;2022-04-13 20:26:47\u0026#39;,21,33333); -- 没有对应日期的子表，会出现错误 INSERT INTO measurement VALUES(4,\u0026#39;2022-03-13 20:26:54\u0026#39;,25,33412); -- 测试更新 UPDATE measurement SET peaktemp=18 WHERE city_id=3 在上面的例子中，我们会每个月创建一个新分区，因此写一个脚本来自动生成所需的DDL会更好。\nHash 分区 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- hash 分区 create table measurement( id int not null, logdata date not null, peaktemp int, unitsales int ) partition by hash (unitsales); -- 创建子表 create table measurement_0 partition of measurement for values with (modulus 4, remainder 0); create table measurement_1 partition of measurement for values with (modulus 4, remainder 1); create table measurement_2 partition of measurement for values with (modulus 4, remainder 2); create table measurement_3 partition of measurement for values with (modulus 4, remainder 3); 分区维护 移除旧数据最简单的选择是删除掉不再需要的分区：\n1 DROP TABLE measurement_y2022m04; 另一种通常更好的选项是把分区从分区表中移除，但是保留它作为一个独立的表：\n1 ALTER TABLE measurement DETACH PARTITION measurement_y2022m04; 限制\n没有办法创建跨越所有分区的排除约束，只可能单个约束每个叶子分区。 分区表上的惟一约束必须包括所有分区键列。存在此限制是因为PostgreSQL只能每个分区中分别强制实施唯一性。 分区剪枝 分区剪枝是一种提升声明式分区表性能的查询优化技术。例如\n1 2 SET enable_partition_pruning = on; -− the default SELECT count(*) FROM measurement WHERE logdate \u0026gt;= DATE \u0026#39;2008-01-01\u0026#39;; 如果没有分区剪枝，上面的查询将会扫描measurement表的每一个分区。如果启用了分区剪枝，规划器将会检查每个分区的定义并且检验该分区是否因为不包含符合查询WHERE子句的行而无需扫描。\n分区剪枝仅由分区键隐式定义的约束所驱动，而不是由索引的存在驱动。因此，没有必要在键列上定义索引。是否需要为一个给定分区创建索引取决于预期的查询扫描该分区时会扫描大部分还是小部分。后一种情况下索引的帮助会比前者大。\n旧的方法 从 v8.1 开始，Postgres 提供约束排除的优化器功能实现区分\n使用表继承建立表的层次结构，在每个子表使用 check 约束描述其分区范围，并在父表使用触发器执行数据分配\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 create table measurement( id int not null, logdata date not null, peaktemp int, unitsales int ); create table measurement_y2020m01 (check (logdata \u0026gt;= \u0026#39;2020-02-1\u0026#39; AND logdata \u0026lt; \u0026#39;2020-02-01\u0026#39;) ) INHERITS (measurement) create table measurement_y2020m02 (check (logdata \u0026gt;= \u0026#39;2020-02-1\u0026#39; AND logdata \u0026lt; \u0026#39;2020-03-01\u0026#39;) ) INHERITS (measurement) 在父表定义触发器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 create trigger insert_measurement_trigger before insert on measurement for each row execute procedure measurement_insert_trigger(); create or replace function measurement_insert_trigger() returns trigger as $$ begin if (NEW.logdate \u0026gt;= DATE \u0026#39;2021-01-01\u0026#39; AND NEW.logdata \u0026lt; DATE \u0026#39;2020-02-01\u0026#39;) THEN INSERT INTO measurement_y2020m01 VALUES(NEW.*) ELSIF NEW.logdate \u0026gt;= DATE \u0026#39;2021-02-01\u0026#39; AND NEW.logdata \u0026lt; DATE \u0026#39;2020-03-01\u0026#39;) THEN INSERT INTO measurement_y2020m02 VALUES(NEW.*) ELSE RAISE EXCEPTION \u0026#39;Date out of range. fix the \u0026#39;; END IF; RETURN NULL: END; $$ LANGUAGE PLPGSQL; 参考 PostgreSQL 官方文档\n","date":"2021-07-13T00:00:00Z","permalink":"https://blog.golang.space/p/%E8%A1%A8%E5%88%86%E5%8C%BA/","title":"表分区"},{"content":"Go 编码规范 转载于 Uber Go 编码规范中文翻译，在其基础上做了一些适合我的补充。\n建议查看官方仓库，很可能是最新的。\n指导原则 指向 interface 的指针 interface 源码\n若存储的数据是指针，则直接存储，若存储的数据是值，则存储指向该值的指针。\n1 2 3 4 5 6 type eface struct { // 类型指针 _type *_type // 数据指针 data unsafe.Pointer } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type F interface { f() } type S1 struct{} func (s S1) f() {} type S2 struct{} func (s *S2) f() {} // f1.f()无法修改底层数据 var f1 F = S1{} // f2.f() 可以修改底层数据,给接口变量f2赋值时使用的是对象指针 var f2 F = \u0026amp;S2{} interface 合理性验证 违反接口合理性检查的场景，都会终止编译。\n如果接口不匹配，那么 var _ http.Handler = (*Handler)(nil) 无法编译通过\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Good type Handler struct { // ... } // 用于触发编译期的接口的合理性检查机制 // 如果Handler没有实现http.Handler,会在编译期报错 var _ http.Handler = (*Handler)(nil) func (h *Handler) ServeHTTP( w http.ResponseWriter, r *http.Request, ) { // ... } 一般写 New() 函数，效果等同\n1 2 3 func New() http.Handler { return \u0026amp;Handler{} } 接收器与接口 使用值接收器的方法既可以通过值调用，也可以通过指针调用。\n带指针接收器的方法只能通过指针或 addressable values 调用.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type S struct { data string } func (s S) Read() string { return s.data } func (s *S) Write(str string) { s.data = str } sVals := map[int]S{1: {\u0026#34;A\u0026#34;}} // 你只能通过值调用 Read sVals[1].Read() // 这不能编译通过： // sVals[1].Write(\u0026#34;test\u0026#34;) sPtrs := map[int]*S{1: {\u0026#34;A\u0026#34;}} // 通过指针既可以调用 Read，也可以调用 Write 方法 sPtrs[1].Read() sPtrs[1].Write(\u0026#34;test\u0026#34;) 类似的,即使方法有了值接收器,也同样可以用指针接收器来满足接口.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type F interface { f() } type S1 struct{} func (s S1) f() {} type S2 struct{} func (s *S2) f() {} s1Val := S1{} s1Ptr := \u0026amp;S1{} s2Val := S2{} s2Ptr := \u0026amp;S2{} var i F i = s1Val i = s1Ptr i = s2Ptr // 下面代码无法通过编译。因为 s2Val 是一个值，而 S2 的 f 方法中没有使用值接收器 // i = s2Val 补充 :\n一个类型可以有两种接收器方法集， 值接收器方法集和指针接收器方法集 值接收器方法集是指针接收器方法集的子集，反之不是 规则 值对象只可以使用值接收器方法集 指针对象可以使用 值接收器方法集 + 指针接收器方法集 接收的实现 类型实现了接口的所有方法，叫 匹配/实现 具体的讲，要么是类型的值方法集匹配接口，要么是指针方法集匹配接口 具体的匹配分两种\n值方法集和接口匹配 给接口变量赋值的不管是值还是指针对象，都可以，因为都包含值方法集 指针方法集和接口匹配 只能将指针对象赋值给接口变量 ( var i F = \u0026amp;S2{} )，因为仅有指针方法集与接口匹配 如果将值对象赋值给接口变量 ( var i F = S2{} )，会在编译期报错 在上面示例中， i = s2Val 会报错，是因为其方法都是指针方法集，与接口不匹配。可以这样操作 i = \u0026amp;s2Val\n零值 Mutex 是有效的 1 2 // Bad mu := new(sync.Mutex) 1 2 // Good var mu sync.Mutex 如果你使用结构体指针，mutex 可以非指针形式作为结构体的组成字段，或者更好的方式是直接嵌入到结构体中。 如果是私有结构体类型或是要实现 Mutex 接口的类型，我们可以使用嵌入 mutex 的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 为私有类型或需要实现互斥接口的类型嵌入。 type smap struct { sync.Mutex // 仅适用于非导出类型 data map[string]string } func newSMap() *smap { return \u0026amp;smap{ data: make(map[string]string), } } func (m *smap) Get(k string) string { m.Lock() defer m.Unlock() return m.data[k] } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // 对于导出的类型，请使用专用字段。 type SMap struct { mu sync.Mutex // 对于导出类型，请使用私有锁 data map[string]string } func NewSMap() *SMap { return \u0026amp;SMap{ data: make(map[string]string), } } func (m *SMap) Get(k string) string { m.mu.Lock() defer m.mu.Unlock() return m.data[k] } 在边界处拷贝 Slices 和 Maps slices 和 maps 包含了指向底层数据的指针，因此在需要复制它们时要特别注意。\n接收 Slices 和 Maps\n请记住，当 map 或 slice 作为函数参数传入时，如果您存储了对它们的引用，则用户可以对其进行修改。\n1 2 3 4 5 6 7 8 9 10 // Bad func (d *Driver) SetTrips(trips []Trip) { d.trips = trips } trips := ... d1.SetTrips(trips) // 你是要修改 d1.trips 吗？ trips[0] = ... 1 2 3 4 5 6 7 8 9 10 11 # Good func (d *Driver) SetTrips(trips []Trip) { d.trips = make([]Trip, len(trips)) copy(d.trips, trips) } trips := ... d1.SetTrips(trips) // 这里我们修改 trips[0]，但不会影响到 d1.trips trips[0] = ... 返回 slices 或 maps\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // Bad type Stats struct { mu sync.Mutex counters map[string]int } // Snapshot 返回当前状态。 func (s *Stats) Snapshot() map[string]int { s.mu.Lock() defer s.mu.Unlock() return s.counters } // snapshot 不再受互斥锁保护 // 因此对 snapshot 的任何访问都将受到数据竞争的影响 // 影响 stats.counters snapshot := stats.Snapshot() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // Good type Stats struct { mu sync.Mutex counters map[string]int } func (s *Stats) Snapshot() map[string]int { s.mu.Lock() defer s.mu.Unlock() result := make(map[string]int, len(s.counters)) for k, v := range s.counters { result[k] = v } return result } // snapshot 现在是一个拷贝 snapshot := stats.Snapshot() 使用 defer 释放资源 使用 defer 释放资源，诸如文件和锁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Bad p.Lock() if p.count \u0026lt; 10 { p.Unlock() return p.count } p.count++ newCount := p.count p.Unlock() return newCount // 当有多个 return 分支时，很容易遗忘 unlock 1 2 3 4 5 6 7 8 9 10 11 12 // Good p.Lock() defer p.Unlock() if p.count \u0026lt; 10 { return p.count } p.count++ return p.count // 更可读 Defer 的开销非常小，只有在您可以证明函数执行时间处于纳秒级的程度时，才应避免这样做。使用 defer 提升可读性是值得的，因为使用它们的成本微不足道。尤其适用于那些不仅仅是简单内存访问的较大的方法，在这些方法中其他计算的资源消耗远超过 defer。\nChannel 的 size 要么是 1，要么是无缓冲的 1 2 3 // Bad // 应该足以满足任何情况！ c := make(chan int, 64) 1 2 3 4 5 // Good // 大小：1 c := make(chan int, 1) // 或者 // 无缓冲 channel，大小为 0 c := make(chan int) 枚举从 1 开始 1 2 3 4 5 6 7 8 9 10 // Bad type Operation int const ( Add Operation = iota Subtract Multiply ) // Add=0, Subtract=1, Multiply=2 1 2 3 4 5 6 7 8 9 10 // Good type Operation int const ( Add Operation = iota + 1 Subtract Multiply ) // Add=1, Subtract=2, Multiply=3 在某些情况下，使用零值是有意义的（枚举从零开始），例如，当零值是理想的默认行为时。\n使用 time 处理时间 时间处理很复杂。关于时间的错误假设通常包括以下几点。\n一天有 24 小时 一小时有 60 分钟 一周有七天 一年 365 天 还有更多 例如，1 表示在一个时间点上加上 24 小时并不总是产生一个新的日历日。\n因此，在处理时间时始终使用 \u0026quot;time\u0026quot; 包，因为它有助于以更安全、更准确的方式处理这些不正确的假设。\n使用 time.Time 表达瞬时时间\n在处理时间的瞬间时使用 time.Time，在比较、添加或减去时间时使用 time.Time 中的方法。\n1 2 3 4 // Bad func isActive(now, start, stop int) bool { return start \u0026lt;= now \u0026amp;\u0026amp; now \u0026lt; stop } 1 2 3 4 // Good func isActive(now, start, stop time.Time) bool { return (start.Before(now) || start.Equal(now)) \u0026amp;\u0026amp; now.Before(stop) } 使用 time.Duration 表达时间段\n1 2 3 4 5 6 7 8 // Bad func poll(delay int) { for { // ... time.Sleep(time.Duration(delay) * time.Millisecond) } } poll(10) // 是几秒钟还是几毫秒? 1 2 3 4 5 6 7 8 // Good func poll(delay time.Duration) { for { // ... time.Sleep(delay) } } poll(10*time.Second) 回到第一个例子，在一个时间瞬间加上 24 小时，我们用于添加时间的方法取决于意图。如果我们想要下一个日历日(当前天的下一天)的同一个时间点，我们应该使用 Time.AddDate。但是，如果我们想保证某一时刻比前一时刻晚 24 小时，我们应该使用 Time.Add。\n1 2 newDay := t.AddDate(0 /* years */, 0 /* months */, 1 /* days */) maybeNewDay := t.Add(24 * time.Hour) 对外部系统使用 time.Time 和 time.Duration\n尽可能在与外部系统的交互中使用 time.Duration 和 time.Time 例如 :\nCommand-line 标志: flag 通过 time.ParseDuration 支持 time.Duration JSON: encoding/json 通过其 UnmarshalJSON method 方法支持将 time.Time 编码为 RFC 3339 字符串 SQL: database/sql 支持将 DATETIME 或 TIMESTAMP 列转换为 time.Time，如果底层驱动程序支持则返回 YAML: gopkg.in/yaml.v2 支持将 time.Time 作为 RFC 3339 字符串，并通过 time.ParseDuration 支持 time.Duration。 当不能在这些交互中使用 time.Duration 时，请使用 int 或 float64，并在字段名称中包含单位。\n例如，由于 encoding/json 不支持 time.Duration，因此该单位包含在字段的名称中。\n1 2 3 4 5 // Bad // {\u0026#34;interval\u0026#34;: 2} type Config struct { Interval int `json:\u0026#34;interval\u0026#34;` } 1 2 3 4 5 // Good // {\u0026#34;intervalMillis\u0026#34;: 2000} type Config struct { IntervalMillis int `json:\u0026#34;intervalMillis\u0026#34;` } 当在这些交互中不能使用 time.Time 时，除非达成一致，否则使用 string 和 RFC 3339 中定义的格式时间戳。默认情况下，Time.UnmarshalText 使用此格式，并可通过 time.RFC3339 在 Time.Format 和 time.Parse 中使用。\n尽管这在实践中并不成问题，但请记住，\u0026quot;time\u0026quot; 包不支持解析闰秒时间戳（8728），也不在计算中考虑闰秒（15190）。如果您比较两个时间瞬间，则差异将不包括这两个瞬间之间可能发生的闰秒。\n错误类型 Go 中有多种声明错误（Error) 的选项：\nerrors.New 对于简单静态字符串的错误 fmt.Errorf 用于格式化的错误字符串 实现 Error() 方法的自定义类型 用 \u0026quot;pkg/errors\u0026quot;.Wrap 的 Wrapped errors 返回错误时，请考虑以下因素以确定最佳选择：\n这是一个不需要额外信息的简单错误吗？如果是这样，errors.New 足够了。 客户需要检测并处理此错误吗？如果是这样，则应使用自定义类型并实现该 Error() 方法。 您是否正在传播下游函数返回的错误？如果是这样，请查看本文后面有关错误包装 section on error wrapping 部分的内容。 否则 fmt.Errorf 就可以了。 如果客户端需要检测错误，并且您已使用创建了一个简单的错误 errors.New，请使用一个错误变量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // Bad // package foo func Open() error { return errors.New(\u0026#34;could not open\u0026#34;) } // package bar func use() { if err := foo.Open(); err != nil { if err.Error() == \u0026#34;could not open\u0026#34; { // handle } else { panic(\u0026#34;unknown error\u0026#34;) } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // Good // package foo var ErrCouldNotOpen = errors.New(\u0026#34;could not open\u0026#34;) func Open() error { return ErrCouldNotOpen } // package bar if err := foo.Open(); err != nil { if errors.Is(err, foo.ErrCouldNotOpen) { // handle } else { panic(\u0026#34;unknown error\u0026#34;) } } 如果您有可能需要客户端检测的错误，并且想向其中添加更多信息（例如，它不是静态字符串），则应使用自定义类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Bad func open(file string) error { return fmt.Errorf(\u0026#34;file %q not found\u0026#34;, file) } func use() { if err := open(\u0026#34;testfile.txt\u0026#34;); err != nil { if strings.Contains(err.Error(), \u0026#34;not found\u0026#34;) { // handle } else { panic(\u0026#34;unknown error\u0026#34;) } } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // Good type errNotFound struct { file string } func (e errNotFound) Error() string { return fmt.Sprintf(\u0026#34;file %q not found\u0026#34;, e.file) } func open(file string) error { return errNotFound{file: file} } func use() { if err := open(\u0026#34;testfile.txt\u0026#34;); err != nil { if _, ok := err.(errNotFound); ok { // handle } else { panic(\u0026#34;unknown error\u0026#34;) } } } 直接导出自定义错误类型时要小心，因为它们已成为程序包公共 API 的一部分。最好公开匹配器功能以检查错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 // package foo type errNotFound struct { file string } func (e errNotFound) Error() string { return fmt.Sprintf(\u0026#34;file %q not found\u0026#34;, e.file) } func IsNotFoundError(err error) bool { _, ok := err.(errNotFound) return ok } func Open(file string) error { return errNotFound{file: file} } // package bar if err := foo.Open(\u0026#34;foo\u0026#34;); err != nil { if foo.IsNotFoundError(err) { // handle } else { panic(\u0026#34;unknown error\u0026#34;) } } 错误包装 (Error Wrapping) 一个（函数/方法）调用失败时，有三种主要的错误传播方式：\n如果没有要添加的其他上下文，并且您想要维护原始错误类型，则返回原始错误。 添加上下文，使用 \u0026quot;pkg/errors\u0026quot;.Wrap 以便错误消息提供更多上下文 ,\u0026quot;pkg/errors\u0026quot;.Cause 可用于提取原始错误。 如果调用者不需要检测或处理的特定错误情况，使用 fmt.Errorf。 建议在可能的地方添加上下文，以使您获得诸如“调用服务 foo：连接被拒绝”之类的更有用的错误，而不是诸如“连接被拒绝”之类的模糊错误。\n在将上下文添加到返回的错误时，请避免使用“failed to”之类的短语以保持上下文简洁，这些短语会陈述明显的内容，并随着错误在堆栈中的渗透而逐渐堆积：\n1 2 3 4 5 6 // Bad s, err := store.New() if err != nil { return fmt.Errorf( \u0026#34;failed to create new store: %v\u0026#34;, err) } 1 2 3 4 5 6 // Good s, err := store.New() if err != nil { return fmt.Errorf( \u0026#34;new store: %v\u0026#34;, err) } 但是，一旦将错误发送到另一个系统，就应该明确消息是错误消息（例如使用err标记，或在日志中以”Failed”为前缀）。\n另请参见 Don\u0026rsquo;t just check errors, handle them gracefully. 不要只是检查错误，要优雅地处理错误\n处理类型断言失败 type assertion 的单个返回值形式针对不正确的类型将产生 panic。因此，请始终使用“comma ok”的惯用法。\n1 2 // Bad t := i.(string) 1 2 3 4 5 // Good t, ok := i.(string) if !ok { // 优雅地处理错误 } 不要 panic 在生产环境中运行的代码必须避免出现 panic。panic 是 cascading failures 级联失败的主要根源 。如果发生错误，该函数必须返回错误，并允许调用方决定如何处理它。\n1 2 3 4 5 6 7 8 9 10 11 // Bad func run(args []string) { if len(args) == 0 { panic(\u0026#34;an argument is required\u0026#34;) } // ... } func main() { run(os.Args[1:]) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // Good func run(args []string) error { if len(args) == 0 { return errors.New(\u0026#34;an argument is required\u0026#34;) } // ... return nil } func main() { if err := run(os.Args[1:]); err != nil { fmt.Fprintln(os.Stderr, err) os.Exit(1) } } panic/recover 不是错误处理策略。仅当发生不可恢复的事情（例如：nil 引用）时，程序才必须 panic。程序初始化是一个例外：程序启动时应使程序中止的不良情况可能会引起 panic。\n1 var _statusTemplate = template.Must(template.New(\u0026#34;name\u0026#34;).Parse(\u0026#34;_statusHTML\u0026#34;)) 即使在测试代码中，也优先使用t.Fatal或者t.FailNow而不是 panic 来确保失败被标记。\n1 2 3 4 5 6 7 // Bad // func TestFoo(t *testing.T) f, err := ioutil.TempFile(\u0026#34;\u0026#34;, \u0026#34;test\u0026#34;) if err != nil { panic(\u0026#34;failed to set up test\u0026#34;) } 1 2 3 4 5 6 7 // Good // func TestFoo(t *testing.T) f, err := ioutil.TempFile(\u0026#34;\u0026#34;, \u0026#34;test\u0026#34;) if err != nil { t.Fatal(\u0026#34;failed to set up test\u0026#34;) } 使用 go.uber.org/atomic ( 仅摘录，此条不一定适合我使用 )\n使用 sync/atomic 包的原子操作对原始类型 (int32, int64等）进行操作，因为很容易忘记使用原子操作来读取或修改变量。\ngo.uber.org/atomic 通过隐藏基础类型为这些操作增加了类型安全性。此外，它包括一个方便的atomic.Bool类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // Bad type foo struct { running int32 // atomic } func (f* foo) start() { if atomic.SwapInt32(\u0026amp;f.running, 1) == 1 { // already running… return } // start the Foo } func (f *foo) isRunning() bool { return f.running == 1 // race! } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // Good type foo struct { running atomic.Bool } func (f *foo) start() { if f.running.Swap(true) { // already running… return } // start the Foo } func (f *foo) isRunning() bool { return f.running.Load() } 避免可变全局变量 使用选择依赖注入方式避免改变全局变量。 既适用于函数指针又适用于其他值类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // Bad // sign.go var _timeNow = time.Now func sign(msg string) string { now := _timeNow() return signWithTime(msg, now) } // sign_test.go func TestSign(t *testing.T) { oldTimeNow := _timeNow _timeNow = func() time.Time { return someFixedTime } defer func() { _timeNow = oldTimeNow }() assert.Equal(t, want, sign(give)) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // Good // sign.go type signer struct { now func() time.Time } func newSigner() *signer { return \u0026amp;signer{ now: time.Now, } } func (s *signer) Sign(msg string) string { now := s.now() return signWithTime(msg, now) } // sign_test.go func TestSigner(t *testing.T) { s := newSigner() s.now = func() time.Time { return someFixedTime } assert.Equal(t, want, s.Sign(give)) } 避免在公共结构中嵌入类型 这些嵌入的类型泄漏实现细节、禁止类型演化和模糊的文档。\n假设您使用共享的 AbstractList 实现了多种列表类型，请避免在具体的列表实现中嵌入 AbstractList。 相反，只需手动将方法写入具体的列表，该列表将委托给抽象列表。\n1 2 3 4 5 6 7 8 9 type AbstractList struct {} // 添加将实体添加到列表中。 func (l *AbstractList) Add(e Entity) { // ... } // 移除从列表中移除实体。 func (l *AbstractList) Remove(e Entity) { // ... } 1 2 3 4 5 // Bad // ConcreteList 是一个实体列表。 type ConcreteList struct { *AbstractList } 1 2 3 4 5 6 7 8 9 10 11 12 13 // Good // ConcreteList 是一个实体列表。 type ConcreteList struct { list *AbstractList } // 添加将实体添加到列表中。 func (l *ConcreteList) Add(e Entity) { l.list.Add(e) } // 移除从列表中移除实体。 func (l *ConcreteList) Remove(e Entity) { l.list.Remove(e) } Go 允许 类型嵌入 作为继承和组合之间的折衷。 外部类型获取嵌入类型的方法的隐式副本。 默认情况下，这些方法委托给嵌入实例的同一方法。\n结构还获得与类型同名的字段。 所以，如果嵌入的类型是 public，那么字段是 public。为了保持向后兼容性，外部类型的每个未来版本都必须保留嵌入类型。\n很少需要嵌入类型。 这是一种方便，可以帮助您避免编写冗长的委托方法。\n即使嵌入兼容的抽象列表 interface，而不是结构体，这将为开发人员提供更大的灵活性来改变未来，但仍然泄露了具体列表使用抽象实现的细节。\n1 2 3 4 5 6 7 8 9 10 // Bad // AbstractList 是各种实体列表的通用实现。 type AbstractList interface { Add(Entity) Remove(Entity) } // ConcreteList 是一个实体列表。 type ConcreteList struct { AbstractList } 1 2 3 4 5 6 7 8 9 10 11 12 13 // Good // ConcreteList 是一个实体列表。 type ConcreteList struct { list AbstractList } // 添加将实体添加到列表中。 func (l *ConcreteList) Add(e Entity) { l.list.Add(e) } // 移除从列表中移除实体。 func (l *ConcreteList) Remove(e Entity) { l.list.Remove(e) } 无论是使用嵌入式结构还是使用嵌入式接口，嵌入式类型都会限制类型的演化.\n向嵌入式接口添加方法是一个破坏性的改变。 删除嵌入类型是一个破坏性的改变。 即使使用满足相同接口的替代方法替换嵌入类型，也是一个破坏性的改变。 尽管编写这些委托方法是乏味的，但是额外的工作隐藏了实现细节，留下了更多的更改机会，还消除了在文档中发现完整列表接口的间接性操作。\n避免使用内置名称 Go语言规范language specification 概述了几个内置的， 不应在Go项目中使用的名称标识predeclared identifiers。\n根据上下文的不同，将这些标识符作为名称重复使用， 将在当前作用域（或任何嵌套作用域）中隐藏原始标识符，或者混淆代码。 在最好的情况下，编译器会报错；在最坏的情况下，这样的代码可能会引入潜在的、难以恢复的错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // Bad var error string // `error` 作用域隐式覆盖 // or func handleErrorMessage(error string) { // `error` 作用域隐式覆盖 } type Foo struct { // 虽然这些字段在技术上不构成阴影，但`error`或`string`字符串的重映射现在是不明确的。 error error string string } func (f Foo) Error() error { // `error` 和 `f.error` 在视觉上是相似的 return f.error } func (f Foo) String() string { // `string` and `f.string` 在视觉上是相似的 return f.string } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // Good var errorMessage string // `error` 指向内置的非覆盖 // or func handleErrorMessage(msg string) { // `error` 指向内置的非覆盖 } type Foo struct { // `error` and `string` 现在是明确的。 err error str string } func (f Foo) Error() error { return f.err } func (f Foo) String() string { return f.str } 注意，编译器在使用预先分隔的标识符时不会生成错误， 但是诸如go vet之类的工具会正确地指出这些和其他情况下的隐式问题。\n避免使用 init() 尽可能避免使用init()。当init()是不可避免或可取的，代码应先尝试：\n无论程序环境或调用如何，都要完全确定。 避免依赖于其他init()函数的顺序或副作用。虽然init()顺序是明确的，但代码可以更改， 因此init()函数之间的关系可能会使代码变得脆弱和容易出错。 避免访问或操作全局或环境状态，如机器信息、环境变量、工作目录、程序参数/输入等。 避免I/O，包括文件系统、网络和系统调用。 不能满足这些要求的代码可能属于要作为main()调用的一部分（或程序生命周期中的其他地方）， 或者作为main()本身的一部分写入。特别是，打算由其他程序使用的库应该特别注意完全确定性， 而不是执行“init magic”\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // Bad type Foo struct { // ... } var _defaultFoo Foo func init() { _defaultFoo = Foo{ // ... } } type Config struct { // ... } var _config Config func init() { // Bad: 基于当前目录 cwd, _ := os.Getwd() // Bad: I/O raw, _ := ioutil.ReadFile( path.Join(cwd, \u0026#34;config\u0026#34;, \u0026#34;config.yaml\u0026#34;), ) yaml.Unmarshal(raw, \u0026amp;_config) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // Good var _defaultFoo = Foo{ // ... } // or, 为了更好的可测试性: var _defaultFoo = defaultFoo() func defaultFoo() Foo { return Foo{ // ... } } type Config struct { // ... } func loadConfig() Config { cwd, err := os.Getwd() // handle err raw, err := ioutil.ReadFile( path.Join(cwd, \u0026#34;config\u0026#34;, \u0026#34;config.yaml\u0026#34;), ) // handle err var config Config yaml.Unmarshal(raw, \u0026amp;config) return config } 考虑到上述情况，在某些情况下，init()可能更可取或是必要的，可能包括：\n不能表示为单个赋值的复杂表达式。 可插入的钩子，如database/sql、编码类型注册表等。 对Google Cloud Functions和其他形式的确定性预计算的优化。 追加时优先指定切片容量 追加时优先指定切片容量\n在尽可能的情况下，在初始化要追加的切片时为make()提供一个容量值。\n1 2 3 4 5 6 7 8 9 // Bad for n := 0; n \u0026lt; b.N; n++ { data := make([]int, 0) for k := 0; k \u0026lt; size; k++{ data = append(data, k) } } // BenchmarkBad-4 100000000 2.48s 1 2 3 4 5 6 7 8 9 // Good for n := 0; n \u0026lt; b.N; n++ { data := make([]int, 0, size) for k := 0; k \u0026lt; size; k++{ data = append(data, k) } } // BenchmarkGood-4 100000000 0.21s 主函数退出方式(Exit) Go程序使用os.Exit 或者 log.Fatal* 立即退出 (使用panic不是退出程序的好方法，请 don\u0026rsquo;t panic.)\n**仅在main（）**中调用其中一个 os.Exit 或者 log.Fatal*。所有其他函数应将错误返回到信号失败中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // Bad func main() { body := readFile(path) fmt.Println(body) } func readFile(path string) string { f, err := os.Open(path) if err != nil { log.Fatal(err) } b, err := ioutil.ReadAll(f) if err != nil { log.Fatal(err) } return string(b) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // Good func main() { body, err := readFile(path) if err != nil { log.Fatal(err) } fmt.Println(body) } func readFile(path string) (string, error) { f, err := os.Open(path) if err != nil { return \u0026#34;\u0026#34;, err } b, err := ioutil.ReadAll(f) if err != nil { return \u0026#34;\u0026#34;, err } return string(b), nil } 原则上：退出的具有多种功能的程序存在一些问题：\n不明显的控制流：任何函数都可以退出程序，因此很难对控制流进行推理。 难以测试：退出程序的函数也将退出调用它的测试。这使得函数很难测试，并引入了跳过 go test 尚未运行的其他测试的风险。 跳过清理：当函数退出程序时，会跳过已经进入defer队列里的函数调用。这增加了跳过重要清理任务的风险。 一次性退出 如果可能的话，你的main（）函数中最多一次 调用 os.Exit或者log.Fatal。如果有多个错误场景停止程序执行，请将该逻辑放在单独的函数下并从中返回错误。 这会缩短 main()函数，并将所有关键业务逻辑放入一个单独的、可测试的函数中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // Bad package main func main() { args := os.Args[1:] if len(args) != 1 { log.Fatal(\u0026#34;missing file\u0026#34;) } name := args[0] f, err := os.Open(name) if err != nil { log.Fatal(err) } defer f.Close() // 如果我们调用log.Fatal 在这条线之后 // f.Close 将会被执行. b, err := ioutil.ReadAll(f) if err != nil { log.Fatal(err) } // ... } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // Good package main func main() { if err := run(); err != nil { log.Fatal(err) } } func run() error { args := os.Args[1:] if len(args) != 1 { return errors.New(\u0026#34;missing file\u0026#34;) } name := args[0] f, err := os.Open(name) if err != nil { return err } defer f.Close() b, err := ioutil.ReadAll(f) if err != nil { return err } // ... } 性能 优先使用 strconv 而不是 fmt 将原语转换为字符串或从字符串转换时，strconv速度比fmt快。\n1 2 3 4 // Bad for i := 0; i \u0026lt; b.N; i++ { s := fmt.Sprint(rand.Int()) } 1 2 3 4 // Good for i := 0; i \u0026lt; b.N; i++ { s := strconv.Itoa(rand.Int()) } 避免字符串到字节的转换 不要反复从固定字符串创建字节 slice。相反，请执行一次转换并捕获结果。\n1 2 3 4 5 6 // Bad for i := 0; i \u0026lt; b.N; i++ { w.Write([]byte(\u0026#34;Hello world\u0026#34;)) } // BenchmarkBad-4 50000000 22.2 ns/op 1 2 3 4 5 6 7 // Good data := []byte(\u0026#34;Hello world\u0026#34;) for i := 0; i \u0026lt; b.N; i++ { w.Write(data) } // BenchmarkGood-4 500000000 3.25 ns/op 指定容器容量 尽可能指定容器容量，以便为容器预先分配内存。这将在添加元素时最小化后续分配（通过复制和调整容器大小）。\n指定Map容量提示 在尽可能的情况下，在使用 make() 初始化的时候提供容量信息\n1 make(map[T1]T2, hint) 向make()提供容量提示会在初始化时尝试调整map的大小，这将减少在将元素添加到map时为map重新分配内存。\n注意，与slices不同。map capacity提示并不保证完全的抢占式分配，而是用于估计所需的hashmap bucket的数量。 因此，在将元素添加到map时，甚至在指定map容量时，仍可能发生分配。\n1 2 3 4 5 6 7 8 9 // Bad m := make(map[string]os.FileInfo) files, _ := ioutil.ReadDir(\u0026#34;./files\u0026#34;) for _, f := range files { m[f.Name()] = f } // m 是在没有大小提示的情况下创建的； 在运行时可能会有更多分配。 1 2 3 4 5 6 7 8 9 10 // Good files, _ := ioutil.ReadDir(\u0026#34;./files\u0026#34;) m := make(map[string]os.FileInfo, len(files)) for _, f := range files { m[f.Name()] = f } // m 是有大小提示创建的；在运行时可能会有更少的分配。 指定切片容量 在尽可能的情况下，在使用make()初始化切片时提供容量信息，特别是在追加切片时。\n1 make([]T, length, capacity) 与maps不同，slice capacity不是一个提示：编译器将为提供给make()的slice的容量分配足够的内存， 这意味着后续的append()`操作将导致零分配（直到slice的长度与容量匹配，在此之后，任何append都可能调整大小以容纳其他元素）。\n1 2 3 4 5 6 7 8 9 // Bad for n := 0; n \u0026lt; b.N; n++ { data := make([]int, 0) for k := 0; k \u0026lt; size; k++{ data = append(data, k) } } // BenchmarkBad-4 100000000 2.48s 1 2 3 4 5 6 7 8 9 // Good for n := 0; n \u0026lt; b.N; n++ { data := make([]int, 0, size) for k := 0; k \u0026lt; size; k++{ data = append(data, k) } } // BenchmarkGood-4 100000000 0.21s 规范 一致性 本文中概述的一些标准都是客观性的评估，是根据场景、上下文、或者主观性的判断；\n但是最重要的是，保持一致.\n一致性的代码更容易维护、是更合理的、需要更少的学习成本、并且随着新的约定出现或者出现错误后更容易迁移、更新、修复 bug\n相反，在一个代码库中包含多个完全不同或冲突的代码风格会导致维护成本开销、不确定性和认知偏差。所有这些都会直接导致速度降低、代码审查痛苦、而且增加 bug 数量。\n将这些标准应用于代码库时，建议在 package（或更大）级别进行更改，子包级别的应用程序通过将多个样式引入到同一代码中，违反了上述关注点。\n相似的声明放在一组 Go 语言支持将相似的声明放在一个组内。\n1 2 3 // Bad import \u0026#34;a\u0026#34; import \u0026#34;b\u0026#34; 1 2 3 4 5 // Good import ( \u0026#34;a\u0026#34; \u0026#34;b\u0026#34; ) 这同样适用于常量、变量和类型声明：\n1 2 3 4 5 6 7 8 9 10 // Bad const a = 1 const b = 2 var a = 1 var b = 2 type Area float64 type Volume float64 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // Good const ( a = 1 b = 2 ) var ( a = 1 b = 2 ) type ( Area float64 Volume float64 ) 仅将相关的声明放在一组。不要将不相关的声明放在一组。\n1 2 3 4 5 6 7 8 9 // Bad type Operation int const ( Add Operation = iota + 1 Subtract Multiply EnvVar = \u0026#34;MY_ENV\u0026#34; ) 1 2 3 4 5 6 7 8 9 10 // Good type Operation int const ( Add Operation = iota + 1 Subtract Multiply ) const EnvVar = \u0026#34;MY_ENV\u0026#34; 分组使用的位置没有限制，例如：你可以在函数内部使用它们：\n1 2 3 4 5 6 7 8 // Bad func f() string { var red = color.New(0xff0000) var green = color.New(0x00ff00) var blue = color.New(0x0000ff) ... } 1 2 3 4 5 6 7 8 9 10 // Good func f() string { var ( red = color.New(0xff0000) green = color.New(0x00ff00) blue = color.New(0x0000ff) ) ... } import 分组 导入应该分为两组：\n标准库 其他库 默认情况下，这是 goimports 应用的分组。\n1 2 3 4 5 6 7 // Bad import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;go.uber.org/atomic\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) 1 2 3 4 5 6 7 8 // Good import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;go.uber.org/atomic\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) 包名 当命名包时，请按下面规则确定名称：\n全部小写。没有大写或下划线。 大多数使用命名导入的情况下，不需要重命名。 简短而简洁。请记住，在每个使用的地方都完整标识了该名称。 不用复数。例如net/url，而不是net/urls。 不要用“common”，“util”，“shared”或“lib”。这些是不好的，信息量不足的名称。 另请参阅 Package Names 和 Go 包样式指南.\n函数名 我们遵循 Go 社区关于使用 MixedCaps 作为函数名 的约定。有一个例外，为了对相关的测试用例进行分组，函数名可能包含下划线，如：TestMyFunction_WhatIsBeingTested.\n导入别名 如果程序包名称与导入路径的最后一个元素不匹配，则必须使用导入别名。\n1 2 3 4 5 6 import ( \u0026#34;net/http\u0026#34; client \u0026#34;example.com/client-go\u0026#34; trace \u0026#34;example.com/trace/v2\u0026#34; ) 在所有其他情况下，除非导入之间有直接冲突，否则应避免导入别名。\n1 2 3 4 5 6 7 // Bad import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; nettrace \u0026#34;golang.net/x/trace\u0026#34; ) 1 2 3 4 5 6 7 8 // Good import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;runtime/trace\u0026#34; nettrace \u0026#34;golang.net/x/trace\u0026#34; ) 函数分组与顺序 函数应按粗略的调用顺序排序。 同一文件中的函数应按接收者分组。 因此，导出的函数应先出现在文件中，放在struct, const, var定义的后面。\n在定义类型之后，但在接收者的其余方法之前，可能会出现一个 newXYZ()/NewXYZ()\n由于函数是按接收者分组的，因此普通工具函数应在文件末尾出现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Bad func (s *something) Cost() { return calcCost(s.weights) } type something struct{ ... } func calcCost(n []int) int {...} func (s *something) Stop() {...} func newSomething() *something { return \u0026amp;something{} } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Good type something struct{ ... } func newSomething() *something { return \u0026amp;something{} } func (s *something) Cost() { return calcCost(s.weights) } func (s *something) Stop() {...} func calcCost(n []int) int {...} 减少嵌套 代码应通过尽可能先处理错误情况/特殊情况并尽早返回或继续循环来减少嵌套。减少嵌套多个级别的代码的代码量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 // Bad for _, v := range data { if v.F1 == 1 { v = process(v) if err := v.Call(); err == nil { v.Send() } else { return err } } else { log.Printf(\u0026#34;Invalid v: %v\u0026#34;, v) } } 1 2 3 4 5 6 7 8 9 10 11 12 13 // Good for _, v := range data { if v.F1 != 1 { log.Printf(\u0026#34;Invalid v: %v\u0026#34;, v) continue } v = process(v) if err := v.Call(); err != nil { return err } v.Send() } 不必要的 else 如果在 if 的两个分支中都设置了变量，则可以将其替换为单个 if。\n1 2 3 4 5 6 7 // Bad var a int if b { a = 100 } else { a = 10 } 1 2 3 4 5 // Good a := 10 if b { a = 100 } 顶层变量声明 在顶层，使用标准var关键字。请勿指定类型，除非它与表达式的类型不同。\n1 2 3 4 // Bad var _s string = F() func F() string { return \u0026#34;A\u0026#34; } 1 2 3 4 5 6 // Good var _s = F() // 由于 F 已经明确了返回一个字符串类型，因此我们没有必要显式指定_s 的类型 // 还是那种类型 func F() string { return \u0026#34;A\u0026#34; } 如果表达式的类型与所需的类型不完全匹配，请指定类型。\n1 2 3 4 5 6 7 8 type myError struct{} func (myError) Error() string { return \u0026#34;error\u0026#34; } func F() myError { return myError{} } var _e error = F() // F 返回一个 myError 类型的实例，但是我们要 error 类型 对于未导出的顶层常量和变量，使用_作为前缀 在未导出的顶级vars和consts， 前面加上前缀_，以使它们在使用时明确表示它们是全局符号。\n例外：未导出的错误值，应以err开头。\n基本依据：顶级变量和常量具有包范围作用域。使用通用名称可能很容易在其他文件中意外使用错误的值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // Bad // foo.go const ( defaultPort = 8080 defaultUser = \u0026#34;user\u0026#34; ) // bar.go func Bar() { defaultPort := 9090 ... fmt.Println(\u0026#34;Default port\u0026#34;, defaultPort) // We will not see a compile error if the first line of // Bar() is deleted. } 1 2 3 4 5 6 7 // Good // foo.go const ( _defaultPort = 8080 _defaultUser = \u0026#34;user\u0026#34; ) 结构体中的嵌入 嵌入式类型（例如 mutex）应位于结构体内的字段列表的顶部，并且必须有一个空行将嵌入式字段与常规字段分隔开。\n1 2 3 4 5 // Bad type Client struct { version int http.Client } 1 2 3 4 5 6 // Good type Client struct { http.Client version int } 内嵌应该提供切实的好处，比如以语义上合适的方式添加或增强功能。 它应该在对用户不利影响的情况下完成这项工作（另请参见：避免在公共结构中嵌入类型Avoid Embedding Types in Public Structs）。\n嵌入 不应该:\n纯粹是为了美观或方便。 使外部类型更难构造或使用。 影响外部类型的零值。如果外部类型有一个有用的零值，则在嵌入内部类型之后应该仍然有一个有用的零值。 作为嵌入内部类型的副作用，从外部类型公开不相关的函数或字段。 公开未导出的类型。 影响外部类型的复制形式。 更改外部类型的API或类型语义。 嵌入内部类型的非规范形式。 公开外部类型的实现详细信息。 允许用户观察或控制类型内部。 通过包装的方式改变内部函数的一般行为，这种包装方式会给用户带来一些意料之外情况。 简单地说，有意识地和有目的地嵌入。一种很好的测试体验是， \u0026ldquo;是否所有这些导出的内部方法/字段都将直接添加到外部类型\u0026rdquo; 如果答案是some或no，不要嵌入内部类型-而是使用字段。\n1 2 3 4 5 6 // Bad type A struct { // Bad: A.Lock() and A.Unlock() 现在可用 // 不提供任何功能性好处，并允许用户控制有关A的内部细节。 sync.Mutex } 1 2 3 4 5 6 7 8 9 10 11 // Good type countingWriteCloser struct { // Good: Write() 在外层提供用于特定目的， // 并且委托工作到内部类型的Write()中。 io.WriteCloser count int } func (w *countingWriteCloser) Write(bs []byte) (int, error) { w.count += len(bs) return w.WriteCloser.Write(bs) } 1 2 3 4 5 6 7 8 9 10 11 // Bad type Book struct { // Bad: 指针更改零值的有用性 io.ReadWriter // other fields } // later var b Book b.Read(...) // panic: nil pointer b.String() // panic: nil pointer b.Write(...) // panic: nil pointer 1 2 3 4 5 6 7 8 9 10 11 // Good type Book struct { // Good: 有用的零值 bytes.Buffer // other fields } // later var b Book b.Read(...) // ok b.String() // ok b.Write(...) // ok 1 2 3 4 5 6 7 // Bad type Client struct { sync.Mutex sync.WaitGroup bytes.Buffer url.URL } 1 2 3 4 5 6 7 // Good type Client struct { mtx sync.Mutex wg sync.WaitGroup buf bytes.Buffer url url.URL } 本地变量声明 如果将变量明确设置为某个值，则应使用短变量声明形式 (:=)。\n1 2 // Bad var s = \u0026#34;foo\u0026#34; 1 2 // Good s := \u0026#34;foo\u0026#34; 但是，在某些情况下，var 使用关键字时默认值会更清晰。例如，声明空切片。\n1 2 3 4 5 6 7 8 9 // Bad func f(list []int) { filtered := []int{} for _, v := range list { if v \u0026gt; 10 { filtered = append(filtered, v) } } } 1 2 3 4 5 6 7 8 9 // Good func f(list []int) { var filtered []int for _, v := range list { if v \u0026gt; 10 { filtered = append(filtered, v) } } } nil 是一个有效的 slice nil 是一个有效的长度为 0 的 slice，这意味着，\n您不应明确返回长度为零的切片。应该返回nil 来代替。 1 2 3 4 // Bad if x == \u0026#34;\u0026#34; { return []int{} } 1 2 3 4 // Good if x == \u0026#34;\u0026#34; { return nil } 要检查切片是否为空，请始终使用len(s) == 0。而非 nil。 1 2 3 4 // Bad func isEmpty(s []string) bool { return s == nil } 1 2 3 4 // Good func isEmpty(s []string) bool { return len(s) == 0 } 零值切片（用var声明的切片）可立即使用，无需调用make()创建。 1 2 3 4 5 6 7 8 9 10 11 // Bad nums := []int{} // or, nums := make([]int) if add1 { nums = append(nums, 1) } if add2 { nums = append(nums, 2) } 1 2 3 4 5 6 7 8 9 10 // Good var nums []int if add1 { nums = append(nums, 1) } if add2 { nums = append(nums, 2) } 记住，虽然nil切片是有效的切片，但它不等于长度为0的切片（一个为nil，另一个不是），并且在不同的情况下（例如序列化），这两个切片的处理方式可能不同。\n缩小变量作用域 如果有可能，尽量缩小变量作用范围。除非它与 减少嵌套的规则冲突。\n1 2 3 4 5 // Bad err := ioutil.WriteFile(name, data, 0644) if err != nil { return err } 1 2 3 4 // Good if err := ioutil.WriteFile(name, data, 0644); err != nil { return err } 如果需要在 if 之外使用函数调用的结果，则不应尝试缩小范围。\n1 2 3 4 5 6 7 8 9 10 11 12 // Bad if data, err := ioutil.ReadFile(name); err == nil { err = cfg.Decode(data) if err != nil { return err } fmt.Println(cfg) return nil } else { return err } 1 2 3 4 5 6 7 8 9 10 11 12 // Good data, err := ioutil.ReadFile(name) if err != nil { return err } if err := cfg.Decode(data); err != nil { return err } fmt.Println(cfg) return nil 避免参数语义不明确(Avoid Naked Parameters) 函数调用中的意义不明确的参数可能会损害可读性。当参数名称的含义不明显时，请为参数添加 C 样式注释 (/* ... */)\n1 2 3 // Bad // func printInfo(name string, isLocal, done bool) printInfo(\u0026#34;foo\u0026#34;, true, true) 1 2 3 // Good // func printInfo(name string, isLocal, done bool) printInfo(\u0026#34;foo\u0026#34;, true /* isLocal */, true /* done */) 对于上面的示例代码，还有一种更好的处理方式是将上面的 bool 类型换成自定义类型。将来，该参数可以支持不仅仅局限于两个状态（true/false）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 type Region int const ( UnknownRegion Region = iota Local ) type Status int const ( StatusReady Status= iota + 1 StatusDone // Maybe we will have a StatusInProgress in the future. ) func printInfo(name string, region Region, status Status) 使用原始字符串字面值，避免转义 Go 支持使用 原始字符串字面值，也就是 \u0026quot; ` \u0026quot; 来表示原生字符串，在需要转义的场景下，我们应该尽量使用这种方案来替换。\n可以跨越多行并包含引号。使用这些字符串可以避免更难阅读的手工转义的字符串。\n1 2 // Bad wantError := \u0026#34;unknown name:\\\u0026#34;test\\\u0026#34;\u0026#34; 1 2 // Good wantError := `unknown error:\u0026#34;test\u0026#34;` 初始化结构体 使用字段名初始化结构 初始化结构时，几乎应该始终指定字段名。目前由go vet强制执行。\n1 2 // Bad k := User{\u0026#34;John\u0026#34;, \u0026#34;Doe\u0026#34;, true} 1 2 3 4 5 6 // Good k := User{ FirstName: \u0026#34;John\u0026#34;, LastName: \u0026#34;Doe\u0026#34;, Admin: true, } 例外：当有3个或更少的字段时，测试表中的字段名may可以省略。\n1 2 3 4 5 6 7 tests := []struct{ op Operation want string }{ {Add, \u0026#34;add\u0026#34;}, {Subtract, \u0026#34;subtract\u0026#34;}, } 省略结构中的零值字段 初始化具有字段名的结构时，除非提供有意义的上下文，否则忽略值为零的字段。 也就是，让我们自动将这些设置为零值\n1 2 3 4 5 6 7 // Bad user := User{ FirstName: \u0026#34;John\u0026#34;, LastName: \u0026#34;Doe\u0026#34;, MiddleName: \u0026#34;\u0026#34;, Admin: false, } 1 2 3 4 5 // Good user := User{ FirstName: \u0026#34;John\u0026#34;, LastName: \u0026#34;Doe\u0026#34;, } 这有助于通过省略该上下文中的默认值来减少阅读的障碍。只指定有意义的值。\n在字段名提供有意义上下文的地方包含零值。例如，表驱动测试 中的测试用例可以受益于字段的名称，即使它们是零值的。\n1 2 3 4 5 6 7 tests := []struct{ give string want int }{ {give: \u0026#34;0\u0026#34;, want: 0}, // ... } 对零值结构使用 var 如果在声明中省略了结构的所有字段，请使用 var 声明结构。\n1 2 // Bad user := User{} 1 2 // Good var user User 这将零值结构与那些具有类似于为[初始化 Maps]创建的,区别于非零值字段的结构区分开来， 并与我们更喜欢的declare empty slices方式相匹配。\n初始化 Struct 引用 在初始化结构引用时，请使用\u0026amp;T{}代替new(T)，以使其与结构体初始化一致。\n1 2 3 4 5 6 // Bad sval := T{Name: \u0026#34;foo\u0026#34;} // inconsistent sptr := new(T) sptr.Name = \u0026#34;bar\u0026#34; 1 2 3 4 // Good sval := T{Name: \u0026#34;foo\u0026#34;} sptr := \u0026amp;T{Name: \u0026#34;bar\u0026#34;} 初始化 Maps 对于空 map 请使用 make(..) 初始化， 并且 map 是通过编程方式填充的。 这使得 map 初始化在表现上不同于声明，并且它还可以方便地在 make 后添加大小提示。\n1 2 3 4 5 6 7 8 9 // Bad var ( // m1 读写安全; // m2 在写入时会 panic m1 = map[T1]T2{} m2 map[T1]T2 ) // 声明和初始化看起来非常相似的。 1 2 3 4 5 6 7 8 9 // Good var ( // m1 读写安全; // m2 在写入时会 panic m1 = make(map[T1]T2) m2 map[T1]T2 ) // 声明和初始化看起来差别非常大。 在尽可能的情况下，请在初始化时提供 map 容量大小，详细请看 指定Map容量提示。\n另外，如果 map 包含固定的元素列表，则使用 map literals(map 初始化列表) 初始化映射。\n1 2 3 4 5 // Bad m := make(map[T1]T2, 3) m[k1] = v1 m[k2] = v2 m[k3] = v3 1 2 3 4 5 6 // Good m := map[T1]T2{ k1: v1, k2: v2, k3: v3, } 基本准则是：在初始化时使用 map 初始化列表 来添加一组固定的元素。否则使用 make (如果可以，请尽量指定 map 容量)。\n字符串 string format 如果你在函数外声明Printf-style 函数的格式字符串，请将其设置为const常量。\n这有助于go vet对格式字符串执行静态分析。\n1 2 3 // Bad msg := \u0026#34;unexpected values %v, %v\\n\u0026#34; fmt.Printf(msg, 1, 2) 1 2 3 // Good const msg = \u0026#34;unexpected values %v, %v\\n\u0026#34; fmt.Printf(msg, 1, 2) 命名 Printf 样式的函数 声明Printf-style 函数时，请确保go vet可以检测到它并检查格式字符串。\n这意味着您应尽可能使用预定义的Printf-style 函数名称。go vet将默认检查这些。有关更多信息，请参见 Printf 系列。\n如果不能使用预定义的名称，请以 f 结束选择的名称：Wrapf，而不是Wrap。go vet可以要求检查特定的 Printf 样式名称，但名称必须以f结尾。\n1 $ go vet -printfuncs=wrapf,statusf 另请参阅 go vet: Printf family check.\n编程模式 表驱动测试 当测试逻辑是重复的时候，通过 subtests 使用 table 驱动的方式编写 case 代码看上去会更简洁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // Bad // func TestSplitHostPort(t *testing.T) host, port, err := net.SplitHostPort(\u0026#34;192.0.2.0:8000\u0026#34;) require.NoError(t, err) assert.Equal(t, \u0026#34;192.0.2.0\u0026#34;, host) assert.Equal(t, \u0026#34;8000\u0026#34;, port) host, port, err = net.SplitHostPort(\u0026#34;192.0.2.0:http\u0026#34;) require.NoError(t, err) assert.Equal(t, \u0026#34;192.0.2.0\u0026#34;, host) assert.Equal(t, \u0026#34;http\u0026#34;, port) host, port, err = net.SplitHostPort(\u0026#34;:8000\u0026#34;) require.NoError(t, err) assert.Equal(t, \u0026#34;\u0026#34;, host) assert.Equal(t, \u0026#34;8000\u0026#34;, port) host, port, err = net.SplitHostPort(\u0026#34;1:8\u0026#34;) require.NoError(t, err) assert.Equal(t, \u0026#34;1\u0026#34;, host) assert.Equal(t, \u0026#34;8\u0026#34;, port) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // Good // func TestSplitHostPort(t *testing.T) tests := []struct{ give string wantHost string wantPort string }{ { give: \u0026#34;192.0.2.0:8000\u0026#34;, wantHost: \u0026#34;192.0.2.0\u0026#34;, wantPort: \u0026#34;8000\u0026#34;, }, { give: \u0026#34;192.0.2.0:http\u0026#34;, wantHost: \u0026#34;192.0.2.0\u0026#34;, wantPort: \u0026#34;http\u0026#34;, }, { give: \u0026#34;:8000\u0026#34;, wantHost: \u0026#34;\u0026#34;, wantPort: \u0026#34;8000\u0026#34;, }, { give: \u0026#34;1:8\u0026#34;, wantHost: \u0026#34;1\u0026#34;, wantPort: \u0026#34;8\u0026#34;, }, } for _, tt := range tests { t.Run(tt.give, func(t *testing.T) { host, port, err := net.SplitHostPort(tt.give) require.NoError(t, err) assert.Equal(t, tt.wantHost, host) assert.Equal(t, tt.wantPort, port) }) } 很明显，使用 test table 的方式在代码逻辑扩展的时候，比如新增 test case，都会显得更加的清晰。\n我们遵循这样的约定：将结构体切片称为tests。 每个测试用例称为tt。此外，我们鼓励使用give和want前缀说明每个测试用例的输入和输出值。\n1 2 3 4 5 6 7 8 9 10 11 tests := []struct{ give string wantHost string wantPort string }{ // ... } for _, tt := range tests { // ... } 功能选项 功能选项是一种模式，您可以在其中声明一个不透明 Option 类型，该类型在某些内部结构中记录信息。您接受这些选项的可变编号，并根据内部结构上的选项记录的全部信息采取行动。\n将此模式用于您需要扩展的构造函数和其他公共 API 中的可选参数，尤其是在这些功能上已经具有三个或更多参数的情况下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // Bad // package db func Open( addr string, cache bool, logger *zap.Logger ) (*Connection, error) { // ... } // 必须始终提供缓存和记录器参数，即使用户希望使用默认值。 db.Open(addr, db.DefaultCache, zap.NewNop()) db.Open(addr, db.DefaultCache, log) db.Open(addr, false /* cache */, zap.NewNop()) db.Open(addr, false /* cache */, log) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // Good // package db type Option interface { // ... } func WithCache(c bool) Option { // ... } func WithLogger(log *zap.Logger) Option { // ... } // Open creates a connection. func Open( addr string, opts ...Option, ) (*Connection, error) { // ... } // 只有在需要时才提供选项。 db.Open(addr) db.Open(addr, db.WithLogger(log)) db.Open(addr, db.WithCache(false)) db.Open( addr, db.WithCache(false), db.WithLogger(log), ) 我们建议实现此模式的方法是使用一个 Option 接口，该接口保存一个未导出的方法，在一个未导出的 options 结构上记录选项。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 type options struct { cache bool logger *zap.Logger } type Option interface { apply(*options) } type cacheOption bool func (c cacheOption) apply(opts *options) { opts.cache = bool(c) } func WithCache(c bool) Option { return cacheOption(c) } type loggerOption struct { Log *zap.Logger } func (l loggerOption) apply(opts *options) { opts.logger = l.Log } func WithLogger(log *zap.Logger) Option { return loggerOption{Log: log} } // Open creates a connection. func Open( addr string, opts ...Option, ) (*Connection, error) { options := options{ cache: defaultCache, logger: zap.NewNop(), } for _, o := range opts { o.apply(\u0026amp;options) } // ... } 注意: 还有一种使用闭包实现这个模式的方法，但是我们相信上面的模式为作者提供了更多的灵活性，并且更容易对用户进行调试和测试。特别是，在不可能进行比较的情况下它允许在测试和模拟中对选项进行比较。此外，它还允许选项实现其他接口，包括 fmt.Stringer，允许用户读取选项的字符串表示形式。\n还可以参考下面资料：\nSelf-referential functions and the design of options Functional options for friendly APIs Linting 比任何 \u0026ldquo;blessed\u0026rdquo; linter 集更重要的是，lint在一个代码库中始终保持一致。\n我们建议至少使用以下linters，因为我认为它们有助于发现最常见的问题，并在不需要规定的情况下为代码质量建立一个高标准：\nerrcheck 以确保错误得到处理 goimports 格式化代码和管理 imports golint 指出常见的文体错误 govet 分析代码中的常见错误 staticcheck 各种静态分析检查 Lint Runners 我们推荐 golangci-lint 作为go-to lint的运行程序，这主要是因为它在较大的代码库中的性能以及能够同时配置和使用许多规范。这个repo有一个示例配置文件.golangci.yml和推荐的linter设置。\ngolangci-lint 有various-linters可供使用。建议将上述linters作为基本set，我们鼓励团队添加对他们的项目有意义的任何附加linters。\nvscode 如何集成 ?\nsettings.json\n1 2 \u0026#34;go.lintTool\u0026#34;: \u0026#34;golangci-lint\u0026#34;, \u0026#34;go.lintFlags\u0026#34;: [\u0026#34;--config=~/.golangci.yml\u0026#34;, \u0026#34;--fast\u0026#34;], 项目目录下创建 .golangci.yml 文件，配置说明\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 2021-06-05 # ixugo # options for analysis running run: timeout: 1m # 分析超时时间 issues-exit-code: 1 # 发现至少一个问题时退出代码 tests: true # 是否包含测试文件 modules-download-mode: readonly linters: enable: - errcheck # 以确保错误得到处理 - goimports # 格式化代码和管理 imports - golint # 指出常见的文体错误 - govet # 分析代码中的常见错误,例如数与格式字符串不对齐的 Printf 调用 - staticcheck # 各种静态分析检查 - deadcode # 未使用的代码 - unused # 未使用的常量/变量/函数/类型 - varcheck # 未使用的全局变量/常量 - funlen # 检查长函数，默认 60 行 40 条语句 - nestif # 深度嵌套的 if 语句 - unconvert # 不必要的类型转换 issues: exclude-use-default: false max-issues-per-linter: 0 max-same-issues: 0 ","date":"2021-06-24T00:00:00Z","permalink":"https://blog.golang.space/p/go-%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83/","title":"Go 编码规范"},{"content":"Go memory model 在程序处理期间从多个 Go 协程访问共享内存时。\n如果不阅读内存模型，可能对程序作出错误的假设，这会导致你的代码出问题。\n不要在共享内存中通信，要在通信中共享内存。\nGo 语言并发操作 Goroutines\n1 go hello() // 开启一个协程去执行，不用等待返回 Channels\n1 2 3 ch := make(chan int, 1) ch \u0026lt;- 10 // 发送值到通道 _ \u0026lt;- ch\t// 接收值 例如\n**创建一个 goroutine **\n1 2 3 4 5 6 7 8 9 var a string func f(){ print(a) } func hello(){ a = \u0026#34;hello，world\u0026#34; go f() } 使用 channel\n1 2 3 4 5 6 7 8 9 10 11 12 var c = make(chan int,1) var a string func f(){ a = \u0026#34;hello , world\u0026#34; c \u0026lt;- 0 // 或者 close(c) } func main(){ go f() \u0026lt;- c // 阻塞等待 print(a) } 使用 channel 限制函数同时执行数量\n1 2 3 4 5 6 7 8 9 10 11 var limit = make(chan int, 3) func main(){ func _,w := range work { go func(w func()){ limit \u0026lt;- 1 w() \u0026lt;-limit }(w) } select{} } 使用 once 保证在多个 goroutine 中仅初始化一次\n1 2 3 4 5 6 7 8 9 var a string var once sync.Once func main(){ once.Do(func(){ a = \u0026#34;hello, world\u0026#34; }) print(a) } 不适用锁 / 使用锁 / 使用 channel 三者区别\ninit 初始化 如果包 X 导入包 Y，则 Y 的 init 函数在运行 X 的 init 函数之前。\nMain 函数的开始是在所有 init 函数之后。\n参考 Go 官方内存模型文档\n","date":"2021-05-03T00:00:00Z","permalink":"https://blog.golang.space/p/go-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","title":"Go 内存模型"},{"content":" 思考一下，为什么 Go 语言只提供了 array，slice 和 map 给我们用，为什么没有提供 栈，队列，堆等?\n怎样高效的处理数据 ? 怎样写出清晰易懂的代码? 怎样才能把代码所引发的开销给强调出来?\nCPU 缓存 CPU 一般有三级缓存和主内存。l1 \u0026gt; l2 \u0026gt; l3 \u0026gt; 主内存，访问速度是越来越慢的，内存空间是越来越大。\n一个缓存行的长度，访问缓存行中的其他元素，基本是免费的。昂贵的是访问一个新的缓存，只有我们访问更少的缓存行时，我们的程序会更高效。\n当下的高速缓存行是 32 或 64 字节宽，具体取决于硬件。硬件喜欢沿着缓存线线性遍历数据和指令。\n切片：直达缓存友好的性能\n数组 应该培养一种特质，知道自己正在做什么，搞清楚为什么这样做，这样做的道理和效果，这样可以做出更好的设计决策。\nGo 语言中数组的各个元素地址是连续的，更符合 CPU 预测，使用数组的程序会更快。\nCPU 有三级缓存，为了更快，当你读取数据的时候，它会预测你接下来要读什么，提前放入缓存中。\n1 2 3 4 // 指针语义遍历 for i := range arr { total += arr[i] } 1 2 3 4 // 值语义遍历 for _,v := range arr{ total += v } 切片 这将是你的首选数据结构。除非你真能确定自己遇到特殊情况，需要用到链表等结构，否则还是应该优先考虑使用切片。而且要尽可能使用由值构成的切片，而不是由指针构成的切片。\n使用 make 创建，这是 Go 语言内置函数，让我们可以创建出 3 种引用类型。\n目前我们用到的类型分钟为两种:\n内置类型 结构体类型(用户自定义) 引用类型 ( slice / map / channel / 函数 / 接口 )。这是带有指针的数据结构，如果将该类型变量设置零值，相当于 nil，好比指针设置为 nil。字符串实际很接近于引用类型，但是零值是空串，而不是 nil，所以不能归类到引用类型。 slice 跟 字符串的结构有点像，但是 slice 比 字符串多一个 cap 字段，表示切片容量。\n长度和容量有什么区别呢?\n长度表示从当前位置开始，可能访问多少个元素。\n容量表示将来有可能增加到多少个元素，为考虑以后的扩充而设计。\n如果访问超过切片长度的内容，会发生 runtime error。\n1 2 3 4 5 type slice struct{ array unsafe.Pointer len int cap int } 这个结构作为函数参数传递时，非常高效。 数组会将每一个元素拷贝，而切片只会拷贝这样一个结构，占用 24 字节。切片本来就应该采用值语义操作，本来就应该留在使用它的那个栈里。\n1 2 3 func inspectSlice(slice []string) { fmt.Printf(\u0026#34;length[%d] capacity[%d]\\n\u0026#34;, len(slice),cap(slice)) } 切片结构中 array 是数组指针，意味着通过修改切片会产生副作用。\nnil slice，empty slice 与 nil Go 语言可以通过 nil 与 empty 来表达式不同的意思 你可以返回零值切片来表示错误 empty 切片可以表示顺利，但是没有数据\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func TestNilSlice(t *testing.T) { // 声明未赋值的零值切片 slice == nil var nilSlice []string require.Nil(t, nilSlice) // 声明赋值的空切片 slice != nil emptySlice := []string{} require.NotNil(t, emptySlice) require.Nil(t, nilSliceF()) require.NotNil(t, emptySliceF()) } func nilSliceF() []string { return nil } func emptySliceF() []string { return make([]string, 0) } 零分配的空白结构体 可以根据这样的结构体，创建上百万个值，但不会引发任何分配。\n因为在运行时环境里面，有一个 8 字节的固定值，它就像一个全局变量一样，可以让这种空白的结构体引用。所以无论有多少个空白结构体，它们都可以指向这同一个地址。\n比如 nil slice 里面的指针，就是指向这个空白结构体。\n1 var emptyStruct struct{} 扩容 如果提前知道需要多少容量，在创建时指定，这能减少需要扩容时的内存分配。这是非常高效的!! 即想要写出高效的代码，避免使用 append函数，直接操作对应位置的元素。\n但有可能我们并不知道到底需要操作多少数据，可能是 0 或更多，没办法提前把数组分配出来，即便分配了也可能浪费。为了尽量降低程序消耗的资源量，我们可能要稍微损耗一点性能，这样做，跟真正有可能影响性能的地方相比，这种损耗算不了什么。这时，只好从 nil slice 开始。\n1 var data []string 通过 append 扩容，将新数据添加到切片的尾部。注意其调用方式，这个函数的 API 用的是值语义，这是很好的设计。这样的 API 可以叫做通过 值语义 进行修改的 API。它通过对我们传入的切片值复制，在副本上做修改，并返回。这很重要，将修改效果隔离起来，无副作用。这是一种优雅，安全而又清晰的做法。\n1 data = append(data, \u0026#34;value\u0026#34;) append 会导致内存泄漏吗?\n如果资源不释放，在内存里滚雪球慢慢增大，这就是内存泄漏了。可以通过 Go trace 工具检查，检查 GC 后内存是否并没有减少，而是增大。\n典型的内存泄漏:\n是否每个 goroutine 无法自行终止，持有的引用无法释放。 map 只添加数据，因未清理而一直膨胀。 某些 API 用完后需要主动 close，但却忘记调用。 append 的返回值未赋给充当参数的变量，原有支持结构的引用数量未清零。 当切片的 len 和 cap 相同时，此时调用 append 会创建一个容量翻倍的支撑数组，然后将原数组和参数复制过去，让切片的指针指向新的数组。\n扩容规则是什么?\n查看源码 ，注意要区分 1.18 版本 和 小于其的版本\n1.18 开始\n所需容量大于容量翻倍，预估容量等于所需容量 否则 \u0026lt; 256 时，2倍扩容 从 2 倍扩容到 1.25 倍平滑过度扩容，公式: newcap += (newcap + 3*256) / 4 最后，匹配内存规格，公式为 8 * (2*x)，x 为递增变量。 \u0026lt;= 1.17 以前是，仅作为了解。\n所需容量大于容量翻倍，预估容量等于所需容量 否则 \u0026lt; 1024 时，双倍扩容 \u0026gt;= 1024 时，1.25 倍扩容 最后，匹配内存规格。 切片的高效操作 1 2 slice1 := make([]string,5,8) slice2 := slice1[2:2+2] // 从 2 开始，取两个值 上面的写法，可以高效的创建出新的切片值，而且新值和原值可以高效的共享同一个支撑数组。这意味着需要分配在堆上面的至多只有原来的那个支撑数组。\n注意，通过 append 对 slice2 添加元素，会影响到 slice1。因为上面提到的是同一个支撑数组。\n1 slice2 := slice1[2:4:4] // 从 2 开始，取两个值。容量为 2。 在创建新切片值时，可以指定容量与长度相等，此时使用 append 会创建一个新的数组，并将旧数组值复制过去，这样就消除了上面的副作用。三下标制作切片的方法，让你既可以在尾部追加元素，同时又不会影响使用原来那个支持数组的其它切片。这样当然很棒，但有时候，可能需要自己复制，当然还是应该尽量少用复制操作。\nGo 语言提供了内置函数copy ，它能够将源切片中的元素复制到目标切片。\n1 2 slice3 := make([]string,len(slice1)) copy(slice3,slice1) 函数式编程 如果不注意防范副作用，那么可能会产生想当危险的结果。通过指针操纵切片时，修改的是切片的支持数组所在的内存，这当然会让程序写起来困难一些。假如使用函数式编程，就不用担心这种问题了。\n函数式编程，所有内容都通过值语义来操纵，每一段代码每一个函数，操纵的都是它自己的那份数据。可是这样，就不能根据需要把程序速度优化到最快，这提现了 Go 语言的一项优势，它让我们自己决定，是操纵数值还是指针。\n必须注意，采用指针语义操作，必须当心这种做法在修改数据时，是否会引发什么问题。\n1 2 3 4 5 6 // Bad likes := make([]int,3) u1 := \u0026amp;likes[1] // 控制 u1 指针来修改数据 // 如果 likes 发生 append 扩容，u1 修改是旧数据，且因为旧数组被引用，而无法释放。 // 必须反复检查调用 append 函数的地方，避免支撑数组发生替换，进而给程序带来副作用 字符串和切片 字符串归根结底还是由一系列字节组成，最底层是字节，中间一层叫做代码点，每个代码点都可以当做一个 32 位(4 字节)值，在代码点上方是字符层。代码点有可能1 个字节就能表示，也可能需要 4 个字节才能表示。\n汉字需要 3 个字节 英文字母需要 1 个字节。 字符串可以用 for range 来遍历，遍历的是代码点，string(v) 可以将代码点转为字符。值遍历 v 是 rune 类型，这个类型并不是真正的类型，而是 int32 的别名，实际上，byte 类型是 uint8 的别名。\n对字符串切片操作，要小心不同字符的长度。可以转为[]rune 切片来处理。\nfor range for range 是值语义，也就是遍历拷贝的副本。在遍历中操作切片不影响遍历。这样的写法一个切片发生变化，不会影响到使用另一个切片所涉及的程序。\n1 2 3 4 // 值语义，不影响 for _,v := range slice1 { slice1 = slice1[:2] } 是指针语义时，它访问的就是原来的切片，如下面的代码，可能会发生数组下标溢出。\n1 2 3 for i := range slice1{ slice1 = slice1[:2] } ","date":"2021-05-03T00:00:00Z","permalink":"https://blog.golang.space/p/go-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","title":"Go 内存模型"},{"content":"React Hook useState 使用 useState 声明变量, 及修改状态\n1 2 3 4 5 6 7 function ExampleWithManyStates() { // 声明多个 state 变量！ const [age, setAge] = useState(42); const [fruit, setFruit] = useState(\u0026#39;banana\u0026#39;); const [todos, setTodos] = useState([{ text: \u0026#39;Learn Hooks\u0026#39; }]); // ... } 不刷新的对象合并\n1 Object.assign(obj,{\u0026#34;name\u0026#34;:\u0026#34;list\u0026#34;}) 刷新的对象合并\n1 setObj({...obj,name:\u0026#34;list\u0026#34;}) useEffect 告诉 React 在完成对 DOM 的更改后运行你的“副作用”函数。\n默认情况下，React 会在每次渲染后调用副作用函数 ——包括第一次渲染的时候。\n1 2 3 4 5 6 const [count, setCount] = useState(0); // 相当于 componentDidMount 和 componentDidUpdate: useEffect(() =\u0026gt; { // 使用浏览器的 API 更新页面标题 document.title = `You clicked ${count} times`; }); 仅仅执行第一次 加一个 空数组即可\n1 useEffect(()=\u0026gt;{} , []) 不写数组监听所有状态 写入参数, 监听参数状态 空数组, 仅首次渲染执行 第一个参数函数中加返回值, 销毁时执行 1 2 3 4 userEffect( ()=\u0026gt;{ // 渲染后执行 return ()=\u0026gt;{} } ) useRef 获取 dom 元素\n1 2 3 4 5 6 const inputEl = useRef(null) \u0026lt;Input inputRef={inputEl} /\u0026gt; inputEl.current 当前元素 inputEl.current.value 值 useContext 与 createContext 1 2 3 4 5 const MyContext = createContext() \u0026lt;MyContext.Provider value={count}\u0026gt; \u0026lt;child\u0026gt;\u0026lt;/child\u0026gt; \u0026lt;/MyContext.Provider\u0026gt; 父组件刷新，子组件不会刷新\n通过子组件监听 props ，重新加载数据，达到刷新的目的\n","date":"2021-04-10T15:00:00Z","permalink":"https://blog.golang.space/p/react-hook/","title":"React Hook"},{"content":"从开源项目学习优雅的关闭 HTTP 服务 服务器难免遇到重启，升级等问题。\n当服务器关闭的时候，为了避免服务突然中断，产生的不可控和冗余数据，需要有以下考虑。\n摘掉流量，通过网关或负载均衡控制 服务拒绝新的请求 等待处理中的请求结束 如果上一步超时，强制关闭 释放资源 关闭服务 强制关闭，比如多次退出信号 实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 package httpserver import ( \u0026#34;context\u0026#34; \u0026#34;net\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) const ( defaultReadTimeout = 10 * time.Second defaultWriteTimeout = 10 * time.Second defaultAddr = \u0026#34;:8080\u0026#34; defaultShutdownTimeout = 3 * time.Second ) // Server HTTP 服务 type Server struct { server *http.Server notify chan error shutdownTimeout time.Duration } // NewServer 初始化并启动路由 func NewServer(handler http.Handler, opts ...Option) *Server { httpSer := http.Server{ Addr: defaultAddr, Handler: handler, ReadTimeout: defaultReadTimeout, WriteTimeout: defaultWriteTimeout, } s := \u0026amp;Server{ server: \u0026amp;httpSer, notify: make(chan error, 1), shutdownTimeout: defaultShutdownTimeout, } for _, opt := range opts { opt(s) } go s.start() return s } func (s *Server) start() { s.notify \u0026lt;- s.server.ListenAndServe() close(s.notify) } // Notify . func (s *Server) Notify() \u0026lt;-chan error { return s.notify } // Shutdown 关闭服务 func (s *Server) Shutdown() error { ctx, cancel := context.WithTimeout(context.Background(), s.shutdownTimeout) defer cancel() return s.server.Shutdown(ctx) } // Option 修改 server 相关参数 type Option func(*Server) // Port 修改端口 func Port(v string) Option { return func(s *Server) { s.server.Addr = net.JoinHostPort(\u0026#34;\u0026#34;, v) } } 使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func main(){ handler := gin.New() server := httpserver.New(handler) interrupt := make(chan os.Signal, 1) signal.Notify(interrupt, os.Interrupt, syscall.SIGTERM) // 等待信号 select { case s := \u0026lt;-interrupt: fmt.Println(\u0026#34;app - Run - signal: \u0026#34; + s.String()) case err = \u0026lt;-httpServer.Notify(): fmt.Printf(\u0026#34;app - Run - httpServer.Notify: %w\u0026#34;, err) } // 关闭 err = httpServer.Shutdown() if err != nil { fmt.Printf(\u0026#34;app - Run - httpServer.Shutdown: %w\u0026#34;, err) } } 参考 go-clean-template\n","date":"2021-03-22T00:00:00Z","permalink":"https://blog.golang.space/p/%E4%BB%8E%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0%E4%BC%98%E9%9B%85%E7%9A%84%E5%85%B3%E9%97%AD-http-%E6%9C%8D%E5%8A%A1/","title":"从开源项目学习优雅的关闭 HTTP 服务"},{"content":"zerolog 什么是 Zerolog ? zerolog 包提供了一个专门用于 JSON 输出的简单快速的Logger。\nzerolog 的 API 旨在为开发者提供出色的体验和令人惊叹的性能。其独特的链式 API 允许通过避免内存分配和反射来写入 JSON ( 或 CBOR ) 日志。\nuber 的 zap 库开创了这种方法，zerolog 通过更简单的应用编程接口和更好的性能，将这一概念提升到了更高的层次。\n使用 zerolog 安装 1 go get -u github.com/rs/zerolog/log Contextual Logger 1 2 3 4 5 6 7 8 9 func TestContextualLogger(t *testing.T) { log := zerolog.New(os.Stdout) log.Info().Str(\u0026#34;content\u0026#34;, \u0026#34;Hello world\u0026#34;).Int(\u0026#34;count\u0026#34;, 3).Msg(\u0026#34;TestContextualLogger\u0026#34;) // 添加上下文 (文件名/行号/字符串) log = log.With().Caller().Str(\u0026#34;foo\u0026#34;, \u0026#34;bar\u0026#34;).Logger() log.Info().Msg(\u0026#34;Hello wrold\u0026#34;) } 输出\n1 2 // {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;content\u0026#34;:\u0026#34;Hello world\u0026#34;,\u0026#34;count\u0026#34;:3,\u0026#34;message\u0026#34;:\u0026#34;TestContextualLogger\u0026#34;} // {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;caller\u0026#34;:\u0026#34;log_example_test.go:29\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;Hello wrold\u0026#34;} 与 zap 相同的是，都定义了强类型字段，你可以在这里找到支持字段的完整列表。\n与 zap 不同的是，zerolog 采用链式调用。\n多级Logger zerolog 提供了从 Trace 到 Panic 七个级别\n1 2 3 4 5 6 7 8 // 设置日志级别 zerolog.SetGlobalLevel(zerolog.WarnLevel) log.Trace().Msg(\u0026#34;Trace\u0026#34;) log.Debug().Msg(\u0026#34;Debug\u0026#34;) log.Info().Msg(\u0026#34;Info\u0026#34;) log.Warn().Msg(\u0026#34;Warn\u0026#34;) log.Error().Msg(\u0026#34;Error\u0026#34;) log.Log().Msg(\u0026#34;没有级别\u0026#34;) 输出\n1 2 3 {\u0026#34;level\u0026#34;:\u0026#34;warn\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;Warn\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;Error\u0026#34;} {\u0026#34;message\u0026#34;:\u0026#34;没有级别\u0026#34;} 注意事项 1.zerolog 不会对重复的字段删除\n1 2 3 4 logger := zerolog.New(os.Stderr).With().Timestamp().Logger() logger.Info(). Timestamp(). Msg(\u0026#34;dup\u0026#34;) 输出\n1 {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;time\u0026#34;:1494567715,\u0026#34;time\u0026#34;:1494567715,\u0026#34;message\u0026#34;:\u0026#34;dup\u0026#34;} 2.链式调用必须调用 Msg 或 Msgf，Send 才能输出日志，Send 相当于调用 Msg(\u0026quot;\u0026quot;)\n3.一旦调用 Msg ，Event 将会被处理 ( 放回池中或丢掉 )，不允许二次调用。\n了解源码 本次zerolog的源码分析基于 zerolog 1.22.0 版本，源码分析较长，希望大家耐心看完。希望大家能有所收获。\n看一下 Logger 结构体 Logger 的参数 w 类型是 LevelWriter 接口，用于向目标输出事件。zerolog.New 函数用来创建 Logger，看下方源码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // ============ log.go === type Logger struct { w LevelWriter // 输出对象 level Level // 日志级别 sampler Sampler // 采样器 context []byte // 存储上下文 hooks []Hook stack bool } func New(w io.Writer) Logger { if w == nil { // ioutil.Discard 所有成功执行的 Write 操作都不会产生任何实际的效果 w = ioutil.Discard } lw, ok := w.(LevelWriter) // 传入的不是 LevelWriter 类型，封装成此类型 if !ok { lw = levelWriterAdapter{w} } // 默认输出日志级别 TraceLevel return Logger{w: lw, level: TraceLevel} } debug 了解输出日志流程 如上图所示，在第三行打上断点。\n下图表示该行代码执行流程。\n开始 debug\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // ============ log.go === // Info 开始记录一条 info 级别的消息 // 你必须在返回的 *Event 上调用 Msg 才能发送事件 func (l *Logger) Info() *Event { return l.newEvent(InfoLevel, nil) } func (l *Logger) newEvent(level Level, done func(string)) *Event { // 判断是否应该记录的级别 enabled := l.should(level) if !enabled { return nil } // 创建记录日志的对象 e := newEvent(l.w, level) // 设置 done 函数 e.done = done // 设置 hook 函数 e.ch = l.hooks // 记录日志级别 if level != NoLevel \u0026amp;\u0026amp; LevelFieldName != \u0026#34;\u0026#34; { e.Str(LevelFieldName, LevelFieldMarshalFunc(level)) } // 记录上下文 if l.context != nil \u0026amp;\u0026amp; len(l.context) \u0026gt; 1 { e.buf = enc.AppendObjectData(e.buf, l.context) } // 堆栈跟踪 if l.stack { e.Stack() } return e } should 函数用于判断是否需要记录本次消息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 // ============ log.go === // should 如果应该被记录，则返回 true func (l *Logger) should(lvl Level) bool { if lvl \u0026lt; l.level || lvl \u0026lt; GlobalLevel() { return false } // 采样后面讲 if l.sampler != nil \u0026amp;\u0026amp; !samplingDisabled() { return l.sampler.Sample(lvl) } return true } newEvent 函数使用 sync.Pool 获取Event对象，并将 Event 参数初始化：日志级别level和写入对象LevelWriter。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 // ============ event.go === // 表示一个日志事件 type Event struct { buf []byte\t// 消息 w LevelWriter // 待写入的目标接口 level Level\t// 日志级别 done func(msg string)\t// msg 函数结束事件 stack bool // 错误堆栈跟踪 ch []Hook\t// hook 函数组 skipFrame int } func newEvent(w LevelWriter, level Level) *Event { e := eventPool.Get().(*Event) e.buf = e.buf[:0] e.ch = nil // 在开始添加左大括号 \u0026#39;{\u0026#39; e.buf = enc.AppendBeginMarker(e.buf) e.w = w e.level = level e.stack = false e.skipFrame = 0 return e } Str 函数是负责将键值对添加到 buf，字符串类型添加到 JSON 格式，涉及到特殊字符编码问题，如果是特殊字符，调用 appendStringComplex 函数解决。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // ============ event.go === func (e *Event) Str(key, val string) *Event { if e == nil { return e } e.buf = enc.AppendString(enc.AppendKey(e.buf, key), val) return e } // ============ internal/json/base.go === type Encoder struct{} // 添加一个新 key func (e Encoder) AppendKey(dst []byte, key string) []byte { // 非第一个参数，加个逗号 if dst[len(dst)-1] != \u0026#39;{\u0026#39; { dst = append(dst, \u0026#39;,\u0026#39;) } return append(e.AppendString(dst, key), \u0026#39;:\u0026#39;) } // === internal/json/string.go === func (Encoder) AppendString(dst []byte, s string) []byte { // 双引号起 dst = append(dst, \u0026#39;\u0026#34;\u0026#39;) // 遍历字符 for i := 0; i \u0026lt; len(s); i++ { // 检查字符是否需要编码 if !noEscapeTable[s[i]] { dst = appendStringComplex(dst, s, i) return append(dst, \u0026#39;\u0026#34;\u0026#39;) } } // 不需要编码的字符串，添加到 dst dst = append(dst, s...) // 双引号收 return append(dst, \u0026#39;\u0026#34;\u0026#39;) } Int 函数将键值(int类型)对添加到 buf，内部调用 strconv.AppendInt 函数实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // ============ event.go === func (e *Event) Int(key string, i int) *Event { if e == nil { return e } e.buf = enc.AppendInt(enc.AppendKey(e.buf, key), i) return e } // === internal/json/types.go === func (Encoder) AppendInt(dst []byte, val int) []byte { // 添加整数 return strconv.AppendInt(dst, int64(val), 10) } Msg 函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 // === event.go === // Msg 是对 msg 的封装调用，当指针接收器为 nil 返回 func (e *Event) Msg(msg string) { if e == nil { return } e.msg(msg) } // msg func (e *Event) msg(msg string) { // 运行 hook for _, hook := range e.ch { hook.Run(e, e.level, msg) } // 记录消息 if msg != \u0026#34;\u0026#34; { e.buf = enc.AppendString(enc.AppendKey(e.buf, MessageFieldName), msg) } // 判断不为 nil，则使用 defer 调用 done 函数 if e.done != nil { defer e.done(msg) } // 写入日志 if err := e.write(); err != nil { if ErrorHandler != nil { ErrorHandler(err) } else { fmt.Fprintf(os.Stderr, \u0026#34;zerolog: could not write event: %v\\n\u0026#34;, err) } } } // 写入日志 func (e *Event) write() (err error) { if e == nil { return nil } if e.level != Disabled { // 大括号收尾 e.buf = enc.AppendEndMarker(e.buf) // 换行 e.buf = enc.AppendLineBreak(e.buf) // 向目标写入日志 if e.w != nil { // 这里传递的日志级别，函数内并没有使用 _, err = e.w.WriteLevel(e.level, e.buf) } } // 将对象放回池中 putEvent(e) return } // === writer.go === func (lw levelWriterAdapter) WriteLevel(l Level, p []byte) (n int, err error) { return lw.Write(p) } 以上 debug 让我们对日志记录流程有了大概的认识，接下来扩充一下相关知识。\n从 zerolog 学习避免内存分配 每一条日志都会产生一个 *Event对象 ，当多个 Goroutine 操作日志，导致创建的对象数目剧增，进而导致 GC 压力增大。形成 \u0026ldquo;并发大 - 占用内存大 - GC 缓慢 - 处理并发能力降低 - 并发更大\u0026rdquo; 这样的恶性循环。在这个时候，需要有一个对象池，程序不再自己单独创建对象，而是从对象池中获取。\n使用 sync.Pool 可以将暂时不用的对象缓存起来，下次需要的时候从池中取，不用再次经过内存分配。\n下面代码中 putEvent 函数，当对象中记录消息的 buf 不超过 64KB 时，放回池中。这里有个链接，通过这个 issue 23199了解到使用动态增长的 buffer 会导致大量内存被固定，在活锁的情况下永远不会释放。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 var eventPool = \u0026amp;sync.Pool{ New: func() interface{} { return \u0026amp;Event{ buf: make([]byte, 0, 500), } }, } func putEvent(e *Event) { // 选择占用较小内存的 buf，将对象放回池中 // See https://golang.org/issue/23199 const maxSize = 1 \u0026lt;\u0026lt; 16 // 64KiB if cap(e.buf) \u0026gt; maxSize { return } eventPool.Put(e) } 学习日志级别 下面代码中，包含了日志级别类型的定义，日志级别对应的字符串值，获取字符串值的方法以及解析字符串为日志级别类型的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 // ============= log.go === // 日志级别类型 type Level int8 // 定义所有日志级别 const ( DebugLevel Level = iota InfoLevel WarnLevel ErrorLevel FatalLevel PanicLevel NoLevel Disabled TraceLevel Level = -1 ) // 返回当前级别的 value func (l Level) String() string { switch l { case TraceLevel: return LevelTraceValue case DebugLevel: return LevelDebugValue case InfoLevel: return LevelInfoValue case WarnLevel: return LevelWarnValue case ErrorLevel: return LevelErrorValue case FatalLevel: return LevelFatalValue case PanicLevel: return LevelPanicValue case Disabled: return \u0026#34;disabled\u0026#34; case NoLevel: return \u0026#34;\u0026#34; } return \u0026#34;\u0026#34; } // ParseLevel 将级别字符串解析成 zerolog level value // 当字符串不匹配任何已知级别，返回错误 func ParseLevel(levelStr string) (Level, error) { switch levelStr { case LevelFieldMarshalFunc(TraceLevel): return TraceLevel, nil case LevelFieldMarshalFunc(DebugLevel): return DebugLevel, nil case LevelFieldMarshalFunc(InfoLevel): return InfoLevel, nil case LevelFieldMarshalFunc(WarnLevel): return WarnLevel, nil case LevelFieldMarshalFunc(ErrorLevel): return ErrorLevel, nil case LevelFieldMarshalFunc(FatalLevel): return FatalLevel, nil case LevelFieldMarshalFunc(PanicLevel): return PanicLevel, nil case LevelFieldMarshalFunc(Disabled): return Disabled, nil case LevelFieldMarshalFunc(NoLevel): return NoLevel, nil } return NoLevel, fmt.Errorf(\u0026#34;Unknown Level String: \u0026#39;%s\u0026#39;, defaulting to NoLevel\u0026#34;, levelStr) } // ============= globals.go === var ( // ...... // 级别字段的 key 名称 LevelFieldName = \u0026#34;level\u0026#34; // 各个级别的 value LevelTraceValue = \u0026#34;trace\u0026#34; LevelDebugValue = \u0026#34;debug\u0026#34; LevelInfoValue = \u0026#34;info\u0026#34; LevelWarnValue = \u0026#34;warn\u0026#34; LevelErrorValue = \u0026#34;error\u0026#34; LevelFatalValue = \u0026#34;fatal\u0026#34; LevelPanicValue = \u0026#34;panic\u0026#34; // 返回形参级别的 value LevelFieldMarshalFunc = func(l Level) string { return l.String() } // ...... ) 全局日志级别参数\n这里使用 atomic 来保证原子操作，要么都执行，要么都不执行，外界不会看到只执行到一半的状态，原子操作由底层硬件支持，通常比锁更有效率。\natomic.StoreInt32 用于存储 int32 类型的值。\natomic.LoadInt32 用于读取 int32 类型的值。\n在源码中，做级别判断时，多处调用 GlobalLevel 以保证并发安全。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // ============= globals.go === var ( gLevel = new(int32) // ...... ) // SetGlobalLevel 设置全局日志级别 // 要全局禁用日志，入参为 Disabled func SetGlobalLevel(l Level) { atomic.StoreInt32(gLevel, int32(l)) } // 返回当前全局日志级别 func GlobalLevel() Level { return Level(atomic.LoadInt32(gLevel)) } 学习如何实现 Hook 首先定义 Hook 接口，内部有一个 Run 函数，入参包含 Event，日志级别*level和消息 ( Msg 函数的参数 )。\n然后定义了 LevelHook 结构体，用于为每个级别设置 Hook 。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 // ============= hook.go === // hook 接口 type Hook interface { Run(e *Event, level Level, message string) } // HookFunc 函数适配器 type HookFunc func(e *Event, level Level, message string) // Run 实现 Hook 接口. func (h HookFunc) Run(e *Event, level Level, message string) { h(e, level, message) } // 为每个级别应用不同的 hook type LevelHook struct { NoLevelHook, TraceHook, DebugHook, InfoHook, WarnHook, ErrorHook, FatalHook, PanicHook Hook } // Run 实现 Hook 接口 func (h LevelHook) Run(e *Event, level Level, message string) { switch level { case TraceLevel: if h.TraceHook != nil { h.TraceHook.Run(e, level, message) } case DebugLevel: if h.DebugHook != nil { h.DebugHook.Run(e, level, message) } case InfoLevel: if h.InfoHook != nil { h.InfoHook.Run(e, level, message) } case WarnLevel: if h.WarnHook != nil { h.WarnHook.Run(e, level, message) } case ErrorLevel: if h.ErrorHook != nil { h.ErrorHook.Run(e, level, message) } case FatalLevel: if h.FatalHook != nil { h.FatalHook.Run(e, level, message) } case PanicLevel: if h.PanicHook != nil { h.PanicHook.Run(e, level, message) } case NoLevel: if h.NoLevelHook != nil { h.NoLevelHook.Run(e, level, message) } } } // NewLevelHook 创建一个 LevelHook func NewLevelHook() LevelHook { return LevelHook{} } 在源码中是如何使用的?\n定义 PrintMsgHook 结构体并实现 Hook 接口，作为参数传递给 log.Hook 函数，Logger 内部的 hooks 参数用来保存对象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 使用案例 type PrintMsgHook struct{} // 实现 Hook 接口，用来向控制台输出 msg func (p PrintMsgHook) Run(e *zerolog.Event, l zerolog.Level, msg string) { fmt.Println(msg) } func TestContextualLogger(t *testing.T) { log := zerolog.New(os.Stdout) log = log.Hook(PrintMsgHook{}) log.Info().Msg(\u0026#34;TestContextualLogger\u0026#34;) } 添加 hook 源码如下\n1 2 3 4 5 6 7 // ============ log.go === // Hook 返回一个带有 hook 的 Logger func (l Logger) Hook(h Hook) Logger { l.hooks = append(l.hooks, h) return l } 输出日志必须调用 msg 函数，hook 将在此函数的开头执行。\n1 2 3 4 5 6 7 8 9 10 11 // ============ event.go === // msg 函数用来运行 hook func (e *Event) msg(msg string) { for _, hook := range e.ch { hook.Run(e, e.level, msg) } // ....... // 写入日志，此函数上面已经介绍过，此处省略 // ....... } 学习如何得到调用者函数名 在看 zerolog 源码之前，需要知道一些关于 runtime.Caller 函数的前置知识，\nruntime.Caller 可以获取相关调用 goroutine 堆栈上的函数调用的文件和行号信息。\n参数skip 是堆栈帧的数量，当 skip=0 时，输出当前函数信息; 当 skip=1 时，输出调用栈上一帧，即调用函数者的信息。\n返回值为 程序计数器，文件位置，行号，是否能恢复信息\n1 2 3 4 5 6 7 8 9 10 11 // ============ go@1.16.5 runtime/extern.go === func Caller(skip int) (pc uintptr, file string, line int, ok bool) { rpc := make([]uintptr, 1) n := callers(skip+1, rpc[:]) if n \u0026lt; 1 { return } frame, _ := CallersFrames(rpc).Next() return frame.PC, frame.File, frame.Line, frame.PC != 0 } 再看 zerolog 源码，定义 callerHook 结构体并实现了 Hook 接口，实现函数中调用了参数 *Event 提供的 caller 函数。\n其中入参为预定义参数 CallerSkipFrameCount 和 contextCallerSkipFrameCount ，值都为 2。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // ============ context.go === type callerHook struct { callerSkipFrameCount int } func newCallerHook(skipFrameCount int) callerHook { return callerHook{callerSkipFrameCount: skipFrameCount} } func (ch callerHook) Run(e *Event, level Level, msg string) { switch ch.callerSkipFrameCount { // useGlobalSkipFrameCount 是 int32 类型最小值 case useGlobalSkipFrameCount: // CallerSkipFrameCount 预定义全局变量，值为 2 // contextCallerSkipFrameCount 预定义变量，值为 2 e.caller(CallerSkipFrameCount + contextCallerSkipFrameCount) default: e.caller(ch.callerSkipFrameCount + contextCallerSkipFrameCount) } } // useGlobalSkipFrameCount 值:-2147483648 const useGlobalSkipFrameCount = math.MinInt32 // 创建默认 callerHook var ch = newCallerHook(useGlobalSkipFrameCount) // Caller 为 Logger 添加 hook ，该 hook 用于记录函数调用者的 file:line func (c Context) Caller() Context { c.l = c.l.Hook(ch) return c } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // ============ event.go === func (e *Event) caller(skip int) *Event { if e == nil { return e } _, file, line, ok := runtime.Caller(skip + e.skipFrame) if !ok { return e } // CallerFieldName是默认的 key 名 // CallerMarshalFunc 函数用于拼接 file:line e.buf = enc.AppendString(enc.AppendKey(e.buf, CallerFieldName), CallerMarshalFunc(file, line)) return e } 从日志采样中学习 atomic 这个使用案例中，TestSample 每秒允许 记录5 条消息，超过则每 20 条仅记录一条\n1 2 3 4 5 6 7 8 9 10 func TestSample(t *testing.T) { sampled := log.Sample(\u0026amp;zerolog.BurstSampler{ Burst: 5, Period: 1 * time.Second, NextSampler: \u0026amp;zerolog.BasicSampler{N: 20}, }) for i := 0; i \u0026lt;= 50; i++ { sampled.Info().Msgf(\u0026#34;logged messages : %2d \u0026#34;, i) } } 输出结果本来应该输出 50 条日志，使用了采样，在一秒内输出最大 5 条日志，当大于 5 条后，每 20 条日志输出一次。\n采样的流程示意图如下\n下方是定义采样接口及实现函数的源码。\n在 inc 函数中，使用 atomic 包将竞争的接收器对象的参数变成局部变量，是学习 atomic 很好的实例。函数说明都写在注释里。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 // =========== sampler.go === // 采样器接口 type Sampler interface { // 如果事件是样本的一部分返回 true Sample(lvl Level) bool } // BasicSampler 基本采样器 // 每 N 个事件发送一次，不考虑日志级别 type BasicSampler struct { N counter uint32 } // 实现采样器接口 func (s *BasicSampler) Sample(lvl Level) bool { n := s.N if n == 1 { return true } c := atomic.AddUint32(\u0026amp;s.counter, 1) return c%n == 1 } type BurstSampler struct { // 调用 NextSampler 之前每个时间段(Period)调用的最大事件数量 Burst uint32 // 如果为 0，则始终调用 NextSampler Period time.Duration // 采样器 NextSampler Sampler // 用于计数在一定时间内(Period)的调用数量 counter uint32 // 时间段的结束时间(纳秒)，即 当前时间+Period resetAt int64 } // 实现 Sampler 接口 func (s *BurstSampler) Sample(lvl Level) bool { // 当设置了 Burst 和 Period，大于零时限制 一定时间内的最大事件数量 if s.Burst \u0026gt; 0 \u0026amp;\u0026amp; s.Period \u0026gt; 0 { if s.inc() \u0026lt;= s.Burst { return true } } // 没有采样器，结束 if s.NextSampler == nil { return false } // 调用采样器 return s.NextSampler.Sample(lvl) } func (s *BurstSampler) inc() uint32 { // 当前时间 (纳秒) now := time.Now().UnixNano() // 重置时间 (纳秒) resetAt := atomic.LoadInt64(\u0026amp;s.resetAt) var c uint32 // 当前时间 \u0026gt; 重置时间 if now \u0026gt; resetAt { c = 1 // 重置 s.counter 为 1 atomic.StoreUint32(\u0026amp;s.counter, c) // 计算下一次的重置时间 newResetAt := now + s.Period.Nanoseconds() // 比较函数开头获取的重置时间与存储的时间是否相等 // 相等时，将下一次的重置时间存储到 s.resetAt，并返回 true reset := atomic.CompareAndSwapInt64(\u0026amp;s.resetAt, resetAt, newResetAt) if !reset { // 在上面比较赋值那一步没有抢到的 goroutine 计数器+1 c = atomic.AddUint32(\u0026amp;s.counter, 1) } } else { c = atomic.AddUint32(\u0026amp;s.counter, 1) } return c } 在代码中如何调用的呢?\nInfo 函数及其他级别函数都会调用 newEvent，在该函数的开头， should 函数用来判断是否需要记录的日志级别和采样。\n1 2 3 4 5 6 7 8 9 10 11 12 // ============ log.go === // should 如果应该被记录，则返回 true func (l *Logger) should(lvl Level) bool { if lvl \u0026lt; l.level || lvl \u0026lt; GlobalLevel() { return false } // 如果使用了采样，则调用采样函数，判断本次事件是否记录 if l.sampler != nil \u0026amp;\u0026amp; !samplingDisabled() { return l.sampler.Sample(lvl) } return true } Doc 关于更多zerolog的使用可以参考 https://pkg.go.dev/github.com/rs/zerolog\n比较 说明 : 以下资料来源于 zerolog 官方。从性能分析上zerolog比zap和其他logger库更胜一筹，关于zerolog和zap的使用，gopher可根据实际业务场景具体考量。\n记录 10 个 KV 字段的消息 :\nLibrary Time Bytes Allocated Objects Allocated zerolog 767 ns/op 552 B/op 6 allocs/op ⚡ zap 848 ns/op 704 B/op 2 allocs/op ⚡ zap (sugared) 1363 ns/op 1610 B/op 20 allocs/op go-kit 3614 ns/op 2895 B/op 66 allocs/op lion 5392 ns/op 5807 B/op 63 allocs/op logrus 5661 ns/op 6092 B/op 78 allocs/op apex/log 15332 ns/op 3832 B/op 65 allocs/op log15 20657 ns/op 5632 B/op 93 allocs/op 使用一个已经有 10 个 KV 字段的 logger 记录一条消息 :\nLibrary Time Bytes Allocated Objects Allocated zerolog 52 ns/op 0 B/op 0 allocs/op ⚡ zap 283 ns/op 0 B/op 0 allocs/op ⚡ zap (sugared) 337 ns/op 80 B/op 2 allocs/op lion 2702 ns/op 4074 B/op 38 allocs/op go-kit 3378 ns/op 3046 B/op 52 allocs/op logrus 4309 ns/op 4564 B/op 63 allocs/op apex/log 13456 ns/op 2898 B/op 51 allocs/op log15 14179 ns/op 2642 B/op 44 allocs/op 记录一个字符串，没有字段或 printf 风格的模板 :\nLibrary Time Bytes Allocated Objects Allocated zerolog 50 ns/op 0 B/op 0 allocs/op ⚡ zap 236 ns/op 0 B/op 0 allocs/op standard library 453 ns/op 80 B/op 2 allocs/op ⚡ zap (sugared) 337 ns/op 80 B/op 2 allocs/op go-kit 508 ns/op 656 B/op 13 allocs/op lion 771 ns/op 1224 B/op 10 allocs/op logrus 1244 ns/op 1505 B/op 27 allocs/op apex/log 2751 ns/op 584 B/op 11 allocs/op log15 5181 ns/op 1592 B/op 26 allocs/op 相似的库 logrus 功能强大\nzap 非常快速，结构化，分级\n参考资料 zerolog 官方文档\n","date":"2021-02-18T15:00:00Z","permalink":"https://blog.golang.space/p/%E4%BB%8E%E6%BA%90%E7%A0%81%E4%BA%86%E8%A7%A3-zerolog/","title":"从源码了解 zerolog"},{"content":"本文翻译自 https://ioshellboy.medium.com/circuit-breakers-in-golang-1779da9b001，由于本人翻译水平有限，翻译不当之处烦请指出。\nGo 中使用熔断器 当你看到 “熔断器” 这个术语时，你会想到什么呢?\n从图片字面意思理解是使用锤子破坏了一个电路。\n我们一般都会在自己家里安装熔断器，以阻止异常的电流从电网流向自己住宅。在开始“微服务的熔断器”之前，让我们先看看它是如何工作的。\n如上图所示，一个典型的熔断器装置有 2 个主要部件:\n用火线紧紧包裹的软铁芯 触体。只要接触点能够形成一个连接点，电流就会从外部电源流向我们的房子。相反，如果连接断开，电流就停止流动。 当电流通过缠绕在软铁芯周围的导线时，软铁芯就像一块电磁铁，当流过它的电流高于预期的安培时，电磁铁就会变得强大到足以吸引邻近的触点，从而导致短路。\n您一定在想，这与微服务架构有什么关系。在我看来，这是高度相关的，正如我们将要看到的！\n微服务架构中的级联故障 微服务架构已经很好地取代了单体架构，但是为了使我们的系统具有高度的弹性，我们还需要解决一些关键问题。\n微服务的一个问题是级联故障。举一个例子来更好地理解它。\n在上图中，参与者调用我们的主服务，它依赖于上游服务ー A，B，C。现在假定，服务 A 是一个读取量较大的系统，它依赖于数据库。这个数据库有其自身的局限性，并且在过载时，可能导致连接重置。这个问题不仅会影响服务 A 的性能，还会影响主服务，因为goroutine会继续等待它，从而记录线程池。\n这就是人们所说的“一个坏苹果糟蹋了整个桶”，喝了糟糕的果酒的人肯定会有同感。下面让我们用一个例子来验证这一点。\n让我们构建一个 Netflixisc 应用程序。其中一个微服务负责提供feed页面的电影服务。此服务还依赖于推荐服务为用户提供适当的推荐。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // Recommendation Service func main() { logGoroutines() http.HandleFunc(\u0026#34;/recommendations\u0026#34;, recoHandler) log.Fatal(http.ListenAndServe(\u0026#34;:9090\u0026#34;, nil)) } func logGoroutines() { ticker := time.NewTicker(500 * time.Millisecond) done := make(chan bool) go func() { for { select { case \u0026lt;-done: return case t := \u0026lt;-ticker.C: fmt.Printf(\u0026#34;\\n%v - %v\u0026#34;, t, runtime.NumGoroutine()) } } }() } func recoHandler(w http.ResponseWriter, r *http.Request) { a := `{\u0026#34;movies\u0026#34;: [\u0026#34;Few Angry Men\u0026#34;, \u0026#34;Pride \u0026amp; Prejudice\u0026#34;]}` w.Write([]byte(a)) } 推荐服务暴露一个路由接口 /recommendations，它返回一个推荐电影列表，同时每 500 毫秒打印一次 goroutine 的数量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // Movies App type MovieResponse struct { Feed []string Recommendation []string } func main() { http.HandleFunc(\u0026#34;/movies\u0026#34;, fetchMoviesFeedHandler) log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)) } func fetchMoviesFeedHandler(w http.ResponseWriter, r *http.Request) { mr := MovieResponse{ Feed: []string{\u0026#34;Transformers\u0026#34;, \u0026#34;Fault in our stars\u0026#34;, \u0026#34;The Old Boy\u0026#34;}, } rms, err := fetchRecommendations() if err != nil { w.WriteHeader(500) } mr.Recommendation = rms bytes, err := json.Marshal(mr) if err != nil { w.WriteHeader(500) } w.Write(bytes) } func fetchRecommendations() ([]string, error) { resp, err := http.Get(\u0026#34;http://localhost:9090/recommendations\u0026#34;) if err != nil { return []string{}, err } defer resp.Body.Close() body, err := ioutil.ReadAll(resp.Body) if err != nil { return []string{}, err } var mvsr map[string]interface{} err = json.Unmarshal(body, \u0026amp;mvsr) if err != nil { return []string{}, err } mvsb, err := json.Marshal(mvsr[\u0026#34;movies\u0026#34;]) if err != nil { return []string{}, err } var mvs []string err = json.Unmarshal(mvsb, \u0026amp;mvs) if err != nil { return []string{}, err } return mvs, nil } 电影服务暴露一个路由 /movies，它返回电影列表和推荐列表。为了获取推荐，它反过来调用上游的推荐服务。\n通过此设置，让我们以每秒 100 个请求的速率访问电影服务，持续 3 秒钟。在 99% 的毫秒范围内，我们可以获得 100% 的成功。这是预期的，因为只提供静态数据。\n现在，假设推荐服务的响应时间过长，并在 recoHandler 添加20秒的等待时间，然后重新进行测试。成功率会下降，而响应时间也会开始受到影响。此外，在测试期间阻塞在推荐服务上的 goroutine 数量将急剧增加。\n推荐服务的停工时间影响了终端用户，因为本来可以提供给他的电影feed列表都没有提供。这正是级联故障对我们的系统造成的影响。\n电路熔断器的救援 熔断器是一个非常简单但相当重要的概念，因为它可以让我们保持服务的高可用性。熔断器有三种状态:\nClosed State 关闭状态\n关闭状态是指数据通过的时候连接处关闭的状态。这是我们的理想状态，其中上游服务正如预期的那样工作。\nOpen State 开放状态\n打开状态指的是由于上游服务未按预期响应而导致电路短路的状态。这种短路可以避免上游服务在已经挣扎的情况下不堪重负。此外，下游服务的业务逻辑可以更快地获得上游可用性状态的反馈，而无需等待上游的响应。\nHalf Open State 半开状态\n如果电路是打开状态，我们希望它在上游服务再次可用时立即关闭它。虽然你可以通过手动干预来实现，但首选的方法应该是在电路最后一次打开，让一些请求延迟之后通过电路，\n如果这些请求请求上游服务成功，我们就可以安全地接通电路。\n另一方面，如果这些请求失败，电路仍然处于打开状态。\n熔断器的状态图如下:\n如果电路是关闭的，当故障超过配置的阈值，则可以打开\n如果电路是打开的，在一段睡眠时间延迟后，部分打开\n如果电路是半开的，它可以\n再次打开，如果允许通过的请求也失败了\n关闭，如果允许通过的请求成功响应\n熔断器在 Golang 的应用 虽然有多个库可供选择，但最常用的是 hystix。正如文档建议的那样，hystrix 是 Netflix 设计的一个延迟和容错库，用于隔离远程系统、服务和第三方库的访问，阻止级联故障，并在不可避免的故障发生的复杂分布式系统中实现恢复能力。\nHystrix 熔断器的实现取决于以下配置:\n超时 ー 上游服务响应的等待时间 最大并发请求 ー 上游服务允许调用的最大并发 请求容量阈值 ー 在熔断之前的请求数，断路器在需要更改状态时无法评估的请求数量 睡眠窗口 ー 开放状态与半开放状态之间的延迟时间 误差百分比阈值ー电路短路时的误差百分比阈值 接下来让我们在电影和推荐示例中使用它，并在获取推荐时实现熔断器模式。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 var downstreamErrCount int var circuitOpenErrCount int func main() { downstreamErrCount = 0 circuitOpenErrCount = 0 hystrix.ConfigureCommand(\u0026#34;recommendation\u0026#34;, hystrix.CommandConfig{ Timeout: 100, RequestVolumeThreshold: 25, ErrorPercentThreshold: 5, SleepWindow: 1000, }) http.HandleFunc(\u0026#34;/movies\u0026#34;, fetchMoviesFeedHandlerWithCircuitBreaker) log.Fatal(http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)) } func fetchMoviesFeedHandlerWithCircuitBreaker(w http.ResponseWriter, r *http.Request) { mr := MovieResponse{ Feed: []string{\u0026#34;Transformers\u0026#34;, \u0026#34;Fault in our stars\u0026#34;, \u0026#34;The Old Boy\u0026#34;}, } // output := make(chan bool, 1) errors := hystrix.Go(\u0026#34;recommendation\u0026#34;, func() error { // talk to other services rms, err := fetchRecommendations() if err != nil { return err } mr.Recommendation = rms output \u0026lt;- true return nil }, func(err error) error { // 写你的fallback(回退)逻辑 return nil }) select { case err := \u0026lt;-errors: if err == hystrix.ErrCircuitOpen { circuitOpenErrCount = circuitOpenErrCount + 1 } else { downstreamErrCount = downstreamErrCount + 1 } case _ = \u0026lt;-output: } bytes, err := json.Marshal(mr) if err != nil { w.WriteHeader(500) } fmt.Printf(\u0026#34;\\ndownstreamErrCount=%d, circuitOpenErrCount=%d\u0026#34;, downstreamErrCount, circuitOpenErrCount) w.Write(bytes) } 使用 Hystrix，您还可以在电路打开时实现回退逻辑。这种逻辑可能因情况而异。如果电路打开，则从缓存中获取。\n使用这个更新的逻辑，让我们尝试以每秒100个请求的速率重新攻击 3 秒钟。\n哇! ！100% 的成功率，在打开的情况下，我们只提供 Feed 和返回 0个推荐。此外，由于每当电路短路，我们不再调用上游服务，因此推荐服务不会不堪重负，阻塞的 goroutine 数量不会像以前那么多。\n想了解更多？ 我的建议:\n关于 Netflix Hystrix Hystrix 是怎样工作的？ Hystrix bucketing ","date":"2021-02-03T12:00:00Z","image":"http://img.golang.space/shot-1626770277464.png","permalink":"https://blog.golang.space/p/circuit-breakers-in-golang/","title":"Circuit Breakers in Golang"},{"content":"本文翻译自 https://github.com/evrone/go-clean-template，由于本人翻译水平有限，翻译不当之处烦请指出。\nGo 整洁架构模板。 概括 模板的作用 :\n如何组织项目并防止它变成一坨意大利面条式的代码。 在哪里存放业务逻辑，使其保持独立，整洁和可扩展。 如何在微服务扩展时不失控 模版使用了 Robert Martin ( 也叫 Bob 叔叔 ) 的原则。\nGo-clean-template 此仓库由 Evrone 创建及维护。\n目录内容 快速开始 项目结构 依赖注入 整洁架构之道 快速开始 本地开发\n1 2 3 4 # Postgres, RabbitMQ $ make compose-up # Run app with migrations $ make run 集成测试 ( 可以在 CI 中运行 )\n1 2 # DB, app + migrations, integration tests $ make compose-up-integration-test 项目结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 ├── cmd │ └── app │ └── main.go ├── config │ ├── config.go │ └── config.yml ├── docs │ ├── docs.go │ ├── swagger.json │ └── swagger.yaml ├── go.mod ├── go.sum ├── integration-test │ ├── Dockerfile │ └── integration_test.go ├── internal │ ├── app │ │ ├── app.go │ │ └── migrate.go │ ├── delivery │ │ ├── amqp_rpc │ │ │ ├── router.go │ │ │ └── translation.go │ │ └── http │ │ └── v1 │ │ ├── error.go │ │ ├── router.go │ │ └── translation.go │ ├── domain │ │ └── translation.go │ └── service │ ├── interfaces.go │ ├── repo │ │ └── translation_postgres.go │ ├── translation.go │ └── webapi │ └── translation_google.go ├── migrations │ ├── 20210221023242_migrate_name.down.sql │ └── 20210221023242_migrate_name.up.sql └── pkg ├── httpserver │ ├── options.go │ └── server.go ├── logger │ ├── interface.go │ ├── logger.go │ └── zap.go ├── postgres │ ├── options.go │ └── postgres.go └── rabbitmq └── rmq_rpc ├── client │ ├── client.go │ └── options.go ├── connection.go ├── errors.go └── server ├── options.go └── server.go cmd/app/main.go 配置和日志实例的初始化，main 函数中调用internal/app/app.go 文件中 的 Run 函数，main 函数将会在此 \u0026ldquo;延续\u0026rdquo;。\nconfig 配置。首先读取 config.yml，然后用环境变量覆盖相匹配的 yaml 配置。配置的结构体在 config.go 文件中。env-required: true 结构体标签强制您指定一个值 ( 在 yaml 或在环境变量中 )。\n对于配置读取，我们选择 cleanenv 库。它在 GitHub 上没有很多 star，但很简单且满足所有的需求。\n从 yaml 中读取配置违背了12 要素，但在实践中，它比从环境变量中读取整个配置更方便。假设默认值定义在 yaml 中，敏感的变量定义在环境变量中。\ndocs Swagger 文档。可以由 swag 库自动生成。而你不需要自己改正任何事情。\nintegration-test 集成测试。它们作为单独的容器启动，紧挨着应用程序容器。使用 go-hit 测试 REST API 非常方便。\ninternal/app 在 app.go 文件中一般会有一个 Run 函数，它“延续”了main函数。\n这是创建所有主要对象的地方。依赖注入通过“ New\u0026hellip;”构造函数 ( 参见依赖注入 ) 。这种技术允许我们使用依赖注入原则对应用程序进行分层，使得业务逻辑独立于其他层。\n接下来，为了优雅的完成，我们启动服务并在select中等待特定的信号。如果 app.go 代码越来越多，可以将其拆分为多个文件。\n对于大量的注入，可以使用 wire 库 ( wire 是一个代码生成工具，它使用依赖注入自动连接组件)。\nmigrate.go 文件用于数据库自动迁移。如果指定了 migrate 标签的参数，则会包含它。例如 :\n1 $ go run -tags migrate ./cmd/app internal/delivery 服务的handler层 ( MVC 控制器 )。模板展示了两个服务:\nRPC ( RabbitMQ 用于传递消息 ) REST HTTP ( GIN 框架 ) 服务的路由也以同样的风格编写 :\nHandlers按照应用领域分组 ( 按公共基础 ) 对于每个组，都创建自己的路由结构，以及处理接口路径的方法 业务逻辑的结构被注入到路由结构中，由handlers处理调用 internal/delivery/http 简单的 REST 版本控制。对于 v2，我们需要添加具有相同内容的 http/v2 文件夹。在 internal/app 程序文件中添加以下行 :\n1 2 3 handler := gin.New() v1.NewRouter(handler, translationService) v2.NewRouter(handler, translationService) 你可以使用任何其他的 HTTP 框架甚至是标准的 net/http 库来代替 Gin。\n在 v1/router.go 和上面的 handler 方法中，有一些注释是用 swag库来生成 swagger 文档的。\ninternal/domain 业务逻辑的实体 ( 模型 ) 可以在任何层中使用。也可以有方法，例如，用于验证。\ninternal/service 业务逻辑\n方法按应用领域分组 ( 在公共的基础上 ) 每个组都有自己的结构 一个文件一个结构 Repositories、 webapi、 rpc 和其他业务逻辑结构被注入到业务逻辑结构中 ( 见依赖注入 )。\ninternal/service/repo repository 是业务逻辑使用的抽象存储 ( 数据库 )。\ninternal/service/webapi 它是业务逻辑使用的抽象 web API。例如，它可能是业务逻辑通过 REST API 访问的另一个微服务。包的名称根据用途而变化。\npkg/rabbitmq RabbitMQ RPC 模式 :\nRabbitMQ 内部没有路由 使用Exchange fanout 广播模式，将1 个独立队列绑定到其中，这是最高效的配置。 重新连接断开丢失的连接 依赖注入 为了消除业务逻辑对外部包的依赖，使用了依赖注入。\n例如，通过 NewService 构造函数，我们将依赖注入到业务逻辑的结构中。这使得业务逻辑独立 ( 便于移植 )。我们可以重写接口的实现，而不需要对 service 包进行更改。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package service import ( // Nothing! ) type Repository interface { Get() } type Service struct { repo Repository } func NewService(r Repository) *Service{ return \u0026amp;Service{r} } func (s *Service) Do() { s.repo.Get() } 它还允许我们自动生成模拟参数 ( 例如使用 mockery ) 和轻松地编写单元测试。\n我们可以不受特定实现的约束，来将一个组件更改为另一个组件。如果新组件实现了该接口，则业务逻辑中不需要进行任何更改。\n整洁架构之道 关键点 程序员在编写了大量代码后才意识到应用程序的最佳架构。\n一个好的架构允许尽可能推迟决策。\n主要原则 Dependency Inversion ( 与 SOLID 相同 ) 是依赖倒置的原则。依赖关系的方向是从外层到内层。由于这个原因，业务逻辑和实体仍然独立于系统的其他部分。\n因此，应用程序分为内部和外部两个层次 :\n业务逻辑 ( 使用 Go 标准库 ) 工具 ( 数据库、其他服务、消息代理、任何其他包和框架 ) 业务逻辑的内层应该是整洁的，它应该 :\n没有从外层导入的包 只使用标准库的功能 通过接口调用外层 ! 业务逻辑对 Postgres 或详细的 web API 一无所知。业务逻辑应该具有一个用于处理抽象数据库或抽象 web API 的接口。\n外层还有其他限制 :\n这一层的所有组成部分都不知道彼此的存在。如何从一个工具调用另一个工具？不是直接，而是只能通过内层的业务逻辑来调用。 对内层的所有调用都是通过接口来完成的 数据以便于业务逻辑的格式传输 ( internal/domain ) 例如，你需要从 HTTP ( 控制器 ) 访问数据库。HTTP 和数据库都在外层，这意味着它们对彼此一无所知。它们之间的通信是通过 service ( 业务逻辑 ) 进行的 :\n1 2 3 4 HTTP \u0026gt; service service \u0026gt; repository (Postgres) service \u0026lt; repository (Postgres) HTTP \u0026lt; service 符号 \u0026gt; 和 \u0026lt; 通过接口显示层与层边界的交集，如图所示 :\n或者更复杂的业务逻辑 :\n1 2 3 4 5 6 7 8 9 10 HTTP \u0026gt; service service \u0026gt; repository service \u0026lt; repository service \u0026gt; webapi service \u0026lt; webapi service \u0026gt; RPC service \u0026lt; RPC service \u0026gt; repository service \u0026lt; repository HTTP \u0026lt; service 层级 整洁架构的术语\n实体是业务逻辑操作的结构。它们位于 internal/domain 文件夹中。Domain 暗示我们坚持 DDD ( 领域驱动设计 ) 的原则，这在一定程度上是正确的。在 MVC 术语中，实体就是模型。 用例是位于 internal/service 中的业务逻辑。从整洁架构的角度来看，调用业务逻辑使用 service 一词不是习惯的用法，但是对于一个包名称来说，使用一个单词 ( service ) 比使用两个单词 ( use case ) 更方便。 业务逻辑直接交互的层通常称为基础设施层。它们可以是存储库 internal/service/repo、web API internal/service/webapi、任何pkg，以及其他微服务。在模板中，_ infrastructure 包位于 internal/service 中。\n你可以根据需要去选择如何调用入口点。选项如下 :\ndelivery (in our case) controllers transport gateways entrypoints primary input 附加层 经典版本的 整洁架构之道 是为构建大型单体应用程序而设计的，它有4层。\n在最初的版本中，外层被分为两个以上的层，两层之间也存在相互依赖关系倒置 ( 定向内部 )，并通过接口进行通信。\n在逻辑复杂的情况下，内层也分为两个( 接口分离 )。\n复杂的工具可以被划分成更多的附加层，但你应该在确实需要时再添加层。\n替代方法 除了整洁架构之道，洋葱架构和六边形架构 ( 端口适配器模式 ) 是类似的。两者都是基于依赖倒置的原则。端口和适配器模式非常接近于整洁架构之道，差异主要在术语上。\n类似的项目 https://github.com/bxcodec/go-clean-arch https://github.com/zhashkevych/courses-backend 扩展阅读链接 整洁架构之道 12 要素 ","date":"2021-02-01T12:00:00Z","image":"http://img.golang.space/shot-1629111300629.svg","permalink":"https://blog.golang.space/p/go-clean-template/","title":"go clean template"},{"content":"⚡ZAP 简介 zap 是什么? ⚡ZAP 是uber 开源的提供快速，结构化，高性能的日志记录包。\nzap 高性能体现在哪里? 在介绍zap包的优化部分之前，让我们看下zap日志库的工作流程图\n大多数日志库提供的方式是基于反射的序列化和字符串格式化，这种方式代价高昂，而 Zap 采取不同的方法。\n避免 interface{} 使用强类型设计\n封装强类型，无反射\n使用零分配内存的 JSON 编码器，尽可能避免序列化开销，它比其他结构化日志包快 4 - 10 倍。\n1 2 3 4 5 logger.Info(\u0026#34;failed to fetch URL\u0026#34;, zap.String(\u0026#34;url\u0026#34;, \u0026#34;https://baidu.com\u0026#34;), zap.Int(\u0026#34;attempt\u0026#34;, 3), zap.Duration(\u0026#34;backoff\u0026#34;, time.Second), ) 使用 sync.Pool 以避免记录消息时的内存分配 详情在下文 zapcore 模块介绍。\nExample 安装 1 go get -u go.uber.org/zap Zap 提供了两种类型的 logger\nSugaredLogger Logger 在性能良好但不是关键的情况下，使用 SugaredLogger，它比其他结构化的日志包快 4-10 倍，并且支持结构化和 printf 风格的APIs。\n例一 调用 NewProduction 创建logger对象 1 2 3 4 5 6 7 8 func TestSugar(t *testing.T) { logger, _ := zap.NewProduction() // 默认 logger 不缓冲。 // 但由于底层 api 允许缓冲，所以在进程退出之前调用 Sync 是一个好习惯。 defer logger.Sync() sugar := logger.Sugar() sugar.Infof(\u0026#34;Failed to fetch URL: %s\u0026#34;, \u0026#34;https://baidu.com\u0026#34;) } 对性能和类型安全要求严格的情况下，可以使用 Logger ，它甚至比前者SugaredLogger更快，内存分配次数也更少，但它仅支持强类型的结构化日志记录。\n例二 调用 NewDevelopment 创建logger对象 1 2 3 4 5 6 7 8 9 10 func TestLogger(t *testing.T) { logger, _ := zap.NewDevelopment() defer logger.Sync() logger.Info(\u0026#34;failed to fetch URL\u0026#34;, // 强类型字段 zap.String(\u0026#34;url\u0026#34;, \u0026#34;https://baidu.com\u0026#34;), zap.Int(\u0026#34;attempt\u0026#34;, 3), zap.Duration(\u0026#34;backoff\u0026#34;, time.Second), ) } 不需要为整个应用程序决定选择使用 Logger 还是 SugaredLogger ，两者之间都可以轻松转换。\n例三 Logger 与 SugaredLogger 相互转换 1 2 3 4 5 6 7 8 // 创建 logger logger := zap.NewExample() defer logger.Sync() // 转换 SugaredLogger sugar := logger.Sugar() // 转换 logger plain := sugar.Desugar() 例四 自定义格式 自定义一个日志消息格式，带着问题看下列代码。\ndebug 级别的日志打印到控制台了吗? 最后的 error 会打印到控制台吗 ? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 package main import ( \u0026#34;os\u0026#34; \u0026#34;go.uber.org/zap\u0026#34; \u0026#34;go.uber.org/zap/zapcore\u0026#34; ) func NewCustomEncoderConfig() zapcore.EncoderConfig { return zapcore.EncoderConfig{ TimeKey: \u0026#34;ts\u0026#34;, LevelKey: \u0026#34;level\u0026#34;, NameKey: \u0026#34;logger\u0026#34;, CallerKey: \u0026#34;caller\u0026#34;, FunctionKey: zapcore.OmitKey, MessageKey: \u0026#34;msg\u0026#34;, StacktraceKey: \u0026#34;stacktrace\u0026#34;, LineEnding: zapcore.DefaultLineEnding, EncodeLevel: zapcore.CapitalColorLevelEncoder, EncodeTime: zapcore.TimeEncoderOfLayout(\u0026#34;2006-01-02 15:04:05\u0026#34;), EncodeDuration: zapcore.SecondsDurationEncoder, EncodeCaller: zapcore.ShortCallerEncoder, } } func main() { atom := zap.NewAtomicLevelAt(zap.DebugLevel) core := zapcore.NewCore( zapcore.NewConsoleEncoder(NewCustomEncoderConfig()), zapcore.NewMultiWriteSyncer(zapcore.AddSync(os.Stdout)), atom, ) logger := zap.New(core, zap.AddCaller(), zap.Development()) defer logger.Sync() // 配置 zap 包的全局变量 zap.ReplaceGlobals(logger) // 运行时安全地更改 logger 日记级别 atom.SetLevel(zap.InfoLevel) sugar := logger.Sugar() // 问题 1: debug 级别的日志打印到控制台了吗? sugar.Debug(\u0026#34;debug\u0026#34;) sugar.Info(\u0026#34;info\u0026#34;) sugar.Warn(\u0026#34;warn\u0026#34;) sugar.DPanic(\u0026#34;dPanic\u0026#34;) // 问题 2: 最后的 error 会打印到控制台吗? sugar.Error(\u0026#34;error\u0026#34;) } 结果见下图\n问题 1:\n没有打印。AtomicLevel 是原子性可更改的动态日志级别，通过调用 atom.SetLevel 更改日志级别为 infoLevel 。\n问题 2:\n没有打印。zap.Development() 启用了开发模式，在开发模式下 DPanic 函数会引发 panic，所以最后的 error 不会打印到控制台。\n源码分析 此次源码分析基于 Zap 1.16\n上图仅表示 zap 可调用两种 logger，没有表达 Logger 与 SugaredLogger 的关系，继续往下看，你会更理解。\nLogger logger 提供快速，分级，结构化的日志记录。所有的方法都是安全的，内存分配很重要，因此它的 API 有意偏向于性能和类型安全。\nzap@v1.16.0 - logger.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 type Logger struct { // 实现编码和输出的接口 core zapcore.Core // 记录器开发模式，DPanic 等级将记录 panic development bool // 开启记录调用者的行号和函数名 addCaller bool\t// 致命日志采取的操作，默认写入日志后 os.Exit() onFatal zapcore.CheckWriteAction name string\t// 设置记录器生成的错误目的地 errorOutput zapcore.WriteSyncer // 记录 \u0026gt;= 该日志等级的堆栈追踪 addStack zapcore.LevelEnabler // 避免记录器认为封装函数为调用方 callerSkip int\t// 默认为系统时间 clock Clock\t} 在 Example 中分别使用了 NewProduction 和 NewDevelopment ，接下来以这两个函数开始分析。下图表示 A 函数调用了 B 函数，其中箭头表示函数调用关系。图中函数都会分析到。\nNewProduction\n从下面代码中可以看出，此函数是对 NewProductionConfig().Build(...) 封装的快捷方式。\nzap@v1.16.0 - logger.go\n1 2 3 func NewProduction(options ...Option) (*Logger, error) { return NewProductionConfig().Build(options...) } NewProductionConfig\n在 InfoLevel 及更高级别上启用了日志记录。它使用 JSON 编码器，写入 stderr，启用采样。\nzap@v1.16.0 - config.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func NewProductionConfig() Config { return Config{ // info 日志级别 Level: NewAtomicLevelAt(InfoLevel), // 非开发模式 Development: false, // 采样设置 Sampling: \u0026amp;SamplingConfig{ Initial: 100, // 相同日志级别下相同内容每秒日志输出数量 Thereafter: 100, // 超过该数量，才会再次输出 }, // JSON 编码器 Encoding: \u0026#34;json\u0026#34;, // 后面介绍 EncoderConfig: NewProductionEncoderConfig(), // 输出到 stderr OutputPaths: []string{\u0026#34;stderr\u0026#34;}, ErrorOutputPaths: []string{\u0026#34;stderr\u0026#34;}, } } Config 结构体\n通过 Config 可以设置通用的配置项。\nzap@v1.16.0 - config.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 type Config struct { // 日志级别 Level AtomicLevel `json:\u0026#34;level\u0026#34; yaml:\u0026#34;level\u0026#34;` // 开发模式 Development bool `json:\u0026#34;development\u0026#34; yaml:\u0026#34;development\u0026#34;` // 停止使用调用方的函数和行号 DisableCaller bool `json:\u0026#34;disableCaller\u0026#34; yaml:\u0026#34;disableCaller\u0026#34;` // 完全停止使用堆栈跟踪，默认为 `\u0026gt;=WarnLevel` 使用堆栈跟踪 DisableStacktrace bool `json:\u0026#34;disableStacktrace\u0026#34; yaml:\u0026#34;disableStacktrace\u0026#34;` // 采样设置策略 Sampling *SamplingConfig `json:\u0026#34;sampling\u0026#34; yaml:\u0026#34;sampling\u0026#34;` // 记录器的编码，有效值为 \u0026#39;json\u0026#39; 和 \u0026#39;console\u0026#39; 以及通过 `RegisterEncoder` 注册的有效编码 Encoding string `json:\u0026#34;encoding\u0026#34; yaml:\u0026#34;encoding\u0026#34;` // 编码器选项 EncoderConfig zapcore.EncoderConfig `json:\u0026#34;encoderConfig\u0026#34; yaml:\u0026#34;encoderConfig\u0026#34;` // 日志的输出路径 OutputPaths []string `json:\u0026#34;outputPaths\u0026#34; yaml:\u0026#34;outputPaths\u0026#34;` // zap 内部错误的输出路径 ErrorOutputPaths []string `json:\u0026#34;errorOutputPaths\u0026#34; yaml:\u0026#34;errorOutputPaths\u0026#34;` // 添加到根记录器的字段的集合 InitialFields map[string]interface{} `json:\u0026#34;initialFields\u0026#34; yaml:\u0026#34;initialFields\u0026#34;` } NewDevelopment\n从下面代码中可以看出，此函数是对 NewDevelopmentConfig().Build(...) 封装的快捷方式\nzap@v1.16.0 - logger.go\n1 2 3 func NewDevelopment(options ...Option) (*Logger, error) { return NewDevelopmentConfig().Build(options...) } NewDevelopmentConfig\n此函数在 DebugLevel 及更高版本上启用日志记录，它使用 console 编码器，写入 stderr，禁用采样。\nzap@v1.16.0 - config.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func NewDevelopmentConfig() Config { return Config{ // debug 等级 Level: NewAtomicLevelAt(DebugLevel), // 开发模式 Development: true, // console 编码器 Encoding: \u0026#34;console\u0026#34;, EncoderConfig: NewDevelopmentEncoderConfig(), // 输出到 stderr OutputPaths: []string{\u0026#34;stderr\u0026#34;}, ErrorOutputPaths: []string{\u0026#34;stderr\u0026#34;}, } } NewProductionEncoderConfig 和 NewDevelopmentEncoderConfig 都是返回编码器配置。\nzap@v1.16.0 - config.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 type EncoderConfig struct { // 设置 编码为 JSON 时的 KEY // 如果为空，则省略 MessageKey string `json:\u0026#34;messageKey\u0026#34; yaml:\u0026#34;messageKey\u0026#34;` LevelKey string `json:\u0026#34;levelKey\u0026#34; yaml:\u0026#34;levelKey\u0026#34;` TimeKey string `json:\u0026#34;timeKey\u0026#34; yaml:\u0026#34;timeKey\u0026#34;` NameKey string `json:\u0026#34;nameKey\u0026#34; yaml:\u0026#34;nameKey\u0026#34;` CallerKey string `json:\u0026#34;callerKey\u0026#34; yaml:\u0026#34;callerKey\u0026#34;` FunctionKey string `json:\u0026#34;functionKey\u0026#34; yaml:\u0026#34;functionKey\u0026#34;` StacktraceKey string `json:\u0026#34;stacktraceKey\u0026#34; yaml:\u0026#34;stacktraceKey\u0026#34;` // 配置行分隔符 LineEnding string `json:\u0026#34;lineEnding\u0026#34; yaml:\u0026#34;lineEnding\u0026#34;` // 配置常见复杂类型的基本表示形式。 EncodeLevel LevelEncoder `json:\u0026#34;levelEncoder\u0026#34; yaml:\u0026#34;levelEncoder\u0026#34;` EncodeTime TimeEncoder `json:\u0026#34;timeEncoder\u0026#34; yaml:\u0026#34;timeEncoder\u0026#34;` EncodeDuration DurationEncoder `json:\u0026#34;durationEncoder\u0026#34; yaml:\u0026#34;durationEncoder\u0026#34;` EncodeCaller CallerEncoder `json:\u0026#34;callerEncoder\u0026#34; yaml:\u0026#34;callerEncoder\u0026#34;` // 日志名称，此参数可选 EncodeName NameEncoder `json:\u0026#34;nameEncoder\u0026#34; yaml:\u0026#34;nameEncoder\u0026#34;` // 配置 console 编码器使用的字段分隔符，默认 tab ConsoleSeparator string `json:\u0026#34;consoleSeparator\u0026#34; yaml:\u0026#34;consoleSeparator\u0026#34;` } NewProductionEncoderConfig\nzap@v1.16.0 - config.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func NewProductionEncoderConfig() zapcore.EncoderConfig { return zapcore.EncoderConfig{ TimeKey: \u0026#34;ts\u0026#34;, LevelKey: \u0026#34;level\u0026#34;, NameKey: \u0026#34;logger\u0026#34;, CallerKey: \u0026#34;caller\u0026#34;, FunctionKey: zapcore.OmitKey, MessageKey: \u0026#34;msg\u0026#34;, StacktraceKey: \u0026#34;stacktrace\u0026#34;, // 默认换行符 \\n LineEnding: zapcore.DefaultLineEnding, // 日志等级序列为小写字符串，如:InfoLevel被序列化为 \u0026#34;info\u0026#34; EncodeLevel: zapcore.LowercaseLevelEncoder, // 时间序列化成浮点秒数 EncodeTime: zapcore.EpochTimeEncoder, // 时间序列化，Duration为经过的浮点秒数 EncodeDuration: zapcore.SecondsDurationEncoder, // 以 包名/文件名:行数 格式序列化 EncodeCaller: zapcore.ShortCallerEncoder, } } 该配置会输出如下结果，此结果出处参见 Example 中的例一\n1 {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:1620367988.461055,\u0026#34;caller\u0026#34;:\u0026#34;test/use_test.go:24\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Failed to fetch URL: https://baidu.com\u0026#34;} NewDevelopmentEncoderConfig\nzap@v1.16.0 - config.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func NewDevelopmentEncoderConfig() zapcore.EncoderConfig { return zapcore.EncoderConfig{ // keys 值可以是任意非空的值 TimeKey: \u0026#34;T\u0026#34;, LevelKey: \u0026#34;L\u0026#34;, NameKey: \u0026#34;N\u0026#34;, CallerKey: \u0026#34;C\u0026#34;, FunctionKey: zapcore.OmitKey, MessageKey: \u0026#34;M\u0026#34;, StacktraceKey: \u0026#34;S\u0026#34;, // 默认换行符 \\n LineEnding: zapcore.DefaultLineEnding, // 日志等级序列为大写字符串，如:InfoLevel被序列化为 \u0026#34;INFO\u0026#34; EncodeLevel: zapcore.CapitalLevelEncoder, // 时间格式化为 ISO8601 格式 EncodeTime: zapcore.ISO8601TimeEncoder, EncodeDuration: zapcore.StringDurationEncoder, // // 以 包名/文件名:行数 格式序列化 EncodeCaller: zapcore.ShortCallerEncoder, } } 该配置会输出如下结果，此结果出处参见 Example 中的 例二\n1 2021-05-07T14:14:12.434+0800\tINFO\ttest/use_test.go:31\tfailed to fetch URL\t{\u0026#34;url\u0026#34;: \u0026#34;https://baidu.com\u0026#34;, \u0026#34;attempt\u0026#34;: 3, \u0026#34;backoff\u0026#34;: \u0026#34;1s\u0026#34;} NewProductionConfig 和 NewDevelopmentConfig 返回 config 调用 Build 函数返回 logger，接下来我们看看这个函数。\nzap@v1.16.0 - config.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func (cfg Config) Build(opts ...Option) (*Logger, error) { enc, err := cfg.buildEncoder() if err != nil { return nil, err } sink, errSink, err := cfg.openSinks() if err != nil { return nil, err } if cfg.Level == (AtomicLevel{}) { return nil, fmt.Errorf(\u0026#34;missing Level\u0026#34;) } log := New( zapcore.NewCore(enc, sink, cfg.Level), cfg.buildOptions(errSink)..., ) if len(opts) \u0026gt; 0 { log = log.WithOptions(opts...) } return log, nil } 从上面的代码中，通过解析 config 的参数，调用 New 方法来创建 Logger。在 Example 中例四，就是调用 New 方法来自定义 Logger。\nSugaredLogger Logger 作为 SugaredLogger 的属性，这个封装优点在于不是很在乎性能的情况下，可以快速调用Logger。所以名字为加了糖的 Logger。\nzap@v1.16.0 - logger.go\n1 2 3 type SugaredLogger struct { base *Logger } 1 2 3 zap.ReplaceGlobals(logger)\t// 重新配置全局变量 zap.S().Info(\u0026#34;SugaredLogger\u0026#34;) // S 返回全局 SugaredLogger zap.L().Info(\u0026#34;logger\u0026#34;)\t// L 返回全局 logger 与Logger不同，SugaredLogger不强制日志结构化。所以对于每个日志级别，都提供了三种方法。\nzap@v1.16.0 - sugar.go\n以 info 级别为例，相关的三种方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Info 使用 fmt.Sprint 构造和记录消息。 func (s *SugaredLogger) Info(args ...interface{}) { s.log(InfoLevel, \u0026#34;\u0026#34;, args, nil) } // Infof 使用 fmt.Sprintf 记录模板消息。 func (s *SugaredLogger) Infof(template string, args ...interface{}) { s.log(InfoLevel, template, args, nil) } // Infow 记录带有其他上下文的消息 func (s *SugaredLogger) Infow(msg string, keysAndValues ...interface{}) { s.log(InfoLevel, msg, nil, keysAndValues) } 在 sugar.Infof(\u0026quot;...\u0026quot;) 打上断点，从这开始追踪源码。\n在调试代码之前，先给大家看一下SugaredLogger 的 Infof 函数的调用的大致工作流，其中不涉及采样等。\nInfo , Infof, Infow 三个函数都调用了 log 函数，log 函数代码如下\nzap@v1.16.0 - sugar.go\n1 2 3 4 5 6 7 8 9 10 11 12 func (s *SugaredLogger) log(lvl zapcore.Level, template string, fmtArgs []interface{}, context []interface{}) { // 判断是否启用的日志级别 if lvl \u0026lt; DPanicLevel \u0026amp;\u0026amp; !s.base.Core().Enabled(lvl) { return } // 将参数合并到语句中 msg := getMessage(template, fmtArgs) // Check 可以帮助避免分配一个分片来保存字段。 if ce := s.base.Check(lvl, msg); ce != nil { ce.Write(s.sweetenFields(context)...) } } 函数的第一个参数 InfoLevel 是日志级别，其源码如下\nzap@v1.16.0 - zapcore/level.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 const ( // Debug 应是大量的，且通常在生产状态禁用. DebugLevel = zapcore.DebugLevel // Info 是默认的记录优先级. InfoLevel = zapcore.InfoLevel // Warn 比 info 更重要. WarnLevel = zapcore.WarnLevel // Error 是高优先级的,如果程序顺利不应该产生任何 err 级别日志. ErrorLevel = zapcore.ErrorLevel // DPanic 特别重大的错误，在开发模式下引起 panic. DPanicLevel = zapcore.DPanicLevel // Panic 记录消息后调用 panic. PanicLevel = zapcore.PanicLevel // Fatal 记录消息后调用 os.Exit(1). FatalLevel = zapcore.FatalLevel ) getMessage 函数处理 template 和 fmtArgs 参数，主要为不同的参数选择最合适的方式拼接消息\nzap@v1.16.0 - sugar.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func getMessage(template string, fmtArgs []interface{}) string { // 没有参数直接返回 template if len(fmtArgs) == 0 { return template } // 此处调用 Sprintf 会使用反射 if template != \u0026#34;\u0026#34; { return fmt.Sprintf(template, fmtArgs...) } // 消息为空并且有一个参数，返回该参数 if len(fmtArgs) == 1 { if str, ok := fmtArgs[0].(string); ok { return str } } // 返回所有 fmtArgs return fmt.Sprint(fmtArgs...) } 关于 s.base.Check ，这就需要介绍zapcore ，下面分析相关模块。\nzapcore zapcore包 定义并实现了构建 zap 的低级接口。通过提供这些接口的替代实现，外部包可以扩展 zap 的功能。\nzap@v1.16.0 - zapcore/core.go\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Core 是一个最小的、快速的记录器接口。 type Core interface { // 接口，决定一个日志等级是否启用 LevelEnabler // 向 core 添加核心上下文 With([]Field) Core // 检查是否应记录提供的条目 // 在调用 write 之前必须先调用 Check Check(Entry, *CheckedEntry) *CheckedEntry // 写入日志 Write(Entry, []Field) error // 同步刷新缓存日志(如果有) Sync() error } Check 函数有两个入参。第一个参数表示一条完整的日志消息，第二个参数为 nil 时会从 sync.Pool 创建的池中取出*CheckedEntry 对象复用，避免重新分配内存。该函数内部调用 AddCore 实现获取 *CheckedEntry对象，最后调用 Write 写入日志消息。\n相关代码全部贴在下面，更多介绍请看代码中的注释。\nzap@v1.16.0 - zapcore/entry.go\n1 2 3 4 5 6 7 8 9 // 一个 entry 表示一个完整的日志消息 type Entry struct { Level Level Time time.Time LoggerName string Message string Caller EntryCaller Stack string } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 // 使用 sync.Pool 复用临时对象 var ( _cePool = sync.Pool{New: func() interface{} { return \u0026amp;CheckedEntry{ cores: make([]Core, 4), } }} ) // 从池中取出 CheckedEntry 并初始化值 func getCheckedEntry() *CheckedEntry { ce := _cePool.Get().(*CheckedEntry) ce.reset() return ce } // CheckedEntry 是 enter 和 cores 集合。 type CheckedEntry struct { Entry ErrorOutput WriteSyncer dirty bool // 用于检测是否重复使用对象 should CheckWriteAction // 结束程序的动作 cores []Core } // 重置对象 func (ce *CheckedEntry) reset() { ce.Entry = Entry{} ce.ErrorOutput = nil ce.dirty = false ce.should = WriteThenNoop for i := range ce.cores { // 不要保留对 core 的引用!! ce.cores[i] = nil } ce.cores = ce.cores[:0] } // 将 entry 写入存储的 cores // 最后将 CheckedEntry 添加到池中 func (ce *CheckedEntry) Write(fields ...Field) { if ce == nil { return } if ce.dirty { if ce.ErrorOutput != nil { // 检查 CheckedEntry 的不安全重复使用 fmt.Fprintf(ce.ErrorOutput, \u0026#34;%v Unsafe CheckedEntry re-use near Entry %+v.\\n\u0026#34;, ce.Time, ce.Entry) ce.ErrorOutput.Sync() } return } ce.dirty = true var err error // 写入日志消息 for i := range ce.cores { err = multierr.Append(err, ce.cores[i].Write(ce.Entry, fields)) } // 处理内部发生的错误 if ce.ErrorOutput != nil { if err != nil { fmt.Fprintf(ce.ErrorOutput, \u0026#34;%v write error: %v\\n\u0026#34;, ce.Time, err) ce.ErrorOutput.Sync() } } should, msg := ce.should, ce.Message // 将 CheckedEntry 添加到池中，下次复用 putCheckedEntry(ce) // 判断是否需要 panic 或其它方式终止程序.. switch should { case WriteThenPanic: panic(msg) case WriteThenFatal: exit.Exit() case WriteThenGoexit: runtime.Goexit() } } func (ce *CheckedEntry) AddCore(ent Entry, core Core) *CheckedEntry { if ce == nil { // 从池中取 CheckedEntry，减少内存分配 ce = getCheckedEntry() ce.Entry = ent } ce.cores = append(ce.cores, core) return ce } Doc https://pkg.go.dev/go.uber.org/zap\nQA 设计问题 为什么要在Logger性能上花费这么多精力呢？ 当然，大多数应用程序不会注意到Logger慢的影响：因为它们每次操作会需要几十或几百毫秒，所以额外的几毫秒很无关紧要。\n另一方面，为什么不使用结构化日志快速开发呢？与其他日志包相比SugaredLogger的使用并不难，Logger使结构化记录在对性能要求严格的环境中成为可能。在 Go 微服务的架构体系中，使每个应用程序甚至稍微更有效地加速执行。\n为什么没有Logger和SugaredLogger接口？ 不像熟悉的io.Writer和http.Handler、Logger和SugaredLogger接口将包括很多方法。正如 Rob Pike 谚语指出的，\u0026ldquo;The bigger the interface, the weaker the abstraction\u0026rdquo;(接口越大，抽象越弱)。接口也是严格的，任何更改都需要发布一个新的主版本，因为它打破了所有第三方实现。\nLogger和SugaredLogger成为具体类型并不会牺牲太多抽象，而且它允许我们在不引入破坏性更改的情况下添加方法。您的应用程序应该定义并依赖只包含您使用的方法的接口。\n为什么我的一些日志会丢失？ 在启用抽样时，通过zap有意地删除日志。生产配置(如NewProductionConfig()返回的那样)支持抽样，这将导致在一秒钟内对重复日志进行抽样。有关为什么启用抽样的更多详细信息，请参见\u0026ldquo;为什么使用示例应用日志\u0026quot;中启用采样.\n为什么要使用示例应用程序日志？ 应用程序经常会遇到错误，无论是因为错误还是因为用户使用错误。记录错误日志通常是一个好主意，但它很容易使这种糟糕的情况变得更糟：不仅您的应用程序应对大量错误，它还花费额外的CPU周期和I/O记录这些错误日志。由于写入通常是序列化的，因此在最需要时，logger会限制吞吐量。\n采样通过删除重复的日志条目来解决这个问题。在正常情况下，您的应用程序会输出每个记录。但是，当类似的记录每秒输出数百或数千次时，zap 开始丢弃重复以保存吞吐量。\n为什么结构化的日志 API 除了接受字段之外还可以接收消息？ 主观上，我们发现在结构化上下文中附带一个简短的描述是有帮助的。这在开发过程中并不关键，但它使调试和操作不熟悉的系统更加容易。\n更具体地说，zap 的采样算法使用消息来识别重复的条目。根据我们的经验，这是一个介于随机抽样（通常在调试时删除您需要的确切条目）和哈希完整条目（代价高）之间的一个中间方法。\n为什么要包括全局 loggers？ 由于许多其他日志包都包含全局变量logger，许多应用程序没有设计成接收logger作为显式参数。更改函数签名通常是一种破坏性的更改，因此zap包含全局logger以简化迁移。\n尽可能避免使用它们。\n为什么包括专用的Panic和Fatal日志级别？ 一般来说，应用程序代码应优雅地处理错误，而不是使用panic或os.Exit。但是，每个规则都有例外，当错误确实无法恢复时，崩溃是很常见的。为了避免丢失任何信息（尤其是崩溃的原因），记录器必须在进程退出之前冲洗任何缓冲条目。\nZap 通过提供在退出前自动冲洗的Panic和Fatal记录方法来使这一操作变得简单。当然，这并不保证日志永远不会丢失，但它消除了常见的错误。\n有关详细信息，请参阅 Uber-go/zap#207 中的讨论。\n什么是DPanic? DPanic代表\u0026quot;panic in development.\u0026quot;。在development中，它会打印Panic级别的日志：反之，它将发生在Error级别的日志，DPanic更加容易捕获可能但实际上不应该发生的错误，而不是在生产环境中Panic。\n如果你曾经写过这样的代码，就可以使用DPanic:\n1 2 3 if err != nil { panic(fmt.Sprintf(\u0026#34;shouldn\u0026#39;t ever get here: %v\u0026#34;, err)) } 安装问题 错误expects import \u0026quot;go.uber.org/zap\u0026quot;是什么意思？ 要么zap安装错误，要么您引用了代码中的错误包名。\nZap 的源代码托管在 GitHub 上，但 import path是 go.uber.org/zap，让我们项目维护者，可以更方便地自由移动源代码。所以在安装和使用包时需要注意这一点。\n如果你遵循两个简单的规则，就会正常工作：安装zapgo get -u go.uber.org/zap并始终导入它在你的代码import \u0026quot;go.uber.org/zap\u0026quot;，代码不应包含任何对github.com/uber-go/zap的引用.\n用法问题 Zap是否支持日志切割？ Zap 不支持切割日志文件，因为我们更喜欢将此交给外部程序，如logrotate.\n但是，日志切割包很容易集成，如 gopkg.in/natefinch/lumberjack.v2 作为zapcore.WriteSyncer.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // lumberjack.Logger is already safe for concurrent use, so we don\u0026#39;t need to // lock it. w := zapcore.AddSync(\u0026amp;lumberjack.Logger{ Filename: \u0026#34;/var/log/myapp/foo.log\u0026#34;, MaxSize: 500, // megabytes MaxBackups: 3, MaxAge: 28, // days }) core := zapcore.NewCore( zapcore.NewJSONEncoder(zap.NewProductionEncoderConfig()), w, zap.InfoLevel, ) logger := zap.New(core) 插件 我们很希望zap 本身能满足的每一个logging需求，但我们只熟悉少数日志摄入(log ingestion)系统、参数解析(flag-parsing)包等。所以我们更愿意发展 zap 插件生态系统。\n下面扩展包，可以作为参考使用：\n包 集成 github.com/tchap/zapext Sentry, syslog github.com/fgrosse/zaptest Ginkgo github.com/blendle/zapdriver Stackdriver github.com/moul/zapgorm Gorm 性能比较 说明 : 以下资料来源于 zap 官方，Zap 提供的基准测试清楚地表明，zerolog是与 Zap 竞争最激烈的。zerolo还提供结果非常相似的基准测试：\n记录一个10个kv字段的消息：\n库名 每次迭代耗时 耗时相比zap 每次迭代内存分配次数 ⚡ zap 862 ns/op +0% 5 allocs/op ⚡ zap (sugared) 1250 ns/op +45% 11 allocs/op zerolog 4021 ns/op +366% 76 allocs/op go-kit 4542 ns/op +427% 105 allocs/op apex/log 26785 ns/op +3007% 115 allocs/op logrus 29501 ns/op +3322% 125 allocs/op log15 29906 ns/op +3369% 122 allocs/op 使用一个已经有10个kv字段的logger记录一条消息：\n库名 每次迭代耗时 耗时相比zap 每次迭代内存分配次数 ⚡ zap 126 ns/op +0% 0 allocs/op ⚡ zap (sugared) 187 ns/op +48% 2 allocs/op zerolog 88 ns/op -30% 0 allocs/op go-kit 5087 ns/op +3937% 103 allocs/op log15 18548 ns/op +14621% 73 allocs/op apex/log 26012 ns/op +20544% 104 allocs/op logrus 27236 ns/op +21516% 113 allocs/op 记录一个字符串，没有字段或printf风格的模板：\n库名 每次迭代耗时 耗时相比zap 每次迭代内存分配次数 ⚡ zap 118 ns/op +0% 0 allocs/op ⚡ zap (sugared) 191 ns/op +62% 2 allocs/op zerolog 93 ns/op -21% 0 allocs/op go-kit 280 ns/op +137% 11 allocs/op standard library 499 ns/op +323% 2 allocs/op apex/log 1990 ns/op +1586% 10 allocs/op logrus 3129 ns/op +2552% 24 allocs/op log15 3887 ns/op +3194% 23 allocs/op 相似的库 logrus 功能强大\nzerolog 性能相当好的日志库\n","date":"2021-01-22T15:00:00Z","permalink":"https://blog.golang.space/p/%E4%BB%8E%E6%BA%90%E7%A0%81%E4%BA%86%E8%A7%A3-zap/","title":"从源码了解 zap"},{"content":"MacOS 1 开启\n1 flutter config --enable-macos-desktop 2 创建( 或已有项目添加 macOS )\n1 flutter create . # 这里的 . 号是在当前文件夹创建 3 运行\n1 flutter run -d macOS 4 打包\n1 flutter build macos 5 在 vscode 中创建启动驱动\n1 2 3 4 5 6 { \u0026#34;name\u0026#34;: \u0026#34;macOS\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;dart\u0026#34;, \u0026#34;deviceId\u0026#34;: \u0026#34;macOS\u0026#34; }, 开启网络权限 iphone7\niOS 13 占70%，iOS 12 占23%，iOS 11 及之前版本占7%。\n","date":"2020-12-10T00:00:00Z","permalink":"https://blog.golang.space/p/flutter-%E5%BC%80%E5%8F%91-mac-%E5%BA%94%E7%94%A8/","title":"Flutter 开发 Mac 应用"},{"content":"Fontlab 7 简要文档 该文档主要帮助您快速了解软件如何操作\n官方英文手册 : https://help.fontlab.com/fontlab/7/manual/\n[toc]\n打开字体 修改字体 您可以使用 contour - create countour controller 轮廓 描边 或其它任意方式实现相同的功能, 这里仅仅提供一种作为参考\n字体标记说明 黑线修改未保存 红线名称不合格 字体加粗方法 菜单栏选择 window - panels - brush, 打开画笔工具窗口 确定图层选择的是当前文字, 点击 set, 拖动笔触大小, 可拖动箭头更改笔触方向, 完成 Expand 最重要的是, 使用画笔描边必须填充空白部分! 快捷键 F 点击文字内空白处 , 避免出现空心字 小技巧 : 按空格键可查看字体效果 字体减细方法 菜单栏选择 window - panels - brush, 打开画笔工具窗口 确定图层选择的是当前文字, 点击 set, 拖动笔触大小, 可拖动箭头更改笔触方向, 完成 Expand 双击图层中的外框, 快捷键 delete 删除 修改字体信息 在字体上右键选择open glyph panel , 修改第一行 , 快捷键enter 保存 修改某个部首 打开图层, 双击某个部首, 添加新图层即可 其余修改参照 2.1 2.2 连笔笔画拆分 快捷键 j 选择刀具, 在合适位置划一刀, 点击节点割断, 快捷键 a 把各自接口重新连接 保存为 TTF 菜单栏 File - Export Font As... 选择 OpenType TT, 修改保存位置等信息, Export根据文件大小稍等时长\n","date":"2020-10-22T00:00:00Z","image":"http://img.golang.space/1598929158698-image-20200901105918160.png","permalink":"https://blog.golang.space/p/fontlab-7-%E7%AE%80%E8%A6%81%E6%96%87%E6%A1%A3/","title":"Fontlab 7 简要文档"},{"content":"Flutter 插件 1 flutter create -t plugin flutter_plugin_demo 1 原生插件(调用 java 或其它语言) 通过 android studio 创建, 包含 java 和 ios 选择 flutter plugin , 纯 dart 选择 flutter package ,\n在 pubspec.yaml 中声明兼容平台\n1 2 3 4 5 6 7 8 9 10 11 12 plugin: platforms: android: package: com.example.flutter_plugin_test pluginClass: FlutterPluginTestPlugin ios: pluginClass: FlutterPluginTestPlugin macos: pluginClass: FlutterPluginTestPlugin web: pluginClass: FlutterPluginTestPlugin fileName: flutter_plugin_test.dart 在 项目名.dart 中创建方法\n调用该方法 进入安卓底层目录, 使用 java 实现数据 参考\nhttps://book.flutterchina.club/chapter12/develop_plugin.html\n2 纯 dart 库 参考\nhttps://book.flutterchina.club/chapter12/develop_package.html\n创建 flutter package 修改 pubspec.yaml 包相关信息, 输入 flutter pub publish --dry-run 测试是否合格 发布见 3 搭建私有仓库\n3 搭建私有仓库 安装 dart 1 2 brew tap dart-lang/dart brew install dart 搭建环境 1 2 3 4 git clone https://github.com/dart-lang/pub_server.git cd pub_server pub get dart example/example.dart -d /tmp/package-db 将项目发布 1 flutter packages pub publish --server=http://localhost:8080 谷歌验证 在浏览器中打开地址, 登录谷歌账户即可\n参考:\n官方提供快速搭建仓库 https://github.com/dart-archive/pub_server\n如何上传插件 https://ejin66.github.io/2019/04/11/flutter_private_pub.html\n","date":"2020-08-04T00:00:00Z","permalink":"https://blog.golang.space/p/flutter-%E5%BC%80%E5%8F%91%E6%8F%92%E4%BB%B6/","title":"Flutter 开发插件"},{"content":"工作流 有 4 种常用工作流\n集中式 功能分支 Git Flow Forking 集中式 本地修改后直接提交到远程 master，有冲突解决冲突。\n团队不建议使用，代码混乱，容易出问题。\n功能分支 功能分支工作流基于集中式工作流演进而来。适合开发团队相对固定，规模较小的项目。\n开发新功能时，基于 master 分支创建一个临时功能分支，在分支上开发，开发完成后合并到 master。\n仅在最后一步合并到 master 分支，使提交历史更简洁 不同的功能分配给不同的开发人员，避免冲突 具体流程 基于 master 创建功能分支\n1 git checkout -b feature/xxx 在分支开发，推送到远程\n1 2 3 git add xxx.go git commit -m \u0026#34;add xxx\u0026#34; git push origin feature/xxx 创建 PR\n代码管理员对代码做 Code Review，审查完成合并到 master\nmerge 有三种方法\nCreate a merge commit，git merge --no-ff，所有 commit 合并成一个，添加到 master。该命令是指强行关闭 fast-forward，但会保存特性分支历史，推荐这种。 Squash and merge，git merge --squash，将不必要的分支上其 commit 压缩合并，创建一个新的提交添加到 master。 Rebase and merge，git rebase，将分支所有 commit 依次添加到 master，属于 fast_forward方式合并。 Git Flow Git Flow 工作流是一个非常成熟的方案，也是非开源项目中最常用到的工作流。适合大型的项目或者迭代速度快的项目。\n5 种分支\n分支名 描述 master 发布状态，禁止开发，每次合并 hotfix/release 要打版本标签 develop 最新代码，禁止开发 feature 研发功能分支，基于 develop，开发完成后合并到 develop 并删除该分支 release 预发布分支，基于 develop，通过测试后合并到 master 和 develop，并删除该分支 hotfix 维护阶段分支，紧急 bug 修复，基于 master 分支创建，完成后合并到 master 和 develop 并删除 Forking 开源项目中，最常用到的是 Forking 工作流。\n假设开发者 A 拥有一个远程仓库，如果开发者 B 也想参与 A 项目的开发，B 可以 fork 一份 A 的远程仓库到自己的 GitHub 账号下，在自己的仓库中修改，完成后向 A 的仓库提交 PR。\n具体流程 fork 仓库\n克隆仓库\n1 2 3 4 5 git clone https://github.com/xxx/kitx cd kitx git remote add upstream https://github.com/ixugo/kitx # 禁止推送到 upstream ，实际上一般也没有权限，因为那并不是你的仓库 git remote set-url --push upstream no_pus 创建功能分支\n1 2 3 4 5 # 要同步 master 最新状态 git fetch upstream git checkout master \u0026amp;\u0026amp; git rebase upstream/master # 创建分支 git checkout -b feature/files 完成开发，提交\n1 2 3 4 5 6 7 # 在特性分支，同步远程仓库最新状态 git fetch upstream \u0026amp;\u0026amp; git rebase upstream/master # 提交代码 git add file.go git commit -m \u0026#34;xxx 功能\u0026#34; # 推送到自己的远程仓库 git push origin feature/files 在 github 自己的仓库那，创建 Pull request。\n参考 Go 语言项目开发实战\nA successful Git branching model\nGit、GitHub、GitLab Flow，傻傻分不清？一图看懂各种分支管理模型\nGit flow 开发指南\ngitflow 是什么，有哪些优缺点？\nGithub 官方文档 pull requests 流程\n","date":"2020-07-22T15:00:00Z","permalink":"https://blog.golang.space/p/git-%E5%B7%A5%E4%BD%9C%E6%B5%81/","title":"Git 工作流"},{"content":"1. 创建项目 https://umijs.org/zh-CN/docs/getting-started\n1 2 3 4 5 6 7 8 9 10 11 # 创建目录 mkdir myapp \u0026amp;\u0026amp; cd myapp # 创建 umijs@3.x 框架 yarn create @umijs/umi-app # 安装依赖 yarn # 启动项目 yarn start # 创建本地配置 echo \u0026#34;import { defineConfig } from \u0026#39;umi\u0026#39;;\u0026#34; \u0026gt; .umirc.local.ts 2. 使用 recoil 状态管理库 https://recoiljs.org/docs/introduction/getting-started\n1 yarn add recoil 使用 RecoilRoot 包裹\n1 2 3 4 5 6 7 8 9 10 11 import React from \u0026#39;react\u0026#39;; import { RecoilRoot } from \u0026#39;recoil\u0026#39;; import styles from \u0026#39;./index.less\u0026#39;; export default function IndexPage() { return ( \u0026lt;RecoilRoot\u0026gt; \u0026lt;h1 className={styles.title}\u0026gt;Page index\u0026lt;/h1\u0026gt; \u0026lt;/RecoilRoot\u0026gt; ); } 3. 安装 UI 框架 1 2 3 yarn add semantic-ui-react semantic-ui-css # 在文件中导入 css import \u0026#39;semantic-ui-css/semantic.min.css\u0026#39; 4. 下拉刷新, 上啦加载 https://github.com/ankeetmaini/react-infinite-scroll-component\nhttps://codesandbox.io/s/yk7637p62z?file=/src/index.js:309-322\n1 2 yarn add react-infinite-scroll-component import InfiniteScroll from \u0026#39;react-infinite-scroll-component\u0026#39;; 其它( 未使用过, 仅在此插件无法使用时,提供更多选择 )\nhttps://github.com/makotot/react-scrollspy\nhttps://github.com/caseywebdev/react-list\nhttps://github.com/danbovey/react-infinite-scroller\n5. 上传图片压缩 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 \u0026lt;Form.Input id=\u0026#34;title\u0026#34; type=\u0026#34;file\u0026#34; multiple error={imageError} accept=\u0026#34;image/*\u0026#34; onChange={(e, data) =\u0026gt; { if (!e.target.files) { return; } if (e.target.files.length \u0026gt; 9) { setImageError(\u0026#39;图片不能超过 9 张\u0026#39;); return; } setImageError(undefined); for (let index = 0; index \u0026lt; e.target.files.length; index++) { const reader = new FileReader(); // 图片加载好执行 reader.onload = function (ev) { // var imgFile = ev \u0026amp;\u0026amp; ev.target \u0026amp;\u0026amp; ev.target.result; //或e.target都是一样的 function setVal(params: any) { if (e \u0026amp;\u0026amp; e.target \u0026amp;\u0026amp; e.target.files) { setImageFiles([ ...imageFiles, { name: e.target.files[index].name, img: String(params), }, ]); } } // 压缩图片并将图片塞入数组 dealImage(String(imgFile), (v: any) =\u0026gt; { setVal(v); }); }; // 读取图片 reader.readAsDataURL(e.target.files[index]); } console.log(imageFiles); }} placeholder=\u0026#34;请输入琴谱地址\u0026#34; // onChange={handleChange} /\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // 通过canvas压缩base64图片 function dealImage(base64: any, callback: any, w: number = 1000) { const newImage = new Image(); const quality = 0.9; // 压缩系数0-1之间 newImage.src = base64; // newImage.setAttribute(\u0026#39;crossOrigin\u0026#39;, \u0026#39;Anonymous\u0026#39;); // url为外域时需要 let imgWidth; let imgHeight; newImage.onload = function () { // @ts-ignore imgWidth = this.width; // @ts-ignore imgHeight = this.height; const canvas = document.createElement(\u0026#39;canvas\u0026#39;); const ctx = canvas.getContext(\u0026#39;2d\u0026#39;) as any; if (Math.max(imgWidth, imgHeight) \u0026gt; w) { if (imgWidth \u0026gt; imgHeight) { canvas.width = w; canvas.height = (w * imgHeight) / imgWidth; } else { canvas.height = w; canvas.width = (w * imgWidth) / imgHeight; } } else { canvas.width = imgWidth; canvas.height = imgHeight; } ctx.clearRect(0, 0, canvas.width, canvas.height); // @ts-ignore ctx.drawImage(this, 0, 0, canvas.width, canvas.height); const newBase64 = canvas.toDataURL(\u0026#39;image/jpeg\u0026#39;, quality); callback(newBase64); }; } 6. toast 1 yarn add react-hot-toast 7 . 部署 如果是在非根目录下，增加 base 属性用于识别路由，增加 publicPath 属性用于识别静态文件地址。\n","date":"2020-07-15T15:00:00Z","permalink":"https://blog.golang.space/p/%E4%BD%BF%E7%94%A8-umi.js-%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE/","title":"使用 umi.js 创建项目"},{"content":"Go 函数式编程 核心概念\n纯函数 函数复合 避免共享状态 避免改变状态 避免副作用 说明 纯函数\n相同的输入总是返回相同的输出 不产生副作用 不依赖于外部状态 1 2 3 4 5 6 7 8 9 // 非函数式 num1,num2 := 2,3 sum := num1 + num2 // 函数式 func add (n1, n2 int) int { return n1 + n2 } sum1 := add(2, 3) 共享状态\n任意变量/对象或者内存空间存在于共享作用域，函数式编程避免共享状态\n避免改变状态\n函数式编程只返回新的值，不修改变量\n副作用\n包括\n改变任何外部变量或对象属性 写入文件 发网络请求 在屏幕调用输出 调用另一个有副作用得很局数 声明式与命令式\n命令式: 大量代码描述来达成期望结果， How to do 声明式: 抽象控制流过程，大量代码描述数据流，What to do 1 2 3 4 5 6 // 命令式 list := []int{1,2,3,4,5} list2 := make([]int,len(list)) for i,v := range list{ list2[i] = v*2 } 1 // 声明式 柯里化\n柯里化是将一个多参数函数转换成多个单参数函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // 柯里化之前 func add(x, y int) int { return x + y } add(1, 2) // 3 // 柯里化之后 func addX(y) func (x) int { return function (x) int { return x + y } } addX(2)(1) // 3 ","date":"2020-05-22T15:00:00Z","permalink":"https://blog.golang.space/p/go-%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/","title":"Go 函数式编程"},{"content":"API design * 表示必须遵守，没有则为建议 请求 提供用于自检的请求 ID 在每个 API 响应中包含一个 Request_ID 标头，并采用 UUID 值填充。通过在客户机、服务器和任何后台服务上记录这些值，它提供了一种跟踪、诊断和调试请求的机制。\n*在请求体中接收序列化的 JSON 在 PUT/PATCH/POST 请求体接收序列化的 JSON，而不是表单编码\n例如\n1 2 3 4 5 6 7 8 9 10 11 12 13 curl -X POST https://service.com/apps \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;demoapp\u0026#34;}\u0026#39; { \u0026#34;id\u0026#34;: \u0026#34;01234567-89ab-cdef-0123-456789abcdef\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;demoapp\u0026#34;, \u0026#34;owner\u0026#34;: { \u0026#34;email\u0026#34;: \u0026#34;username@example.com\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;01234567-89ab-cdef-0123-456789abcdef\u0026#34; }, ... } *REST API 资源名\n资源名使用复数版本，除非所涉及的资源是系统中的单例\n1 2 /user\t# Bad /users # Good Request Method\n资源 POST GET PUT DELETE /users 创建新客户 检索所有客户 批量更新客户 删除所有客户 /users/:id - 检索指定客户 更新指定客户 删除指定客户 POST 创建资源，不应具有不相关的副作用 PUT 更新资源，该请求必须是幂等的。 GET 获取资源 DELETE 删除资源 避免实现琐碎的 POST / PUT / DELETE 操作。\n在实际 API 开发中，有些操作可能不能很好的映射为 REST 资源，如禁言某用户，可以参考以下做法:\n将操作变为资源的属性， /users/id?active=false，缺点是一个接口要处理多种参数组合，尽可能将属性相关的放在一起，不然建议新增一个接口。 下级资源 /users/id/active，通过不同的请求方式决定增删，优点是接口作用明晰，缺点是接口数量会很大，我认为，接口明晰更重要。 以上不能解决，有时可以打破规范，如登录就/login 分页 / 过滤 / 排序 / 搜索 如 /users 列出所有用户，需要提供分页功能。\n滚动翻页，可以使用 /users?limit=10\u0026amp;since=10000 ，since 是前一页最后一条数据的 ID 或序号。\n跳转分页，可以使用 /users?limit=10\u0026amp;page=1，page 表示第几页\n过滤属性，如果用户不需要资源的全部属性，可以在 uri 参数中指定需要哪些，/users?fields=email,username,address\n排序，/users?sort=age desc，/users?sort=id,age desc ，注意 id ，age desc应该与例子中等价，多余的空格可以忽略\n搜索，/users?key=zhangsan\n关于分页的补充\n默认 limit = 20 ， limit \u0026lt; 100，要指定上限防止拒绝服务攻击\n1 2 3 4 type Response struct{ Data any // 分页数据 Next string // 下一页的 since，在请求下一页时应该带上这个参数 } 重复请求 服务端能够通过此ID来检测请求是否重复，保证请求只被处理一次。\n1 2 3 // 用于检测冗余请求的唯一标识符 // 这个字段应该命名为 `request_id` string request_id = ...; 异步操作\n有时，POST、PUT、PATCH 或 DELETE 操作可能需要处理操作需要一段时间才能完成。 如果需要等待该操作完成后才能向客户端发送响应，可能会造成不可接受的延迟。 在这种情况下，请考虑将该操作设置为异步操作。\n应公开一个可返回异步请求状态的终结点，使客户端能够通过轮询状态终结点来监视状态。\n异步请求\n1 2 3 4 5 6 7 GET /service/restart 状态码 : 201 { \u0026#34;url\u0026#34; : \u0026#34;/service/status\u0026#34; } 通过访问 URL 可以知道当前异步执行的状态\nAction 明确以行动前缀详细说明\n1 /resources/:resource/actions/:action 例如停止某一特定的运行:\n1 /runs/{run_id}/actions/stop 对集合的操作也应该最小化。如果需要，应该使用一个顶级的动作延长来避免名称空间冲突，并清楚地显示动作的范围:\n1 /actions/:action/resources 例如重启所有服务器\n1 /actions/restart/servers *一致的路径格式 使用小写和破折号分隔的路径名\n1 2 service-api.com/users service-api.com/app-setups 最小化路径嵌套，优先在资源的父路径上定位资源来限制嵌套深度\n避免超过 2 层的资源嵌套，建议将其它资源 转换为?参数，\n1 2 # Bad /orgs/{org_id}/apps/{app_id}/dynos/{dyno_id} 1 2 3 4 5 6 # Good /orgs/{org_id} /orgs/{org_id}/apps /apps/{app_id} /apps/{app_id}/dynos /dynos/{dyno_id} 响应 *返回适当的状态代码 200 OK 请求成功 400 Bad Request 请求参数有误 401 Unauthorized 用户身份未验证 403 Forbidden 用户没有访问该资源权限 500 Internal Server Error 服务器异常 响应提供全部资源 在响应中尽可能提供完整的资源表示(即包含所有属性的对象)。\n1 2 3 4 5 6 7 8 9 10 11 12 $ curl -X DELETE \\ https://service.com/apps/1f9b/domains/0fd4 HTTP/1.1 200 OK Content-Type: application/json;charset=utf-8 ... { \u0026#34;created_at\u0026#34;: \u0026#34;2012-01-01T12:00:00Z\u0026#34;, \u0026#34;hostname\u0026#34;: \u0026#34;subdomain.example.com\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;01234567-89ab-cdef-0123-456789abcdef\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2012-01-01T12:00:00Z\u0026#34; } 提供资源 UUID 默认情况下为每个资源提供一个 id 属性。除非有充分的理由，否则请使用 uuid。\n1 \u0026#34;id\u0026#34;: \u0026#34;01234567-89ab-cdef-0123-456789abcdef\u0026#34; 提供标准时间戳 只接受和返回 UTC ( 世界标准时间 )时间。以 ISO8601格式呈现时间。\n1 2 3 4 5 6 { // ... \u0026#34;created_at\u0026#34;: \u0026#34;2012-01-01T12:00:00Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2012-01-01T13:00:00Z\u0026#34;, // ... } *提供标准的响应类型 当为 null 时，可以忽略该参数\n字符串 string || null 布尔 false || true 数字 number || null ，注意:一些 JSON 解析器将返回精度超过15位的数字作为字符串。 数组 [] ， 没有值时返回空数组 对象 object || null *使用嵌套对象序列化 1 2 3 4 5 6 # Bad { \u0026#34;name\u0026#34;: \u0026#34;service-production\u0026#34;, \u0026#34;owner_id\u0026#34;: \u0026#34;5d8201b0...\u0026#34;, // ... } 1 2 3 4 5 6 7 8 # Good { \u0026#34;name\u0026#34;: \u0026#34;service-production\u0026#34;, \u0026#34;owner\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;5d8201b0...\u0026#34; }, // ... } 这种方法可以在不改变响应结构或引入更多顶级响应字段的情况下内联更多关于相关资源的信息，例如:\n1 2 3 4 5 6 7 8 { \u0026#34;name\u0026#34;: \u0026#34;service-production\u0026#34;, \u0026#34;owner\u0026#34;: { \u0026#34;id\u0026#34;: \u0026#34;5d8201b0...\u0026#34;, \u0026#34;email\u0026#34;: \u0026#34;alice@heroku.com\u0026#34; }, // ... } 注意要为子集提供唯一值，避免不一致和混淆，如 id 字段\n*生成结构化错误 对错误生成一致的，结构化的响应。\n包括一个机器可读的错误 ID，可以通过该 ID 判断出哪类错误，字段用 code 表示。 包括一个用户可读的错误消息，以及错误详情，如有需要可以增加URL ，向客户端提示如何解决错误的地址。 http 的状态码不要使用太多，建议需要以下3个\n200 - 请求成功 400 - 发生错误 401 - 未登录或身份令牌过期 导致的身份验证失败 经过更多的实验与学习，认为 英文错误码 比 数字错误码 更适合大多数场景，以下方案仅供了解\nCode 设计规范，纯数字表示，如10101，1 开头的通用模块适合所有项目，其它数字开头的业务错误针对业务设计。\n1，通用 01，资源模块 01，错误码序号，比如该序号表示请求频繁 服务 模块 说明 1 01 通用 - 基本错误 1 02 通用 - 数据库类错误 1 03 通用 - 认证授权类错误 1 04 通用 - 编解码类错误 2 01 用户服务 - 历史登录模块 HTTP 状态码 错误码 说明 200 0 实际上也无需返回 code，正常返回业务数据即可 400 10101 未知错误 400 10102 请求参数有误 400 10201 SQL 语法错误 401 10301 token 验证失败 400 10302 操作了不属于自己的资源 400 10401 json 编解码出错 400 20101 记录用户登录出错 错误信息规范 对外暴露的错误要简介，能准确说明问题 错误说明，应该是该怎么做，而不是哪里错了。 错误中不能出现敏感的信息，比如数据库的错误提示，用户某某资源提示 1 2 3 4 5 6 7 HTTP/1.1 400 Bad Requests { \u0026#34;code\u0026#34;: 10101, \u0026#34;msg\u0026#34;: \u0026#34;Account reached its API rate limit.\u0026#34;, \u0026#34;details\u0026#34;: [] } 速率限制 速率限制来自客户的请求，以保护服务的健康和维护其他客户的高服务质量。您可以使用令牌桶算法来量化请求限制。可以在 RateLimit-Remaining response header 中返回每个请求的请求标记的剩余数量。\n在所有回复中保持 JSON 的简化 额外的空白为请求增加了不必要的响应大小，最好尽量减少 JSON 响应。\n1 2 3 4 5 # Bad { \u0026#34;beta\u0026#34;: false, \u0026#34;email\u0026#34;: \u0026#34;alice@heroku.com\u0026#34; } 1 2 # Good {\u0026#34;beta\u0026#34;:false,\u0026#34;email\u0026#34;:\u0026#34;alice@heroku.com\u0026#34;} 对于项目要求 提供团队可读的文档\n提供可执行的示例\n参考 Google API 设计指南\n了解更多 RESTful API 设计 Heroku RESTful API Design\nMicrosoft RESTful API 设计\nGithub RESTful API 设计\n","date":"2020-05-21T00:00:00Z","permalink":"https://blog.golang.space/p/restful-api-%E8%AE%BE%E8%AE%A1%E6%8C%87%E5%8D%97/","title":"RESTful API 设计指南"},{"content":"Redis 参考文档 :　http://redisdoc.com/\n[toc]\n一 linux 的环境软件安装 1 2 3 4 5 6 # 安装 服务器端 sudo apt-get install redis-server # 检查服务器系统进程 ps -agx | grep redis # 通过命令行访问 redis-cli 尝试操作\n解决中文乱码, 启动时加参数 --raw\n1 redis-cli --raw # 可解决部分交互环境中出现的中文乱码问题 redis 安装完毕, 默认有 16 个数据库, 初始默认使用 0 号库, 编号 0,1,2\u0026hellip;15\n1 2 3 4 5 6 7 8 9 10 # 小试牛刀 set key1 value # 增加一条记录 # 如果 value 是数字类型,可以自增 INCR key1 # 即+1操作 get key1 # 获取对应的值 select 1 # 切换数据库 keys * # 查看当前库所有 key dbsize # 查看当前 key-val 数量 flushdb # 清空当前数据库的key-val flushall # 清空所有数据库的key-val 2. 基础知识 一般电商场景解决方案\n适用场景\nredis 存储的是 key,value 格式数据\n其中的 key 都是字符串, value 有 ==5== 大数据类型\n字符串类型\n哈希类型 hash:map\n列表类型 list: linkedlist格式,支持重复元素\n集合类型 set : 不允许重复元素且无序\n有序集合类型 sortedset: 不允许重复元素,且元素有序\n2.1. 使用 help 了解命令 1 help incr 2.2. string 类型 单个操作\n1 2 3 4 5 set key value # set 如果key存在则修改, 不在则添加 get key # get 获取 del key # del 删除 strlen key # 获取字符串长度 append key value # 存储则追加，否则新建，返回追加后的长度 多个操作\n1 2 mset mess1 北京 mess2 天安门 # mset 同时设置一个或多个 key-value mget mess1 mess2 # mget 同时获取多个值 扩展操作\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 增 incr key\t# +1，返回+1 后的值 incrby key increment\t# +increment incrbyfloat key increment\t# 浮点操作 # 减 decr key\t# -1 decrby key increment\t# -increment # 有效时间 setex message 10 北京天安门 # setex(set with expire) 设置有效时间为 10 秒 psetex key 10 故宫 # 设置有效期 10 毫秒 # 仅当值不存在时，写入 setnx key 13 操作注意事项\n应用场景\n2.3. hash 类型 对一系列数据编组，方便管理，典型应用存储对象信息 底层使用 哈希表结构实现数据存储 单个操作\n1 2 3 4 5 6 hset key age 15 # json 是这样表示 { \u0026#34;mess\u0026#34;: { \u0026#34;age\u0026#34;:15 } } hset key name lucy # json 是这样表示 { \u0026#34;mess\u0026#34;: { \u0026#34;age\u0026#34;:\u0026#34;15\u0026#34;, \u0026#34;name\u0026#34;:\u0026#34;locy\u0026#34; } } hget key field # 获取 hdel key field1 [field2] # 删除 hgetall key # 获取所有的键值对 多个操作\n1 2 3 4 5 6 7 8 # 添加/修改 hmset key field1 value1 field2 value2 # 获取 hmget key field1 field2 # 获取表中字段数量 hlen key # 是否存在指定的字段 hexists key field 扩展操作\n1 2 3 4 5 6 7 8 9 10 # 获取所有 key 或 value hkeys key hvals key # 设置指定字段的数值增加指定范围的值 hincrby key field increment hincrbyfloat key field increment # 仅仅当字段不存在时设置该值 hsetnx key age 11 注意事项\n应用场景\n3 list 类型 redis 列表是简单的字符串列表, 按照插入顺序排序, 可以添加元素到头部或者尾部 (即 队列)\n该类型底层实现是双向链表\n1 2 3 4 5 6 7 8 9 10 # 添加 lpush key value # 左边添加 rpush key value # 右边添加 # 获取 lrange key start end # 范围获取 lrange key 0 -1 # 获取所有元素 # 删除 lpop key # 弹出列表左边一个元素并返回 rpop key # 弹出列表左边一个元素并返回 brpop key 5 # 弹出元素, 若是没有,最多等待5秒 扩展操作\n1 2 3 4 5 6 7 # 规定时间内获取并移除元素 # 阻塞从链表获取数据，当链表为空时。等待最大时间内，入值就取出来 blpop key1 [key2] timeout brpop key1 [key2] timeout # 移除指定数据 lrem key count value 应用场景\n4 set 类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 存储 sadd key member1 [member2] # 获取 SMEMBERS key # 获取 set 集合中所有元素 # 删除 SREM key member1 [member2] # 删除 set 集合中的某个元素 # 获取集合数据总量 scard key # 判断集合中是否包含指定数据 sismember key member # 随机获取集合中指定的数量的数据 srandmember key [count] # 随机将数据移除集合 spop key 适合应用于随机推荐类信息检索，热点歌单推荐/热点新闻推荐/热卖商品/大 V 推荐/\n注意事项\nset 类型不允许数据重复，如果添加的数据在 set 中已存在，将只保留一份 set 虽然与 hash 的存储结构相同，但是无法启用 hash 中存储值的空间 应用场景\n依赖 set 集合数据不重复的特征 根据用户 ID 获取用户所有角色 根据用户所有角色获取用户所有操作权限 根据用户所有角色获取用户的所有数据 5 有序集合 ( sorted_set ) 有序/不允许重复/String类型\n每个元素都关联一个 double 类型的数, 根据此数排序\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 添加 ZADD key score value [score2 value2] # 获取 zrange key start end zrange key 0 -1 withscores # 显示数据同时显示分数 zrange key 0 -1 # 获取全部数据 zrevrange key start stop # 倒序 # 删除 zrem key value # 按条件获取数据 zrangebyscore key min max [withscores] [limit] zrevrangebyscore key max min [withscores] # 按条件删除数据 zremrangebyrank key start stop zremrangebyscore key min max # 获取集合数据总量 zcard key zcount key min max # 集合交/并操作 zinterstore destination numkeys key [key ...] zunionstore destination numkeys key [key ...] # 适合做动态排行榜 注意:\nmin 与 max 用于限定搜索查询的条件 start 与 stop 用于限定查询范围，作用于索引，表示开始和结束索引 offset 与 count 用于限定查询范围，作用于查询结果，表示开始位置和数据总量 通用命令 1 2 3 4 keys * # 查询所有的键(可匹配正则) type key # 查询值的类型 del key # 删除指定的 key and value EXPIRE mess 10 // 设置 键为 mess 的元素 有效时间为 10 秒 持久化 redis 是一个内存数据库, 当 redis 服务器重启, 或者电脑重启, 数据会丢失, 可以将内存中的数据持久化保存到硬盘上\nredis 持久化机制( 分别以 reb 和 aof 结尾 ):\nRDB 默认方式, 不需要进行配置 在一定间隔时间中,检测 key 的变化情况, 然后持久化数据( 见图1 图2) AOF 日志记录的方式, 可以记录每一条命令的操作, 可以每一次命令操作好持久化数据 ( 图3 图4) 即每一次操作都写入文件 Go 使用 Redis 导入第三方包 : \u0026quot;github.com/garyburd/redigo/redis\u0026quot;\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 // // Author: leafsoar // Date: 2017-05-04 16:29:03 // package redic import ( \u0026#34;time\u0026#34; \u0026#34;github.com/garyburd/redigo/redis\u0026#34; ) // Client 客户端 type Client struct { pool *redis.Pool } // NewRedisClient 创建客户端 func NewRedisClient(addr string) *Client { ret := \u0026amp;Client{ pool: \u0026amp;redis.Pool{ MaxIdle: 3, MaxActive: 1000, IdleTimeout: time.Second * 180, Dial: func() (redis.Conn, error) { // fmt.Println(\u0026#34;new redis conn ...\u0026#34;) c, err := redis.Dial(\u0026#34;tcp\u0026#34;, addr) if err != nil { return nil, err } _, _ = c.Do(\u0026#34;select\u0026#34;, 0) return c, nil }, }, } return ret } // Close 关闭所有链接 func (c *Client) Close() { c.pool.Close() } func (c *Client) do(commandName string, args ...interface{}) (reply interface{}, err error) { rc := c.pool.Get() reply, err = rc.Do(commandName, args...) _ = rc.Close() return } // Do 操作 func (c *Client) Do(commandName string, args ...interface{}) (reply interface{}, err error) { return c.do(commandName, args...) } // Set 设置值 func (c *Client) Set(key, value string) (err error) { _, err = c.do(\u0026#34;SET\u0026#34;, key, value) return } // Expire 失效 func (c *Client) Expire(key string, second int) (err error) { _, err = c.do(\u0026#34;EXPIRE\u0026#34;, key, second) return err } // Get 获取值 func (c *Client) Get(key string) (string, error) { return redis.String(c.do(\u0026#34;GET\u0026#34;, key)) } // Del 删除 func (c *Client) Del(key string) (err error) { _, err = c.do(\u0026#34;DEL\u0026#34;, key) return err } // Push 队列 func (c *Client) Push(key string, value interface{}) (err error) { _, err = c.do(\u0026#34;lpush\u0026#34;, key, value) return } // Pop 默认为 list 的 brpop 操作 func (c *Client) Pop(key string, fn func(string, error)) { for { func() { time.Sleep(time.Millisecond * 800) rc := c.pool.Get() defer func() { _ = rc.Close() }() for { ret, err := redis.Strings(rc.Do(\u0026#34;brpop\u0026#34;, key, 5)) if err == redis.ErrNil { return } else if err != nil { fn(\u0026#34;\u0026#34;, err) return } fn(ret[1], nil) } }() } } // PopByte 默认为 list 的 brpop 操作 func (c *Client) PopByte(key string, fn func([]byte, error)) { for { func() { time.Sleep(time.Millisecond * 800) rc := c.pool.Get() defer func() { _ = rc.Close() }() for { ret, err := redis.ByteSlices(rc.Do(\u0026#34;brpop\u0026#34;, key, 5)) if err == redis.ErrNil { return } else if err != nil { fn(nil, err) return } fn(ret[1], nil) } }() } } 一 连接池 二 字符串 set/get incr 计数器 用于防止表单重复提交等问题\n类似效果的有 singleFight ，其间隔时间为执行完当前函数\n计数器可以通过设置过期时间，来延长提交间隔，一般 1 / 2 即可\n1 2 3 4 5 6 7 8 9 10 11 r, err := uc.Do(\u0026#34;incr\u0026#34;, \u0026#34;123\u0026#34;) if err != nil { fmt.Println(err) } k, _ := r.Result() // 业务 if k.(int64) \u0026gt; 1 { return } uc.Do(\u0026#34;EXPIRE\u0026#34;, \u0026#34;123\u0026#34;, 2) fmt.Println(\u0026#34;开始业务\u0026#34;, id) 封装计数器\n此封装并未实现幂等，\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func Incr(k string, s int, fn func() (interface{}, error)) (interface{}, error) { r, err := uc.Do(\u0026#34;incr\u0026#34;, k) if err != nil { return nil, err } count, _ := r.Result() if count.(int64) != 1 { return nil, nil } _, err = uc.Do(\u0026#34;expire\u0026#34;, s) if err != nil { return nil, err } return fn() } 测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func TestDemo(t *testing.T) { if uc == nil { return } var wg sync.WaitGroup for i := 0; i \u0026lt; 1000; i++ { wg.Add(1) go func(i int) { defer wg.Done() Incr(\u0026#34;123\u0026#34;, 2, func() (interface{}, error) { fmt.Println(\u0026#34;123\u0026#34;) return nil, nil }) }(i) } wg.Wait() } ","date":"2020-05-15T00:00:00Z","permalink":"https://blog.golang.space/p/redis-%E5%9F%BA%E7%A1%80/","title":"Redis 基础"},{"content":"设置自增 ID 随机步长，此方式使用触发器实现，每次获取自增 id 后，再随机多获取几个自增值扔掉。\n以下仅仅是从数据库的角度考虑如何解决问题，并不是最优解决方案，也不推荐使用。\n优点 资源消耗小 用户无法通过注册新账号获取自增 ID 来猜测数据总量 ( 使用固定步长，也容易被用户发现规律 ) 避免爬虫自增，拉取大量用户数据 ( 通过网关设置，判断相同 ip 连续打空，封 IP 地址 ) 当你需要更安全，或自增 ID 已不满足你的需求时，应该考虑 雪花 ID 和 UUID。\n方法 创建表\n1 2 3 CREATE TABLE test ( id SERIAL -- 主键。自增序列，默认名序列名 test_id_seq ) 设置序列开始值，建议 6 位数开始\n或者从 任意自然数 开始，建议预留一定的位置，用于数据库管理员塞入默认数据。\n1 SELECT setval(\u0026#39;test_id_seq\u0026#39;,100000,FALSE) 查询一下，下一个 ID 是不是设定的值\n1 SELECT nextval(\u0026#39;test_id_seq\u0026#39;::regclass) 设置触发器函数，当你的主键名并非 id 时，需要修改一下函数内 id 为你的主键名\n执行此函数会随机扔掉 1-9 个自增数值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 CREATE OR REPLACE FUNCTION seq_func() RETURNS TRIGGER AS $body$ DECLARE -- 获取随机数 r INTEGER := (random()*8)::INTEGER+1; t INTEGER := 1; -- 获取序列名 seq_name VARCHAR := pg_get_serial_sequence(TG_TABLE_NAME,\u0026#39;id\u0026#39;); BEGIN -- raise notice \u0026#39;name:%s\u0026#39;,seq_name; WHILE t\u0026lt;=r LOOP PERFORM nextval(seq_name::regclass); t=t+1; END LOOP; RETURN NEW; END; $body$ LANGUAGE plpgsql; 创建触发器，在插入数据完成后执行。 此处加了一个条件，当插入 ID 小于序列自增起始值时，不触发。小于自增起始值时，一般为数据库管理员手动插入默认数据。\nsql 内的 1000000 需要修改为起始值。\n1 2 3 4 5 6 7 8 9 -- 创建触发器 CREATE TRIGGER test_id_seq_insert_trigger AFTER INSERT ON test FOR EACH ROW WHEN (NEW.id \u0026gt; 100000) EXECUTE FUNCTION seq_func(); -- 删除触发器 DROP TRIGGER IF EXISTS test_id_seq_insert ON test; 如果有多个表，仅需要改动 触发器名称 及 表名\n1 2 3 4 5 6 7 8 9 10 11 12 13 -- 创建第二张表 create table example( id SERIAL ) -- 设置序列起始值，注意此处已更换 序列名称 SELECT setval(\u0026#39;temp_id_seq\u0026#39;,100000,FALSE) -- 设置触发器，注意此处已更换 触发器名 和 表名 CREATE TRIGGER example_id_seq_insert_trigger AFTER INSERT ON example FOR EACH ROW WHEN (NEW.id \u0026gt; 100000) EXECUTE FUNCTION seq_func(); -- 相关测试，检查是否设置成功 并发测试 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func TestInsertTest(t *testing.T) { var ( wg sync.WaitGroup ids = make([]int, 100) ) // 并发插入 100 条数据，获取 100 个自增 ID for i := 0; i \u0026lt; 100; i++ { wg.Add(1) go func(i int) { defer wg.Done() r := new(Test) r.K = strconv.Itoa(i) _, err := db.InsertOne(r) if err != nil { require.NoError(t, err) } ids[i] = r.ID }(i) } wg.Wait() // 排序后，输出 sort.Ints(ids) for _, v := range ids { fmt.Println(\u0026#34;id : \u0026#34;, v) } } 结果\n1 2 3 4 5 6 7 8 9 10 11 12 13 id : 1000000 id : 1000001 id : 1000011 id : 1000012 id : 1000013 id : 1000014 id : 1000019 id : 1000036 id : 1000048 id : 1000057 id : 1000068 id : 1000069 ...... ","date":"2020-05-01T12:00:00Z","permalink":"https://blog.golang.space/p/%E5%BA%8F%E5%88%97%E8%87%AA%E5%A2%9E%E6%AD%A5%E9%95%BF/","title":"序列自增步长"},{"content":"React 开发基础 1.0 受控组件 1.1 父组件向子组件单向传值 1 2 3 renderSquare(i) { return \u0026lt;Square value={i}/\u0026gt;; } 子组件 Square\n1 2 3 4 5 class Square extends React.Component { render() { return \u0026lt;button className=\u0026#34;square\u0026#34;\u0026gt;{this.props.value}\u0026lt;/button\u0026gt;; } } 说明: 父组件使用属性方式传值过去, 子组件直接 props 接收\n1.2 子组件向父组件传值 子组件通过 props 调用 父类的方法, 将数据通过方法参数传递过去\n1 2 3 \u0026lt;button className=\u0026#34;square\u0026#34; onClick={() =\u0026gt; this.props.onClick.bind(this, this.state.value)}\u0026gt; {this.props.value} \u0026lt;/button\u0026gt; 父组件, 调用子组件时传递函数\n1 2 3 4 5 6 7 8 9 10 renderSquare(i) { return ( \u0026lt;Square value={this.state.squares[i]} onClick={() =\u0026gt; this.handleClick(i)} /\u0026gt; ); handleClick(i) { const squares = this.state.squares.slice(); squares[i] = \u0026#39;X\u0026#39;; this.setState({squares: squares}); } 注意在 handleClick 方法中调用了 slice 方法进行数组赋值, 为什么要这么做, 而不是在原数组中改变呢?\n不直接在源数据上修改, 可以跟踪到数据的改变 , 同时确定了\n1.2 函数组件\n1 2 3 4 5 6 7 function Square(props) { return ( \u0026lt;button className=\u0026#34;square\u0026#34; onClick={props.onClick}\u0026gt; {props.value} \u0026lt;/button\u0026gt; ); } 1.2 如何阻止默认行为 1 2 3 4 5 6 7 8 9 10 11 12 function ActionLink() { function handleClick(e) { e.preventDefault(); // 阻止默认行为 console.log(\u0026#39;The link was clicked.\u0026#39;); } return ( \u0026lt;a href=\u0026#34;#\u0026#34; onClick={handleClick}\u0026gt; Click me \u0026lt;/a\u0026gt; ); } 1.3 函数事件绑定 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Toggle extends React.Component { constructor(props) { super(props); this.state = { isToggleOn: true }; // 为了在回调中使用 `this`，这个绑定是必不可少的 this.handleClick = this.handleClick.bind(this); } handleClick() { this.setState(state =\u0026gt; ({ isToggleOn: !state.isToggleOn })); } render() { return \u0026lt;button onClick={this.handleClick}\u0026gt;{this.state.isToggleOn ? \u0026#39;ON\u0026#39; : \u0026#39;OFF\u0026#39;}\u0026lt;/button\u0026gt;; } } 通常情况下，如果你没有在方法后面添加 ()，例如 onClick={this.handleClick}，你应该为这个方法绑定 this。\n向事件处理程序传递参数, 两种方式等价\n1 2 \u0026lt;button onClick={(e) =\u0026gt; this.deleteRow(id, e)}\u0026gt;Delete Row\u0026lt;/button\u0026gt; // 显式传递 \u0026lt;button onClick={this.deleteRow.bind(this, id)}\u0026gt;Delete Row\u0026lt;/button\u0026gt; // 隐式传递 1.4 使用条件运算符条件渲染 1.4.1 IF 1 2 3 4 5 6 7 function Greeting(props) { const isLoggedIn = props.isLoggedIn; if (isLoggedIn) { return \u0026lt;UserGreeting /\u0026gt;; } return \u0026lt;GuestGreeting /\u0026gt;; } 1.4.2 \u0026amp;\u0026amp; 1 2 3 4 5 6 7 8 9 function Mailbox(props) { const unreadMessages = props.unreadMessages; return ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Hello!\u0026lt;/h1\u0026gt; {unreadMessages.length \u0026gt; 0 \u0026amp;\u0026amp; \u0026lt;h2\u0026gt;You have {unreadMessages.length} unread messages.\u0026lt;/h2\u0026gt;} \u0026lt;/div\u0026gt; ); } 1.4.3 阻止渲染 return 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 function WarningBanner(props) { if (!props.warn) { return null; } return \u0026lt;div className=\u0026#34;warning\u0026#34;\u0026gt;Warning!\u0026lt;/div\u0026gt;; } class Page extends React.Component { constructor(props) { super(props); this.state = { showWarning: true }; this.handleToggleClick = this.handleToggleClick.bind(this); } handleToggleClick() { this.setState(state =\u0026gt; ({ showWarning: !state.showWarning })); } render() { return ( \u0026lt;div\u0026gt; \u0026lt;WarningBanner warn={this.state.showWarning} /\u0026gt; \u0026lt;button onClick={this.handleToggleClick}\u0026gt;{this.state.showWarning ? \u0026#39;Hide\u0026#39; : \u0026#39;Show\u0026#39;}\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; ); } } 1.5 生命周期 1 2 3 componentDidMount(){} // 渲染后 componentDidUpdate(){} // 更新时 componentWillUnmount(){} // 销毁时 1.6 列表 列表需要制定 key 值, key 唯一. 当不指定时默认以下标作为 key , 会出现警告提示\nkey 应在数组上下文中指定\n1 2 3 4 5 6 7 8 9 10 11 12 13 function ListItem(props) { // 正确！这里不需要指定 key： return \u0026lt;li\u0026gt;{props.value}\u0026lt;/li\u0026gt;; } function NumberList(props) { const numbers = props.numbers; const listItems = numbers.map(number =\u0026gt; ( // 正确！key 应该在数组的上下文中被指定 \u0026lt;ListItem key={number.toString()} value={number} /\u0026gt; )); return \u0026lt;ul\u0026gt;{listItems}\u0026lt;/ul\u0026gt;; } 1.7 表单-受控组件 https://zh-hans.reactjs.org/docs/forms.html\n1.7.1 input 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class NameForm extends React.Component { constructor(props) { super(props); this.state = { value: \u0026#39;\u0026#39; }; this.handleChange = this.handleChange.bind(this); this.handleSubmit = this.handleSubmit.bind(this); } handleChange(event) { this.setState({ value: event.target.value }); } handleSubmit(event) { alert(\u0026#39;提交的名字: \u0026#39; + this.state.value); event.preventDefault(); } render() { return ( \u0026lt;form onSubmit={this.handleSubmit}\u0026gt; \u0026lt;label\u0026gt; 名字: \u0026lt;input type=\u0026#34;text\u0026#34; value={this.state.value} onChange={this.handleChange} /\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; ); } } 1.7.2 textarea 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class EssayForm extends React.Component { constructor(props) { super(props); this.state = { value: \u0026#39;请撰写一篇关于你喜欢的 DOM 元素的文章.\u0026#39; }; this.handleChange = this.handleChange.bind(this); this.handleSubmit = this.handleSubmit.bind(this); } handleChange(event) { this.setState({ value: event.target.value }); } handleSubmit(event) { alert(\u0026#39;提交的文章: \u0026#39; + this.state.value); event.preventDefault(); } render() { return ( \u0026lt;form onSubmit={this.handleSubmit}\u0026gt; \u0026lt;label\u0026gt; 文章: \u0026lt;textarea value={this.state.value} onChange={this.handleChange} /\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; ); } } 1.7.3 select 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class FlavorForm extends React.Component { constructor(props) { super(props); this.state = { value: \u0026#39;coconut\u0026#39; }; this.handleChange = this.handleChange.bind(this); this.handleSubmit = this.handleSubmit.bind(this); } handleChange(event) { this.setState({ value: event.target.value }); } handleSubmit(event) { alert(\u0026#39;你喜欢的风味是: \u0026#39; + this.state.value); event.preventDefault(); } render() { return ( \u0026lt;form onSubmit={this.handleSubmit}\u0026gt; \u0026lt;label\u0026gt; 选择你喜欢的风味: \u0026lt;select value={this.state.value} onChange={this.handleChange}\u0026gt; \u0026lt;option value=\u0026#34;grapefruit\u0026#34;\u0026gt;葡萄柚\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;lime\u0026#34;\u0026gt;酸橙\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;coconut\u0026#34;\u0026gt;椰子\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;mango\u0026#34;\u0026gt;芒果\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; ); } } 1.8 约定: 自定义组件以大写字母开头 react 认为小写的 tag 是原生 dom 节点 大写字母开头为自定义组件\n1.9 生命周期 getDerivedStateFromProp 适合表单初始化 componentDidMount 适合资源加载, 发起 ajax 请求 componeWillUnmount 组件移除时调用, 释放资源 getSnapshotBeforeUpdate render 之前调用, 获取 render 之前的状态 componentDidUpdate ui 更新时被调用, 页面需要 prop 变化时重新获取数据 showldComponentUpdate 性能优化 1.9.1 demo 来了新消息保证位置不变 新数据会重新渲染界面, 就会导致高度不断增加, 滚动条根据消息变化, 在 render 之前获取高度, 更新时加上差值\n2 HOOK 1 2 3 4 5 6 7 8 9 10 import React,{useState} from \u0026#39;react\u0026#39;; const [count,setCount] = useState(0); render(){ return ( \u0026lt;h2\u0026gt;{count} \u0026lt;/h2\u0026gt; \u0026lt;buttton onClick={ ()=\u0026gt;setCount(count+1) }\u0026gt; change\u0026lt;/button\u0026gt; ); } ANT 1.0 安装 1 2 3 4 5 npm create umi // 选择模板 app // 空格选择功能, npm install npm run start Typescript 语法 1.0 安装 1 sudo npm i typescript -g 1.3 函数事件绑定 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Toggle extends React.Component { constructor(props) { super(props); this.state = { isToggleOn: true }; // 为了在回调中使用 `this`，这个绑定是必不可少的 this.handleClick = this.handleClick.bind(this); } handleClick() { this.setState(state =\u0026gt; ({ isToggleOn: !state.isToggleOn })); } render() { return \u0026lt;button onClick={this.handleClick}\u0026gt;{this.state.isToggleOn ? \u0026#39;ON\u0026#39; : \u0026#39;OFF\u0026#39;}\u0026lt;/button\u0026gt;; } } 通常情况下，如果你没有在方法后面添加 ()，例如 onClick={this.handleClick}，你应该为这个方法绑定 this。\n向事件处理程序传递参数, 两种方式等价\n1 2 \u0026lt;button onClick={(e) =\u0026gt; this.deleteRow(id, e)}\u0026gt;Delete Row\u0026lt;/button\u0026gt; // 显式传递 \u0026lt;button onClick={this.deleteRow.bind(this, id)}\u0026gt;Delete Row\u0026lt;/button\u0026gt; // 隐式传递 1.4 使用条件运算符条件渲染 1.4.1 IF 1 2 3 4 5 6 7 function Greeting(props) { const isLoggedIn = props.isLoggedIn; if (isLoggedIn) { return \u0026lt;UserGreeting /\u0026gt;; } return \u0026lt;GuestGreeting /\u0026gt;; } 1.4.2 \u0026amp;\u0026amp; 1 2 3 4 5 6 7 8 9 function Mailbox(props) { const unreadMessages = props.unreadMessages; return ( \u0026lt;div\u0026gt; \u0026lt;h1\u0026gt;Hello!\u0026lt;/h1\u0026gt; {unreadMessages.length \u0026gt; 0 \u0026amp;\u0026amp; \u0026lt;h2\u0026gt;You have {unreadMessages.length} unread messages.\u0026lt;/h2\u0026gt;} \u0026lt;/div\u0026gt; ); } 1.4.3 阻止渲染 return 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 function WarningBanner(props) { if (!props.warn) { return null; } return \u0026lt;div className=\u0026#34;warning\u0026#34;\u0026gt;Warning!\u0026lt;/div\u0026gt;; } class Page extends React.Component { constructor(props) { super(props); this.state = { showWarning: true }; this.handleToggleClick = this.handleToggleClick.bind(this); } handleToggleClick() { this.setState(state =\u0026gt; ({ showWarning: !state.showWarning })); } render() { return ( \u0026lt;div\u0026gt; \u0026lt;WarningBanner warn={this.state.showWarning} /\u0026gt; \u0026lt;button onClick={this.handleToggleClick}\u0026gt;{this.state.showWarning ? \u0026#39;Hide\u0026#39; : \u0026#39;Show\u0026#39;}\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; ); } } 1.5 生命周期 1 2 3 componentDidMount(){} // 渲染后 componentDidUpdate(){} // 更新时 componentWillUnmount(){} // 销毁时 1.6 列表 列表需要制定 key 值, key 唯一. 当不指定时默认以下标作为 key , 会出现警告提示\nkey 应在数组上下文中指定\n1 2 3 4 5 6 7 8 9 10 11 12 13 function ListItem(props) { // 正确！这里不需要指定 key： return \u0026lt;li\u0026gt;{props.value}\u0026lt;/li\u0026gt;; } function NumberList(props) { const numbers = props.numbers; const listItems = numbers.map(number =\u0026gt; ( // 正确！key 应该在数组的上下文中被指定 \u0026lt;ListItem key={number.toString()} value={number} /\u0026gt; )); return \u0026lt;ul\u0026gt;{listItems}\u0026lt;/ul\u0026gt;; } 1.7 表单-受控组件 https://zh-hans.reactjs.org/docs/forms.html\n1.7.1 input 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class NameForm extends React.Component { constructor(props) { super(props); this.state = { value: \u0026#39;\u0026#39; }; this.handleChange = this.handleChange.bind(this); this.handleSubmit = this.handleSubmit.bind(this); } handleChange(event) { this.setState({ value: event.target.value }); } handleSubmit(event) { alert(\u0026#39;提交的名字: \u0026#39; + this.state.value); event.preventDefault(); } render() { return ( \u0026lt;form onSubmit={this.handleSubmit}\u0026gt; \u0026lt;label\u0026gt; 名字: \u0026lt;input type=\u0026#34;text\u0026#34; value={this.state.value} onChange={this.handleChange} /\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; ); } } 1.7.2 textarea 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class EssayForm extends React.Component { constructor(props) { super(props); this.state = { value: \u0026#39;请撰写一篇关于你喜欢的 DOM 元素的文章.\u0026#39; }; this.handleChange = this.handleChange.bind(this); this.handleSubmit = this.handleSubmit.bind(this); } handleChange(event) { this.setState({ value: event.target.value }); } handleSubmit(event) { alert(\u0026#39;提交的文章: \u0026#39; + this.state.value); event.preventDefault(); } render() { return ( \u0026lt;form onSubmit={this.handleSubmit}\u0026gt; \u0026lt;label\u0026gt; 文章: \u0026lt;textarea value={this.state.value} onChange={this.handleChange} /\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; ); } } 1.7.3 select 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 class FlavorForm extends React.Component { constructor(props) { super(props); this.state = { value: \u0026#39;coconut\u0026#39; }; this.handleChange = this.handleChange.bind(this); this.handleSubmit = this.handleSubmit.bind(this); } handleChange(event) { this.setState({ value: event.target.value }); } handleSubmit(event) { alert(\u0026#39;你喜欢的风味是: \u0026#39; + this.state.value); event.preventDefault(); } render() { return ( \u0026lt;form onSubmit={this.handleSubmit}\u0026gt; \u0026lt;label\u0026gt; 选择你喜欢的风味: \u0026lt;select value={this.state.value} onChange={this.handleChange}\u0026gt; \u0026lt;option value=\u0026#34;grapefruit\u0026#34;\u0026gt;葡萄柚\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;lime\u0026#34;\u0026gt;酸橙\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;coconut\u0026#34;\u0026gt;椰子\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;mango\u0026#34;\u0026gt;芒果\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;提交\u0026#34; /\u0026gt; \u0026lt;/form\u0026gt; ); } } Redux 数据管理 state 数据 store 仓库 action 修改 state reducer 触发 action 进行修改 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // project \u0026gt; index.js import { createStore } from \u0026#39;redux\u0026#39;; const counterReducer = (state = 0, action) =\u0026gt; { switch (action.type) { case \u0026#39;INCREMENT\u0026#39;: return state + 1; default: return state; } }; const store = createStore(counterReducer); console.log(store.getState()); // 指派动作 store.dispatch({ type: \u0026#39;INCREMENT\u0026#39; }); 在 reducer 中不建议修改源数据, 使用以下方式复制数据\n1 let newState = JSON.parse(JSON.stringify(state)); demo\n1 创建 store 存放应用状态\n1 2 3 4 5 6 7 8 9 10 11 // src -\u0026gt; store -\u0026gt; index.js import { createStore } from \u0026#39;redux\u0026#39;; import reducer from \u0026#39;./reducer\u0026#39;; // 创建 Redux store 来存放应用的状态。 // API 是 { subscribe, dispatch, getState }。 const store = createStore(reducer, window.__REDUX_DEVTOOLS_EXTENSION__ \u0026amp;\u0026amp; window.__REDUX_DEVTOOLS_EXTENSION__()); // 可以手动订阅更新，也可以事件绑定到视图层。 store.subscribe(() =\u0026gt; console.log(store.getState())); export default store; 2 创建 reducer\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // src -\u0026gt; store -\u0026gt; reducer.js import * as types from \u0026#39;./action\u0026#39;; const defaultState = { inputValue: \u0026#39;Write Something\u0026#39;, list: [\u0026#39;早上 8 点晨会, 分配今天的任务1\u0026#39;, \u0026#39;早上 8 点晨会, 分配今天的任务2\u0026#39;, \u0026#39;早上 8 点晨会, 分配今天的任务3\u0026#39;] }; export default (state = defaultState, action) =\u0026gt; { switch (action.type) { case types.CHANGEINPUT: console.log(\u0026#39;action\u0026#39;, action); console.log(\u0026#39;state\u0026#39;, state); return Object.assign({}, state, { inputValue: action.value }); default: return state; } }; 3 创建 actionTypes\n1 2 // src -\u0026gt; store -\u0026gt; actionTypes.js export const CHANGEINPUT = \u0026#39;CHANGEINPUT\u0026#39;; 4 创建 actionCreates.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import * as types from \u0026#39;./actionTypes\u0026#39;; export const ChangeInputAction = val =\u0026gt; ({ type: types.CHANGE_INPUT, val }); export const AddListTile = () =\u0026gt; ({ type: types.ADD_LIST_TILE }); export const DeleteItem = index =\u0026gt; ({ type: types.DELETE_ITEM, index }); 组件 ui 与业务逻辑拆分 创建业务逻辑与组件 ui, 使用 业务逻辑页面调用 组件\n使用无状态组件有更好的性能, 无状态组件存放 ui\n异步请求 1 2 3 4 5 6 7 yarn add axios import axios from \u0026#39;axios\u0026#39; axios.get(\u0026#39;\u0026#39;).then(()=\u0026gt;{ console.log }) ","date":"2020-04-10T15:00:00Z","permalink":"https://blog.golang.space/p/react-%E5%9F%BA%E7%A1%80/","title":"React 基础"},{"content":"分析源码中的依赖变化，自动增删依赖。\n如果存在 vendor 目录，在修改依赖后，必须更新 vendor。\n1 2 go mod tidy go mod vendor 查询 logrus 的所有发布版本\n1 go list -m -versions github.com/sirupsen/logrus 通常有指定某个版本的需要，比如升级后发现存在某些问题，需要使用更新之前的版本\n1 go get github.com/sirupsen/logrus@v1.7.0 当依赖的主版本号为 0 或 1 的时候，在 Go 代码中添加导入路径不需要加版本号。\n1 2 3 4 5 6 # import github.com/user/repo/v0 import github.com/user/repoimport # github.com/user/repo/v1 import github.com/user/repo # 主版本号 \u0026gt;1 的情况 import github.com/user/repo/v2/xxx ","date":"2020-03-21T15:00:00Z","permalink":"https://blog.golang.space/p/go-module/","title":"Go Module"},{"content":"nginx 1. 配置文件语法 每条指令以;结尾 , 指令与参数间以空格符号分隔; 时间单位 : s m h d w M y yyyy-MM-dd hh:mm:ss 支持正则表达式 localtion ~* \\.(jpg | png | jpeg)$ {} 空间单位 : 不写单位默认是 byte ; kb,mb,gb, 分别用 k m g 表示 常用变量\n1 $binary_remote_addr // 远端地址 2. nginx 命令行 重载配置文件 - 不停止服务\n1 nginx -s reload 日至切割\n手动切割\n1 2 mv access.log access.log.back nginx -s reopen 3. 配置静态服务器 配置文件结构\n1 vim conf.d/default.conf server 包含在 http 中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 http { gzip on;\t# 开启压缩 gzip_min_length 1k; # 小于多少就不在压缩 gzip_comp_level 2; # 压缩级别 gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png application/vnd.ms-fontobject font/ttf font/opentype font/x-woff image/svg+xml; server { listen 8080; #监听端口 server_name\tdomain.org; # 域名 access_log\tlogs/domain.access.log main; # 日志 location / { alias lib/; # 所有的请求都去访问 lib/ 文件下 # 反向代理 proxy_set_header Host $host;\tproxy_set_header X-Real-IP $remote_addr; # 传递用户 IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # 用于传递所有 ip proxy_redirect off; proxy_pass http://127.0.0.1:8089 } } } http 核心模块文档\nX-Forwarded-For 会记录每次跳转的 IP, 每一次反向代理都会记录 IP 到数组头部\nX-Real-IP 用户的公网 IP\nserver 块 listen 端口监听\n1 2 listen 8080; listen 127.0.0.1:8080; # 只能本机的进程访问 可以监听端口 , 或者 ip\nserver_name 域名\n1 2 3 4 5 server_name blog.golang.space; server_name blog.golang.space test.golang.space;# 可以配置多个域名 server_name *.golang.space; # 所有子域名 server_name .golang.space; # 主域名及子域名都包含 server_name_in_redirect off; # on/off , on 表示会重定向到主域名(第一个参数) 匹配顺序\n精确匹配 *在前的泛域名 *在后的泛域名 文件顺序匹配正则表达式 default server 第一个 listen 指定 default **rewrite ** 重定向\n1 2 rewrite regex replacement [flag] rewrite ^/(.*) http://golang.space/$1 permanent; flag\nlast 用 replacement URI 新的匹配\nbreak 指令停止\nredirect 302 临时重定向\npermanent 301 永久重定向\nlocation 路径匹配\n代码实例以优先级排序\n1 2 3 4 5 location = /xxx {}\t# 精准匹配 location ^~ /images/ {} # 匹配以 /images/ 路径 location ~ /xxx {}\t# 正则匹配所有 /xxx 开头路径 location ~* \\.(gif|jpg|png)${} # 匹配 gif..结尾的路径 location / {}\t# 优先级最低，匹配所有 优先级\n= \u0026gt;\t/x/y\t\u0026gt;\t^~\t\u0026gt;\t~ /~*\t\u0026gt;\t/x \u0026gt;\t/\n3 ssl https 自动创建 安装\n1 apt-get install python2-certbot-nginx 执行\n1 certbot --nginx --nginx-server-root=/user/local/conf/ -d blog.golang.space 指定 nginx 配置文件, 获取证书并部署\n常用关键字 alias 分配指定位置的路径 1 2 3 location /i/ { alias /spool/w3/images/; } 访问 \\i\\top.gif 时, 实际 nginx 访问路径 /spool/w3/images/top.gif\n特征\n必须以 / 结尾 只能在 location 块中 会替换掉监听的路径 , 如上面的 /i/ 在正则匹配中 , 必须捕捉要匹配的内容 ( 此处还未理解如何使用 ) root 指定请问文档根目录 1 2 3 location /i/ { root /spool/w3; } 访问 /i/top.gif 时, 实际 nginx 访问路径 /spool/w3/i/top.gif\n特征\n结尾有没有 / 无所谓 可以在 http , server, location, if 等多个块中使用 实际访问路径是 root + path index 确定初始页 主要用于访问根目录时 , 文件夹目录时返回页面\n1 2 3 location / { index index.html; } 当访问 / 的时候 , 没有指定任何文件, 会默认去访问 index.html;\n特征\n这里并不是直接指定目录下 index.html 文件, 而是发起一个内部请求到 /index.html , 意味着可以加一个正则匹配, 如 location ~ \\.html${ root /data/www } , 将真实请求地址设置为 /data/www/index.html try_files 尝试查找文件 1 2 3 location / { try_files $uri $uri/ /index.html; } 请求地址 : http://location/example , 变量 $uri 就是 /example\n此处先去查找这个文件, 没有找到就找目录, 还是没有就转到 http://location/index.html\n4. 指令的继承规则 子块继承父块 子块存在则覆盖父块 非对称加密 对称加密 参考 https://juejin.im/post/6844903944267759624\n","date":"2020-03-15T15:00:00Z","permalink":"https://blog.golang.space/p/nginx-%E5%85%A5%E9%97%A8/","title":"nginx 入门"},{"content":"Dart 入门到摔门而去 [toc]\n一切皆对象, null 都是对象 , 全部继承于 Object\n概览 Dart 是一门强类型语言, 但是可以使用 var and dynamic , 前者用来自动识别类型, 后者标记为不确定类型 ;\n支持泛型 : List\u0026lt;int\u0026gt;\n标识符以下划线开头表示私有: _private\nAssert( boolean ) 方法可在开发过程中进行判断, boolean 是 false 时会抛出异常\n语法基础 1. 入口函数 程序执行的入口函数, 有且只能有一个 main\n2. 字符串输出方式 1 2 3 4 5 6 7 8 9 String str = \u0026#34;123\u0026#34;; print(\u0026#34;该字符串是 $str\u0026#34;); // 如果是对象 print(\u0026#34;该对象的 xx 字段是 ${obj.xx}\u0026#34;); // 多行字符串 var str = \u0026#34;\u0026#34;\u0026#34;123 123 123 321\u0026#34;\u0026#34;\u0026#34;; 使用 r 前缀可以使特殊字符作为普通字符串\n3. 内置类型 numbers strings booleans lists sets maps runes symbols numbers 包含 int 和 double\n3.1 list 值可以重复, 类型可以不同 使用 list.add() 添加对象 list.lenght 获取长度\n3.2 set 值不可以重复, 类型必须相同 set.addAll() 同类型集合添加现有集合\n3.3 map 1 2 3 var git = {\u0026#34;h\u0026#34;:1}; git[\u0026#34;k\u0026#34;] = 2; // 添加 var result = git[\u0026#34;h\u0026#34;]; // 取, 如果没有则为 null, git 必须存在 4. 运算符 is 表示判断, as 表示转换\n1 2 3 4 5 6 7 8 print(\u0026#34;string\u0026#34; is String); // true , 表示 前者是字符串类型 print(\u0026#34;1\u0026#34; as String); // 1, 如果 \u0026#34;1\u0026#34; 是 string 类型正常输出, 否则报错 // 常用在 if+is 判断类型, 使用一个 as 即可完成 if(emp is UserModel){ emp.name = \u0026#34;\u0026#34;; } // -\u0026gt; (emp as UserModel).name = \u0026#34;\u0026#34; // 如果 emp 为 null,或者不是 UserModel 对象,第一段代码不做任何事, 第二段代码报错 ??= 赋值操作符 kk ??= \u0026quot;123\u0026quot; 如果 kk 为 null, 则 kk = \u0026ldquo;123\u0026rdquo; , 否则 kk=kk, 常用于样式中填充数据\n:: 级联符号 通过级联符号可以快速操作同一对象, emp.name=\u0026quot;123\u0026quot;::age=15::sex=\u0026quot;男\u0026quot;\n?. 条件成员访问符号\n1 var name = emp?.name // 如果 emp 为空, 则 name 为空 以上符号组合常用场景\n从 api 获取数据时\n1 2 var name = data[\u0026#34;name\u0026#34;] ...Text(name??=\u0026#34;用户名\u0026#34;) 1 2 3 4 5 // Valid compile-time constants as of Dart 2.5. const Object i = 3; // Where i is a const Object with an int value... const list = [i as int]; // Use a typecast. const map = {if (i is int) i: \u0026#34;int\u0026#34;}; // Use is and collection if. const set = {if (list is List\u0026lt;int\u0026gt;) ...list}; // ...and a spread. 5. 闭包 在函数中嵌套匿名函数并返回, 就会形成闭包, 以图片为例, 变量 n 会递增\n6 类的构造函数 常量对象\n6.1 访问器和存储器 get set 7 工厂构造方法 8 仿真函数 让类向方法一样调用\n9 继承 方法和变量重写\n子类重写父类构造方法\n### 10 抽象类 11 接口 11 混合 被混合的类不能有 显示构造方法 实现多继承的一种方式\n12 枚举 13 泛型约束函数 类泛型\n异步方法 使用 future 使用 async 和 await 多请求并发执行 链式请求执行\n三种库 流 创建一个流控制器, 监听流, 如果发现添加数据, 就输出\nsink 插入\nstream 弹出\n值传递与引用传递 基础数据类型都是值传递\nstring int bool double 对象都是引用传递\nset map class ","date":"2020-03-10T00:00:00Z","permalink":"https://blog.golang.space/p/dart-%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/","title":"Dart 语法基础"},{"content":"Docker image 镜像, 相当于类 container 容器, 相当于对象 repository 仓库, 集中存储镜像 tag 标签, 版本号 零 安装 docker\nhttps://docs.docker.com/engine/install/ubuntu/ 官方文档\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 sudo apt-get install \\ ca-certificates \\ curl \\ gnupg \\ lsb-release curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) stable\u0026#34; | sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io 一 重用命令 帮助命令\ndocker info 列出当前docker 的所有信息 docker --help 帮助 镜像命令\ndocker images 列出本地所有镜像\n-a 所有\n-q 全部镜像 id\n\u0026ndash;digests 摘要说明\n\u0026ndash;no-true 列出完整信息,比如长 id\ndocker search {image} 搜索镜像\n-s 点赞数排序 docker search -s 30 ubuntu // 列出30以上点赞的ubuntu 镜像\n\u0026ndash;no-trunc 完整信息\n\u0026ndash;automated 只列出automated build 镜像\ndocker pull {image[:tag]} 下载镜像\ndocker rmi {image} 删除某个镜像\n-f 强制删除, 当有容器在运行时需要强制删除才能删除镜像\n参数可以是 镜像id, 也可以是唯一镜像名, 多个镜像以空格分割\n删除全部 docker rmi -f ${docker images -qa}\n容器命令\ndocker run [option] {image} [command] [ARG...] 运行镜像\n-name 名字\n-d 后台运行\n-i 交互运行,与 -t 一同使用\n-t 分配伪终端\n-P 随机端口映射\n-p 指定端口映射 8888:8080 对外暴露端口, 内部端口\ndocker ps查看容器\n仅仅查看正在运行的容器\n-a 查看所有容器,正在运行+历史运行\n\u0026gt; -l 显示最近创建 \u0026gt; \u0026gt; -n 显示最近 n 个容器 \u0026gt; \u0026gt; -q 静默模式, 只显示容器编号 \u0026gt; \u0026gt; --no-trunc 不截断输出(完整信息) 退出容器\nexit 容器停止退出 ctrl+p+q 容器不停止退出 docker start启动容器\ndocker restart 重启容器\n停止容器\ndocker stop 软停止 docker kill 强制 docker rm 删除容器\n一次性删除多个\ndocker ps -aq | xargs docker rm\n==守护进程== 以后台方式启动容器,\ndocker 容器后台运行, 必须有一个前台进程\n查看容器日志\n1 docker logs -ft --tail 3 3757f -t 加入时间\n-f 跟随最新的日志\n\u0026ndash;tail n 显示最后 n 条\n查看容器内进程\n1 docker top 501d8 查看容器内部细节\n1 docker inspect 501d8 进入容器\ndocker exec -it 容器id /bin/bash 进入并可以启动新进程, 末尾加命令可以蹭蹭不进去 重新进入 docker attach 容器id 直接进入,不会启动新进程 docker cp拷贝\n1 2 docker cp 容器id:/home/demo.go ~/Desktop/demo.go // 容器内拷贝到宿主机 docker cp ~/Desktop/demo.go 容器id:/home/demo.go // 宿主机拷贝到容器 如果不指定镜像的版本, 默认最新版, :latest, 使用 {image}:{tag} 来指定版本\n二 补充 提交容器副本使之建立新镜像\ndocker commit\ndocker commit -m=\u0026ldquo;描述信息\u0026rdquo; -a=\u0026ldquo;作者\u0026rdquo; 容器id 要创建的目标镜像名:[标签名]\n1 docker commit -a=\u0026#34;breeze\u0026#34; -m=\u0026#34;delete tomcat docs\u0026#34; 614 breeze/tomcat:0.1 打包成压缩包\n1 2 3 docker save -o adc.tar \u0026lt;镜像名\u0026gt; # 加载镜像 docker load -i adc.tar 三 容器数据卷 目的是解决 持久化与数据共享, 没有目录会自动创建目录\n1 docker run -it -v /宿主机绝对路径:/容器内目录 镜像名 添加权限 :ro read only , 仅仅可读\n1 docker run -it -v /宿主机绝对路径:/容器内目录:ro 镜像名 开启多个容器卷\n1 docker run -it -v /host1:/volume1 -v /host2:/volume2 centos 通过 docker inspect 查看镜像信息, 关键字 volumes 表示数据卷, true 表示可使用\n共享数据 \u0026ndash;volumes-from\n新建容器,并共享前一个容器的数据卷\n1 docker run -it --name dc02 ---volumes-from dc01 breeze/centos 四 Dockerfile dockerfile 用来构建 docker 镜像的构建文件, 由一系列命令和参数构成的脚本\n如何用?\n通过 dockerfile 创建镜像\n1 docker build -f /mydocker/dockerfile -t breeze/centos . 注意后面有个 . , 即在当前目录生成\n说明\n每条保留字指令都必须为大写字母且后面要跟随至少一个参数 指令从上到下, 顺序执行 每条指令都会创建一个新的镜像层, 并对镜像进行提交 指令\nFROM 基础镜像, 当前镜像基于哪个镜像 MAINTAINER 镜像维护者的姓名和邮箱 iXugo xx@golang.space RUN 容器构建时需要运行的命令 EXPOSE 当前容器对外暴露出的端口 WORKDIR 制定创建容器后, 终端默认登录的工作目录 ENV 构建镜像过程中设置环境变量 ADD 将宿主机目录下的文件拷贝进镜像且自动处理 url 和解压 tar 压缩包 COPY 类似 add, 拷贝文件和目录到镜像中 VOLUME 容器数据卷, 数据保存和持久化工作 CMD 指定一个容器启动时运行的命令, 可以有多个, 但只执行一个 ENTRYPOINT 指定容器启动时运行的命令 ONBUILD 构建一个被继承的 dockerfile 时运行命令, 父镜像被子继承后 父镜像的 onbuild 被触发, 基础镜像 scratch 共享网络 \u0026ndash;net=host 那些坑 容器内时间与宿主机时间相差 8 小时\n1 docker cp /etc/localtime 41c:/etc/localtime 使用数据卷, 挂载主机目录 docker 访问出现error\n提示为：　cannot open directory : Permission denied\n解决　：　在挂载目录时增加参数　\u0026ndash;privileged=true\n配置加速地址 1 mac 1 https://xobyp2t2.mirror.aliyuncs.com 2 ubuntu 通过修改daemon配置文件/etc/docker/daemon.json来使用加速器\n1 2 3 4 5 6 7 8 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://xobyp2t2.mirror.aliyuncs.com\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker docker 常用软件们 安装 ctop 性能监控\n1 2 3 wget https://github.com/bcicen/ctop/releases/download/v0.7.1/ctop-0.7.1-linux-amd64 -O /usr/local/bin/ctop chmod +x /usr/local/bin/ctop 1 mysql 8.0 运行实例\n1 2 docker run --name first-mysql -p 3308:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql docker run --name second-mysql -p 3307:3306 -e MYSQL_ROOT_PASSWORD=123456 -d mysql 使用 docker 部署 mysql 集群\n1 mysql -h127.0.0.1 -uroot -P3308 -p123456 1 mysql -h127.0.0.1 -uroot -P3307 -p123456 1\n1 show master status; 无法登陆\nsudo apt install gnupg2 pass\n","date":"2020-03-05T10:00:00Z","permalink":"https://blog.golang.space/p/docker-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"Docker 学习笔记"},{"content":"PostgreSQL [toc]\n1. 安装 1.1. linux 命令行安装 1 2 3 sudo apt-get install postgresql su - postgres psql linux 服务管理命令 service\n1 2 3 service postgresql status // 查看状态 service postgresql stop // 停止 service postgresql start // 开始 1.2. 使用 docker-compose 1 2 mkdir plv8 \u0026amp;\u0026amp; cd plv8 vim docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 postgres: restart: always image: ionx/postgres-plv8:12.2 environment: - POSTGRES_PASSWORD=123456789 - TZ=Asia/Shanghai volumes: - $PWD/data:/var/lib/postgresql/data - /etc/localtime:/etc/localtime ports: - \u0026#34;8001:5432\u0026#34; # 端口映射 postgresql.conf 配置文件\n1 2 3 4 5 6 7 8 listen_addresses = \u0026#39;*\u0026#39; # 监听 IP 地址, 若是 localhost 表示仅本地可以连接 port = 5432 # 数据库端口 logging_collector = on # 日志收集 log_directory = \u0026#39;log\u0026#39; # 日志目录 shared_buffers = 128MB # 共享内存大小, 有足够内存时, 可以设置大一些 work_mem = 4M # 单 sql 执行时, 排序,hash join 使用的内存 日志方案 1 每天新生成一个文件\n1 2 3 4 log_filename = \u0026#39;postgresql-%Y-%m-%d_%H%M%S.log\u0026#39; log_truncate_on_rotation = on\tlog_rotation_age = 1d\t# 循环 log_rotation_size = 0\t日志方案 2 写满一定大小, 如 10m 则切换日志\n1 2 3 4 log_filename = \u0026#39;postgresql-%Y-%m-%d_%H%M%S.log\u0026#39; log_truncate_on_rotation = off\tlog_rotation_age = 0\tlog_rotation_size = 10M\t日志方案 3 保留 7 天日志, 循环覆盖\n1 2 3 4 log_filename = \u0026#39;postgresql-%a.log\u0026#39; log_truncate_on_rotation = on log_rotation_age = 1d\tlog_rotation_size = 0\t2. SQL 简单提一下 SQL 区分 DQL (查询), DML(插入/更新/删除数据) , DDL(创建/修改/删除表)\n2.1. DDL 创建表\n1 2 3 4 create table \u0026lt;tab_name\u0026gt; ( col_name integer age integer ); 删除表\n1 drop table \u0026lt;tab_name\u0026gt; 2.2. DML 插入数据\n1 Insert INTO \u0026lt;tab_name\u0026gt; VALUES(2); 指定列插入数据\n1 Insert INTO \u0026lt;tab_name\u0026gt;(age) VALUES(17); 更新语句 , 不设置条件会更新表中所有数据\n1 update \u0026lt;tab_name\u0026gt; SET age = 18; 更新多条且设置 where 条件\n1 update \u0026lt;tab_name\u0026gt; SET col_name = 1,age=19 WHERE age=18; DELETE FROM 删除 , 当没有 where 关键词时, 表示删除整个表,\n1 DELETE FROM \u0026lt;tab_name\u0026gt; WHERE age = 19; 2.3. DQL 排序 order by 1 SELECT * FROM \u0026lt;tab_name\u0026gt; ORDER BY age DESC,col_name; 分组查询 group by 需要使用聚合函数\n1 SELECT age,count(id) FROM \u0026lt;tab_name\u0026gt; GROUP BY age; 2.4. 其它 SQL 语句 union 两张表查询的数据整合到一起\nunion 重复的数据会合并为一条 union all 不合并重复数据 1 2 3 SELECT * FROM \u0026lt;tab_name\u0026gt; WHERE age = 18 UNION SELECT * FROM \u0026lt;tab_name\u0026gt; WHERE col_name \u0026gt;= 2 删除表\ntruncate table 丢弃旧表, 创建新表, 重建索引 delete from 一条条删除数据 3. PSQL 3.1. 使用方法 1 2 3 4 5 6 \\l # 列出所有数据库 \\c \u0026lt;database\u0026gt;\t# 连接数据库 \\d # 显示数据库中的表/序列/视图/索引 \\d+ # 展示更多信息 \\d \u0026lt;table\u0026gt; # 显示表结构 \\q # 退出 数据库安装好后, 有三个数据库\npostgre 默认数据库 template0 最简化模板数据库 template1 用户新建数据库时, 默认从 template1 克隆, 通常可以定制 template1 的内容 , 使用 PSQL 连接数据库\n1 psql -h \u0026lt;ip\u0026gt; -p \u0026lt;5432\u0026gt; [数据库名称] [用户名称] 3.2. 常用命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 \\dt # 列出表 \\di # 列出索引 \\ds # 列出序列 \\dv # 列出视图 \\df # 列出函数 \\dn # 列出 schema \\db # 列出表空间 \\du # 列出用户 \\z # 列出表的权限分配 \\i \u0026lt;文件名\u0026gt; # 执行外部文件 SQL \\? # 命令提示 \\timing on # 列出 sql 执行时间 3.3. 事务 1 2 3 4 5 begin; -- dml commit; -- 或者 rollback; 4. 数据类型 4.1. 表格 类型 说明 其它数据库对比 布尔 boolean 与 mysql 类型相同, 一字节 整型 smallint 2 字节 int 4 字节 bigint 8 字节 浮点 real 和 double precision money 8 字节的货币类型 numeric(m,n) 10 进制精确类型 字符类型 varchar(n) 变长字符 char(n) 定长, 不足补空格 text 长变文本,无限制 Postgresql 的 varchar 最大可存储 1G mysql 的 varchar 最大可存储 64kb 二进制 bytea 对应 mysql 的 blob 和 longblob 二进制位串 bit(n) bit varying(n) 无 日期 date 年月日 time 时分秒 timestamp 年月日时分秒 网络地址 cidr 7-19字节, 网络地址 inet 7-19字节, 网络或主机地址macaddr 6 字节, 以太网 mac 地址 无 数组类型 枚举类型 略 几何类型 略 复合类型 类似结构体 xml json json 和 jsonb range 范围类型 其它类型 不好分类的类型, 如 UUID 4.2. 类型转换 方法一 标准 SQL 转换函数 CAST\n1 select cast(\u0026#39;5\u0026#39; as int),cast(\u0026#39;2014-07-17\u0026#39; as date); 方法二 psql 双冒号转换\n1 select \u0026#39;5\u0026#39;::int 4.3. boolean 类型 使用 boolean 类型, 可以约束非空, 设置默认值, 避免 SQL查询时还需要判断空的情况\n4.4. 布尔类型操作符 AND\na,b 都是 null 为 null a,b 都是 true, 为 true, 否则 false OR\n存在 true 则为 true , 若 a,b 都是 false ,存在 null 则为 null NOT\nnot null = null not true = false not false = true IS\n布尔类型使用 is 比较\n4.5. 字符串函数与操作符 拼接字符串\n1 \u0026#39;Post\u0026#39; || \u0026#39;greSQL\u0026#39; # PostgreSQL 求字符串长度\n1 char_length(\u0026#39;post\u0026#39;) # 4 4.6. 二进制类型 适合存储图片/视频/文件类型\n4.7. 时间类型 SELECT LOCALTIMESTAMP(0) - interval \u0026lsquo;15 day\u0026rsquo;\nextract 提取时间中的子域, 如年/月/日/时/分/秒\n4.8. 枚举类型 创建枚举, 插入时如果不是枚举中存在的字符串, 则报错\n该类型大小写敏感, Sun != sun\n1 create type week as ENUM (\u0026#39;Sun\u0026#39;,\u0026#39;Mon\u0026#39;,\u0026#39;Tues\u0026#39;,\u0026#39;Wed\u0026#39;,\u0026#39;Thur\u0026#39;,\u0026#39;Fri\u0026#39;,\u0026#39;Sat\u0026#39;) 查询所有枚举类型\n1 \\dT 4.9. json 类型 json 类型保留空格/格式/顺序\njsonb 类型存入时会转换二进制, 取用时不用再次转换, 更高效; 且不会保留空格/格式/顺序等\n操作符\n操作符 描述 -\u0026gt; 下标取数组元素 [1,2,3]::json-\u0026gt;1 key 取子对象 {\u0026ldquo;a\u0026rdquo;:12,\u0026ldquo;b\u0026rdquo;:13}::json-\u0026gt;\u0026lsquo;a\u0026rsquo; -\u0026gt;\u0026gt; 同上, 取出来的结果是 text 类型 #\u0026gt; 取嵌套对象 {\u0026ldquo;a\u0026rdquo;:{\u0026ldquo;b\u0026rdquo;:{\u0026ldquo;c\u0026rdquo;:1}}} :: json #\u0026gt; \u0026lsquo;{a,b}\u0026rsquo; #\u0026gt;\u0026gt; 同上, 取出来的结果是 text 类型 有一些操作符仅可用于 jsonb\n操作符 演示 说明 = jsonb \u0026lsquo;[1,2]\u0026rsquo; = jsonb \u0026lsquo;[1,2]\u0026rsquo; @\u0026gt; jsonb \u0026lsquo;[1,2]\u0026rsquo; @\u0026gt; jsonb \u0026lsquo;[1]\u0026rsquo; 左边对象是否包含右边对象 \u0026lt;@ \u0026hellip; ? Jsonb \u0026lsquo;{\u0026ldquo;a\u0026rdquo;:1,\u0026ldquo;b\u0026rdquo;:1}\u0026rsquo; ? \u0026lsquo;a\u0026rsquo; a 是否存在于对象的 key 或字符串类型元素中 `? ` Jsonb \u0026lsquo;{\u0026ldquo;a\u0026rdquo;:1,\u0026ldquo;b\u0026rdquo;:1}\u0026rsquo; ?| array[\u0026lsquo;a\u0026rsquo;,\u0026lsquo;b\u0026rsquo;] ?\u0026amp; Jsonb \u0026lsquo;{\u0026ldquo;a\u0026rdquo;:1,\u0026ldquo;b\u0026rdquo;:1}\u0026rsquo; ?| array[\u0026lsquo;a\u0026rsquo;,\u0026lsquo;b\u0026rsquo;] 数组中的内容是否都在 json 中 4.9.1. jsonb 类型创建索引 1 create index idx_name ON table_name USING gin (index_col) 5. 逻辑结构管理 修改数据库最大连接数\n1 alter database testdb01 connection limit 10; 修改表名\n1 alter table posts rename to postsNew 删除数据库\n1 drop databse [if exists] name; 5.1. 创建模式 schema 是数据库的概念, 可以理解为命名空间或目录;\n创建模式\n1 create schema schema_name [authorization username]; 删除模式\n1 drop schema schema_name; 修改所有者\n1 alter schema name owner to new_owner; 修改模式名\n1 alter schema name rename to new_name; 常用函数 NULLIF 两个参数相等时，返回空值，否则返回 v1\n1 NULLIF(v1,v2) COALESCE 返回第一个非控参数的值，所有参数都为空时返回空\n1 COALESCE(v1,[,...]) CASE 条件表达式\n1 2 3 4 5 CASE WHEN \u0026lt;条件\u0026gt; THEN \u0026lt;结果\u0026gt; [WHEN ...] ELSE \u0026lt;结果\u0026gt; END ","date":"2020-02-23T12:00:00Z","permalink":"https://blog.golang.space/p/postgresql-%E5%9F%BA%E7%A1%80/","title":"PostgreSQL 基础"},{"content":"什么是 SingleFlight? 应对并发的利器! 常用场景有: 缓存穿透\n100 个并发，普通的加锁方式会导致队列执行。\n而 SingleFlight 会缓存一瞬间的并发请求函数返回值。第 1 个访问的函数去执行，其余 99 个进入协程等待，当第一个函数执行结果出来，剩下 99 个直接返回该结果。最后删除 map 中缓存的结果。\n如何使用 SingleFlight? 1 2 3 4 5 6 func TestSingleFlight(t *testing.T){ var g singleflight.Group g.Do(\u0026#34;key\u0026#34;,func() (interface{}, error){ return \u0026#34;test\u0026#34;,nil }) } 看看源码 singleflight\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 package singleflight import \u0026#34;sync\u0026#34; type call struct { wg sync.WaitGroup // 阻塞并发函数请求 val interface{}\t// 函数返回值 err error\t// 函数返回值 } // 一类工作 type Group struct { mu sync.Mutex m map[string]*call // 延迟初始化,用于临时存储函数 } // 判断 key 是否第一次调用 // 是则调用函数获取结果 // 不是, 则阻塞在 c.wg.Wait() 等待函数返回值 func (g *Group) Do(key string, fn func() (interface{}, error)) (interface{}, error) { g.mu.Lock() // 创建 map if g.m == nil { g.m = make(map[string]*call) } // 如果已经有这个函数了, 则进入并解锁, 让其它协程全部进入 // 等待函数返回值，注意 map 的值是指针 if c, ok := g.m[key]; ok { g.mu.Unlock() // 等待函数执行结果 c.wg.Wait() return c.val, c.err } // 初始化 call,写入 map 后解锁 c := new(call) c.wg.Add(1) g.m[key] = c g.mu.Unlock() // 执行函数 c.val, c.err = fn() // 已经获取结果, 后进来的协程都可以返回了 c.wg.Done() // group 仅仅是执行函数时的临时存储空间 // 操作结束后, 删除内容 g.mu.Lock() delete(g.m, key) g.mu.Unlock() return c.val, c.err } ","date":"2020-01-22T15:00:00Z","permalink":"https://blog.golang.space/p/singleflight/","title":"singleflight"},{"content":"atomic 1. 基础知识 1.1. 概念 原子性：一个或多个操作在CPU的执行过程中不被中断的特性，称为原子性。这些操作对外表现成一个不可分割的整体，他们要么都执行，要么都不执行，外界不会看到他们只执行到一半的状态。\n原子操作：进行过程中不能被中断的操作，原子操作由底层硬件支持，而锁则是由操作系统提供的API实现，若实现相同的功能，前者通常会更有效率\n1.2. 介绍 atomic包提供了底层的原子级内存操作，对于同步算法的实现很有用。\n这些函数必须谨慎地保证正确使用。除了某些特殊的底层应用，使用通道或者sync包的函数/类型实现同步更好。\n应通过通信来共享内存，而不通过共享内存实现通信。\n被SwapT系列函数实现的交换操作，在原子性上等价于：\n1 2 3 old = *addr *addr = new return old CompareAndSwapT系列函数实现的比较-交换操作，在原子性上等价于：\n1 2 3 4 5 if *addr == old { *addr = new return true } return false AddT 系列函数实现加法操作，在原子性上等价于：\n1 2 *addr += delta return *addr LoadT和StoreT系列函数实现的加载和保持操作，在原子性上等价于：\u0026ldquo;return *addr\u0026quot;和\u0026rdquo;*addr = val\u0026quot;。\n1.3. 类型与函数 atomic包中支持六种类型\nint32 uint32 int64 uint64 uintptr unsafe.Pointer 对于每一种类型，提供了五类原子操作：\nLoadXXX(addr): 原子性的获取*addr的值，等价于：\n1 return *addr StoreXXX(addr, val): 原子性的将val的值保存到*addr，等价于：\n1 addr = val AddXXX(addr, delta): 原子性的将delta的值添加到*addr并返回新值（unsafe.Pointer不支持），等价于：\n1 2 *addr += delta return *addr SwapXXX(addr, new) old: 原子性的将new的值保存到*addr并返回旧值，等价于：\n1 2 3 old = *addr *addr = new return old CompareAndSwapXXX(addr, old, new) bool: 原子性的比较*addr和old，如果相同则将new赋值给*addr并返回true，等价于：\n1 2 3 4 5 if *addr == old { *addr = new return true } return false 1.4. 支持任意类型的 atomic.Value Go语言在1.4版本的时候向sync/atomic包中添加了新的类型Value，此类型相当于一个容器，被用来\u0026quot;原子地\u0026quot;存储（Store）和加载任意类型的值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func TestGosched(t *testing.T) { done := false var v atomic.Value v.Store(done) go func() { v.Store(true) }() for !v.Load().(bool) { } println(\u0026#34;done !\u0026#34;) } 2. 使用案例 2.1. atomic.AddInt32 多个 goroutine 令 count 递增，在没有任何保护措施情况下，会发生 data race。此处使用 atomic.AddInt32 来保证原子性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 func TestAtomicAddInt32(t *testing.T) { var count int32 var wg sync.WaitGroup for i := 0; i \u0026lt; 100; i++ { wg.Add(1) go func() { defer wg.Done() atomic.AddInt32(\u0026amp;count, 1) }() } wg.Wait() fmt.Println(\u0026#34;count: \u0026#34;, count) } 2.2. atomic.Value 3. 注意事项 4. 源码浅析 4.1. Value go@1.16.5\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 // 提供原子的加载和存储 // 零值为 nil // 调用 Store 后，禁止复制 Value // 第一次使用后，禁止复制 type Value struct { v interface{} } // ifaceWords 是 interface{} 内部表示 type ifaceWords struct { typ unsafe.Pointer // 原始类型 data unsafe.Pointer\t// 值 } // 返回最近 Store 设置的值 // 如果没有调用 Store 则返回 nil func (v *Value) Load() (x interface{}) { vp := (*ifaceWords)(unsafe.Pointer(v)) typ := LoadPointer(\u0026amp;vp.typ) if typ == nil || uintptr(typ) == ^uintptr(0) { // 第一次存储没有完成 return nil } data := LoadPointer(\u0026amp;vp.data) xp := (*ifaceWords)(unsafe.Pointer(\u0026amp;x)) xp.typ = typ xp.data = data return } // Store 将 Value 的值设置为 x // 所有 Store 调用必须使用相同类型的值 // 类型不一致会发生 panic， Store(nil) 也是如此 func (v *Value) Store(x interface{}) { if x == nil { panic(\u0026#34;sync/atomic: store of nil value into Value\u0026#34;) } // 将 V 和 x 转换为 ifaceWords 类型，这样下一步方便获取原始类型和值 vp := (*ifaceWords)(unsafe.Pointer(v)) xp := (*ifaceWords)(unsafe.Pointer(\u0026amp;x)) for { // 现有的值 typ := LoadPointer(\u0026amp;vp.typ) // 如果 typ = nil 则表示第一次 Store if typ == nil { // 开始第一次存储 runtime_procPin() if !CompareAndSwapPointer(\u0026amp;vp.typ, nil, unsafe.Pointer(^uintptr(0))) { runtime_procUnpin() continue } // Complete first store. StorePointer(\u0026amp;vp.data, xp.data) StorePointer(\u0026amp;vp.typ, xp.typ) runtime_procUnpin() return } if uintptr(typ) == ^uintptr(0) { // 如果typ为^uintptr(0)说明第一次写入还没有完成，继续循环等待 continue } // 类型不一致，panic if typ != xp.typ { panic(\u0026#34;sync/atomic: store of inconsistently typed value into Value\u0026#34;) } // 覆盖数据 StorePointer(\u0026amp;vp.data, xp.data) return } } // 禁用/启用 抢占, 在 runtime 实现 func runtime_procPin() func runtime_procUnpin() runtime_procPin 可以将一个 Goroutine 占用当前使用的 P，不允许其他的 Gouroutine 抢占，runtime_procUnpin 释放。\n","date":"2020-01-05T15:00:00Z","permalink":"https://blog.golang.space/p/24.atomic/","title":"24.atomic"},{"content":"反射 请远离reflect和unsafe包，除非你确实需要它们。原因有三\n基于反射的代码是比较脆弱的。反射在真正运行代码时才可能抛出异常, 可能是写完代码很久以后, 而且程序也可能运行了很长的时间。 即使对应类型提供了相同文档，但是反射的操作不能做静态类型检查，而且大量反射的代码通常难以理解。总是需要小心翼翼地为每个导出的类型和其它接受interface{}或reflect.Value类型参数的函数维护说明文档。 基于反射的代码通常比正常的代码运行速度慢一到两个数量级。对于一个典型的项目，大部分函数的性能和程序的整体性能关系不大，所以当反射能使程序更加清晰的时候可以考虑使用。测试是一个特别适合使用反射的场景，因为每个测试的数据集都很小。但是对于性能关键路径的函数，最好避免使用反射。 Go语言提供了一种机制，能够在运行时更新变量和检查它们的值、调用它们的方法和它们支持的内在操作，而不需要在编译时就知道这些变量的具体类型。这种机制被称为反射。\n1. 为什么需要反射? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // Sprint 这是仿的 fmt 包的同名函数,功能不全, 且如果输入 map/array 等类型 // 分支还需要补充这些代码,若是需要导入的组合类型,将会产生依赖 // 所以需要反射 func Sprint(x interface{}) string { type stringer interface { String() string } switch x := x.(type) { case stringer: return x.String() case string: return x case int: return strconv.Itoa(x) case bool: if x { return \u0026#34;true\u0026#34; } return \u0026#34;false\u0026#34; default: // array, chan, func, map, pointer, slice, struct return \u0026#34;???\u0026#34; } } 2. 如何使用? 2.1. TypeOf 函数 reflect.TypeOf 接受任意的 interface{} 类型，并以 reflect.Type 形式返回其动态类型\n1 2 3 t := reflect.TypeOf(3) // a reflect.Type fmt.Println(t.String()) // \u0026#34;int\u0026#34; fmt.Println(t) // \u0026#34;int\u0026#34; 因为 reflect.TypeOf 返回的是一个动态类型的接口值，它总是返回具体的类型。\n1 2 var w io.Writer = os.Stdout fmt.Println(reflect.TypeOf(w)) // \u0026#34;*os.File\u0026#34; fmt.Printf 提供了一个缩写 %T 参数，内部使用 reflect.TypeOf 来输出\n1 fmt.Printf(\u0026#34;%T\\n\u0026#34;, 3) // \u0026#34;int\u0026#34; 2.2. ValueOf 和 reflect.Type 类似，reflect.Value 也满足 fmt.Stringer 接口，但是除非 Value 持有的是字符串，否则 String 方法只返回其类型。而使用 fmt 包的 %v 标志参数会对 reflect.Values 特殊处理。\n1 2 3 4 v := reflect.ValueOf(3) // a reflect.Value fmt.Println(v) // \u0026#34;3\u0026#34; fmt.Printf(\u0026#34;%v\\n\u0026#34;, v) // \u0026#34;3\u0026#34; fmt.Println(v.String()) // note :\u0026#34;\u0026lt;int Value\u0026gt;\u0026#34; 如何判断类型?\n1 2 t := v.Type() // a reflect.Type fmt.Println(t.String()) // \u0026#34;int\u0026#34; 如何获取对象?\n它返回一个 interface{} 类型，装载着与 reflect.Value 相同的具体值\n1 2 3 4 v := reflect.ValueOf(3) // a reflect.Value x := v.Interface() // an interface{} i := x.(int) // an int fmt.Printf(\u0026#34;%d\\n\u0026#34;, i) // \u0026#34;3\u0026#34; 2.3. 使用反射判断类型 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func formatAtom(v reflect.Value) string { switch v.Kind() { case reflect.Invalid: // 空的 reflect.Value 的 kind 即为 Invalid return \u0026#34;Invalid\u0026#34; case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: return strconv.FormatInt(v.Int(), 10) case reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr: return strconv.FormatUint(v.Uint(), 10) case reflect.Bool: return strconv.FormatBool(v.Bool()) case reflect.String: // 将字符串 s 转换为“双引号”引起来的字符串 return strconv.Quote(v.String()) case reflect.Chan, reflect.Func, reflect.Ptr, reflect.Slice, reflect.Map: return v.Type().String() + \u0026#34; 0x\u0026#34; + strconv.FormatUint(uint64(v.Pointer()), 16) default: return v.Type().String() + \u0026#34; value\u0026#34; } } 2.4. 调用方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 //------------- 使用反射调用对象方法 ----------------- type Employee struct { EmployeeID string Name string `format:\u0026#34;normal\u0026#34;` Age int } func (e *Employee)UpdateAge(newVal int ) { e.Age = newVal } type Customer struct { CookieId string Name string Age int } func TestInvokeByName(t *testing.T){ e := \u0026amp;Employee{\u0026#34;1\u0026#34;,\u0026#34;Mike\u0026#34;,30} //t.Log(\u0026#34;Name:value(%[1]v), Type(%[1]T)\u0026#34;,reflect.ValueOf(*e).FieldByName(\u0026#34;Name\u0026#34;), //\treflect.ValueOf(*e).FieldByName(\u0026#34;Age\u0026#34;)) if nameField,ok:=reflect.TypeOf(*e).FieldByName(\u0026#34;name\u0026#34;); ok { t.Error(\u0026#34;Failed to get `name` field.\u0026#34;) }else{ t.Log(\u0026#34;Tag:format\u0026#34;, nameField.Tag.Get(\u0026#34;format\u0026#34;)) } // 调用方法 reflect.ValueOf(e).MethodByName(\u0026#34;UpdateAge\u0026#34;).Call([]reflect.Value{reflect.ValueOf(1)}) t.Log(\u0026#34;update age:\u0026#34;,e) } 深度比较 map 不能直接使用等于比较, 可以使用 反射的 reflect.DeepEqual(s1,s2) 进行比较, 也适用于切片\n","date":"2019-12-01T15:00:00Z","permalink":"https://blog.golang.space/p/23.%E5%8F%8D%E5%B0%84/","title":"23.反射"},{"content":"包和工具 查看标准包数量\n1 go list std | wc -l 检索包地址\n前言 特性 : 快\nGo语言的闪电般的编译速度主要得益于三个语言特性。\n导包在文件开头显示声明 禁止包环装依赖 , 形成有向无环图 记录包的依赖关系, 无需遍历所有依赖文件 ( 解决重复依赖 ) main 包\n名字为main的包是给go build 构建命令一个信息，这个包编译完之后必须调用连接器生成一个可执行程序。\n_test.go 为后缀的包\n_ 和 . 开头的源文件会被构建工具忽略\n所有以_test为后缀包名的测试外部扩展包都由go test命令独立编译\n1. 包 1.1. 导入包 在包声明语句后 , 添加导包声明 , 可以使用圆括号同时导入多个 包之间可添加空行分组, 每个分组的导入顺序会被 gofmt 格式化成字母顺序 循环依赖构建工具会报错 本地化导入\n1 2 import . \u0026#34;strings\u0026#34; Swap(1,3) 别名导入 用于解决包重名, 或长包名\n1 2 import st \u0026#34;strings\u0026#34; st.Swap(1,3) 匿名导入 它会计算包级变量的初始化表达式和执行导入包的init初始化函数\n1 import _ \u0026#34;strings\u0026#34; 1.2. 包名 包名一般采用单数的形式。标准库的bytes、errors和strings使用了复数形式，这是为了避免和预定义的类型冲突，同样还有go/types是为了避免和type关键字冲突。\n如果你计划分享或发布包，那么导入路径最好是全球唯一的。为了避免冲突，所有非标准库包的导入路径建议以所在组织的互联网域名为前缀；而且这样也有利于包的检索。\n1.3. internal 内部包 一个internal包只能被和internal目录有同一个父目录的包所导入。\n例如，\n1 2 3 4 5 6 7 net/http/internal/chunked // 可以导入 net/http/httputil net/http // 不能导入 net/url net/http/internal/chunked内部包只能被net/http/httputil或net/http包导入，但是不能被net/url包导入。不过net/url包却可以导入net/http/httputil包。\n1.4. go list 查询包 列出工作区所有包\n1 go list ... 特定子目录下所有包\n1 go list gopl.io/ch3/... 某个主题相关包\n1 go list ...xml... 包的元信息\n1 go list -json hash 命令行参数-f则允许用户使用text/template包的模板语言定义输出文本的格式。\n1 go list -f \u0026#34;{{join .Deps \\\u0026#34; \\\u0026#34;}}\u0026#34; strconv 查询哪些 go 源文件参与编译\n1 go list -f={{.GoFiles}} fmt 查询哪些 Go 测试源文件参与编译\n1 go list -f={{.TestGoFiles}} fmt 1.5. 如何给已有的包添加方法( 实现继承想要做的事情 ) 定义别名\n1 2 3 4 5 6 // 定义别名 type alias []int func (a alias) IsEmpty(){ // ... } 使用组合 将已有结构组合到新的结构中\n1 2 3 4 5 type myFunc struct { myint *[]int } // ... 导包方式\n1 import . XXX 那么就会让这个“XXX”包中公开的程序实体，被当前源码文件中的代码，视为当前代码包中的程序实体。\n2. 工具 1 go help # 查看更多帮助 2.1. 下载包 1 go get ... Go语言工具箱的go命令同时计算并下载所依赖的每个包\n一旦go get命令下载了包，然后就是安装包或包对应的可执行的程序。\n如果指定-u命令行标志参数，go get命令将确保所有的包和依赖的包的版本都是最新的，然后重新编译和安装它们。如果不包含该标志参数的话，而且如果包已经在本地存在，那么代码将不会被自动更新。\n2.2. 构建包 go build命令编译命令行参数指定的每个包。如果包是一个库，则忽略输出结果；这可以用于检测包是可以正确编译的。如果包的名字是main，go build将调用链接器在当前目录创建一个可执行程序；以导入路径的最后一段作为可执行程序的名字。\n针对不同操作系统或CPU的交叉构建也是很简单的。只需要设置好目标对应的GOOS和GOARCH，然后运行构建命令即可。\n1 2 3 4 5 6 # 编译成 linux 可执行 CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build main.go # 编译成 Windows 可执行 CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build main.go # 编译成 Mac 可执行 CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build main.go CGO_ENABLED CGO 工具, 交叉编译不能使用\nGOOS : 目标平台\nmac 对应 darwin linux 对应 linux windows 对应 windows GOARCH ：目标平台的体系架构\n386 也称 x86 对应 32位操作系统 amd64 也称 x64 对应 64位操作系统 arm 2.3. 注释的技巧 1 2 // +build ignore package temp 在 包声明前面加入此行, 表示不编译这个文件\n1 // +build linux darwin 构建过程控制\n1 go doc go/build # 更多查看文档 3. 文档 如果注释后紧跟着包声明语句，那注释对应整个包的文档。\nGo语言中的文档注释一般是完整的句子，第一行通常是摘要说明，以被注释者的名字开头。注释中函数的参数或其它的标识符并不需要额外的引号或其它标记注明。\n3.1. 命令 在命令行查看\ngo doc 后面可以跟包名/成员名/方法名\n1 2 go doc time go doc time.Since 在网页查看\n1 2 go get golang.org/x/tools/cmd/godoc # 需要先安装 godoc -http :8080 官方文档地址\n","date":"2019-11-24T15:00:00Z","permalink":"https://blog.golang.space/p/21.%E5%8C%85%E5%92%8C%E5%B7%A5%E5%85%B7/","title":"21.包和工具"},{"content":"共享变量的并发 一个函数在并发调用时没法工作的原因太多了，比如死锁（deadlock）、活锁（livelock）和饿死（resource starvation）。我们没有空去讨论所有的问题，这里我们只聚焦在竞争条件上。\n无论任何时候，只要有两个 goroutine 并发访问同一变量，且至少其中的一个是写操作的时候就会发生数据竞争。\n数据竞争会在两个以上的goroutine并发访问相同的变量且至少其中一个为写操作时发生。根据上述定义，有三种方式可以避免数据竞争:\n1. 不要去写变量\n使用 map 判断是否有改变量\n2. 避免从多个 gorontine 访问变量\n不要使用共享数据来通信；使用通信来共享数据 , 仅使用一个 gorontine 访问变量, 提供对一个指定的变量通过channel来请求的goroutine叫做这个变量的monitor（监控）goroutine。\n例如:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 package bank import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;testing\u0026#34; ) var deposits = make(chan int) // 汇款 var balances = make(chan int) // 余额 // Deposit 存款 func Deposit(amount int) { deposits \u0026lt;- amount } // Balance 余额 func Balance() int { return \u0026lt;-balances } type draw struct { amount int succeed chan bool } var withdraws = make(chan draw) // 取款 // Withdraw 取款 func Withdraw(amount int) bool { succeed := make(chan bool) withdraws \u0026lt;- draw{amount, succeed} return \u0026lt;-succeed } func teller() { var balance int for { select { case amount := \u0026lt;-deposits: // 存款 balance += amount case balances \u0026lt;- balance: // 余额 case draw := \u0026lt;-withdraws: if draw.amount \u0026lt;= balance { balance -= draw.amount draw.succeed \u0026lt;- true } else { draw.succeed \u0026lt;- false } } } } func init() { go teller() } func TestTeller(t *testing.T) { var wg sync.WaitGroup for i := 0; i \u0026lt; 10; i++ { wg.Add(1) go func(i int) { defer wg.Done() Deposit(100 * i) }(i) } for i := 0; i \u0026lt; 4; i++ { wg.Add(1) go func(i int) { defer wg.Done() flag := Withdraw(2000 * i) if !flag { fmt.Println(\u0026#34;余额不足\u0026#34;) } }(i) } wg.Wait() fmt.Println(Balance()) fmt.Println(\u0026#34;end\u0026#34;) } // 练习 9.1： 给bank1程序添加一个Withdraw(amount int)取款函数。其返回结果应该要表明事务是成功了还是因为没有足够资金失败了。这条消息会被发送给monitor的goroutine，且消息需要包含取款的额度和一个新的channel，这个新channel会被monitor goroutine来把boolean结果发回给Withdraw。 即使当一个变量无法在其整个生命周期内被绑定到一个独立的goroutine，绑定依然是并发问题的一个解决方案。\n例如在一条流水线上的goroutine之间共享变量是很普遍的行为，在这两者间会通过channel来传输地址信息。如果流水线的每一个阶段都能够避免在将变量传送到下一阶段后再去访问它，那么对这个变量的所有访问就是线性的。其效果是变量会被绑定到流水线的一个阶段，传送完之后被绑定到下一个，以此类推。这种规则有时被称为串行绑定。\n下面的例子中，Cakes会被严格地顺序访问，先是baker gorouine，然后是icer gorouine：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 type Cake struct{ state string } func baker(cooked chan\u0026lt;- *Cake) { for { cake := new(Cake) cake.state = \u0026#34;cooked\u0026#34; cooked \u0026lt;- cake // baker never touches this cake again } } func icer(iced chan\u0026lt;- *Cake, cooked \u0026lt;-chan *Cake) { for cake := range cooked { cake.state = \u0026#34;iced\u0026#34; iced \u0026lt;- cake // icer never touches this cake again } } 3. 互斥锁 允许很多 goruntine 访问, 但是同一时刻只有一个访问\n3.1. 二元信号量 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 var ( sema = make(chan struct{}, 1) // 二元信号量 balance int ) func Deposit(amount int) { sema \u0026lt;- struct{}{} // acquire token balance = balance + amount \u0026lt;-sema // release token } func Balance() int { sema \u0026lt;- struct{}{} // acquire token b := balance \u0026lt;-sema // release token return b } 3.2. sync.Mutex （1）使用Lock()加锁，Unlock()解锁；\n（2）对未解锁的 Mutex 使用 Lock() 会阻塞；\n（3）对未上锁的 Mutex 使用 Unlock() 会导致 panic 异常。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import \u0026#34;sync\u0026#34; var ( mu sync.Mutex // guards balance balance int ) func Deposit(amount int) { mu.Lock() balance = balance + amount mu.Unlock() } func Balance() int { mu.Lock() b := balance mu.Unlock() return b } defer调用只会比显式地调用Unlock成本高那么一点点，不过却在很大程度上保证了代码的整洁性。大多数情况下对于并发程序来说，代码的整洁性比过度的优化更重要。如果可能的话尽量使用defer来将临界区扩展到函数的结束。\n1 2 3 4 5 func Balance() int { mu.Lock() defer mu.Unlock() return balance } 注意: 没法对一个已经锁上的mutex来再次上锁——这会导致程序死锁，没法继续执行下去，会永远阻塞下去。\n1 2 3 4 5 6 7 8 9 10 11 12 // ❌ 错误示例 // 此函数并非原子操作,遇到并发时, 会出现异常 func Withdraw(amount int) bool { // mu.Lock() // defer mu.Unlock() Deposit(-amount) if Balance() \u0026lt; 0 { Deposit(amount) return false // insufficient funds } return true } 一个通用解决办法是\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 不安全的的存款操作 func deposit(amount int) { balance += amount } // 安全的存款操作 func Deposit(amount int) { mu.Lock() defer mu.Unlock() deposit(amount) } // 安全的取款操作 func Withdraw(amount int) bool { mu.Lock() defer mu.Unlock() deposit(-amount) if balance \u0026lt; 0 { deposit(amount) return false // insufficient funds } return true } 4. 读写锁 多读单写 特点：读共享，写独占，写优先\n1 2 3 4 5 6 7 var mu sync.RWMutex var balance int func Balance() int { mu.RLock() // readers lock defer mu.RUnlock() return balance } 1 2 3 4 5 func (rw *RWMutex) Lock() // 锁读写 func (rw *RWMutex) RLock()\t// 锁定为读取状态, 禁止写入 func (rw *RWMutex) RLocker() Locker // 返回互斥锁 func (rw *RWMutex) RUnlock()\t// 解读写锁 func (rw *RWMutex) Unlock()\t// 解互斥锁 （1）RWMutex是单写多读锁，该锁可以加多个读锁或者一个写锁；\n（2）读锁占用的情况下会阻止写，不会阻止读，多个 goroutine 可以同时获取读锁；\n（3）写锁会阻止其他 goroutine（无论读和写）进来，整个锁由该 goroutine 独占；\n（4）适用于读多写少的场景。\n内存同步 这个有点复杂\n直接总结\n可能的话，将变量限定在goroutine内部；如果是多个goroutine都需要访问的变量，使用互斥条件来访问。\n因为赋值和打印指向不同的变量，编译器可能会断定两条语句的顺序不会影响执行结果，并且会交换两个语句的执行顺序。如果两个goroutine在不同的CPU上执行，每一个核心有自己的缓存，这样一个goroutine的写入对于其它goroutine的Print，在主存同步之前就是不可见的了。\n1 2 3 4 5 var x, y int go func() { x = 1 // A1 fmt.Print(\u0026#34;y:\u0026#34;, y, \u0026#34; \u0026#34;) // A2 }() sync.Once 仅执行一次 互斥锁的单例\n1 2 3 4 5 6 7 8 func Icon(name string) image.Image { mu.Lock() defer mu.Unlock() if icons == nil { loadIcons() } return icons[name] } 使用互斥访问icons的代价就是没有办法对该变量进行并发访问，即使变量已经被初始化完毕且再也不会进行变动。这里我们可以引入一个允许多读的锁：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 var mu sync.RWMutex // guards icons var icons map[string]image.Image // Concurrency-safe. func Icon(name string) image.Image { mu.RLock() if icons != nil { icon := icons[name] mu.RUnlock() return icon } mu.RUnlock() // acquire an exclusive lock mu.Lock() if icons == nil { // NOTE: must recheck for nil loadIcons() } icon := icons[name] mu.Unlock() return icon } 上面的代码太复杂了, 再简化一下\n1 2 3 4 5 6 7 var loadIconsOnce sync.Once var icons map[string]image.Image // Concurrency-safe. func Icon(name string) image.Image { loadIconsOnce.Do(loadIcons) return icons[name] } 竞争检查器 只要在go build，go run或者go test命令后面加上-race的flag\n竞争检查器会检查这些事件，会寻找在哪一个goroutine中出现了这样的case，例如其读或者写了一个共享变量，这个共享变量是被另一个goroutine在没有进行干预同步操作便直接写入的。\n1 go test -run=TestConcurrent -race -v gopl.io/ch9/memo1 并发的非阻塞缓冲 一个 http 请求的例子 , 函数调用开销比较大\n1 2 3 4 5 6 7 8 func httpGetBody(url string) (interface{}, error) { resp, err := http.Get(url) if err != nil { return nil, err } defer resp.Body.Close() return ioutil.ReadAll(resp.Body) } 第一个版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package memo type Memo struct{ f Func cache map[string]result } type Func func(key string) (interface{},error) type result struct{ value interface{} err error } // 构造 func New(f Func) *Memo { return \u0026amp;Memo{ f:f, cache:make(map[string]result) } } // 非线程安全 func (memo *Memo) Get(key string) (interface{},err){ res, ok := memo.cache[key] if !ok{ res.value,res.err = memo.f(key) memo.cache[key] = res } return res.value,res.err } 第二个版本\n并发、不重复、无阻塞的cache就完成了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 type result struct { value interface{} err error } type entry struct{ res reuslt ready chan struct{} // res 数据准备好后关闭 } func New(f Func) *Memo { return \u0026amp;Memo{f:f,cache:make(map[string]*entry)} } func Memo struct{ f Func mu sync.Mutex cache map[string]*entry } func (memo *Memo) Get(key string) (value interface{}) { // 获取互斥锁来保护共享变量cache map memo.mu.lock() e := memo.cache[key] if e==nil{ // 插入一个新条目，释放互斥锁 e = \u0026amp;entry{ready: make(chan struct{})} memo.cache[key] = e memo.mu.Unlock() e.res.value, e.res.err = memo.f(key) close(e.ready) // 取到值,通知关闭 }else{ memo.mu.Unlock() \u0026lt;- e.ready // 等待拿值 } return e.res.value,e.res.err } 第三个版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 type request struct { key string response chan\u0026lt;- result // the client wants a single result } type Memo struct{ requests chan request } func New(f Func) *Memo { memo := \u0026amp;Memo{requests: make(chan request)} go memo.server(f) return memo } func (memo *Memo) Get(key string) (interface{}, error) { response := make(chan result) memo.requests \u0026lt;- request{key, response} res := \u0026lt;-response return res.value, res.err } func (memo *Memo) Close() { close(memo.requests) } func (memo *Memo) server(f Func){ cache := make(map[string]*entry) for req := range memo.requests{ e := cache[req.key] if e ==nil{ e = \u0026amp;entry{ready:make(chan struct{})} cache[req.key] = e go e.call(f,req.key) // 获取数据 } go e.deliver(req.response) // 监听数据 } } // 获取数据 func (e *entry) call(f Func, key string){ e.res.value,e.res.err = f(key) close(e.ready) } // 阻塞直到关闭,然后返回结果 func (e *entry) deliver(response chan\u0026lt;- result){ \u0026lt;-e.ready response \u0026lt;- e.res } Goroutines 和线程 每个 os 线程都有固定大小的内存块( 一般 2MB ) 做栈, 用来存储调用或挂起的函数内部变量 , 若是创建成百上千非常浪费内存空间 ;\n而 Goroutine 会以很小的栈开始生命周期 ( 一般 2KB ) , 空间是动态伸缩 , 最大值可达到 1GB,\nOS 线程会被操作系统内核调度 , 进行线程切换 , 其局部性很差, 需要几次内存访问\n而 Go 的运行包含了自己的调度器 , 使用 M:N , n 和 os 线程操作 M 个 goroutine\nGOMAXPROCS 环境变量决定有多少个os 线程同时执行 Go 代码, 默认值是机器 CPU 核心数 , 阻塞/休眠不需要对应 os 线程, I/O,系统调用,非 go 语言函数需要对应 OS 线程, GOMAXPROCS 不会计算这几种情况 , 运行时使用 runtime.GOMAXPROCS 修改\n","date":"2019-11-21T18:00:00Z","permalink":"https://blog.golang.space/p/20.%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%E7%9A%84%E5%B9%B6%E5%8F%91/","title":"20.共享变量的并发"},{"content":"channels channel 是一个通信机制，它可以让一个 goroutine 通过它给另一个goroutine 发送值信息。\nchannel 是线程安全的, 多个协程操作同一管道, 不会发生资源争抢\n[toc]\n1. 基础知识 1.1. 创建 channel channel 的零值也是 nil , 和 map 类似，channel 也对应一个make创建的底层数据结构的引用。当我们复制一个 channel 或用于函数参数传递时，我们只是拷贝了一个 channel 引用，因此调用者和被调用者将引用同一个channel对象。\n1 2 ch := make(chan int) // 无缓存 ch2 := make(chan int,1) // 有缓冲 1.2. 读写操作 1 2 3 ch \u0026lt;- x // 发送 x := \u0026lt;-ch // 接收 \u0026lt;-ch // 接收,丢弃结果 1.3. 关闭 关闭channel，随后对该 channel 的任何发送都将导致panic异常;\n对一个已经被close过的 channel 进行接收操作依然可以接受到之前已经成功发送的数据；如果channel中已经没有数据的话将产生一个零值的数据。\n1 2 3 close(ch) result, ok := \u0026lt;- ch 第二个结果是一个布尔值ok，ture表示成功从channels接收到值，false表示channels已经被关闭并且里面没有值可接收。\n试图重复关闭一个channel将导致panic异常，试图关闭一个nil值的channel也将导致panic异常。关闭一个channels还会触发一个广播机制;\n不管一个channel是否被关闭，当它没有被引用时将会被Go语言的垃圾自动回收器回收。\n1.4. 比较 两个相同类型的channel可以使用 == 运算符比较\n如果两个 channel 引用的是相同的对象，那么比较的结果为真。一个 channel 也可以和nil进行比较。\n1 2 3 4 5 ch := make(chan int) ch1 := make(chan int) ch2 := ch fmt.Printf(\u0026#34;%v\u0026#34; , ch==ch2) // false fmt.Printf(\u0026#34;%v\u0026#34;, ch==ch2) // true 引用相同对象 1.5. channel 的两种类型 无缓存\n1 2 3 ch := make(chan int) // 无缓存 ch1 := make(chan int, 0) // 无缓存 \u0026lt;-ch // 接收 : 阻塞, 会等待发送 1 ch \u0026lt;- 5 // 发送: 阻塞, 会等待接收 Channels的发送操作将导致发送者goroutine阻塞，直到另一个goroutine在相同的Channels上执行接收操作;\n当发送的值通过Channels成功传输之后，两个goroutine可以继续执行后面的语句。反之，如果接收操作先发生，那么接收者goroutine也将阻塞，直到有另一个goroutine在相同的Channels上执行发送操作。\n有缓存\n带缓存的Channel内部持有一个元素队列。队列的最大容量是在调用make函数创建channel时通过第二个参数指定的。向缓存Channel的发送操作就是向内部缓存队列的尾部插入元素，接收操作则是从队列的头部删除元素。\n1 2 3 ch := make(chan int, 1) ch1 := make(chan int, 3) ch \u0026lt;- 5 // 发送: 队列已满则阻塞 1 \u0026lt;-ch // 接收: 队列为空则阻塞 1.6. 单向 channel 1 func foo(ch chan\u0026lt;- int) \u0026lt;-chan int 在这个函数中 , 参数是单向发送channel , 返回值是单向接收channel\n类型chan\u0026lt;- int 表示一个只发送int的channel，只能发送不能接收\n类型\u0026lt;-chan int表示一个只接收int的channel，只能接收不能发送。\n会在编译阶段自动转换单向类型\n注意 : 关闭操作只用于断言不再向channel发送新的数据，所以只有在发送者所在的goroutine才会调用close函数，因此对一个只接收的channel调用close将是一个编译错误。\n2. 使用案例 2.1. 模拟镜像点请求 , 获取最快的 1 2 3 4 5 6 7 8 func mirroredQuery() string { responses := make(chan string, 3) go func() { responses \u0026lt;- request(\u0026#34;asia.gopl.io\u0026#34;) }() go func() { responses \u0026lt;- request(\u0026#34;europe.gopl.io\u0026#34;) }() go func() { responses \u0026lt;- request(\u0026#34;americas.gopl.io\u0026#34;) }() return \u0026lt;-responses // return the quickest response } func request(hostname string) (response string) { /* ... */ } 2.2. select 多路复用 在select语句中操作nil的channel永远都不会被select到 多个 case 同时就绪, select 会随机选择执行 break 只能跳出 select 1 2 3 4 5 6 7 // 外层套个 for 循环, 可用于轮询监听 select { case \u0026lt;-abort: fmt.Printf(\u0026#34;Launch aborted!\\n\u0026#34;) default: // do nothing } 2.3. 超时控制 1 2 3 4 5 6 select { case \u0026lt;- ch: //... case \u0026lt;- time.After(10*time.Second) // ... } 2.4. for..range\u0026hellip; 遍历 使用range 来操作channel , 当 channel 关闭时, 取完所有数据自动结束循环\n1 2 for ch := range chs { } 2.5. 通知所有 goroutine 退出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // 从终端接收任意键盘输入, 关闭 channel go func() { os.Stdin.Read(make([]byte, 1)) // read a single byte close(done) }() // 轮询退出状态 工具函数 var done = make(chan struct{}) func cancelled() bool { select { case \u0026lt;-done: return true default: return false } } go func(){ // 在所有函数头部做轮询判断 if cancelled() { return } }() 2.6. 定时器 1 2 3 4 5 6 7 8 9 10 func main() { fmt.Println(\u0026#34;Commencing countdown.\u0026#34;) // 定时器 tick := time.Tick(1 * time.Second) for countdown := 10; countdown \u0026gt; 0; countdown-- { fmt.Println(countdown) \u0026lt;-tick launch() } Tick函数挺方便，但是只有当程序整个生命周期都需要这个时间时我们使用它才比较合适。否则的话，我们应该使用下面的这种模式：\n1 2 3 ticker := time.NewTicker(1 * time.Second) \u0026lt;-ticker.C ticker.Stop() 3. 注意避坑 3.1. goroutine 泄露 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func makeThumbnails4(filenames []string) error { errors := make(chan error) for _, f := range filenames { go func(f string) { _, err := thumbnail.ImageFile(f) errors \u0026lt;- err }(f) } for range filenames { if err := \u0026lt;-errors; err != nil { return err // NOTE: incorrect: goroutine leak! } } return nil } 当它遇到第一个非nil的error时会直接将error返回到调用方，使得没有一个goroutine去排空errors channel。这样剩下的worker goroutine在向这个channel中发送值时，都会永远地阻塞下去，并且永远都不会退出。这种情况叫做goroutine泄露，可能会导致整个程序卡住或者跑出out of memory的错误。\n最简单的解决办法就是用一个具有合适大小的buffered channel，这样这些worker goroutine向channel中发送错误时就不会被阻塞。\nsync.WaitGroup\n1 2 3 4 5 var wg sync.WaitGroup wg.Add(1) // 加入 wg.Done() // 完成 wg.Wait() // 等待 简单使用就是在创建一个任务的时候wg.Add(1), 任务完成的时候使用wg.Done()来将任务减一。使用wg.Wait()来阻塞等待所有任务完成。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func makeThumbnails6(filenames \u0026lt;-chan string) int64 { sizes := make(chan int64) var wg sync.WaitGroup // number of working goroutines for f := range filenames { wg.Add(1) // worker go func(f string) { defer wg.Done() thumb, err := thumbnail.ImageFile(f) if err != nil { log.Println(err) return } info, _ := os.Stat(thumb) // OK to ignore error sizes \u0026lt;- info.Size() }(f) } // closer go func() { wg.Wait() close(sizes) }() var total int64 for size := range sizes { total += size } return total } 判断 channel 是否关闭\n来看看源码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type hchan struct { qcount uint // 队列中有多少数据 dataqsiz uint // 环形队列有多大 buf unsafe.Pointer // 指向大小为 dataqsiz 的数组 elemsize uint16\t// 元素大小\tclosed uint32\t// 是否关闭 elemtype *_type // 发送什么类型 *_type 指针是运行时的类型系统 sendx uint // 队列头, 发送索引 recvx uint // 队列尾, 接受索引 recvq waitq // recv 等待列表 ( \u0026lt;- chan ) sendq waitq // send 等待列表 ( ch\u0026lt;- ) // 保护 hchan 所有字段,以及在此 channel 上阻塞 sudog 的一些字段 lock mutex } 警告\n关闭一个已关闭的 channel 会导致 panic\n向已经关闭的 channel 发送数据会导致 panic\n向已经关闭的 channel 读取数据不会导致 panic ，但读取的值为 Channel 缓存数据的零值，可以通过接受语句第二个返回值来检查 Channel 是否关闭：\n1 2 3 4 v, ok := \u0026lt;- ch if !ok { ... // Channel 已经关闭 } ","date":"2019-11-18T11:00:00Z","permalink":"https://blog.golang.space/p/19.channels/","title":"19.Channels"},{"content":"Goroutines 第一个小例子\n主函数返回时，所有的goroutine都会被直接打断，程序退出。\n除了从主函数退出或者直接终止程序之外，没有其它的编程方法能够让一个goroutine来打断另一个的执行，但是之后可以看到一种方式来实现这个目的，通过goroutine之间的通信来让一个goroutine请求其它的goroutine，并让被请求的goroutine自行结束执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { go spinner(100 * time.Millisecond) const n = 45 fibN := fib(n) // slow fmt.Printf(\u0026#34;\\rFibonacci(%d) = %d\\n\u0026#34;, n, fibN) } func spinner(delay time.Duration) { for { for _, r := range `-\\|/` { fmt.Printf(\u0026#34;\\r%c\u0026#34;, r) time.Sleep(delay) } } } func fib(x int) int { if x \u0026lt; 2 { return x } return fib(x-1) + fib(x-2) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func T1() { go T2() fmt.Println(\u0026#34;t1\u0026#34;) } func T2() { fmt.Println(\u0026#34;t2\u0026#34;) } func Test1(t *testing.T) { var wg sync.WaitGroup wg.Add(1) go func() { defer wg.Done() T1() }() wg.Wait() fmt.Println(\u0026#34;t3\u0026#34;) } 资源共享并发\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func TestCounterThreadSafe2(t *testing.T) { var mut sync.Mutex var wg sync.WaitGroup counter := 0 for i := 0; i \u0026lt; 5000; i++ { wg.Add(1) go func() { mut.Lock() defer wg.Done() defer mut.Unlock() counter++ }() } wg.Wait() t.Logf(\u0026#34;counter = %d\u0026#34;, counter) } 参数竞争\n匿名函数中的循环变量快照问题。上面这个单独的变量f是被所有的匿名函数值所共享，且会被连续的循环迭代所更新的。当新的goroutine开始执行字面函数时，for循环可能已经更新了f并且开始了另一轮的迭代或者（更有可能的）已经结束了整个循环，所以当这些goroutine开始读取f的值时，它们所看到的值已经是slice的最后一个元素了。显式地添加这个参数，我们能够确保使用的f是当go语句执行时的“当前”那个f。\n1 2 3 4 5 6 for _, f := range filenames { go func() { thumbnail.ImageFile(f) // NOTE: incorrect! // ... }() } 正确的做法\n1 2 3 4 5 6 for _, f := range filenames { go func(f string) { thumbnail.ImageFile(f) // NOTE: incorrect! // ... }(f) } GMP 调度器 goroutine 协程 machine 是操作系统的主线程, 物理线程 processor 处理器抽象，负责衔接 M 和 G 的调度上下文，将等待的 G 和 M 对接。P 决定了并行任务的数量，可通过 runtine.GOMAXPROCS 来设定，默认设置是可用核心数。 调度流程\ngo func()创建 入 局部队列 局部已入全局队列 M 获取 G 若 m1 的 P 本地队列为空则中全局获取 若为空, 从其它 MP 组合中偷取 G 调度 执行 若发生阻塞 创建一个M 或从 休眠队列取一个 接管当前正在阻塞 G 的P 时间片超时返回 参考 Go：g0，特殊的 Goroutine\n","date":"2019-11-15T19:00:00Z","permalink":"https://blog.golang.space/p/18.goroutine/","title":"18.Goroutine"},{"content":"接口 接口只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要。\n当一个接口只被一个单一的具体类型实现时有一个例外，就是由于它的依赖，这个具体类型不能和这个接口存在在一个相同的包中。这种情况下，一个接口是解耦这两个包的一个好方式。\n使用 %T 打印接口的动态类型\n1 2 var w io.Writer fmt.Printf(\u0026#34;%T\\n\u0026#34;, w) // \u0026#34;\u0026lt;nil\u0026gt;\u0026#34; 一个不包含任何值的nil接口值和一个刚好包含nil指针的接口值是不同的。\n一个包含nil指针的接口不是nil接口 容易难到程序员的陷阱\n接口类型包含 type 和 value 两个参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 const debug = true func TestInterface(t *testing.T){ var buf *bytes.Buffer if debug { buf = new(bytes.Buffer) } f(buf) } f(out io.Writer){ // 函数被调用 , out 参数赋值一个指针 // 此时 out 是不为 nil 的, 但其值, 指针可能为 nil // 所以永远为 true if out != nil{ // 对 nil指针调用方法,panic 异常 out.Write([]byte(\u0026#34;done!\\n\u0026#34;)) } } sort 提供了一个排序接口\n1 2 3 4 5 6 7 package sort type Interface interface { Len() int\t// 长度 Less(i, j int) bool // 比较,i,j 是列表索引 Swap(i, j int)\t// 交换 } 为了对序列进行排序，我们需要定义一个实现了这三个方法的类型，然后对这个类型的一个实例应用sort.Sort函数。\n如\n1 2 3 4 5 6 type StringSlice []string func (p StringSlice) Len() int { return len(p) } func (p StringSlice) Less(i, j int) bool { return p[i] \u0026lt; p[j] } func (p StringSlice) Swap(i, j int) { p[i], p[j] = p[j], p[i] } sort.Sort(StringSlice(names)) sort包提供了StringSlice类型，也提供了Strings函数能让上面这些调用简化成sort.Strings(names)。\nsort函数会交换很多对元素，所以如果每个元素都是指针而不是Track类型会更快，指针是一个机器字码长度而Track类型可能是八个或更多。\n解析时间\n1 time.ParseDuration(\u0026#34;3m38s\u0026#34;) text/tabwriter包来生成一个列整齐对齐和隔开的表格\nsort.Reverse函数值得进行更近一步的学习\n**http.handler ** 接口\n1 2 3 4 5 6 7 package http type Handler interface { ServeHTTP(w ResponseWriter, r *Request) } func ListenAndServe(address string, h Handler) error 实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func main() { db := database{\u0026#34;shoes\u0026#34;: 50, \u0026#34;socks\u0026#34;: 5} log.Fatal(http.ListenAndServe(\u0026#34;localhost:8000\u0026#34;, db)) } type dollars float32 func (d dollars) String() string { return fmt.Sprintf(\u0026#34;$%.2f\u0026#34;, d) } type database map[string]dollars func (db database) ServeHTTP(w http.ResponseWriter, req *http.Request) { for item, price := range db { fmt.Fprintf(w, \u0026#34;%s: %s\\n\u0026#34;, item, price) } } 路由请求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func (db database) ServeHTTP(w http.ResponseWriter, req *http.Request) { switch req.URL.Path { case \u0026#34;/list\u0026#34;: for item, price := range db { fmt.Fprintf(w, \u0026#34;%s: %s\\n\u0026#34;, item, price) } case \u0026#34;/price\u0026#34;: // 解析 form 参数 // request.ParseForm() // mobile := request.Form.Get(\u0026#34;mobile\u0026#34;) // 解析 url 中的 query 参数 item := req.URL.Query().Get(\u0026#34;item\u0026#34;) price, ok := db[item] if !ok { w.WriteHeader(http.StatusNotFound) // 404 fmt.Fprintf(w, \u0026#34;no such item: %q\\n\u0026#34;, item) return } fmt.Fprintf(w, \u0026#34;%s\\n\u0026#34;, price) default: // 也可以使用 // msg := fmt.Sprintf(\u0026#34;no such page: %s\\n\u0026#34;, req.URL) // http.Error(w, msg, http.StatusNotFound) // 404 w.WriteHeader(http.StatusNotFound) // 404 fmt.Fprintf(w, \u0026#34;no such page: %s\\n\u0026#34;, req.URL) } } net/http包提供了一个请求多路器ServeMux来简化URL和handlers的联系。一个ServeMux将一批http.Handler聚集到一个单一的http.Handler中。\n在一个项目早期使用框架是非常方便的，但是它们带来额外的复杂度会使长期的维护更加困难。\n直接使用框架, 也不易于底层学习\nServeMux 请求多路器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 func main() { db := database{\u0026#34;shoes\u0026#34;: 50, \u0026#34;socks\u0026#34;: 5} mux := http.NewServeMux() mux.Handle(\u0026#34;/list\u0026#34;, http.HandlerFunc(db.list)) mux.Handle(\u0026#34;/price\u0026#34;, http.HandlerFunc(db.price)) // 简化 // mux.HandleFunc(\u0026#34;/list\u0026#34;, db.list) log.Fatal(http.ListenAndServe(\u0026#34;localhost:8000\u0026#34;, mux)) } type database map[string]dollars func (db database) list(w http.ResponseWriter, req *http.Request) { for item, price := range db { fmt.Fprintf(w, \u0026#34;%s: %s\\n\u0026#34;, item, price) } } func (db database) price(w http.ResponseWriter, req *http.Request) { item := req.URL.Query().Get(\u0026#34;item\u0026#34;) price, ok := db[item] if !ok { w.WriteHeader(http.StatusNotFound) // 404 fmt.Fprintf(w, \u0026#34;no such item: %q\\n\u0026#34;, item) return } fmt.Fprintf(w, \u0026#34;%s\\n\u0026#34;, price) } net/http包提供了一个全局的ServeMux实例DefaultServerMux和包级别的http.Handle和http.HandleFunc函数。\n1 2 3 4 5 6 func main() { db := database{\u0026#34;shoes\u0026#34;: 50, \u0026#34;socks\u0026#34;: 5} http.HandleFunc(\u0026#34;/list\u0026#34;, db.list) http.HandleFunc(\u0026#34;/price\u0026#34;, db.price) log.Fatal(http.ListenAndServe(\u0026#34;localhost:8000\u0026#34;, nil)) } web服务器在一个新的协程中调用每一个handler，所以当handler获取其它协程或者这个handler本身的其它请求也可以访问到变量时，一定要使用预防措施，比如锁机制。\nerror 接口\n1 2 3 4 5 6 7 package errors func New(text string) error { return \u0026amp;errorString{text} } type errorString struct { text string } func (e *errorString) Error() string { return e.text } **类型断言 ** x.(T)\n具体类型的类型断言从它的操作对象中获得具体的值。如果检查失败，接下来这个操作会抛出panic\n第二个结果表示是否断言成功\n1 2 3 var w io.Writer = os.Stdout f, ok := w.(*os.File) // success: ok, f == os.Stdout b, ok := w.(*bytes.Buffer) // failure: !ok, b == nil 常常不会新声明一个其他名字的变量, 而是\n1 2 3 4 // 这里并没有对 w 重新赋值, 而是创建一个局部 w 变量 if w, ok := w.(*os.File); ok { // ...use w... } i/o 有三种经常出现的错误, os 包提供了三个帮助函数\n1 2 3 func IsExist(err error) bool // 文件是否存在 func IsNotExist(err error) bool\t// 文件不存在 func IsPermission(err error) bool // 权限拒绝 一个更可靠的方式是使用一个专门的类型来描述结构化的错误。os包中定义了一个PathError类型来描述在文件路径操作中涉及到的失败，像Open或者Delete操作；并且定义了一个叫LinkError的变体来描述涉及到两个文件路径的操作，像Symlink和Rename。这下面是os.PathError：\n1 2 3 4 5 6 7 8 9 10 11 12 package os // PathError records an error and the operation and file path that caused it. type PathError struct { Op string Path string Err error } func (e *PathError) Error() string { return e.Op + \u0026#34; \u0026#34; + e.Path + \u0026#34;: \u0026#34; + e.Err.Error() } 错误如下\n1 2 3 4 5 _, err := os.Open(\u0026#34;/no/such/file\u0026#34;) fmt.Println(err) // \u0026#34;open /no/such/file: No such file or directory\u0026#34; fmt.Printf(\u0026#34;%#v\\n\u0026#34;, err) // Output: // \u0026amp;os.PathError{Op:\u0026#34;open\u0026#34;, Path:\u0026#34;/no/such/file\u0026#34;, Err:0x2} 通过类型断言选择行为\n在函数中定义接口 , 判断传入的参数是否实现了该接口\n标准库中 io.WriteString 函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // writeString writes s to w. // If w has a WriteString method, it is invoked instead of w.Write. func writeString(w io.Writer, s string) (n int, err error) { type stringWriter interface { WriteString(string) (n int, err error) } if sw, ok := w.(stringWriter); ok { return sw.WriteString(s) // avoid a copy } return w.Write([]byte(s)) // allocate temporary copy } func writeHeader(w io.Writer, contentType string) error { if _, err := writeString(w, \u0026#34;Content-Type: \u0026#34;); err != nil { return err } if _, err := writeString(w, contentType); err != nil { return err } // ... } switch 还可以这样操作\n1 switch x := x.(type) { /* ... */ } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func sqlQuote(x interface{}) string { switch x := x.(type) { case nil: return \u0026#34;NULL\u0026#34; case int, uint: return fmt.Sprintf(\u0026#34;%d\u0026#34;, x) // x has type interface{} here. case bool: if x { return \u0026#34;TRUE\u0026#34; } return \u0026#34;FALSE\u0026#34; case string: return sqlQuoteString(x) // (not shown) default: panic(fmt.Sprintf(\u0026#34;unexpected type %T: %v\u0026#34;, x, x)) } } ","date":"2019-11-12T16:00:00Z","permalink":"https://blog.golang.space/p/17.%E6%8E%A5%E5%8F%A3/","title":"17.接口"},{"content":"跟结构体绑定的函数, 称为方法\n1 2 3 4 type fire struct{} func (f fire) Play(){ } Java 中对象里使用 this , python 对象里使用 self , 而 golang 建议可以使用其类型的第一个字母，比如这里使用了Point的首字母p。可以任意选择变量名\n方法不能与结构体的属性重名, 编译器会报错\n当调用一个函数时，会对其每一个参数值进行拷贝，如果一个函数需要更新一个变量，或者函数的其中一个参数实在太大我们希望能够避免进行这种默认的拷贝，这种情况下我们就需要用到指针了。对应到我们这里用来更新接收器的对象的方法，当这个接受者变量本身比较大时，我们就可以用其指针而不是对象来声明方法\n1 2 3 4 func (p *Point) ScaleBy(factor float64) { p.X *= factor p.Y *= factor } 在现实的程序里，一般会约定如果Point这个类有一个指针作为接收器的方法，那么所有Point的方法都必须有一个指针接收器,即使是那些并不需要这个指针接收器的函数。\n在声明方法时，如果一个类型名本身是一个指针的话，是不允许其出现在接收器中的，比如下面这个例子：\n1 2 type P *int func (P) f() { /* ... */ } // compile error: invalid receiver type 如果方法使用指针作为接收器, 那么要提供一个该类型的指针进行调用方法, 幸运的是 , 如果接收器 p 是point 类型变量 , 编译器会隐式的用 \u0026amp;p.ScaleBy(2) 方式调用, 如果接收器 p 是变量, 方法的接收器是指针, 则会隐式的用 *p 去调用\n1 p.ScaleBy(2) 我们不能通过一个无法取到地址的接收器来调用指针方法，比如临时变量的内存地址就无法获取得到\n1 Point{1, 2}.ScaleBy(2) // 编译错误 但是我们可以用一个*Point这样的接收器来调用Point的方法，因为我们可以通过地址来找到这个变量，只要用解引用符号*来取到该变量即可。编译器在这里也会给我们隐式地插入*这个操作符，所以下面这两种写法等价的：\n1 2 pptr.Distance(q) (*pptr).Distance(q) 声明 method 时, 如何选择使用 值类型还是指针类型的receiver , 需要考虑改变量的大小, 使用值类型会拷贝对象 , 变量过大时会占用较多内存 , 使用指针类型可以直接修改原对象\nnil 是合法的接收器类型\n1 2 3 4 5 6 7 8 9 10 11 12 13 // An IntList is a linked list of integers. // A nil *IntList represents the empty list. type IntList struct { Value int Tail *IntList } // Sum returns the sum of the list elements. func (list *IntList) Sum() int { if list == nil { return 0 } return list.Value + list.Tail.Sum() } 由于url.Values是一个map类型，并且间接引用了其key/value对，因此url.Values.Add对这个map里的元素做任何的更新、删除操作对调用方都是可见的。\n实际上，就像在普通函数中一样，虽然可以通过引用来操作内部值，但在方法想要修改引用本身时是不会影响原始值的，比如把他置换为nil，或者让这个引用指向了其它的对象，调用方都不会受影响。\n注意, 这里指的是修改引用本身, 而非引用指向的地址\n1 2 var kit *int func (k *kit) reset(){ k=nil} // 选择器是值拷贝,不影响对象本身 嵌入结构体 , 匿名属性\n1 2 3 4 5 6 type Point struct{ X, Y float64 } type ColoredPoint struct { Point Color color.RGBA } 对于Point中的方法我们也有类似的用法，我们可以把ColoredPoint类型当作接收器来调用Point里的方法，即使ColoredPoint里没有声明这些方法,当然了，在Point类的方法里，你是访问不到ColoredPoint的任何字段的。\n小技巧\n将包级别变量, sync和 mapping 放到struct 内\n1 2 3 4 5 6 var cache = struct { sync.Mutex // name Mutex mapping map[string]string\t// name Mapping }{ mapping: make(map[string]string), } **方法值与延时执行 **AfterFunc\n1 2 3 4 type Rocket struct { /* ... */ } func (r *Rocket) Launch() { /* ... */ } r := new(Rocket) time.AfterFunc(10 * time.Second, func() { r.Launch() }) 直接用 方法\u0026quot;值\u0026quot;传入 , 省掉了上面例子里的匿名函数。\n1 time.AfterFunc(10 * time.Second, r.Launch) 方法表达式\n当T是一个类型时，方法表达式可能会写作T.f或者(*T).f，会返回一个函数“值”，这种函数会将其第一个参数用作接收器，所以可以用通常（译注：不写选择器）的方式来对其进行调用：\n1 2 3 4 5 6 7 8 9 10 11 p := Point{1, 2} q := Point{4, 6} distance := Point.Distance // method expression fmt.Println(distance(p, q)) // \u0026#34;5\u0026#34; fmt.Printf(\u0026#34;%T\\n\u0026#34;, distance) // \u0026#34;func(Point, Point) float64\u0026#34; scale := (*Point).ScaleBy scale(\u0026amp;p, 2) fmt.Println(p) // \u0026#34;{2 4}\u0026#34; fmt.Printf(\u0026#34;%T\\n\u0026#34;, scale) // \u0026#34;func(*Point, float64)\u0026#34; 当你根据一个变量来决定调用同一个类型的哪个函数时，方法表达式就显得很有用了。你可以根据选择来调用接收器各不相同的方法。\n示例 set\nGo语言里的 set 一般会用map[T]bool这种形式来表示 , 用map类型来表示虽然非常灵活，但我们可以以一种更好的形式来表示它\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 // An IntSet is a set of small non-negative integers. // Its zero value represents the empty set. type IntSet struct { words []uint64 } //\tset 中是否包含 x func (s *IntSet) Has(x int) bool { word, bit := x/64, uint(x%64) return word \u0026lt; len(s.words) \u0026amp;\u0026amp; s.words[word]\u0026amp;(1\u0026lt;\u0026lt;bit) != 0 } // 将 x 添加到 set func (s *IntSet) Add(x int) { // 每一个字都有64个二进制位,用 x/64的商作为字的下标 // 用x%64得到的值作为这个字内的bit的所在位置 word, bit := x/64, uint(x%64) for word \u0026gt;= len(s.words) { s.words = append(s.words, 0) } s.words[word] |= 1 \u0026lt;\u0026lt; bit } // UnionWith sets s to the union of s and t. func (s *IntSet) UnionWith(t *IntSet) { for i, tword := range t.words { if i \u0026lt; len(s.words) { s.words[i] |= tword } else { s.words = append(s.words, tword) } } } x 的 string 方法选择器是指针 , 第一个取址打印正常 第二个编译器会自动加上 \u0026amp;x.string() 第三个是对象, 没有绑定要 string 方法, 1 2 3 fmt.Println(\u0026amp;x) // \u0026#34;{1 9 42 144}\u0026#34; fmt.Println(x.String()) // \u0026#34;{1 9 42 144}\u0026#34; fmt.Println(x) // \u0026#34;{[4398046511618 0 65536]}\u0026#34; ","date":"2019-11-09T11:00:00Z","permalink":"https://blog.golang.space/p/16.%E6%96%B9%E6%B3%95/","title":"16.方法"},{"content":"recover 仅在 defer 调用中使用 获取 panic 的 值 如果无法处理, 可重新 panic 通常来说，不应该对panic异常做任何处理，但有时，也许我们可以从异常中恢复，至少我们可以在程序崩溃前，做一些操作。\n在未发生panic时调用recover，recover会返回nil。\n不加区分的恢复所有的panic异常，不是可取的做法；虽然把对panic的处理都集中在一个包下，有助于简化对复杂和不可以预料问题的处理，但作为被广泛遵守的规范，你不应该试图去恢复其他包引起的panic。\n1 2 3 4 5 6 7 8 9 defer func() { switch p := recover(); p { case nil: // 没有异常 case bailout{}: // 发现异常 err = fmt.Errorf(\u0026#34;multiple title elements\u0026#34;) default: panic(p) //未知异常 } }() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func tryRecover(){ defer func(){ r := recover() if err,ok := r.(error); ok { fmt.Println(\u0026#34;error occurred:\u0026#34;,err) }else{ panic(r) } }() panic(errors.New(\u0026#34;this is an error\u0026#34;)) } func main(){ tryRecover() } ","date":"2019-11-08T18:00:00Z","permalink":"https://blog.golang.space/p/15.recover/","title":"15.recover"},{"content":"panic 用于不可用恢复的严重错误\npanic 退出前会执行 defer 指定内容\n当panic异常发生时，程序会中断运行，并立即执行在该goroutine中被延迟的函数（defer 机制）, 随后，程序崩溃并输出日志信息。\n考虑regexp.Compile函数，该函数将正则表达式编译成有效的可匹配格式。当输入的正则表达式不合法时，该函数会返回一个错误。当调用者明确的知道正确的输入不会引起函数错误时，要求调用者检查这个错误是不必要和累赘的。我们应该假设函数的输入一直合法，就如前面的断言一样：当调用者输入了不应该出现的输入时，触发panic异常。\n输出堆栈信息\n1 2 3 4 5 6 7 8 9 func main() { defer printStack() f(3) } func printStack() { var buf [4096]byte n := runtime.Stack(buf[:], false) os.Stdout.Write(buf[:n]) } 正则\nregexp.MustCompile 检查输入的合法性\n1 var httpSchemeRE = regexp.MustCompile(`^https?:`) //\u0026#34;http:\u0026#34; or \u0026#34;https:\u0026#34; ","date":"2019-11-07T18:00:00Z","permalink":"https://blog.golang.space/p/14.panic/","title":"14.panic"},{"content":"defer os.Exit 退出时不会调用 defer 指定的函数 os.Exit 退出时不输出当前调用栈信息 defer语句经常被用于处理成对的操作，如打开、关闭、连接、断开连接、加锁、释放锁。通过defer机制，不论函数逻辑多复杂，都能保证在任何执行路径下，资源被释放。\ndefer 执行时间 : return语句更新返回值变量之后，函数返回之前\n若defer语句中嵌套了多层函数调用，只是最后一层函数调用才延后执行defer un(trace(\u0026quot;b\u0026quot;)) 会优先执行 trace(\u0026quot;B\u0026quot;)\n若遇到 panic , 先执行 defer , 再 panic\n多个 defer , 会按注册的先后顺序, 逆序执行, 类型栈,后进后出, 递归是正序\n一个函数控制出入口\n1 2 3 4 5 6 7 8 9 10 11 12 13 func bigSlowOperation() { defer trace(\u0026#34;bigSlowOperation\u0026#34;)() // don\u0026#39;t forget the extra parentheses // ...lots of work… time.Sleep(10 * time.Second) // simulate slow operation by sleeping } func trace(msg string) func() { start := time.Now() log.Printf(\u0026#34;enter %s\u0026#34;, msg) return func() { log.Printf(\u0026#34;exit %s (%s)\u0026#34;, msg,time.Since(start)) } } 更改返回值\n1 2 3 4 5 func triple(x int) (result int) { defer func() { result += x }() return double(x) } fmt.Println(triple(4)) // \u0026#34;12\u0026#34; path.Base 提取路径最后一段, 可能为 /\n参考 Golang之轻松化解defer的温柔陷阱\n","date":"2019-11-06T11:00:00Z","permalink":"https://blog.golang.space/p/13.defer/","title":"13.defer"},{"content":"error 可预知的错误\n有些预料中的错误 , 会作为函数的第二个返回值 , 可以使用 fmt.Errorf('%v',err) 封装错误, 使用 Unwrap 来获取上一层的错误\n由于错误信息经常是以链式组合在一起的，所以错误信息中应避免大写和换行符。\n不可预知的 , 偶然的\n一个明智的选择是重新尝试失败的操作。在重试时，我们需要限制重试的时间间隔或重试的次数，防止无限制的重试。\n1 2 3 4 5 6 7 8 9 10 11 12 13 func WaitForServer(url string) error { const timeout = 1 * time.Minute deadline := time.Now().Add(timeout) for tries := 0; time.Now().Before(deadline); tries++ { _, err := http.Head(url) if err == nil { return nil // success } log.Printf(\u0026#34;server not responding (%s);retrying…\u0026#34;, err) time.Sleep(time.Second \u0026lt;\u0026lt; uint(tries)) // exponential back-off } return fmt.Errorf(\u0026#34;server %s failed to respond after %s\u0026#34;, url, timeout) } 当你想忽略某个错误时 , 应该清晰的写下意图\nGo中大部分函数的代码结构几乎相同，首先是一系列的初始检查，防止错误发生，之后是函数的实际逻辑。\n在Go中，错误处理有一套独特的编码风格。检查某个子函数是否失败后，我们通常将处理失败的逻辑代码放在处理成功的代码之前。如果某个错误会导致函数返回，那么成功时的逻辑代码不应放在else语句块中，而应直接放在函数体中。\n文件结尾错误 EOF\nio包保证任何由文件结束引起的读取失败都返回同一个错误——io.EOF\n源码\n1 2 3 type error interface{ Error() string } ","date":"2019-11-05T15:00:00Z","permalink":"https://blog.golang.space/p/12.error/","title":"12.error"},{"content":"函数 函数声明\n1 2 func f(i, j, k int, s, t string) { /* ... */ } func f(i int, j int, k int, s string, t string) { /* ... */ } 函数签名\n函数的类型被称为函数的签名。如果两个函数形式参数列表和返回值列表中的变量类型一一对应，那么这两个函数被认为有相同的类型或签名。\n函数返回值\n可以返回多个值 不需要的值可以使用下划线接收 返回的是值类型变量, 分配在栈上, 返回的是引用类型分配在堆上, 当不再需要时, gc 自动回收\n如果一个函数所有的返回值都有显式的变量名，那么该函数的return语句可以省略操作数。这称之为bare return。\n这样会使代码不易理解 , 不宜过度使用\n1 2 3 4 func sub(x, y int) (z int) { z = x - y; return // 此处等价于 return z } 实参通过值的方式传递，包括引用类型, 也是值传递 , 因此函数的形参是实参的拷贝。\n如果实参是引用类型，如指针，slice(切片)、map、function、channel等类型，实参可能会由于函数的间接引用被修改。\n可能会偶尔遇到没有函数体的函数声明，这表示该函数不是以Go实现的。\n递归\ngolang.org/x/net/html\nhtml.Parse函数读入一组bytes解析后，返回html.Node类型的HTML页面树状结构根节点。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 doc, _ := html.Parse(os.Stdin) visit(nil, doc) func visit(links []string, n *html.Node) []string { if n.Type == html.ElementNode \u0026amp;\u0026amp; n.Data == \u0026#34;a\u0026#34; { for _, a := range n.Attr { if a.Key == \u0026#34;href\u0026#34; { links = append(links, a.Val) } } } for c := n.FirstChild; c != nil; c = c.NextSibling { links = visit(links, c) } return links } 多返回值\n1 2 3 links, err := findLinks(url) // 也可以使用 - 忽略 _, err := findLinks(url) 有些预料中的错误 , 会作为函数的第二个返回值 , 可以使用 fmt.Errorf('%v',err) 封装错误, 使用 Unwrap 来获取上一层的错误\n函数是一等公民\n函数可以赋值 , 有类型\n函数的零值是 nil , 调用零值函数会引起 panic 异常\n函数值可以与 nil 比较, 但是不能相互比较 , 且不能作为 map 的 key\nstrings.Map对字符串中的每个字符调用add1函数，并将每个add1函数的返回值组成一个新的字符串返回给调用者。\n1 2 3 4 5 func add1(r rune) rune { return r + 1 } fmt.Println(strings.Map(add1, \u0026#34;HAL-9000\u0026#34;)) // \u0026#34;IBM.:111\u0026#34; fmt.Println(strings.Map(add1, \u0026#34;VMS\u0026#34;)) // \u0026#34;WNT\u0026#34; fmt.Println(strings.Map(add1, \u0026#34;Admix\u0026#34;)) // \u0026#34;Benjy\u0026#34; 匿名函数\n1 strings.Map(func(r rune) rune { return r + 1 }, \u0026#34;HAL-9000\u0026#34;) 闭包\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func squares() func() int { var x int return func() int { x++ return x * x } } func TestSquares(t *testing.T) { f := squares() fmt.Println(f()) // \u0026#34;1\u0026#34; fmt.Println(f()) // \u0026#34;4\u0026#34; fmt.Println(f()) // \u0026#34;9\u0026#34; fmt.Println(f()) // \u0026#34;16\u0026#34; } 可变参数列表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 多返回值 这里的函数返回值 (q,r int) \u0026lt;=\u0026gt; (int,int) func returnDoubleValue(a,b int) (q, r int){ return a/b,a*b } q, _ := returnDoubleValue(3,9) // 函数为形参, 也可以返回函数 func apply(op func(int,int) int, a,b int) int { return op(a,b) } /// ... 可变参数列表 func sum(numbers ...int) int { s := 0 for i:= range numbers { s += numbers[i] } return s } fmt.Println(sum(1,2,3,4,5)) main 函数\n必须是 main 包 必须是 main 方法 文件名不一定是 main.go Go 中 main 函数不支持任何返回值 通过 os.Exit 来返回状态, 返回的值 范围 -1 ~ 255 ,除了 0 , 其余状态码都是 1 在程序中直接通过 os.Args 获取命令行参数 ","date":"2019-11-05T11:00:00Z","permalink":"https://blog.golang.space/p/11.%E5%87%BD%E6%95%B0/","title":"11.函数"},{"content":"golang 语言标准库 encoding/json 结构体slice 转 JSON 叫编组\n编码时 , 通过反射技术 , 只有导出(首字母大写)的成员才会被编码\n通道、复数、函数类型的值不能编码进json。\njson.Marshal 编码\n返回没有空格的紧凑字节数组\n1 data, err := json.Marshal(movies) json.MarshalIndent 格式化编码\n返回包含空格的格式化字节数组\n参数 2 : 每一行的输出前缀\n参数 3 : 层级缩进\n1 data, err := json.MarshalIndent(movies, \u0026#34;\u0026#34;, \u0026#34; \u0026#34;) **Unmarshal ** 解码\n首先处理json数据是json字面值null的情况。此时，函数将指针设为nil；否则，函数将json数据解码写入指针指向的值；如果指针本身是nil，函数会先申请一个值并使指针指向它。\n1 2 3 4 var titles []struct{ Title string } if err := json.Unmarshal(data, \u0026amp;titles); err != nil { log.Fatalf(\u0026#34;JSON unmarshaling failed: %s\u0026#34;, err) } 结构体中只有Title成员。通过定义合适的Go语言数据结构，我们可以选择性地解码JSON中感兴趣的成员。\nDecoder 流解码器\n还有 Encoder 流编码器\n1 2 3 4 5 6 7 8 9 10 11 12 type IssuesSearchResult struct { TotalCount int `json:\u0026#34;total_count\u0026#34;` Items []*Issue } var result IssuesSearchResult // 发起网络请求, 拿到 resp.body // 此处对流解码 , 也可以使用 ioutil.ReadALL 来读取流数据 if err := json.NewDecoder(resp.Body).Decode(\u0026amp;result); err != nil { resp.Body.Close() return nil, err } tag\nTag可以是任意的字符串面值 , 通常是一系列用空格分隔的key:\u0026ldquo;value\u0026quot;键值对序列；\njson开头键名对应的值用于控制encoding/json包的编码和解码的行为\njson:\u0026quot;color\u0026quot; 编码后的名字为 color\njson:\u0026quot;,omitempty\u0026quot; 名字为变量名, 该类型若为零值 或 nil, 不会被编码\njson:\u0026quot;-\u0026quot; 忽略, 不会被编码\njson:\u0026quot;,string\u0026quot; 编码时为字符串, 仅适用于变量为 字符串、浮点数、整数类型的字段\nomitempty :\n1 2 3 4 type movies struct{ Year int `json:\u0026#34;released\u0026#34;` Color bool `json:\u0026#34;color,omitempty\u0026#34;` } 匿名结构体编码\n1 2 3 4 5 6 7 8 9 type Page struct { Color int Size int } type Book struct { Page Size int } book 中 Size 与 page 中 Size 命名冲突, page 的 Size 不会被编码 编码后{\u0026quot;Color\u0026quot;:255,\u0026quot;Size\u0026quot;:12} 对特殊字符转义操作 url.QueryEscape\n在 URL 中加入查询参数, 避免 ? \u0026amp; 等歧义 , 可以先使用 url.QueryEscape 转义\n1 2 q := url.QueryEscape(strings.Join(terms, \u0026#34; \u0026#34;)) resp, err := http.Get(IssuesURL + \u0026#34;?q=\u0026#34; + q) Json反序列化数字到interface{}类型的值中，默认解析为float64类型，在使用时要注意。\n1 2 3 4 5 6 7 8 9 10 11 var data = []byte(`{\u0026#34;status\u0026#34;: 200}`) var result map[string]interface{} if err := json.Unmarshal(data, \u0026amp;result); err != nil { fmt.Println(\u0026#34;error:\u0026#34;, err) return } //var status = result[\u0026#34;status\u0026#34;].(int) //error: panic: interface conversion: interface is float64, not int var status = uint64(result[\u0026#34;status\u0026#34;].(float64)) //ok fmt.Println(\u0026#34;status value:\u0026#34;,status) ","date":"2019-11-04T14:00:00Z","permalink":"https://blog.golang.space/p/10.json/","title":"10.json"},{"content":"结构体 自定义类型。\n定义结构体 1 2 3 4 5 6 7 8 type Employee struct { ID int Name string Address string DoB time.Time } var dilbert Employee 结构体类型的零值是每个成员都是零值。\n使用 . 操作符可以对每个成员赋值 , 取地址\n指针也可以直接使用 . 操作符, 相当于 (*p).param\n如果结构体成员名字是以大写字母开头的，那么该成员就是导出的；可以被 json 序列化\n一个聚合的值 , 不能包含它本身, 同样适用于数组, 所以 a 结构体不能嵌套 a 结构体 , 但可以包含 *a , 这样可以创建递归的数据结构, 比如链表和树\n例题 使用二叉树排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 type tree struct { value int left, right *tree } // Sort sorts values in place. func Sort(values []int) { var root *tree for _, v := range values { root = add(root, v) } appendValues(values[:0], root) } // appendValues appends the elements of t to values in order // and returns the resulting slice. func appendValues(values []int, t *tree) []int { if t != nil { values = appendValues(values, t.left) values = append(values, t.value) values = appendValues(values, t.right) } return values } func add(t *tree, value int) *tree { if t == nil { // Equivalent to return \u0026amp;tree{value: value}. t = new(tree) t.value = value return t } if value \u0026lt; t.value { t.left = add(t.left, value) } else { t.right = add(t.right, value) } return t } 匿名结构体变量与类型转换 这些字面意义上的类型真的很方便，比如，在一个网络 API 上进行反序列化，你需要一些类型信息，但是给它命名不一定好，因为这只需要在这一个地方使用，而我们不想给只在一个地方使用的东西命名，那将是一种污染。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func main(){ // 声明名为 e1 的变量 var e1 struct{ flag bool counter int64 } e2 := struct{ flag bool counter int64 }{ flag: true, counter: 4, } // ... } bill 和 alice 的字段相同。赋值不会做隐式类型转换\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 type bill struct{ flag bool counter int64 } type alice struct{ flag bool counter int64 } func TestSameStruct(t *testing.T) { b := bill{counter: 11} a := alice{counter: 22} // 强制类型转换 a = alice(b) t.Log(a, b) c := struct { flag bool counter int64 }{ counter: 33, } // 无序类型转换 a = c t.Log(a, c) } 结构体字面值 按定义顺序赋值, 通常用于包内或较小的结构体,\n1 2 type Point struct{ X, Y int } p := Point{1, 2} 更常用的写法 , 顺序不重要 , 未赋值的成员默认零值\n1 anim := gif.GIF{LoopCount: nframes} 作为函数参数 结构体可以作为函数的参数和返回值。\n考虑效率的话, 可以考虑使用指针传入和返回\n1 2 3 func Bonus(e *Employee, percent int) int { return e.Salary * percent / 100 } 在 Go 语言中, 所有的函数参数都是值拷贝 , 函数参数不再是函数调用时的原始变量\n结构体比较 如果所有成员可以比较, 则相同类型的结构体可以使用 == 或 != 比较\n注意, 每个结构体都是不同类型, 哪怕成员属性一样;\n可比较的结构体类型和其他可比较的类型一样，可以用于map的key类型。\n不可比较类型 : since map function\n当结构体中包含 slice 或 map 时, 可以使用 reflect.DeepEaual 比较\n结构体嵌套 和 匿名成员 匿名成员的数据类型必须是命名的类型或指向一个命名的类型的指针。\n匿名成员可以直接访问其叶子属性及方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 type Point struct{ x, y int } type Circle struct { Point Radius int } var c Circle c.x=8 c.y=8 c.Radius=5 fmt.Printf(\u0026#34;%#v\\n\u0026#34;, c) // # 可以输出 包名/结构体名/成员名 不能同时包含两个类型相同的匿名成员, 这会导致命名冲突\n匿名成员 序列化 A结构体成员名与匿名结构体的成员名出现冲突 , 则仅序列化 A结构体成员 序列化后匿名结构体的成员与 A 结构体成员是同级 以上两点详情见 json 那篇文章\n内存对齐 内存对齐是为了使读写尽可能提高内存的效率。\n如果不做内存对齐，一个类型越过了两个边界，那么需要一到两个操作来写它，这并不高效。\n编译器会将不同的类型分配到合适的内存，使它们总是落在边界内。\n比如现在有 bool，int16，int32 三种类型。\n1 2 3 4 5 type T struct{ a bool b int16 c int32 } a 占用 1 个字节，b 占用 2 个字节，c 占用 4 个字节。\n为了对齐边界，内存必须是 2 的倍数，即 a 占用 2 个字节，多的一个字节会自动填充跳过。\n2+2+4 = 8，字段 a 会填充 1 个字节\n如果 b 是 int 32 类型呢?\n4+4+4 = 12，内存必须是 4 的倍数，字段 a 会填充 3 个字节\n如果 b 是 int64 类型呢?\n8+8+8，内存必须是 8 的倍数，字段 a 会填充 7 个字节，字段 c 会填充 4 个字节\n**通过调整字段顺序，可以优化内存，为什么语言不能为你做这个内存对齐? **\n你可以控制你的内存布局，根据需要使他们变得更准确，语言的工作不是在背后试图预先为你优化东西。\n注意: 除非有一个基准，表明因此占用了太多内存，才应该优化这个结构以减少填充。否则，将语义上相同的字段放在一起，可读性更重要。\n","date":"2019-11-04T12:00:00Z","permalink":"https://blog.golang.space/p/9.%E7%BB%93%E6%9E%84%E4%BD%93/","title":"9.结构体"},{"content":"[toc]\nmap 1. 基础知识 1.1. 声明方式 区分: 数组定义了长度, 就会自动初始化, map make 时定义了长度, 也是 0\n无论 map 是否初始化, 都可以使用 len 进行判断长度\n仅仅声明一个 map , 没有初始化, 是 nil map , 不能使用\n1 2 3 4 5 6 7 m := map[string]string{ \u0026#34;name\u0026#34;:\u0026#34;ccmouse\u0026#34;, \u0026#34;course\u0026#34;:\u0026#34;golang\u0026#34;, } m2 := make(map[string]int) // m2 == {} 即 len(m2) == 0 var m3 map[string]int // m3 == nil 也可以 len(m3) == 0 注意不能对 map 中的元素进行取址 , map的key必须是可比较的类型\n禁止对map元素取址的原因是map可能随着元素数量的增长而重新分配更大的内存空间，从而可能导致之前的地址无效。\n1 _ = \u0026amp;ages[\u0026#34;bob\u0026#34;] // ❌ 不能直接更新 map 中 struct 的元素字段值，注意 : array 和 slice 是可以的直接更新的。\n1 m[\u0026#34;x\u0026#34;].name = \u0026#34;Jerry\u0026#34; // ❌ 1 2 3 4 5 6 7 8 9 10 11 12 13 type data struct { name string } func TestData(t *testing.T) { m := map[string]data{ \u0026#34;x\u0026#34;: {\u0026#34;Tom\u0026#34;}, } r := m[\u0026#34;x\u0026#34;] r.name = \u0026#34;Jerry\u0026#34; m[\u0026#34;x\u0026#34;] = r fmt.Println(m) } 1.2. 遍历数据 Map的迭代顺序是不确定的, 在实践中，遍历的顺序是随机的，每一次遍历的顺序都不相同。这是故意的，每次都使用随机的遍历顺序可以强制要求程序不会依赖具体的哈希函数实现。如果要按顺序遍历key/value对，我们必须显式地对key进行排序，可以使用sort包的Strings函数对字符串slice进行排序。\n1 2 3 4 5 m1 := map[string]string{\u0026#34;1\u0026#34;:\u0026#34;2\u0026#34;} for k,v:=range m1 { t.Log(k,\u0026#34; \u0026gt;\u0026gt;\u0026gt; \u0026#34;,v) } 如果想要排序, 可以对 key 排序\n1 2 3 4 5 6 7 8 9 10 import \u0026#34;sort\u0026#34; var names []string for name := range ages { names = append(names, name) } sort.Strings(names) for _, name := range names { fmt.Printf(\u0026#34;%s\\t%d\\n\u0026#34;, name, ages[name]) } 因为我们一开始就知道names的最终大小，因此给slice分配一个合适的大小将会更有效。会避免 append 时浪费内存\n1 names := make([]string, 0, len(ages)) 1.3. map 为 nil 做操作 map上的大部分操作，包括查找、删除、len和range循环都可以安全工作在nil值的map上，它们的行为和一个空的map类似。但是向一个nil值的map存入元素将导致一个panic异常 , 在向map存数据前必须先创建map, 即分配内存空间。\n访问不存在的 key\n1 2 m1 := map[int]int{} // 空 map t.Log(m1[1]) // 访问不存在的 key 返回的结果是零值 , 当访问的 key 不存在, 会返回 value 对应类型的零值\n如果 value 类型是 int, 赋值后是 0 值, 不存在时 也是 0 值, 如何判断?\nkey 存在, 则 ok 为 ture, 不存在 false\n1 2 3 if value, ok:=m1[3]; ok { t.Logf( \u0026#34; key 3 is = %d\u0026#34;,value) } 和slice一样，map之间也不能进行相等比较；唯一的例外是和nil进行比较。\n删除某个 key\n使用 delete , 传入 map 和 key 参数\n1 2 m1 := map[int]int{1:1,2:4,3:9,4:16} delete(m1,1) map 的 key\nmap 使用哈希表, 必须 key 比较相等\n除了 slice, map, function 的内建类型都可以作为 key\n如果想用 slice, 可以定义一个函数获取 slice 的字符串 , 作为 map 的 key\nstruct 类型不包含以上字段(slice,map), 也可以作为 key\n作为函数参数\n传递时拷贝地址, 所以有传引用的效果\nset\n内置集合没有 set 实现, 可以使用 map[type]bool\n1 set := map[string]bool 2. 使用案例 2.1. 寻找最长不含有重复字符的子串 front 指针从 0 开始, 如果没有遇到重复的字符, 就停止移动, 遍历后面的字符, 通过 当前长度-front 获取最长子串\n如果当前遍历的字符在 front 后面出现过, front 就移动到上一次出现位置+1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func TestSelectLongOfNotRepeatingSubStr(t *testing.T) { str := \u0026#34;abcabcdabacd\u0026#34; m1 := make(map[rune]int,len(str)) front :=0 // 头指针 maxLen :=0 // 最大子串长度 for i,ch := range []rune(str) { // 如果当前字符在 front 后面出现过一次 if back,ok := m1[ch]; ok \u0026amp;\u0026amp; back \u0026gt;= front { // 增加 front 位置, 当前遍历到的字符后一个位置 front = back +1 } maxLen = i-front+1 // 更新位置 m1[ch] = i } t.Log(maxLen) } 3. 注意 4. 了解源码 结构体 runtime/map.go/hmap\n1 2 3 4 5 6 7 8 9 10 11 12 type hmap struct{ count int // 键值对数量 flags uint8 B\tuint8\t// 桶的数目是 2 的多少次幂 noverflow uint8 hash0 uint32 buckets unsafe.Pointer // 桶在哪里 oldbuckets unsafe.Pointer // 用于扩容阶段保存旧桶在哪儿 nevacuate uintptr // 即将迁移的旧桶编号 extra *mapextra } Golang的map使用哈希表作为底层实现，一个哈希表里可以有多个哈希表节点，也即bucket，而每个bucket就保存了map中的一个或一组键值对。\n下图展示一个拥有4个bucket的map：\nbucket数据结构 1 2 3 4 5 type bmap struct { tophash [8]uint8 //存储哈希值的高8位 data byte[1] //key value数据:key/key/key/.../value/value/value... overflow *bmap //溢出bucket的地址 } 每个bucket可以存储8个键值对。\ntophash是个长度为8的数组，哈希值相同的键（准确的说是哈希值低位相同的键）存入当前bucket时会将哈希值的高位存储在该数组中，以方便后续匹配。 data区存放的是key-value数据，存放顺序是key/key/key/…value/value/value，如此存放是为了节省字节对齐带来的空间浪费。 overflow 指针指向的是下一个bucket，据此将所有冲突的键连接起来。 下图展示bucket存放8个key-value对：\n哈希冲突 当有两个或以上数量的键被哈希到了同一个bucket时，我们称这些键发生了冲突。Go使用链地址法来解决键冲突。由于每个bucket可以存放8个键值对，所以同一个bucket存放超过8个键值对时就会再创建一个键值对，用类似链表的方式将bucket连接起来。\n下图展示产生冲突后的map：\nbucket数据结构指示下一个bucket的指针称为overflow bucket，意为当前bucket盛不下而溢出的部分。事实上哈希冲突并不是好事情，它降低了存取效率，好的哈希算法可以保证哈希值的随机性，但冲突过多也是要控制的，后面会再详细介绍。\n负载因子 负载因子用于衡量一个哈希表冲突情况，公式为：\n1 负载因子 = 键数量/bucket数量 哈希表需要将负载因子控制在合适的大小，超过其阀值需要进行rehash，也即键值对重新组织：\n哈希因子过小，说明空间利用率低 哈希因子过大，说明冲突严重，存取效率低 每个哈希表的实现对负载因子容忍程度不同，比如Redis实现中负载因子大于1时就会触发rehash，而Go则在在负载因子达到6.5时才会触发rehash，因为Redis的每个bucket只能存1个键值对，而Go的bucket可能存8个键值对，所以Go可以容忍更高的负载因子。\n渐进式扩容 为了保证访问效率，当新元素将要添加进map时，都会检查是否需要扩容，扩容实际上是以空间换时间的手段。触发扩容的条件有二个：\n负载因子 \u0026gt; 6.5时，也即平均每个bucket存储的键值对达到6.5个。 overflow数量 \u0026gt; 2^15时，也即overflow数量超过32768时。 增量扩容 当负载因子过大时，就新建一个bucket，新的bucket长度是原来的2倍，然后旧bucket数据搬迁到新的bucket。考虑到如果map存储了数以亿计的key-value，一次性搬迁将会造成比较大的延时，Go采用逐步搬迁策略，即每次访问map时都会触发一次搬迁，每次搬迁2个键值对。\n下图展示了包含一个bucket满载的map(为了描述方便，图中bucket省略了value区域):\n当前map存储了7个键值对，只有1个bucket。此地负载因子为7。再次插入数据时将会触发扩容操作，扩容之后再将新插入键写入新的bucket。\n当第8个键值对插入时，将会触发扩容，扩容后示意图如下：\nhmap数据结构中oldbuckets成员指身原bucket，而buckets指向了新申请的bucket。新的键值对被插入新的bucket中。后续对map的访问操作会触发迁移，将oldbuckets中的键值对逐步的搬迁过来。当oldbuckets中的键值对全部搬迁完毕后，删除oldbuckets。\n搬迁完成后的示意图如下：\n数据搬迁过程中原bucket中的键值对将存在于新bucket的前面，新插入的键值对将存在于新bucket的后面。实际搬迁过程中比较复杂，将在后续源码分析中详细介绍。\n等量扩容 所谓等量扩容，实际上并不是扩大容量，buckets数量不变，重新做一遍类似增量扩容的搬迁动作，把松散的键值对重新排列一次，以使bucket的使用率更高，进而保证更快的存取。在极端场景下，比如不断的增删，而键值对正好集中在一小部分的bucket，这样会造成overflow的bucket数量增多，但负载因子又不高，从而无法执行增量搬迁的情况，如下图所示：\n上图可见，overflow的buckt中大部分是空的，访问效率会很差。此时进行一次等量扩容，即buckets数量不变，经过重新组织后overflow的bucket数量会减少，即节省了空间又会提高访问效率。\n查找过程 查找过程如下：\n跟据key值算出哈希值 取哈希值低位与hmpa.B取模确定bucket位置 取哈希值高位在tophash数组中查询 如果tophash[i]中存储值也哈希值相等，则去找到该bucket中的key值进行比较 当前bucket没有找到，则继续从下个overflow的bucket中查找。 如果当前处于搬迁过程，则优先从oldbuckets查找 注：如果查找不到，也不会返回空值，而是返回相应类型的0值。\n插入过程 新员素插入过程如下：\n跟据key值算出哈希值 取哈希值低位与hmap.B取模确定bucket位置 查找该key是否已经存在，如果存在则直接更新值 如果没找到将key，将key插入 ","date":"2019-11-04T11:00:00Z","permalink":"https://blog.golang.space/p/8.map/","title":"8.map"},{"content":"1. 数组 array 数组是定长的，长度一旦定义，不能更改。\n1.1. 如何声明? 声明数组，注意要指定长度。如果未指定长度可使用省略号，将会按长度初始化值的个数进行计算。\n1 2 3 var a [3]int v := [...]int{1,2,3} q := [3]int{1, 2, 3, 4} // 编译错误: cannot assign [4]int to [3]int 多维数组初始化\n1 var grid [4][5]int{{1,2},{4,5}} 指定索引初始化\n1 v1 := [...]string{1:\u0026#34;1\u0026#34;,5:\u0026#34;5\u0026#34;,9:\u0026#34;9\u0026#34;} 1.2. 零值 数组是值类型\n声明数组后不赋值，则每个元素都被初始化零值，比如 int 类型会初始化为 0。\n1.3. 特性 Go 语言中数组在初始化之后大小就无法改变，存储元素类型相同、但是大小不同的数组类型在 Go 语言看来也是完全不同的，只有两个条件都相同才是同一个类型。\n1 2 3 var a1 [3]int var a2 [5]int fmt.Printf(\u0026#34;%T != %T\u0026#34;, a1, a2) 两种不同的优化 cmd/compile/internal/gc.anylit\n当元素数量小于或者等于 4 个时，会直接将数组中的元素放置在栈上； 当元素数量大于 4 个时，会将数组中的元素放置到静态区并在运行时取出； 1.4. 元素比较 需要满足两个条件\n如果数组的元素类型可比较，则数组也可以比较 维数相同，含有元素个数相同 1.5. 遍历数组 1 2 3 for i,v := range arr { fmt.Println(i,v) } 1.6. 作为函数参数 调用 func instance(arr [5]int ) 会拷贝数组\n函数参数变量接收的是一个复制的副本，并不是原始调用的变量。因为函数参数传递的机制导致传递大的数组类型将是低效的，并且对数组参数的任何的修改都是发生在复制的数组上，并不能直接修改调用时原始的数组变量。\n1.7. 编译初始化 编译器会在负责初始化字面量的 cmd/compile/internal/gc.anylit 函数中做两种不同的优化：\n当元素数量小于或者等于 4 个时，会直接将数组中的元素放置在栈上； 当元素数量大于 4 个时，会将数组中的元素放置到静态区并在运行时取出拷贝到栈上； 2. 切片 slice 切片 slice 本身是没有数据的，是对底层 array 的一个 view\n2.1. 如何声明? 声明为 nil 的空切片，底层数组指针 = nil，作为函数的实参也是 nil, 可以求长度,结果为 0\n注意空切片可以 append 增加元素，可以动态扩展内存。同样为 nil 的map 不行，对空 map 增加键值对会 panic。\n1 var arr []int 1 2 s2 := []int{} // 空切片,创建了长度和容量都是0的底层数组 s3 := arr[0:2:cap(arr)] // len=2; cap=cap(arr) 声明 len=10, cap=32 的 slice，会初始化 10 个零值\n1 s1 := make([]int, 10 , 32) // 类型,len, cap 2.2. 取内容 多个slice之间可以共享底层的数据，并且引用的数组部分区间可能重叠。\n1 2 3 4 5 arr := []int{0,1,2,3,4,5,6,7,8,9} s := arr[2:6] // s = [2,3,4,5] s := arr[:6] // s = [0,1,2,3,4,5] s := arr[6:] // s = [6,7,8,9] s := arr[:] // 0,1,2,3,4,5,6,7,8,9 切片操作超出cap(s)的上限将导致一个panic异常，但是超出len(s)则是意味着扩展了slice\n1 2 3 4 5 func TestSlice(t *testing.T) { arr := make([]int, 5, 9) fmt.Println(arr[5]) // error fmt.Println(arr[4:7]) // 扩展 } x[m:n]切片操作对于字符串则生成一个新字符串，如果x是[]byte的话则生成一个新的[]byte。\n2.3. 拼接 slice \u0026hellip; 可变参数列表, 在函数中可以 value ...int 用来解析列表, 在传递参数中使用 arr\u0026hellip; 可以将数组解析成参数列表\n1 s1 = append(s1[:3], s2[4:]...) 2.4. 如何删除元素? 删除中间的元素\n1 2 3 4 arr := []int{1, 2, 3, 4} i := 1 fmt.Println(append(arr[0:i], arr[i+1:]...)) fmt.Println(arr[:i+copy(arr[i:], arr[i+1:])]) 2.5. 作为函数参数 因为slice值包含指向第一个slice元素的指针 ( 后面介绍 slice 的源码)，因此向函数传递slice将允许在函数内部修改底层数组的元素。\n复制一个slice只是对底层的数组创建了一个新的 slice 别名\n1 2 3 4 5 6 7 8 9 func change(arr []int){ arr[0] = 100 } func main(){ arr := [5]int{1,2,3,4,5} change(arr[:]) // arr = 100,2,3,4,5 } Go 语言只有值传递\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func TestSlice2(t *testing.T) { s1 := make([]int, 0, 10) // Go 语言只有值传递 appendFunc := func(s []int) { s = append(s, 10, 20, 30) fmt.Println(s) } fmt.Println(s1) appendFunc(s1) fmt.Println(s1) fmt.Println(s1[:10]) } // 结果 // [] // [10 20 30] // [] // [10 20 30 0 0 0 0 0 0 0] 在上面的例子中，切片值传递过去，使用 append 修改，改变了函数入参 s 的 len 和 cap，但没有改变 s1 的 len 和 cap。\n3. 两者区别 数组需要指定长度 数组的长度是固定的, 切片是可变的 作为函数参数，数组是值拷贝，切片\u0026hellip;.. 4. 看看 slice 的结构 译期间的切片是 cmd/compile/internal/types.Slice 类型的，但是在运行时切片可以由如下的 reflect.SliceHeader 结构体表示\n1 2 3 4 5 6 7 8 9 10 11 12 13 // go@1.16.5 runtime/slice.go type slice struct { array unsafe.Pointer // 底层数组 len int\tcap int } // reflect/value.go SliceHeader 是slice 在运行时的表示 type SliceHeader struct { Data uintptr // 连续空间 Len int // 切片长度 Cap int // 容量 } 一个 slice 由三个部分构成：指针、长度和容量。\n指针指向第一个slice元素对应的底层数组元素的地址，要注意的是slice的第一个元素并不一定就是数组的第一个元素。\n长度对应slice中元素的数目；长度不能超过容量，容量一般是从slice的开始位置到底层数据的结尾位置。\n内置的len和cap函数分别返回slice的长度和容量。\nslice 不能直接使用 == != 比较\n底层数组是可以被多个 slice 同时指向的，因此对一个 slice 的元素进行操作是有可能影响到其他 slice 的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import \u0026#34;fmt\u0026#34; func main() { slice := []int{0, 1, 2, 3, 4, 5, 6, 7, 8, 9} s1 := slice[2:5] // 2,3,4 s2 := s1[2:6:7] // 4,5,6,7 // 注意这个7表示是2-\u0026gt;7 也就是容量开始和结束位置 s2 = append(s2, 100) // 4,5,6,7,100 s2 = append(s2, 200) // 4,5,6,7,100,200 s1[2] = 20 // 2,3,20 fmt.Println(s1) // 2,3,20 fmt.Println(s2) // 4,5,6,7,100,200 fmt.Println(slice) // 0,1,2,3,20,5,6,7,100,9 } 5. 实例 循环\n一种将slice元素循环向左旋转n个元素的方法是三次调用reverse反转函数，第一次是反转开头的n个元素，然后是反转剩下的元素，最后是反转整个slice的元素。（如果是向右循环旋转，则将第三个函数调用移到第一个调用位置就可以了。）\n1 2 3 4 5 6 s := []int{0, 1, 2, 3, 4, 5} // Rotate s left by two positions. reverse(s[:2]) reverse(s[2:]) reverse(s) fmt.Println(s) // \u0026#34;[2 3 4 5 0 1]\u0026#34; 扩展用法\ns1 对 arr 取值, s2 对 s1 取值\u0026quot;下标越界\u0026quot;, 但 slice 是 view 视图, 实际取值是对原数组操作, 还是会得到正确的值, s2 中的 3:5 中 3 的位置是相对于 s1\n即 slice 可以向后扩展, 不能越界, 不能向前扩展\n1 2 3 s1 = arr[2:6] s2 = s1[3:5] // 即 s1[2] = s2[0] , 对切片使用append\n函数原型\n1 2 // go@1.16.5 buitltin/builtin.go func append(slice []Type, elems ...Type) []Type 虽然在扩容的时候 Go 语言一定会生成新的底层数组，但是它也同时生成了新的切片。它是把新的切片作为了新底层数组的窗口，而没有对原切片及其底层数组做任何改动。\n请记住，在无需扩容时，append函数返回的是指向原底层数组的新切片，而在需要扩容时，append函数返回的是指向新底层数组的新切片。所以，严格来讲，“扩容”这个词用在这里虽然形象但并不合适。\n顺便说一下，只要新长度不会超过切片的原容量，那么使用append函数对其追加元素的时候就不会引起扩容。这只会使紧邻切片窗口右边的（底层数组中的）元素被新的元素替换掉\n1 2 3 4 5 6 // s1 = [2,3,4,5] s1 = s1.append(s1,100) // s1 = [2,3,4,5,100] // arr = [0,1,2,3,4,5,100,7,8,9] // 当 添加后的 cap \u0026lt; 原数组 cap 时, 在原数组上进行替换 // 添加后的 cap \u0026gt; 源数组 cap 时, go 将新分配一个数组 扩容规则\nGo 1.18 对规则做了优化，以下规则仅适用于 \u0026lt;= 1.17 的版本，详细请见最新的笔记。\n预估扩容后的容量 oldCap * 2 \u0026lt; cap 则 newCap = cap 否则 oldLen \u0026lt; 1024 翻倍扩容，即 newCap = oldCap*2 oldLen \u0026gt;= 1024，扩容 1/4，即 newCap = oldCap*1.25 最后，进行内存对齐 需要多大内存?\n内存管理模块会提前申请内存，分成不同规格管理起来。\n1 2 3 4 5 6 7 // go@1.16.5 runtime/sizeclasses.go // 这个值取的是 8* (2,x) ，x 为递增变量 var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 24, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} var size_to_class8 = [smallSizeMax/smallSizeDiv + 1]uint8{0, 1, 2, 3, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18, 18, 19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 22, 22, 22, 22, 23, 23, 23, 23, 24, 24, 24, 24, 25, 25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 29, 29, 29, 29, 29, 29, 29, 29, 30, 30, 30, 30, 30, 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32} 例如通过 append 的得到 []int{1,2,3,4,5} 一共是 5*8=40 字节，查表可知最近接 40 的值是 48，即占用内存 48 字节，cap=6。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 // go@1.16.5 runtine/slice.go // growslice 处理追加期间的切片增长 func growslice(et *_type, old slice, cap int) slice { // ...... // 如果扩容的数据，超过现有 cap 的两倍，则使用扩容数据的长度 newcap := old.cap doublecap := newcap + newcap if cap \u0026gt; doublecap { newcap = cap } else { // 小于 1024 时，2 倍递增 if old.cap \u0026lt; 1024 { newcap = doublecap } else { // 防止溢出 和 无限循环 for 0 \u0026lt; newcap \u0026amp;\u0026amp; newcap \u0026lt; cap { newcap += newcap / 4 } if newcap \u0026lt;= 0 { newcap = cap } } } var overflow bool var lenmem, newlenmem, capmem uintptr switch { case et.size == 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) \u0026gt; maxAlloc newcap = int(capmem) case et.size == sys.PtrSize: lenmem = uintptr(old.len) * sys.PtrSize newlenmem = uintptr(cap) * sys.PtrSize capmem = roundupsize(uintptr(newcap) * sys.PtrSize) overflow = uintptr(newcap) \u0026gt; maxAlloc/sys.PtrSize newcap = int(capmem / sys.PtrSize) case isPowerOfTwo(et.size): var shift uintptr if sys.PtrSize == 8 { shift = uintptr(sys.Ctz64(uint64(et.size))) \u0026amp; 63 } else { shift = uintptr(sys.Ctz32(uint32(et.size))) \u0026amp; 31 } lenmem = uintptr(old.len) \u0026lt;\u0026lt; shift newlenmem = uintptr(cap) \u0026lt;\u0026lt; shift capmem = roundupsize(uintptr(newcap) \u0026lt;\u0026lt; shift) overflow = uintptr(newcap) \u0026gt; (maxAlloc \u0026gt;\u0026gt; shift) newcap = int(capmem \u0026gt;\u0026gt; shift) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // go@1.16.5\truntime/msize.go // 内存对齐函数 func roundupsize(size uintptr) uintptr { if size \u0026lt; _MaxSmallSize { if size \u0026lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[divRoundUp(size, smallSizeDiv)]]) } else { return uintptr(class_to_size[size_to_class128[divRoundUp(size-smallSizeMax, largeSizeDiv)]]) } } if size+_PageSize \u0026lt; size { return size } return alignUp(size, _PageSize) } // go@1.16.5\truntime/stubs.go func divRoundUp(n, a uintptr) uintptr { // a is generally a power of two. This will get inlined and // the compiler will optimize the division. return (n + a - 1) / a } 依然用上面的例子，class_to_size[size_to_class8[ n+a-1 ]] ，得出 48\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 例题 func main() { s := []int{5} s = append(s, 7) s = append(s, 9) // s 5,7,9 x := append(s, 11) // x 5,7,9,11 y := append(s, 12) // x 5,7,9,12 fmt.Println(s, x, y) } 数组反转\n1 2 3 4 5 func reverse(s []int) { for i, j := 0, len(s)-1; i \u0026lt; j; i++,j-- { s[i], s[j] = s[j], s[i] } } bytes.Equal 切片比较, bytes 提供了 []byte 类型的比较 , 若是其它类型, 自己封装函数\n1 2 3 4 5 6 7 8 9 10 11 func equal(x, y []string) bool { if len(x) != len(y) { return false } for i := range x { if x[i] != y[i] { return false } } return true } ","date":"2019-11-03T17:00:00Z","permalink":"https://blog.golang.space/p/7.%E6%95%B0%E7%BB%84%E5%92%8C%E5%88%87%E7%89%87/","title":"7.数组和切片"},{"content":"循环 1 2 for initialization; condition; post { } 无限循环\n1 for {} 条件循环\n1 for condition {} 遍历数组 , i 是下标\n1 2 for i := range arr{ } 遍历数组, 下标和值\n1 2 for index,value := range arr{ } range的语法要求，要处理元素，必须处理索引。会拷贝一个新的变量 value , 对 value 做修改不会影响 arr\n在 for 多重循环中可以使用 break end 跳出最外层循环, 这里的 eng 是关键字, 有点像是 goto 语句一样\n跳出并结束嵌套循环\n1 2 3 4 5 6 7 8 9 10 11 end: for i := 0; i \u0026lt; 5; i++ { for i := 0; i \u0026lt; 10; i++ { if i == 2 { break end } fmt.Printf(\u0026#34;%d\\n\u0026#34;, i) } } fmt.Println(\u0026#34;end\u0026#34;) } 结果\n1 2 3 0 1 end if 语句 与其他语言的使用区别, 不加括号\n1 2 3 4 5 6 7 8 9 10 11 // 如果当前文件夹下有 abcd.txt 文件, 就文件输出内容 // 否则输入错误信息 func main(){ const filename = \u0026#34;abcd.txt\u0026#34; // 返回 []byte 和 错误信息, 变量作用域在 if 语句内 if contents ,err := ioutil.ReadFile(filename);err != nil { fmt.Println(err) }else{ fmt.Printf(\u0026#34;%s\\n\u0026#34;, contents) } } switch switch 会自动 break, 除非使用关键字 fallthrough switch 后面可以不加表达式, 将表达式放在 case 后面, 逻辑等同 if else 单个 case 中, 可以出现多个结果, 使用 逗号分隔 ","date":"2019-11-03T12:00:00Z","permalink":"https://blog.golang.space/p/6.%E6%9D%A1%E4%BB%B6/","title":"6.条件"},{"content":"包和文件 Go 文件中的内部信息, 根据是否大写字母开头判断是否导出\n1 2 var Str string // 其他类导入包后可以调用 var str string // 包内可调用 按照惯例，一个包的名字和包的导入路径的最后一个字段相同，例如gopl.io/ch2/tempconv包的名字一般是tempconv。\n如果导入了一个包，但是又没有使用该包将被当作一个编译错误处理。这种强制规则可以有效减少不必要的依赖\n使用 golang.org/x/tools/cmd/goimports 自动添加删除导入包\n包的初始化 包的初始化首先是解决包级变量的依赖顺序，然后按照包级变量声明出现的顺序依次初始化：\n1 2 3 4 5 var a = b + c // a 第三个初始化, 为 3 var b = f() // b 第二个初始化, 为 2, 通过调用 f (依赖c) var c = 1 // c 第一个初始化, 为 1 func f() int { return c + 1 } 如果包中含有多个.go源文件，它们将按照发给编译器的顺序进行初始化，Go语言的构建工具首先会将.go文件根据文件名排序，然后依次调用编译器编译。\ninit 函数特点 init 优先于 main 自动执行 , 不能被其它函数调用 每个包可以有多个 init 函数 导入包前缀加上 _ 仅执行 该包的 全局变量初始化和 init 无参数声明和结果声明 在每个文件中的init初始化函数，在程序开始执行时按照它们声明的顺序被自动调用。 注 : 程序不应该依赖各个包的 init 的执行顺序\ninit 常用用途 实现包级变量复杂初始化，注: 尽量不要使用 init 函数来初始化包级变量，如无必要，不要使用 init 函数，减少代码复杂性。\n1 2 3 4 5 6 7 8 var ProjectDebug = false func init(){ e := os.Getenv(\u0026#34;PROJECT_DEBUG\u0026#34;) if strings.Contains(e, \u0026#34;http2debug=1\u0026#34;) { ProjectDebug = true } } 注册模式\n利用 _ 导入，会使导入的依赖初始化，如 pg 包中实现的驱动注册。\n通过在 init 函数中注册自己的实现的模式，有效降低了 Go 包对外的直接暴露。\n1 import _ \u0026#34;github.com/lib/pq\u0026#34; Go 程序初始化流程 初始化导入的包 , 没有依赖的包优先初始化 初始化有依赖的包 初始化没有依赖的常量 , 变量 初始化有依赖的常量 , 变量 执行 init 函数 执行 main 函数 作用域 当编译器遇到一个名字引用时，它会对其定义进行查找，查找过程从最内层的词法域向全局的作用域进行。如果查找失败，则报告“未声明的名字”这样的错误。如果该名字在内部和外部的块分别声明过，则内部块的声明首先被找到。在这种情况下，内部声明屏蔽了外部同名的声明，让外部的声明的名字无法被访问\nfor 循环有显示词法域和隐式词法域 , 显示词法域是花括号里代码块 , 隐式词法域是 i:=0 初始化\n和for循环类似，if和switch语句也会在条件部分创建隐式词法域，还有它们对应的执行体词法域。\nswitch语句的每个分支也有类似的词法域规则：条件部分为一个隐式词法域，然后是每个分支的词法域。\n1 2 3 4 5 6 7 8 if x := f(); x == 0 { fmt.Println(x) } else if y := g(x); x == y { fmt.Println(x, y) } else { fmt.Println(x, y) } fmt.Println(x, y) // compile error: x and y are not visible here 一个错误的演示\n1 2 3 4 5 if f, err := os.Open(fname); err != nil { // compile error: unused: f return err } f.ReadByte() // compile error: undefined f f.Close() // compile e 你可以这样干, 但是不推荐\n1 2 3 4 5 6 7 if f, err := os.Open(fname); err != nil { return err } else { // f and err are visible here too f.ReadByte() f.Close() } 对于变量的初始化 , 如果要处理错误 , 不建议直接声明赋值 , 而是这样做\n1 2 3 4 5 6 7 8 9 var cwd string // 这里的会创建局部变量, 并没有对包变量 cwd 赋值 func init() { cwd, err := os.Getwd() // compile error: unused: cwd if err != nil { log.Fatalf(\u0026#34;os.Getwd failed: %v\u0026#34;, err) } } 不建议的\nvar cwd,_ = os.GetWd()\n正确的做法\n1 2 3 4 5 6 7 8 9 var cwd string func init() { var err error cwd, err = os.Getwd() if err != nil { log.Fatalf(\u0026#34;os.Getwd failed: %v\u0026#34;, err) } } ","date":"2019-11-03T11:00:00Z","permalink":"https://blog.golang.space/p/5.%E5%8C%85%E5%92%8C%E6%96%87%E4%BB%B6/","title":"5.包和文件"},{"content":"字符串 1. 基础知识 1.1. 编码方式 Go 语言默认编码方式是 UTF-8。\n8 个 bit 表示一个 byte (字节) :\n0000 0000 表示 数字 0。 1111 1111 表示数字 255。 unicode 是定长编码，表示如下\n字符 编码 e 0000 0000 0000 0000 0000 0000 0110 0101 世 0000 0000 0000 0000 0100 1110 0001 0111 由于 unicode 占用较多空间，于是有了 变长编码，这就是 UTF-8\n编号 编码模板 说明 [0,127] 0??? ???? 表示 1 个 byte [128,2047] 110? ???? 10?? ???? 表示 2 个 byte [2048,65535] 1110 ???? 10?? ???? 10?? ???? 表示 3 个 byte 通过去掉标识位，获得二进制\n字符 十进制 二进制 UTF-8 编码 e 101 0110 0101 0110 0101 世 19990 0100 1110 0001 0110 1110 0100 1011 1000 1001 0110 1.2. 不可修改 1 2 3 s := \u0026#34;left foot\u0026#34; t := s s += \u0026#34;, right foot\u0026#34; 这并不会导致原始的字符串值被改变，但是变量s将因为+=语句持有一个新的字符串值，但是t依然是包含原先的字符串值。\n字符串是不可修改的，编译器会将字符串内容分配到只读内存段。需要修改则重新赋值，指针没有修改原来的内存，而是创建了新的内存。\n1 2 // Bad s[0]=\u0026#39;a\u0026#39; 1 2 // Good s = \u0026#34;abc\u0026#34; 2. 使用案例 2.1. 计算字符串长度 len() 函数用于求长度，字符串是以 UTF-8 格式进行存储的，len() 获取的是字节数组长度\n遇到中文有以下几种方法处理\n1 2 3 utf8.RuneCountInString(str) // 按 utf8 编码 len([]rune(\u0026#34;字符串\u0026#34;))\t2.2. 字符串遍历 1 2 3 for i,v := range []rune(str) { fmt.Printf(\u0026#34;(%d,%c)\\n\u0026#34;,idx, val) } 2.3.字符串拼接 字符串底层是不可修改的数组，若使用 + 拼接则会创建新的字符串，使用以下两种方式更节省内存\n1 2 3 4 5 6 func TestStringsBuuilder(t *testing.T) { var a strings.Builder a.WriteString(\u0026#34;hello,\u0026#34;) a.WriteString(\u0026#34;world\u0026#34;) fmt.Printf(a.String()) } 1 2 3 4 5 func TestBytesBuffer(t *testing.T) { var buf bytes.Buffer buf.WriteString(\u0026#34;hello,\u0026#34;) fmt.Printf(buf.String()) } 2.4. 字符串和数字的转换 将一个整数转为字符串，一种方法是用fmt.Sprintf返回一个格式化的字符串；另一个方法是用strconv.Itoa(“整数到ASCII”)：\nfmt.Sprintf 会用到反射。\nstrconv.Itoa 效率更高。\n1 2 3 x := 123 y := fmt.Sprintf(\u0026#34;%d\u0026#34;, x) fmt.Println(y, strconv.Itoa(x)) // \u0026#34;123 123\u0026#34; 2.5. 更多 检查字符串前缀\n1 2 3 func HasPrefix(s, prefix string) bool { return len(s) \u0026gt;= len(prefix) \u0026amp;\u0026amp; s[:len(prefix)] == prefix } 后缀\n1 2 3 func HasSuffix(s, suffix string) bool { return len(s) \u0026gt;= len(suffix) \u0026amp;\u0026amp; s[len(s)-len(suffix):] == suffix } 包含子串测试\n1 2 3 4 5 6 7 8 func Contains(s, substr string) bool { for i := 0; i \u0026lt; len(s); i++ { if HasPrefix(s[i:], substr) { return true } } return false } 使用 utf8 包\n1 2 3 4 5 import \u0026#34;unicode/utf8\u0026#34; s := \u0026#34;Hello, 世界\u0026#34; fmt.Println(len(s)) // \u0026#34;13\u0026#34; 字节长度 fmt.Println(utf8.RuneCountInString(s)) // \u0026#34;9\u0026#34; 字符长度 3. 注意 containers 和 正则表达式 哪个性能高??\n标准库中有四个包对字符串处理尤为重要：bytes、strings、strconv和unicode包。strings包提供了许多如字符串的查询、替换、比较、截断、拆分和合并等功能。\nbytes包也提供了很多类似功能的函数，但是针对和字符串有着相同结构的[]byte类型。因为字符串是只读的，因此逐步构建字符串会导致很多分配和复制。在这种情况下，使用bytes.Buffer类型将会更有效\nstrconv包提供了布尔型、整型数、浮点数和对应字符串的相互转换，还提供了双引号转义相关的转换。\npath和path/filepath包提供了关于文件路径名更一般的函数操作。使用斜杠分隔路径可以在任何操作系统上工作。\nstrings 包的函数\n1 2 3 4 5 6 func Contains(s, substr string) bool func Count(s, sep string) int func Fields(s string) []string func HasPrefix(s, prefix string) bool func Index(s, sep string) int func Join(a []string, sep string) string bytes 包\n1 2 3 4 5 6 func Contains(b, subslice []byte) bool func Count(s, sep []byte) int func Fields(s []byte) [][]byte func HasPrefix(s, prefix []byte) bool func Index(s, sep []byte) int func Join(s [][]byte, sep []byte) []byte 当向bytes.Buffer添加任意字符的UTF8编码时，最好使用bytes.Buffer的WriteRune方法，但是WriteByte方法对于写入类似\u0026rsquo;[\u0026lsquo;和\u0026rsquo;]\u0026lsquo;等ASCII字符则会更加有效。\n写入时 , 尽量避免 强制类型转换, 这会拷贝数据, 浪费内存\n4. 了解源码 Go语言字符串的底层结构在reflect.StringHeader中定义。\n1 2 3 4 type StringHeader struct { Data uintptr // 起始地址 Len int\t// byte 长度 } ","date":"2019-11-02T12:00:00Z","permalink":"https://blog.golang.space/p/4.1.%E5%AD%97%E7%AC%A6%E4%B8%B2/","title":"4.1.字符串"},{"content":"元组赋值 1 2 3 4 5 a,b := b,a // 实现变量交换 i, j, k = 2, 3, 5 // 赋值 q, w, e = 2, \u0026#39;3\u0026#39;, true // 不同类型赋值 _, err = io.Copy(dst, src) // 丢弃字节数 _, ok = x.(T) // 只检测类型，忽略具体值 最大公约数\n1 2 3 4 5 6 func gcd(x, y int) int { for y != 0 { x, y = y, x%y } return x } 斐波那契数列\n1 2 3 4 5 6 7 func fib(n int) int { x, y := 0, 1 for i := 0; i \u0026lt; n; i++ { x, y = y, x+y } return x } 1 2 3 4 5 6 v = m[key] // map查找，失败时返回零值 v = x.(T) // type断言，失败时panic异常 v = \u0026lt;-ch // 管道接收，失败时返回零值（阻塞不算是失败） v, ok = m[key] // map lookup v, ok = x.(T) // type assertion v, ok = \u0026lt;-ch // channel receive 目前我们已经讨论过的类型，它的规则是简单的：类型必须完全匹配，nil可以赋值给任何指针或引用类型的变量。\n对于两个值是否可以用==或!=进行相等比较的能力也和可赋值能力有关系：对于任何类型的值的相等比较，第二个值必须是对第一个值类型对应的变量是可赋值的，反之亦然。\n类型 1 type 类型名字 底层类型 类型声明语句一般出现在包一级，因此如果新创建的类型名字的首字符大写，则在包外部也可以使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // Package tempconv performs Celsius and Fahrenheit temperature computations. package tempconv import \u0026#34;fmt\u0026#34; type Celsius float64 // 摄氏温度 type Fahrenheit float64 // 华氏温度 const ( AbsoluteZeroC Celsius = -273.15 // 绝对零度 FreezingC Celsius = 0 // 结冰点温度 BoilingC Celsius = 100 // 沸水温度 ) func CToF(c Celsius) Fahrenheit { return Fahrenheit(c*9/5 + 32) } func FToC(f Fahrenheit) Celsius { return Celsius((f - 32) * 5 / 9) } 它们是不同的数据类型，因此它们不可以被相互比较或混在一个表达式运算。\n只有当两个类型的底层基础类型相同时，才允许类型强制转换\n在任何情况下，运行时不会发生转换失败的错误（译注: 错误只会发生在编译阶段）\n整数除以整数，地板除法，即结果仅保留整数\n任意参数带小数点，则结果就是浮点类型\n内建类型\n复数\ncomplex64和complex128，分别对应float32和float64两种浮点数精度。内置的complex函数用于构建复数，内建的real和imag函数分别返回复数的实部和虚部：\n1 2 3 4 5 var x complex128 = complex(1, 2) // 1+2i var y complex128 = complex(3, 4) // 3+4i fmt.Println(x*y) // \u0026#34;(-5+10i)\u0026#34; fmt.Println(real(x*y)) // \u0026#34;-5\u0026#34; fmt.Println(imag(x*y)) // \u0026#34;10\u0026#34; 格式化\n1 2 3 4 5 6 7 8 9 10 %c # 字符 %q # 单引号字符 %d # 数字 %o #八进制 %x # 十六进制 %g # 紧凑形式浮点 , 建议使用 %f %f # 浮点, 可以 %8.3f, 整数部分 8 位, 小数点后 3 位 %e # 带指数 %+v # 结构体名，参数名和值 %#v # 包名，结构体名，参数名和值 1 2 3 fmt.Printf(\u0026#34;%d %[1]x %#[1]x %#[1]X\\n\u0026#34;, x) // Output: // 3735928559 deadbeef 0xdeadbeef 0XDEADBEEF %之后的[1]副词告诉Printf函数再次使用第一个操作数。第二，%后的#副词告诉Printf在用%o、%x或%X输出时生成0、0x或0X前缀。\n指令修饰符\n% d 如果输出的数字为负，则在其前面加上一个减号\u0026quot;-\u0026quot;。如果输出的是整数，则在前面加一个空格。使用 %x 或者 %X 格式化指令输出时，会在结果之间添加一个空格。例如 fmt.Printf(\u0026quot;% X\u0026quot;, \u0026ldquo;实\u0026rdquo;)输出 E5 AE 9E %#o 以 0 开始的八进制数据 %#x 以 0x 开始的十六进制数据 + 在数值前面输出+号或者-号，为字符串输出 ASCII 字符（非 ASCII 字符会被转义），为结构体输出其字段名 - 将值向左对齐（默认右对齐） 0 以数字 0 进行填充 常量\n常量表达式的值在编译期计算，而不是在运行期。每种常量的潜在类型都是基础类型：boolean、string或数字。指针 , 结构体 , 接口 都不是常量\n1 2 3 4 5 6 7 const err = errors.New(\u0026#34;error\u0026#34;) // ❌ const filename string = \u0026#34;abc.txt\u0026#34; // 或者 const ( filename string = \u0026#34;t.txt\u0026#34; ) Go 语言预定义了 true , false iota 常量\niota 常量生成器\n在const关键字出现时被重置为 0，在下一个 const 出现之前，每出现一次 iota,其所代表的数字自动加 1。\n1 2 3 4 5 6 7 const ( a = iota //a == 0 b = iota //b ==1 c = iota //c == 2 ) const d = iota //d==0,因为const的出现，iota被重置为0 看题\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 const ( c = 0 d = iota // 1 e // 2 f = \u0026#34;hello\u0026#34; // hello // nothing g // hello h = iota // 5 i // 6 j = 0 // 0 k // 0 l, m = iota, iota // 9 9 n, o // 10 10 p = iota + 1 // iota+1 = 12 q // iota+1 = 13 _ // iota+1 = 14 r = iota * iota // iota = 14 14*14=196 s // iota*iota = 15*15 t = r // 建议不要这么做 u // v = 1 \u0026lt;\u0026lt; iota // 1 \u0026lt;\u0026lt; 18 w // 1 \u0026lt;\u0026lt; 19 x = iota * 0.01 // 0.20 y float32 = iota * 0.01 // 0.21 z // 0.22 ) 不同 const 定义块互不干扰 所有注释行和空行全部忽略( _ 是忽略变量, 但是算做一行) 没有表达式的常量定义复用上一行 从第一行开始, iota 逐行+1, 哪怕第一行不是 iota, 也从第一行算 替换所有 iota 如果是批量声明的常量，除了第一个外其它的常量右边的初始化表达式都可以省略，如果省略初始化表达式则表示使用前面常量的初始化表达式写法，对应的常量类型也一样的。\n1 2 3 4 5 6 7 8 const ( a = 1 b c = 2 d ) fmt.Println(a, b, c, d) // \u0026#34;1 1 2 2\u0026#34; Go语言的常量有个不同寻常之处。虽然一个常量可以有任意一个确定的基础类型，例如int或float64\n编译器为这些没有明确基础类型的数字常量提供比基础类型更高精度的算术运算；你可以认为至少有256bit的运算精度。这里有六种未明确类型的常量类型，分别是无类型的布尔型、无类型的整数、无类型的字符、无类型的浮点数、无类型的复数、无类型的字符串。\n只有常量可以是无类型的。当一个无类型的常量被赋值给一个变量的时候，就像下面的第一行语句，或者出现在有明确类型的变量声明的右边，如下面的其余三行语句，无类型的常量将会被隐式转换为对应的类型，如果转换合法的话。\n1 2 3 4 5 6 7 8 9 10 var f float64 = 3 + 0i // untyped complex -\u0026gt; float64 f = 2 // untyped integer -\u0026gt; float64 f = 1e123 // untyped floating-point -\u0026gt; float64 f = \u0026#39;a\u0026#39; // untyped rune -\u0026gt; float64 // 相当于 var f float64 = float64(3 + 0i) f = float64(2) f = float64(1e123) f = float64(\u0026#39;a\u0026#39;) 1 2 3 4 5 6 7 8 9 10 11 12 a := 12 // 默认长度 8,即类型 int64 fmt.Println(\u0026#34;length of a: \u0026#34;, unsafe.Sizeof(a)) var b int = 12 // 根据机器自动,32 or 64 fmt.Println(\u0026#34;length of b(int): \u0026#34;, unsafe.Sizeof(b)) var c int8 = 12 // 0-255 1 个字节 fmt.Println(\u0026#34;length of c(int8): \u0026#34;, unsafe.Sizeof(c)) var d int16 = 12 // 0-65535 2 个字节 fmt.Println(\u0026#34;length of d(int16): \u0026#34;, unsafe.Sizeof(d)) var e int32 = 12 // 四个字节 fmt.Println(\u0026#34;length of e(int32): \u0026#34;, unsafe.Sizeof(e)) var f int64 = 12 fmt.Println(\u0026#34;length of f(int64): \u0026#34;, unsafe.Sizeof(f)) ","date":"2019-11-02T11:00:00Z","permalink":"https://blog.golang.space/p/4.%E8%B5%8B%E5%80%BC%E4%B8%8E%E7%B1%BB%E5%9E%8B/","title":"4.赋值与类型"},{"content":"指针 任何指针的零值都是 nil\n1. 基础内容 1.1. 指针的基本用法 指针不能运算，Go 语言只有值传递一种方式，引用类型，也会拷贝引用的地址\n1 2 3 4 var a int = 2 var pa *int = \u0026amp;a *pa = 3 fmt.Println(a) 1.2. 指针相等的条件 都是 nil 指向同一个变量 在 Go 语言中，返回函数中局部变量的地址也是安全的\n1.3.new 预定义函数 new(T) 将创建一个 T 类型的匿名变量，初始化T 类型零值，返回变量地址，类型是 *T\nnew 是预定义函数，并非关键字，可以更改类型，声明为变量等操作，但不建议这样干!\n1 2 3 4 p := new(int) // p, *int 类型, 指向匿名的 int 变量 fmt.Println(*p) // \u0026#34;0\u0026#34; *p = 2 // 设置 int 匿名变量的值为 2 fmt.Println(*p) // \u0026#34;2\u0026#34; struct{}和[0]int是大小为 0 的类型，(请谨慎使用大小为0的类型，因为这样可能会导致Go语言的自动垃圾回收器有不同的行为，具体请查看runtime.SetFinalizer函数相关文档）。\n1.4.变量的生命周期 包级别的变量，生命周期和程序的运行周期一致\n函数的参数和返回值都是局部变量，在函数被调用的时候创建，函数的生命周期(栈帧)结束销毁\nGolang 语言的自动垃圾回收，这里避开实现细节，说一下思路 :\n从每个包级的变量和每个当前运行函数的每一个局部变量开始，通过指针或引用的访问路径遍历，是否可以找到该变量。如果不存在这样的访问路径，那么说明该变量是不可达的，也就是说它是否存在并不会影响程序后续的计算结果。\n因为一个变量的有效周期只取决于是否可达，因此一个循环迭代内部的局部变量的生命周期可能超出其局部作用域。同时，局部变量可能在函数返回之后依然存在。\n编译器会自动选择在栈上还是在堆上分配局部变量的存储空间，选择并不是由用var还是new声明变量的方式决定\n1 2 3 4 5 6 7 8 9 10 11 12 var global *int func f() { var x int x = 1 global = \u0026amp;x // 堆上, 因为包级别还在引用, 从 f 函数中逃逸了 } func g() { y := new(int) // 外部没有引用, 编辑器可以选择栈或堆上分配, *y = 1 } 其实在任何时候，你并不需为了编写正确的代码而要考虑变量的逃逸行为，要记住的是，逃逸的变量需要额外分配内存，同时对性能的优化可能会产生细微的影响。\n如果将指向短生命周期对象的指针保存到具有长生命周期的对象中，特别是保存到全局变量时，会阻止对短生命周期对象的垃圾回收（从而可能影响程序的性能）。\n2. 使用案例 2.1. 使用指针实现 Echo 命令 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // Echo4 prints its command-line arguments. package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) // 创建布尔变量 , 参数 : 命令行参数,默认值,描述信息 var n = flag.Bool(\u0026#34;n\u0026#34;, false, \u0026#34;omit trailing newline\u0026#34;) var sep = flag.String(\u0026#34;s\u0026#34;, \u0026#34; \u0026#34;, \u0026#34;separator\u0026#34;) func main() { // 获取参数之前必须解析 flag.Parse() // flag.Args() 普通命令行参数 fmt.Print(strings.Join(flag.Args(), *sep)) if !*n { fmt.Println() } } 2.2. 使用指针来交换变量 1 2 3 4 5 6 7 8 9 func swap(a,b *int){ *a,*b = *b,*a } func main(){ var a,b int = 2,4 swap(\u0026amp;a,\u0026amp;b) fmt.Println(a,b) } 1 2 var a *int unsafe.Sizeof(a) // 对指针求大小, 64位系统=8 要改变内容必须使用指针接收者 结构过大也考虑使用指针接收者( 避免大量拷贝浪费性能 ) 一致性: 如有指针接收者, 都使用指针接收者 ( 纯属为方便 ) ","date":"2019-11-01T13:00:00Z","permalink":"https://blog.golang.space/p/3.%E6%8C%87%E9%92%88/","title":"3.指针"},{"content":"变量 Golang 有四种声明\n1 2 3 4 var\t// 声明变量 const\t// 声明常量 type\t// 声明类型 func\t// 声明函数 1. 基础内容 1.1. 变量的基本用法 1 2 3 var {variable} {type} = {表达式} // 其中类型 或表达式可以省略一个 var {variable} = {表达式} var {variable} {type} 表达式省略时，将初始化零值\n1 2 3 4 5 6 // 各个类型的零值 var INT int = 0 var STRING string = \u0026#34;\u0026#34; var BOOL bool = false var INTERFACE interface{} = nil // 引用类型(slice,map,chan,func,point,interface{}) 零值都是 nil Go开发者应该让聚合类型的零值也具有意义，可以保证任何类型变量总有合理有效的零值状态。\n1.2. 多参数声明 1 2 var i,j,k int // int,int,int var b,f,s = true,2.3,\u0026#34;four\u0026#34; // bool,float64,string 在包级别声明的变量会在 main 入口函数之前完成初始化 局部变量将在声明语句被执行到的时候完成初始化 1.3. 简短声明变量 此方式广泛用于局部变量声明和初始化。\n那么什么时候用 var ，什么时候使用简短声明? 建议\n初始化零值时，用 var。因为通常 var 比 := 更醒目，更易辨认声明变量。 非零值，使用 := 1 2 3 4 5 6 7 8 t := 0.0 str := \u0026#34;hello\u0026#34; freq := rand.Float64() * 3.0 i,j := 0,1\t// 交互 a,b 的值 a := 10 b := 20 a,b = b,a // a=20, b=10 注意\n包级别变量 与 局域变量的区分，包级别定义的变量，在函数内使用 := 时，会在函数内声明新变量\n区分 := 「声明语句」 与 = 「赋值语句」\n当 := 左侧的变量已经存在时 , 编译报错 , 有多个返回值且某一个变量存在 , 则赋值存在变量，创建新变量\n1 2 3 var k int k,err := function() // k 已经存在, 此处赋值给 k 并创建 err 变量 k := 10 // 编译器报错,至少需要一个声明的新变量才能使用 := 1.4. 强制类型转换 类型转换会产生一个新的内存成本，但是我们宁可安全也不后悔。\n可以使用 unsafe 包来做一些转换，但是如果有一个字节的偏差就会遇到真正的问题。\n1 2 3 var a,b int = 3,5 var c float64 = a // ❌ 错误示范 var d float64 = float64(a) 1.5. int 类型在不同架构下 在 amd64 架构下，表示 64 位，8 字节(byte)\n在 amd32 架构下，表示 32 位，4 字节(byte)\n","date":"2019-11-01T12:00:00Z","permalink":"https://blog.golang.space/p/2.%E5%8F%98%E9%87%8F/","title":"2.变量"},{"content":"名字很重要 起名要有可读性, 好变量名的特点是\n一致 (容易猜测) 简短 (易于输出) 准备 (易于理解) 通常来说，如果一个名字的作用域比较大，生命周期也比较长，那么用长的名字将会更有意义。但是局部变量还是参考以上三点\n1. 项目目录名 使用中划线组合\n1 2 # BAD blog_server 1 2 # GOOD blog-server 2. 包名 使用 bytes.Buffer and strings.Reader，而没有 bytes.ByteBuffer and strings.StringReader 导出的软件包名要有意义, 避免 util ，common 等 避免使用大写字母, 且不要有重复的单词 1 2 3 4 5 6 7 # BAD import ( \u0026#34;MyUtils\u0026#34; \u0026#34;blog_server\u0026#34; \u0026#34;blog-server\u0026#34; \u0026#34;blog server\u0026#34; ) 1 2 3 4 5 # GOOD import ( \u0026#34;cmd5\u0026#34; \u0026#34;blog\u0026#34; ) 3. 文件或文件夹名 文件或文件夹名建议使用 蛇形命名，一些系统并不会对文件名区分大小写\n1 2 # BAD buildTest.go 1 2 # GOOD build_test.go 避免和保留特定用法的后缀冲突\n1 2 # 测试文件 _test.go 1 2 3 # 系统相关 _386.go、_amd64.go、_arm.go、_arm64.go、_android.go、_darwin.go、_dragonfly.go、_freebsd.go、_linux.go、_nacl.go、_netbsd.go、_openbsd.go、_plan9.go、_solaris.go、_windows.go、_android_386.go、_android_amd64.go、_android_arm.go、_android_arm64.go、_darwin_386.go、_darwin_amd64.go、_darwin_arm.go、_darwin_arm64.go、_dragonfly_amd64.go、_freebsd_386.go、_freebsd_amd64.go、_freebsd_arm.go、_linux_386.go、_linux_amd64.go、_linux_arm.go、_linux_arm64.go、_linux_mips64.go、_linux_mips64le.go、_linux_ppc64.go、_linux_ppc64le.go、_linux_s390x.go、_nacl_386.go、_nacl_amd64p32.go、_nacl_arm.go、_netbsd_386.go、_netbsd_amd64.go、_netbsd_arm.go、_openbsd_386.go、_openbsd_amd64.go、_openbsd_arm.go、_plan9_386.go、_plan9_amd64.go、_plan9_arm.go、_solaris_amd64.go、_windows_386.go _windows_amd64.go 4. 常量 使用大小写混排的驼峰命名，不允许出现下划线 字母缩略词应全大写 , 像ASCII和HTML这样的缩略词则避免使用大小写混合的写法，它们可能被称为htmlEscape、HTMLEscape或escapeHTML，但不会是escapeHtml。 1 2 3 # BAD BLOG_SERVER escapeHtml 1 2 3 # GOOD BlogServer escapeHTML 按照功能来区分，而非所有类型都分在一组，公共常量置于私有常量之前\n1 2 3 4 5 6 7 8 9 10 # BAD const ( # 错误 : 私有常量应写公有常量后面 blog = \u0026#34;BLOG\u0026#34; Page=1 # 用于分页 Limit=10 Page404 = \u0026#34;404\u0026#34; # 标记 ... ) 1 2 3 4 5 6 7 8 9 10 11 12 # GOOD const ( # 分页 Page = 1 Limit = 10 # 标记 Page404 = \u0026#34;404\u0026#34; # 私有常量 blog = \u0026#34;BLOG\u0026#34; ) 5. 变量 使用大小写混排的驼峰命名，不允许出现下划线\n局部变量简短\n用 i 比 index 更合适 用 r 比 reader 更合适 若为 bool 类型, 应以 has，is ，can，allow 开头 考虑上下文, 避免使用冗余名称\nGood code\n1 2 3 4 5 6 7 8 9 10 11 12 13 func RuneCount(b []byte) int { count := 0 for i := 0; i \u0026lt; len(b); { if b[i] \u0026lt; RuneSelf { i++ } else { _, n := DecodeRune(b[i:]) i += n } count++ } return count } 全局变量\n变量长度应与作用域相关，作用域越小，则使用简短的单字母\n作用域越大，可定义完整单词或有意义的句子\n6. 结构体 建议采用名词\n7. 接口 仅指定一种方法的接口通常在函数名后附加 er，尽管可能不是正确的英语\n1 2 3 4 5 6 7 8 type Reader interface { Read(p []byte) (n int, err error) } type Execer interface { Exec(query string, args []Value) (Result, error) } 8. 函数 函数名力求精简准确，并采用动词\n函数参数\n类型是描述性的, 应该简短\n1 2 func AfterFunc(d Duration, f func()) *Timer func Escape(w io.Writer, s []byte) 函数名明确，类型不明确，参数名称可使用单词缩略\n1 func Unix(sec，nsec int64) time 参考 如何取名字 ? CodeReviewComments Effective Go ","date":"2019-11-01T11:00:00Z","permalink":"https://blog.golang.space/p/1.%E5%91%BD%E5%90%8D%E8%A7%84%E5%88%99/","title":"1.命名规则"},{"content":"鲲鹏弹性云服务器运行网络爬虫（上）\n零 系统：ubuntu 18.04\n爬虫：pyspider\n容器引擎：docker\n服务器：鲲鹏弹性云KC1\n记录全部过程\n一 开放5000端口 【控制台】-【弹性云服务器ECS】-【安全组】-【配置规则】-【添加规则】\n二 Python 环境 分别是 依赖库， python3， pip包管理\n1 2 3 4 5 sudo apt-get install python3-dev build-essential libssl-dev libffi-dev libxml2 libxml2-dev libxslt1-dev zlib1g-dev sudo apt-get install python3 sudo apt-get install python3-pip 二 pyspider 安装 pyspider是一个爬虫架构的开源化实现。主要的功能需求是：\n抓取、更新调度多站点的特定的页面 需要对页面进行结构化信息提取 灵活可扩展，稳定可监控 去重调度，队列，抓取，异常处理，监控等功能作为框架，提供给抓取脚本，并保证灵活性。最后加上web的编辑调试环境，以及web任务监控，即成为了这套框架。\n1 pip3 install pyspider 在安装的过程中遇到了错误，期间总共遇到过 3 次异常，超时错误，退出异常等，按照步骤一步步来，会好起来的。\n执行下列命令，再次安装 pyspider，耐心等待几分钟，查看版本\n1 2 apt-get install libcurl4-openssl-dev pip3 install pyspider 三 phantomjs 安装 PhantomJS 是一个基于 webkit 的 javascriptAPI。它使用 QtWebKit 作为它核心浏览器的功能，使用webkit来编译解释执行JavaScript代码。任何你可以在基于 webki t浏览器做的事情，它都能做到。PhantomJS 的用处可谓非常广泛，诸如网络监测、网页截屏、无需浏览器的Web 测试、页面访问自动化等。\n1 2 3 wget https://bitbucket.org/ariya/phantomjs/downloads/phantomjs-2.1.1-linux-x86_64.tar.bz2 tar -jxvf phantomjs.tar.bz2 ln -s /usr/local/phantomjs-2.1.1-linux-x86_64/bin/phantomjs /usr/bin/phantomjs 环境已经配置完毕，运行一下试试\n四 异常 最会，应该还会遇到一个生命中的 BUG，本文可以说涵盖了安装过程的大部分问题\n主要错误信息是\n1 2 3 4 File \u0026#34;/usr/local/lib/python3.6/dist-packages/wsgidav/wsgidav_app.py\u0026#34;, line 118, in _check_config raise ValueError(\u0026#34;Invalid configuration:\\n - \u0026#34; + \u0026#34;\\n - \u0026#34;.join(errors)) ValueError: Invalid configuration: - Deprecated option \u0026#39;domaincontroller\u0026#39;: use \u0026#39;http_authenticator.domain_controller\u0026#39; instead. 执行以下命令\n1 2 3 pip3 install wsgidav==2.4.1 # 终于启动 pyspider all 五 在本地电脑输入 ip:5000 预告： 下一篇博文，正式开始网络爬虫，将以小白的视角来记录，并不会晦涩难懂\n鲲鹏弹性云服务器运行网络爬虫（下）\n零 系统：ubuntu 18.04\n爬虫：pyspider\n服务器：鲲鹏弹性云KC1\n记录全部过程\n一 设置登录账号和密码 创建 db.json 文件，用于设置登录账号和密码\n不要在 data 文件夹内创建 db.json，data 是 pyspider 第一次启动时创建的文件，保存着数据信息，所以最好每次运行都在 data 的父目录或者指定 data 目录位置，以保证旧数据存在。\n执行命令启动\n1 pyspider --config db.json all 在本地电脑，打开浏览器，输入服务器的ip地址：5000，即弹出登录对话框，输入之前设置的用户名和密码\n二 创建第一个爬虫 简单的操作，见图\n创建之后，自动生成基础代码，15 行横线处是待爬取的首页链接，19 行是查找详情页，也就是首页面的所有跳转链接，最后的方框则是返回的结果\n三 实战 爬取网页：http://quotes.toscrape.com/\n信息：名言内容，作者，标签\n查看网页信息，每一句名言都是一个div，class=quote， 这里关键字是 quote\n1 2 3 4 5 6 7 8 9 @every(minutes=24 * 60) def on_start(self): self.crawl(\u0026#39;http://quotes.toscrape.com/\u0026#39;, callback=self.index_page) @config(age=10 * 24 * 60 * 60) def index_page(self, response): results = [] for each in response.doc(\u0026#39;.quote\u0026#39;).items(): pass F12 查看元素，元素选择器（图片中红标1）选择作者名，在右边代码栏可见该标签，其它标签属性有 itemprop=\u0026quot;author\u0026quot; ，以此类推\n代码可以这样写\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 名言结果集 results = [] # 循环每一句名言 for each in response.doc(\u0026#39;.quote\u0026#39;).items(): # 名言 comment = each.find(\u0026#39;[itemprop=\u0026#34;text\u0026#34;]\u0026#39;).text() # 作者 author = each.find(\u0026#39;[itemprop=\u0026#34;author\u0026#34;]\u0026#39;).text() # 标签 tags = each.find(\u0026#39;.tags .tag\u0026#39;).items() # 标签结果集 tagList = [] for tag in tags: tagList.append(tag.text()) # 将查询到名言封装到名言结果集 results.append({ \u0026#34;comment\u0026#34;: comment, \u0026#34;author\u0026#34;: author, \u0026#34;tagList\u0026#34;: tagList }) 结果\n四 将结果存储到 MongoDB 如何在鲲鹏弹性云部署 MongoDB，见下链\nhttps://bbs.huaweicloud.com/forum/thread-28769-1-1.html\n1\n安装 pymongo\n1 pip3 install pymongo 2\n爬虫代码：\n1 2 # 导入 import pymongo 1 2 3 4 # 连接 mongodb 数据库 client = pymongo.MongoClient(\u0026#39;119.3.248.122\u0026#39;) # 库名为 demo1 db = client[\u0026#39;demo1\u0026#39;] 1 2 3 4 5 6 7 8 9 # 如果有结果集，调用存储数据库函数 def on_result(self,result): if result: self.save_to_mongo(result) # 存到数据库 def save_to_mongo(self,result): if self.db[\u0026#39;comment\u0026#39;].insert(result): print(\u0026#39;saved to mongo\u0026#39;,result) #化鲲为鹏，我有话说# 鲲鹏弹性云服务器运行网络爬虫（下）分页与总结\n一 分页 通过之前的方法，用选择器点击图标，右侧代码框会自动定位该元素，这里可以看到通过 /page/2/ 以末尾的数字进行分页\n获取该链接, 然后递归调用自己一直查询\n1 2 next = response.doc(\u0026#39;.next a\u0026#39;).attr.href self.crawl(next, callback=self.index_page) 二 源码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 #!/usr/bin/env python # -*- encoding: utf-8 -*- # Created on 2019-11-24 03:27:43 # Project: demo1 from pyspider.libs.base_handler import * import pymongo class Handler(BaseHandler): crawl_config = { \u0026#39;itag\u0026#39;: \u0026#39;v224\u0026#39; } # 连接 mongodb 数据库 client = pymongo.MongoClient(\u0026#39;localhost\u0026#39;) # 库名为 trip db = client[\u0026#39;demo1\u0026#39;] @every(minutes=24 * 60) def on_start(self): self.crawl(\u0026#39;http://quotes.toscrape.com/\u0026#39;, callback=self.index_page) @config(age=60) def index_page(self, response): self.crawl(response.url, callback=self.detail_page) next = response.doc(\u0026#39;.next a\u0026#39;).attr.href # 递归调用 self.crawl(next, callback=self.index_page) @config(priority=2) def detail_page(self, response): results = [] for each in response.doc(\u0026#39;.quote\u0026#39;).items(): comment = each.find(\u0026#39;[itemprop=\u0026#34;text\u0026#34;]\u0026#39;).text() author = each.find(\u0026#39;[itemprop=\u0026#34;author\u0026#34;]\u0026#39;).text()# 作者 # 标签 tags = each.find(\u0026#39;.tags .tag\u0026#39;).items() # 标签结果集 tagList = [] for tag in tags: tagList.append(tag.text()) # 将查询到名言封装到名言结果集 results.append({ \u0026#34;comment\u0026#34;: comment, \u0026#34;author\u0026#34;: author, \u0026#34;tagList\u0026#34;: tagList }) return results # 保存 def on_result(self,result): if result: self.save_to_mongo(result) # 存到数据库 def save_to_mongo(self,result): if self.db[\u0026#39;comment\u0026#39;].insert(result): print(\u0026#39;saved to mongo\u0026#39;,result) 三 常用方法 auto_recrawl 在任务过期后，自动重爬取\nmethod 请求方法，默认 get 请求\nparams 追加参数 url， 感觉不常用\ndata 用于提交 post 请求的数据，可以用于登录？\nconnect_timeout 连接的超时时间，默认20秒\ntimeout 超时的请求时间，默认120秒\nvalidate_cert 针对 https 网站，会爆证书错误，设置 false 可以忽略并继续访问，默认true\nproxy 代理\netag 布尔类型变量，默认 true， 判断是否发生变化，没有发生变化就不爬了\nfetch_type 请求的原始的 docment, 设置 =js 后,就可以调用 js 进行渲染\nfetch_type='js'\njs_script 可以执行js 操作, 比如滚动到网页的最下端,触发更多加载\n1 window.scrollTo(0,document.body.scrollHeight); js_run_at 将脚本加入到前面或者后面执行,默认是后面\njs_viewport_width/js_viewport_height 视窗的大小\nload_images 是否加载图片,默认 false\nsave 做多个函数之间传递变量,相当于 response 的session\ntaskid 唯一标识码，去重\n四 web 浏览框 使用的时候发现这个浏览框非常的小, 改变方法见下图2\n此方法只能用于本次, 一劳永逸需要修改配置文件\n该路径是指向 pyspider 文件夹\nsudo vim /usr/local/lib/python3.5/dist-packages/pyspider/webui/static/debug.min.css\n增加 iframe 的样式: height:900px !important\n","date":"2019-10-25T15:00:00Z","permalink":"https://blog.golang.space/p/python-%E7%88%AC%E8%99%AB%E7%BB%83%E6%89%8B/","title":"python 爬虫练手"},{"content":"flutter 一些技巧 [toc]\n局部设置明暗主题 多设备启动 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 { // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Current Device\u0026#34;,\t// 设备名 \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;,\t// 操作 \u0026#34;type\u0026#34;: \u0026#34;dart\u0026#34;,\t// 语言类型 \u0026#34;program\u0026#34;: \u0026#34;lib/main_dev.dart\u0026#34; // 入口 }, { \u0026#34;name\u0026#34;: \u0026#34;Android\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;dart\u0026#34;, \u0026#34;deviceId\u0026#34;: \u0026#34;android\u0026#34;, \u0026#34;program\u0026#34;: \u0026#34;lib/main_dev.dart\u0026#34; // 入口 }, { \u0026#34;name\u0026#34;: \u0026#34;iPhone\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;dart\u0026#34;, \u0026#34;deviceId\u0026#34;: \u0026#34;iPhone\u0026#34; } ], \u0026#34;compounds\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;All Devices\u0026#34;, \u0026#34;configurations\u0026#34;: [\u0026#34;Android\u0026#34;, \u0026#34;iPhone\u0026#34;] } ] } ListView 嵌套 ListView 1 2 shrinkWrap: true, //解决无限高度问题 physics: new NeverScrollableScrollPhysics(),\t//禁用滑动事件 刷新效果 , 即转圈动画 背景透明的路由 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Navigator.of(context).push( PageRouteBuilder( opaque:false, pageBuilder: (context, animation, secondaryAnimation) { return Scaffold( backgroundColor: Colors.transparent, body: SafeArea( child: Stack( children: \u0026lt;Widget\u0026gt;[ //... ], ), ) ); } )); 屏幕适配 参考 https://github.com/jiang111/flutter_code/blob/master/lib/ui_4/home_page.dart\n全局坐标转换局部坐标 1 2 RenderBox box = context.findRenderObject(); _tapPos = box.globalToLocal(details.globalPosition); 强制竖屏 1 2 3 // 强制竖屏 // SystemChrome.setPreferredOrientations( // [DeviceOrientation.portraitUp, DeviceOrientation.portraitDown]); 网络请求处理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 return Center( child: FutureBuilder\u0026lt;dynamic\u0026gt;( future: CommentApi.getCommentList( elem[\u0026#34;id\u0026#34;], 10, 0), // a previously-obtained Future\u0026lt;String\u0026gt; or null builder: (BuildContext context, AsyncSnapshot snapshot) { switch (snapshot.connectionState) { // 未执行 case ConnectionState.none: // 连接到异步操作 return Text(\u0026#39;Press button to start.\u0026#39;); case ConnectionState.active: // 请求中 case ConnectionState.waiting: // // 请求未结束，显示loading return Text(\u0026#34;\u0026#34;); // return CircularProgressIndicator(); case ConnectionState.done: // 请求完成 if (snapshot.hasError) return Text(\u0026#39;Error: ${snapshot.error}\u0026#39;); List list = snapshot.data as List; return Column( mainAxisAlignment: MainAxisAlignment.start, crossAxisAlignment: CrossAxisAlignment.start, children: comment(context, list), ); } return null; // unreachable }, )); 时间格式化 1 2 3 4 5 import \u0026#39;package:intl/intl.dart\u0026#39; var _formatter = new DateFormat(\u0026#39;yyyy-MM-dd\u0026#39;); var _createTime = _formatter.format(DateTime.parse(elem[\u0026#34;create_time\u0026#34;])); 渐变色 1 2 3 4 5 6 7 8 Container( decoration: BoxDecoration( gradient: LinearGradient( colors: [Color(0xFFfbab66), Color(0xFFf7418c)], begin: Alignment.topCenter, end: Alignment.bottomCenter, )), ); 圆形头像 1 2 3 4 CircleAvatar( maxRadius: 15, backgroundImage: NetworkImage(_icon), ), likebutton 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 LikeButton( onTap: (bool flag) { return onLikeButtonTap(flag, _id); }, isLiked: _likes, size: 18, likeCount: _count, countPostion: CountPostion.left, likeCountPadding: EdgeInsets.only(right: 5), likeBuilder: (bool flag) { return Image( image: AssetImage(\u0026#34;images/like.png\u0026#34;), height: 18, color: flag ? Colors.redAccent : Colors.grey[600], ); }, ), Future\u0026lt;bool\u0026gt; onLikeButtonTap(bool isLiked, String id) { if (isLiked != true) { // send your request here CommentApi.putLike(id).then((value) { if (value.statusCode != 200) { message(\u0026#34;网络异常,请稍后再试\u0026#34;); isLiked = isLiked; } else { isLiked = true; } }); } final Completer\u0026lt;bool\u0026gt; completer = new Completer\u0026lt;bool\u0026gt;(); Timer(const Duration(milliseconds: 200), () { // if your request is failed,return null, completer.complete(isLiked); }); return completer.future; } 图片上传 https://www.jianshu.com/p/b582daddd737\nhttp://47.105.149.100/web/flutter-cai-kang-ri-ji-chi-xu-geng-xin-\n点击可修改的属性 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 Container( height: 25, width: 100, alignment: Alignment.centerLeft, child: TextField( onTap: () { if (authorController.text == UserApi.model.getUserInfo[\u0026#34;nick_name\u0026#34;]) { authorController.text = \u0026#39;\u0026#39;; } // 默认值则自动置空 }, maxLines: 1, maxLength: 7, // 限制最长字符 controller: authorController, decoration: InputDecoration( counterText: \u0026#34;\u0026#34;, // 不显示字符串数量 disabledBorder: InputBorder.none,// 无边框 enabledBorder: InputBorder.none, focusedBorder: InputBorder.none, border: InputBorder.none, // contentPadding: EdgeInsets.all(10.0), ), autofocus: false, textAlign: TextAlign.left, style: Theme.of(context).textTheme.bodyText2, )), ], ), 组件位置 1 2 3 4 5 GlobalKey anchorKey = GlobalKey(); RenderBox renderBox = anchorKey.currentContext.findRenderObject(); var offset = renderBox.localToGlobal(Offset(0.0, 0.0)); 延迟执行 1 2 3 4 5 // 延时1s执行返回 Future.delayed(Duration(seconds: 1), (){ Navigator.of(context).pop(); print(\u0026#39;延时1s执行\u0026#39;); }); wifi 真机调试 https://juejin.im/post/5c9848cae51d450d91120278\n定时器 循环执行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 import \u0026#39;dart:async\u0026#39;; // 引入定时去所需要的包 Timer _timer; // 定义一个变量，在页面销毁时需要用到，如果在定时器内部已经销毁了，可以不需要 int _count = 0; // 一切为了演示。定义的变量 ... myTimer() { // 定义一个函数，将定时器包裹起来 _timer = Timer.periodic(Duration(milliseconds: 1000), (t) { _count++; if (_count==5) { t.cancel(); // 定时器内部触发销毁 } }); } ... @override void dispose(() { if (_timer != null) { // 页面销毁时触发定时器销毁 if (_timer.isActive) { // 判断定时器是否是激活状态 _timer.cancel(); } } super.dispose(); }); https://juejin.im/post/5cada409e51d456e5b66ad1b\nhttps://juejin.im/post/5d81cf6d518825485e227b8c\n仅仅执行一次, 在构造中写逻辑 1 2 3 4 5 MineView() { WidgetsBinding.instance.addPostFrameCallback((callback) { HttpUtils.userModel.controller.callRefresh(); }); } 自定义高度 appbar 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 appBar: AppBar( brightness: Brightness.dark, leading: navigatPop(context, color: Colors.white), backgroundColor: Colors.blue[300], bottom: PreferredSize( child: Column( children: [ Container( padding: EdgeInsets.only(left: 20, bottom: 30), alignment: Alignment.centerLeft, child: Text( title, style: Theme.of(context) .textTheme .headline6 .copyWith(color: Colors.white), ), ), ], ), preferredSize: Size(double.infinity, 70)), ), 滑动删除 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 Slidable( key: Key(index.toString()), actionPane: SlidableScrollActionPane(), //滑出选项的面板 动画 actionExtentRatio: 0.25, dismissal: SlidableDismissal( child: SlidableDrawerDismissal(), onWillDismiss: (actionType) { return action(index, e.id); }, onDismissed: (actionType) { print(actionType); }, ), secondaryActions: \u0026lt;Widget\u0026gt;[ Padding( padding: EdgeInsetsDirectional.only(top: 20, bottom: 15), child: IconSlideAction( caption: \u0026#39;Delete\u0026#39;, color: Colors.red, icon: Icons.delete, closeOnTap: false, onTap: () { showIosDialog(context, title: title, desc: desc) .then((value) { if (value) { action(index, e.id); } }); })), ], Flutter TextField设置只读不可编辑 1 2 3 4 TextField( enableInteractiveSelection: false, onTap: () { FocusScope.of(context).requestFocus(new FocusNode()); }, ) 参考 : [http://www.appblog.cn/2019/01/22/Flutter%20TextField%E8%AE%BE%E7%BD%AE%E5%8F%AA%E8%AF%BB%E4%B8%8D%E5%8F%AF%E7%BC%96%E8%BE%91/](http://www.appblog.cn/2019/01/22/Flutter TextField设置只读不可编辑/)\n可选的 text selectabletext ","date":"2019-10-09T00:00:00Z","permalink":"https://blog.golang.space/p/flutter-%E4%B8%80%E4%BA%9B%E6%8A%80%E5%B7%A7/","title":"flutter 一些技巧"},{"content":"图床 七牛云免费赠送用户 10G 存储空间，用来做图床绰绰有余\n使用 PicGo 上传图片 注册登录七牛云，绑定相关信息。在 密钥管理 页面复制 「AK」和「SK」。\nPicGo帮助文档\n如果使用快捷键上传, 要使用到 xclip, 必须安装\n存储空间名似乎不能用 - ，第一次配置的时候一直上传失败，更换空间名后搞定\n更换自定义域名 七牛云的融合域名只能使用 30 天, 这里更换成自己的二级域名\n进入页面后添加域名 这里创建时，多次提示域名未备案，域名错误等，多尝试几次即可创建\n在对象存储中将该域名设置为默认路径\n在域名商处设置 dns 解析\n其中的记录值来自于下图\n最后，将域名拷贝至 PicGo\n使用 HTTPS 使用新版本谷歌浏览器 http 的图片不能加载，升级更安全的 https。\n创建证书，上传到七牛云，部署 CDN 即可。\n更换了uPic 在 20 年初使用 PicGo 遇到了上传偶尔失效的 bug，因此切换成 uPic，免费，强大!\n保存路径:\n1 PicGo/{since_millisecond}-{filename}{.suffix} ","date":"2019-03-13T00:00:00Z","image":"http://img.golang.space/1615999792525-o6sBvr.jpg","permalink":"https://blog.golang.space/p/%E5%9B%BE%E5%BA%8A/","title":"图床"},{"content":"记录笔记的风格\n文件名风格 后缀使用小写 同时有中英文，英文两边加空格 使用连字符 -，而非下划线或驼峰，连字符是现在最流行的网址分隔符 主题风格 建议 ## 二级标题之间可多加一行空格 名称由 {大标题序号}.{小标题序号}.{标题} 组成，若文章无序从任意位置查看都可以 ( 比如这篇 ) 可不要序号 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # Title 引言 ## 1.相关见闻 介绍、说明 ### 1.1.小标题 ## 2.基础内容 ### 2.1.小标题 ### 2.2.小标题 ## 3.使用案例 ### 3.1.小标题 ### 3.2.小标题 代码块 Golang 代码块示例\n1 2 3 func main(){ fmt.Println(\u0026#34;hi\u0026#34;) } Golang 代码 markdown 格式，注意右上角标明 go 语言\n1 2 3 4 5 ```go func main(){ fmt.Println(\u0026#34;hi\u0026#34;) } ​``` Javascript 代码格式\n1 2 3 ```js console.log(\u0026#34;hi\u0026#34;) ​``` html 代码格式\n1 2 3 4 5 ```css .body{ padding: 0px; } ​``` 引号使用场景 使用中文的 「」 描述\n描述步骤\n1 「系统偏好设置 - 键盘 - 输入法」 描述快捷键\n1 「Command + Control + 空格键」 这是表情符号窗口 描述属性 使用表格\n属性说明 值/示例 xxx xxx 1 2 3 | 属性说明 | 值/示例 | | :---- | :---- | | xxx | xxx | 清单 一个大工程 子项工程 1 子项工程 2 1 2 3 - [ ] 一个大工程 - [ ] 子项工程 1 - [ ] 子项工程 2 表达 一个段落只表达一个主题 避免连续使用松散的句子 使用相同的结构表达并列的意思 将强调的词放在句末 补充说明 {} 大括号内的内容是变量名, 需要替换成适当的值。\n为方便写代码等，设置输入法「偏好设置 - 中文下使用英文标点」，如需中文符号有下面两种解决方案。\n快捷键 「control + command + .」快速开关该功能。 使用第三方软件控制快捷键，针对个别符号设置快捷键，该方法未找到合适的软件( for mac )。\n使用输入法的「自定义短语设置」。 ","date":"2019-03-12T00:00:00Z","image":"http://img.golang.space/1615740287358-790867.jpg","permalink":"https://blog.golang.space/p/%E5%85%B3%E4%BA%8E-markdown-%E9%A3%8E%E6%A0%BC/","title":"关于 markdown 风格"},{"content":"以前用的是 Spring boot 创建的博客，现在转 Golang 这么久了，想换个与之相关技术的，于是乎有了这个 hugo 创建的博客\n开始 下载安装包, 写此篇文章时版本为 0.81\n解压缩后放入 /usr/bin 文件夹\n创建博客\n1 2 3 hugo new site blog git init \u0026amp;\u0026amp; git add . git commit -m \u0026#34;create blog\u0026#34; 添加主题，首次创建可以使用该主题下的例子，将 exampleSite 文件夹下的 config.yaml ， content，plugins 拷贝到 blog 目录\n1 2 3 4 5 git submodule add https://github.com/CaiJimmy/hugo-theme-stack ./themes/hugo-theme-stack cd ./themes/hugo-theme-stack/exampleSite rm LICENSE README.md mv * ../../../ 回到 blog 目录，commit 代码后，创建服务器查看博客\n1 2 3 4 git add . git commit -m \u0026#34;add theme\u0026#34; hugo server 部署到公网 这里部署到 Github\n创建仓库，仓库名必须以 github.io 结尾\n创建好仓库，回到项目，执行命令创建 html 页面\n1 hugo 项目文件夹中自动创建了 public 文件夹，存放着博客的静态文件，将此文件夹推送到刚刚创建的仓库\n1 2 3 4 5 6 cd public git init git add . git commit -m \u0026#34;blog\u0026#34; git remote add origin 仓库地址 git push -u origin master 回到远程仓库，选择菜单栏中的 settings ，页面翻到底部\n如何自定义域名? 在域名控制面板，比如我在 xxx 买的域名，就登录 xxx 官方，后台控制页面，选择域名解析。\n记录类型为 CNAME ，我使用二级域名 blog.golang.space，记录值填写博客仓库名.\n进入博客目录，创建 CNAME 文件，写入自定义域名，将修改推送到远程\n1 2 3 4 5 6 cd public echo \u0026#34;blog.golang.space\u0026#34; \u0026gt; CNAME git add . git commit -m \u0026#34;add cname\u0026#34; git push 创建自动化脚本 若是每次写了新博文，都要 hugo 推送等等一堆命令, 是很麻烦的。\n在 blog 目录下创建一个自动化脚本。\n1 vim Makefile 1 2 3 4 5 6 7 8 9 10 11 12 13 build: rm -rf ./docs ./hugo -d docs \u0026gt;\u0026gt; build.log @cp ./googlec03aeb90afb546ce.html ./docs @echo \u0026#34;blog.golang.space\u0026#34; \u0026gt; ./docs/CNAME @echo -e \u0026#34;打包完成\u0026#34; push: git add . git commit -m $(m) \u0026gt;\u0026gt; build.log @echo \u0026#34;正在发送到服务器...\u0026#34; git push @echo \u0026#34;OK\u0026#34; 执行\n1 make build push m=初始化博客 添加评论功能 Github 安装 utterances ，配置时我仅仅选择博客存储仓库.\n服务端配置完成后，在网站配置中填写仓库地址，保存文件后执行自动化脚本推送，再次打开博文拉到底部已经有评论面板啦。\n1 2 3 4 cd blog vim config.yaml # 修改并保存文件后 ./auto.sh 创建自己的博文 删除 项目/content/post 下的所有内容，将自己的 markdown 文件复制进来\n所有的文件顶部需要加上以下内容\n1 2 3 4 5 6 7 8 9 10 11 12 --- title: {显示在网站内的标题及网址尾部的文件名} description: {描述} date: {创建日期} slug: {文件夹/文件 路径, 会显示在网址中} image: {封面图} categories: - 杂记 {分类} --- # 正文 SEO 帮助网站快速进入 百度/谷歌 搜索\n谷歌 google search\n百度 登录百度搜索资源平台，在站点管理中添加域名，验证网站所有权, 我选择 CNAME 的方式;\n谷歌分析 打开网站\n左下角设置 创建媒体资源 输入资源名称，并打开显示高级选项，输入网址，选择仅创建 Universal Analytics 媒体资源 将跟踪 ID 填入相关配置 待完善 谷歌分析 网站访问统计，单篇博文点击统计 小部件 分类标签同名不同色，每次都会随机颜色 相同的标签有不同的颜色 清单前面有无序标点 不支持 [toc] ，没有目录 如何制作主题? 仅将链接索引放这，待看\ntemplates 语法\n某个前端开发出的 hugo 教程\n零壹軒主题定制方法\n参考 关于创建 pages GITHUB 官方文档 自定义域名 GITHUB 官方文档 主题的配置说明 google analytics设置 google analytics Hugo 官方文档 ","date":"2019-03-11T00:00:00Z","image":"http://img.golang.space/1615716329188-64aab4ae3e632dbcbf9223995c654317.jpg","permalink":"https://blog.golang.space/p/%E5%9B%BE%E8%AE%B0%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2%E7%9A%84%E8%BF%87%E7%A8%8B/","title":"图记创建博客的过程"},{"content":"文件读写 文件的打开和关闭 打开文件，fopen() 函数，返回一个文件指针\n该 function 有两个参数，形参1表示路径/文件名，形参2表示打开的方式；\n1 2 3 4 5 \u0026#34;r\u0026#34; // 只读，文件必须已存在，否则报错 \u0026#34;w\u0026#34; // 只写，创建并打开文件，若已存在则覆盖 \u0026#34;a\u0026#34; // 只写，指针移动到文件末尾，文件必须已存在，否则报错 \u0026#34;+\u0026#34; // 组合，读写 \u0026#34;b\u0026#34; // 组合，表示打开二进制文件 以读写方式，打开 D 盘根目录下文件 demo.txt ，保留内容，向其文件尾部追加数据：\n1 2 FILE *fp; // 文件指针的定义 fp = fopen(\u0026#34;D:\\\\demo.txt\u0026#34;,\u0026#34;a+\u0026#34;); 打开二进制文件\n1 2 FILE *fp; fp = fopen(\u0026#34;D:\\\\demo.txt\u0026#34;,\u0026#34;ab+\u0026#34;); 在文件使用结束后必须关闭文件，否则会出现意想不到的错误，在 c program 中，函数 fclose() 用来关闭一个由函数 fopen() 打开的文件；该函数关闭成功返回0，否则返回非0值；\n按字符读写文件 函数 fgetc() 用于从一个以只读或读写方式打开的文件上读字符；并将位置指针指向下一个字符，若成功则返回该字符，若读到文件尾则返回EOF；（EOF为符号常量，在 stdio 中定义为 -1）\n函数 fputc() 用于将一个字符写到一个文件上，若写入错误返回EOF，否则返回字符C\n1 int fputc(int c, FILE *fp); // 函数原型 Q1 从键盘输入一串字符，然后把它们转存到磁盘文件；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stalin.h\u0026gt; int main() { FILE *fp; char ch; if ((fp = fopen(\u0026#34;demo.txt\u0026#34;,\u0026#34;w\u0026#34;)) == NULL) // 判断是否为空指针，即文件打开失败后的操作 { printf(\u0026#34;Failure to open demo.txt!\\n\u0026#34;); // 提示失败 exit(0); // 结束程序,这里的退出函数属于 stdlib.h } ch = getchar(); // 输入一个字符 while (ch != \u0026#39;\\n\u0026#39;) // 只要不是换行，回车 { fputc(ch,fp); // 将该字符放入文件中； ch = getchar(); // 再获取一个字符 } fclose(fp); // 关闭文件 return 0; } 若文件打开失败，fopen() 会返回空指针 NULL，因此可以通过检查返回值来判断文件打开是否成功。\nQ2 将 0～127 之间的 ASCLL 字符写到文件中，然后从文件中读出并显示到屏幕\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main() { FIEL *fp; char ch; fp = fopen(\u0026#34;demo.bin\u0026#34;,\u0026#34;wb\u0026#34;); // 以二进制方式创建文件 if(fp == NULL) { printf(\u0026#34;Failure to open demo.bin!\\n\u0026#34;); exit(0); } for(int i = 0; i \u0026lt; 128; i++) { fputc(i,fp); // 将 ASCLL 码值在 0～127 之间的所有字符写入文件 } fclose(fp); // 读 if ((fp = fopen(\u0026#34;demo.bin\u0026#34;,\u0026#34;rb\u0026#34;)) == NULL) { printf(\u0026#34;Error!\\n\u0026#34;); exit(0); } while((ch = fgetc())!=EOF) // 一直读到文件尾 { putchar(ch); } fclose(fp); return 0; } 上面标记的那一行，用来判断是否读到了文件尾，除此之外还可以使用函数 feof() 来判断是否读到文件末尾，代码如下：\n1 2 3 4 5 6 ch = fgetc(fp); while(!feof(fp)) // 这里feof 用于检查是否到达文件尾 { putchar(ch); ch = fgetc(fp); } 当文件位置指针指向文件结束符（End-of-file Indicator）时，若结束返回非0值，未结束返回0值；\nQ3 将上面的程序修改一下，读出的时候判断是否为可打印字符\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main() { FILE *fp; char ch; int i; fp = fopen(\u0026#34;demo.bin\u0026#34;,\u0026#34;wb\u0026#34;); // 创建文件，以二进制形式写入 if(fp == NULL) // 判断是否打开 { printf(\u0026#34;Error!\\n\u0026#34;); exit(0); } for(i=0; i\u0026lt;123; i++) { fputc(i,fp); // 将 i 输出到文件中； } fclose(fp); // 关闭文件 fp = fopen(\u0026#34;demo.bin\u0026#34;,\u0026#34;rb\u0026#34;); // 读取文件，以二进制形式读 if(fp == NULL) // 判断是否打开 { printf(\u0026#34;Error!\\n\u0026#34;); exit(0); } while(!feof(fp)) // 判断文件尾 { ch = fgetc(fp) if (!iscntrl(ch)) // 判断是否可打印 { printf(\u0026#34;%c\\t\u0026#34;,ch); } else { printf(\u0026#34;%d\\t\u0026#34;,ch); } } fclose(fp); return 0; } 两个函数的用法:\n1 2 isprint(变量); // 如果变量可以打印显示，就返回非0值 iscntrl(变量); // 判断是否为控制字符，如果是返回0 读取文件中的字符串 从文件读取字符串可使用函数 fgets() ;\n1 char *fgets(char *s, int n, FILE *fp); // 函数原型 该函数以 fp 所指文件读取字符串并在末尾添加\\0，然后存入 s，最多读取 n-1 个字符；\n当读到换行符或读满时，返回字符串首地址，即指针s，读取失败返回空指针 NULL；\nferror() 函数用来检测是否出现文件错误，若有错误返回一个非0值，否则返回0值；\n将字符串写入文件的函数 fputs() ,若出现写入错误，返回EOF，否则返回一个非负数；\n1 int fputs(const char *s, FILE *fp); Q4 从键盘输入一串字符，然后把它们添加到文本文件 demo.txt 末尾。假设文件 demo.txt 已有内容 I am a student.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #define N 80 int main() { FILE *fp; char str[N]; if ((fp = fopen(\u0026#34;demo.txt\u0026#34;,\u0026#34;a\u0026#34;))==NULL) { printf(\u0026#34;Error!n\u0026#34;); exit(0); } gets(str); fputs(str,fp); fclose; if((fp = fopen(\u0026#34;demo.txt\u0026#34;,\u0026#34;r\u0026#34;))==NULL) { printf(\u0026#34;Error!\\n\u0026#34;); exit(0); } fgets(str,N,fp); puts(str); fclose(fp); return 0; } 与 gets 不同，fgets() 从指定的流读字符串，读到换行符时将换行符也作为字符串的一部分读到字符串中来；同理，与 puts buts的市场，fputs() 不会在写入文件的字符串末尾加上换行符。\nc program 允许按指定格式读写文件。函数 fscanf() 用于按指定格式从文件读数据。该函数有3个参数，参数1为文件指针，参数2为格式控制参数，参数3为地址参数列表；后两个参数与函数 scanf 相同；\n函数 fprintf() 用于按指定格式向文件写入数据。\nQ5 编程计算每个学生的4门课程的平均分，将学生的各科成绩及平均分输出到文件 score.txt 中；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #define N 30 typedef struct date { int year; int month; int day; } DATE; typedef struct student { long studentID; char studentName[10]; char studentSex; DATE birthday; int score[4]; float aver; } STUDENT; void InputScore(STUDENT stu[], int n, int m); void AverScore(STUDENT stu[], int n, int m); void WritetoFile(STUDENT stu[], int n, int m); int main() { STUDENT stu[N]; int n; printf(\u0026#34;How many student?\u0026#34;); scanf(\u0026#34;%d\u0026#34;,\u0026amp;n); InputScore(stu,n,4); WritetoFile(stu,n,4); return 0; } ","date":"2018-08-30T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E5%8D%81%E4%BA%94%E8%AF%BE-%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99/","title":"第十五课 文件读写"},{"content":"递归和迭代 Q1 递归计算 斐波那契数列\n1 2 3 4 5 6 7 8 int fun(int n) { n -= 1; switch(n) case 0: case 1: return 1; return fun(n-1)+fun(n-2); } 在switch中，如果default语句在最前面且没有跳出语句，而case没有匹配到，则接着执行后面的case语句； 有些编译器，switch语句如果没有匹配到，就从头执行case，大部分都会跳过switch整个语句块； 1 2 3 4 5 6 7 8 switch(x) { default: case 0: case 1: x=1; } // 当 x=2 时，输出的结果为 x=1； 回到递归\n当两个函数互相调用对方，称为间接调用；\n递推：由已知求未知，比如阶乘由1到100；\n递归：由未知到已知，由100到1；\nQ2 汉诺塔\n只能用递归来解决；\n","date":"2018-08-25T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E5%8D%81%E5%9B%9B%E8%AF%BE-%E9%80%92%E5%BD%92%E5%92%8C%E8%BF%AD%E4%BB%A3/","title":"第十四课 递归和迭代"},{"content":"结构体 定义 数据类型：基本类型 / 自定义类型\n基本类型就是系统提供，用户可以直接使用：float double char int\n自定义类型就是系统没有用户可以根据自己需要来创建的数据类型，这种类型的特点：一个变量不单能够包含若干数据，同时还能是不同的类型；\nint x;\nint a[]； 这两种数据都是单一类型，仅仅存储 int 变量；\n结构体数据类型，即多又不同；\n在 c program 中，自定义类型主要提供两种：结构体数据，共用体类型（共同体）\n结构体数据类型的创建:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 struct 结构体类型名 // 定义结构体类型，一般定义在全局 { int a; //成员类型 成员名； float b; // 成员类型 成员名； char c; char d[100]; }; struct 结构体类型名 结构体变量名； // 定义结构体变量 struct intfloat a = {23,1.02,\u0026#39;a\u0026#39;,\u0026#34;aaaa\u0026#34;}; // 结构体变量初始化 printf(\u0026#34;%d\u0026#34;,a.a); // 结果为23， 结构体名.成员名 引用方法 printf(\u0026#34;%s\u0026#34;,a.d); // 结果为 aaaa a.c = \u0026#39;k\u0026#39;; // 单个成员赋值 a.d = \u0026#34;bbbb\u0026#34;； // 字符串在初始化过后不可以直接复制； strcpy(x.d,\u0026#34;abcdefg\u0026#34;); // 这样能够变相赋值 在结构体中想包含哪些数据，就定义对应变量；\n结构体指针 如果用结构体指针来引用成员，格式为：\n1 2 3 4 5 struct intfloat *p; struct intfloat a; p = \u0026amp;a; printf(\u0026#34;%s\u0026#34;,p-\u0026gt;d); // 结构为 aaaa，无须带星号 Q1 从键盘输入 10 个同学的考试信息，考试信息包含\n学号：long\n性别：char m/w\n成绩：int\n输出最高分同学的所有信息；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 struct student{ long number; char x; int score; }; main(){ struct student data[10],*p; int k,i,max; p = \u0026amp;data; for(i=0; i\u0026lt;10; i++){ scanf(\u0026#34;%ld %c %d\u0026#34;,\u0026amp;p[i].number,\u0026amp;p[i].x,\u0026amp;p[i].score); } max=data[0].score; for(i=1; i\u0026lt;10; i++){ if(p[i]-\u0026gt;score \u0026gt; max) max = p[i]-\u0026gt;score; k = i; } printf(\u0026#34;%ld %c %d\\n\u0026#34;,p[k]-\u0026gt;number,p[k]-\u0026gt;x,p[k]-\u0026gt;score); } 结构体的类型长度 1 2 3 sizeof(struct std); // 结构体类型长度等于各个成员类型长度之和 // 如上题，4+1+4 = 9，即 9 字节； 实际输出12个字节，求出最大字节数乘以成员数，即 4*3 =12 共同体 共用体关键字：union\n共用体所有的成员共用一个空间，这个空间就是成员当中最大的那个！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 union std { long xh; double x; int j; }; main(){ union std data; data.xh = 12; data.j = 1.333; printf(\u0026#34;%ld\u0026#34;,data.xh); } // 结果为 1.333 // 因为在共用体里，所有成员都是用同一个空间，所有元素的结果 等于最后一次赋值的结果； 存储类型 在 c program 中存储类型有三种：\nauto 动态存储类型 static 静态存储类型 register 寄存器类型 auto 存储类型是最常用的，最有效；随用随给，不用回收；\nstatic 静态类型，一旦将存储空间分配给某个变量，在程序没有结束前，这个空间是不能收回的，永远保存存储的数据，在函数内不会消亡。\nregister 寄存器类型：寄存器是 cpu 中的一块，如果变量是 register 类型，那么该变量的数据是直接送给 cpu 处理，而不需要内存中转；\n**Q2 **\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 int x; int fun(int x){ int a=1,b=1; static c = 1; a++; b++; c++ return a+b+c+x; } main(){ int i; for(i=1; i\u0026lt;=3; i++) printf(\u0026#34;%d\u0026#34;,fun(i)); } // 第一轮循环 // i=1,a=b=c=2 ,re = 6+1 = 7 // 第二轮循环 // i=2,a=b=2,c=3 re = 7+2 = 9 // 第三轮 // i=3,a=b=2,c=4,re=8+3 = 11 ","date":"2018-08-23T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E5%8D%81%E4%B8%89%E8%AF%BE-%E7%BB%93%E6%9E%84%E4%BD%93/","title":"第十三课 结构体"},{"content":"函数 定义 c 语言函数设计：早前模块化设计理念的具体应用；\n将一个复杂问题解决程序的代码，根据功能不同我们给它划分成若干多个简单模块，然后对每个模块进行程序设计；实现对复杂问题解决；\n模块在每个语言上称呼：在 c program 叫做 函数；有的语言叫做过程，在面向对象的语言中：方法();\n格式:\n1 2 3 4 5 6 函数类型 函数名(参数系列) // 函数的数据类型和函数返回处理结果的数据类型一致的； { sentence; ... return 函数处理的结果； } 如果函数没有 return 语句，那么函数类型就是 void 类型；\n函数名：调用的依据；函数名的命名和普通变量的规则相同；\n参数系列：参数提供给函数加工处理的数据；系列是可以提供多个参数\nint x,y 如果作为参数变量，需要分开表达：int x, int y;\n在函数中，一旦执行 return，语句所有执行都全部停止；\nQ1 定义一个函数，求三个数的最大值；\n1 2 3 4 5 6 7 8 9 10 11 12 int FindMax(int x,int y,int z){ // 函数的默认类型是 int int max; max = x\u0026lt;y?y:x; max = max\u0026lt;z?z:max; return max; } main(){ int x; x = fun(12,36,4); printf(\u0026#34;%d\u0026#34;,x); } 调用就是通过一个函数调用另一个函数，在考试范围内，都是通过 main() 函数调用；\nQ2 定义一个函数，求阶乘；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int fun(int n){ int s = 1; for(int i=1; i\u0026lt;=n; i++) s = s*i; return s; } main() { int m,n,s; printf(\u0026#34;input m,n:\u0026#34;); scanf(\u0026#34;%d,%d\u0026#34;,\u0026amp;m,\u0026amp;n); s = fum(m) / (fun(n) * fun(m-n)); printf(\u0026#34;%d\u0026#34;,s); } 将指针作为函数参数 指针参数传递的只能是地址\n1 2 3 4 5 6 7 8 9 10 11 void fun(int pa, int pb){ int t; t = pa; pa = pb; pb = t; // 函数内是局部变量，即改变后的值不会传输给main函数； } main(){ int a,b,c; a = 3, b= 1; c = fun(a,b); // 传值进入函数，对原来的函数没有任何影响 printf(\u0026#34;%d\\n\u0026#34;,c); } 1 2 3 4 5 6 7 8 9 10 11 void fun(int *pa, int *pb){ int t; t = *pa; *pa = *pb; *pb = t; } main(){ int a,b,c; a = 3, b= 1; fun(\u0026amp;a,\u0026amp;b); // 传地址，即直接修改该变量 printf(\u0026#34;%d\\n\u0026#34;,c); } Q3 指针作为参数，定义函数求两个数的最小公倍数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 int fun(int *pa, int *pb){ int t,r; t = *p1 * (*p2); // 求最大公约 while(*pa%*pb!=0){ t = *pa % *pb; *pa = *pb; *pb = t; } // 求最小公倍数 return t/(*p2); } main(){ int m,n; printf(\u0026#34;input m,n:\u0026#34;); scanf(\u0026#34;%d %d\u0026#34;,\u0026amp;a,\u0026amp;b); printf(\u0026#34;%d\\n\u0026#34;,fun(\u0026amp;a,\u0026amp;b)); } 以数组名作为参数 1 2 3 4 int fun(int a[],int n); // a是数组名，n是元素个数 int fun(int *p, int n); // 与前者等同，p是指向数组的首地址，n为元素个数 // 无论如何，参数为数组的传递的实参，肯定是地址；通常传递的是数组的首地址； Q4 定义一个数组，求数组元素的次最大值；\n解题思路：次最大值，它是由最大值反应出来的，在求解过程中，要求出最大值，比自己值大，且比最大值小肯定就是次最大值；如果有比最大值大的，此时最大值就是次最大值；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 int fun(int a[],int n){ int i,j,max,xmax; if(a[0]\u0026gt;a[1]){ max1 = a[0]; max2 = a[1]; } else{max1 = a[1]; max} for(i=0; i\u0026lt;n; i++){ if(xmax\u0026lt;a[i]){ max = xmax; xmax = a[i]; } else if(max\u0026lt;a[i]) max = a[i]; } return max; // 只能返回一个 对象，只能执行一个 return； // 若要返回多个数，必须返回数组，问：数组是地址，修改过后还需要返回吗？ //答：没有必要，除非该数组是在函数内定义的局部变量，返回后空间释放，数组丢失…… } main(){ int a[] = {12,98,6,35,78,21}; int n = 6; int i; for(i=0; i\u0026lt;10; i++){ scanf(\u0026#34;%d\u0026#34;,\u0026amp;a[i]); } k = fun(a,n); printf(\u0026#34;%d\u0026#34;,k); } **Q5 设计一个函数，删除非前导的 ***\n字符串作为函数的参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void fun(char st[]){ // 字符串有 \\0 作为结束，故此无须传入元素个数 int i=0,j; while(st[i]==\u0026#39;*\u0026#39;) i++; while(st[i]!=\u0026#39;\\0\u0026#39;) { if(\u0026#39;*\u0026#39; == st[i]) for(j=i+1; j\u0026lt;strlen(st); j++) st[j-1] = st[j]; if(st[i] != \u0026#39;*\u0026#39;) i++; } } int main(){ char st[] = \u0026#34;****sa**def***zffd\u0026#34;; fun(st); printf(\u0026#34;%s\\n\u0026#34;,st); return 0; } Q6 以指针作为函数子串的参数；设计函数，将一句话的每个单词前面第一个字母变成大写；\nhow are you -\u0026gt; How Are You\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 void fun(char *p); { int i,j; *p -= 32; for(i=1; *(p+i) != \u0026#39;\\0\u0026#39;; i++){ while(*(st+i) == \u0026#39; \u0026#39;) i++; if(*(st+i-1) == \u0026#39; \u0026#39;){ *(st+i) -= 32; } } } main(){ char st[] = \u0026#34;how are you\u0026#34;; fun(st); printf(\u0026#34;%s\\n\u0026#34;,st); } 补充：\n当函数非空型，必须有return返回值，函数没有return 语句时，默认函数类型为 void 若是没有定义函数的类型，默认为int整型 形参与实参占据不同的单元 ","date":"2018-08-23T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E5%8D%81%E4%BA%8C%E8%AF%BE-%E5%87%BD%E6%95%B0/","title":"第十二课 函数"},{"content":"指针 定义 通常在程序中：\n1 2 3 int x; // in system 为该变量分配一个存储空间 x = 10; // 将 10 存入该存储空间，与变量息息相关的存储空间 x = x+1; 通过变量能够找到存储在对应空间中数据，既然如此，那么可以直接去引用这个空间地址( address 编号);\n问：如何获取变量地址呢？获取的地址又如何存放？（指针）\n利用一个取地址运算符：\u0026amp; 读作 and\n格式：\n1 2 3 4 // 类型 *指针名 = \u0026amp;x; 获取地址编号，数；利用指针来存储变量的地址 int x; int *px; // 指针定义 px = \u0026amp;x; // px 指针保存 x 变量的地址； 指针：用于存储地址（指针指向变量）；\n⚠️ 指针类型必须和被指向的变量类型一致；\n星号，取指针所指向存储空间中的数据；\n指针本身可以运算\n1 2 3 int p[10]; int *q = p; q++ 操作系统如何管理内存 栈空间: 4~8M 大小，每进入一个函数时，会分配空间，离开时，系统自动回收。\n堆空间: 内存较大，需要手动分配回收，一旦分配，在所有函数中只要知道地址就可以访问\n内存映射: 磁盘的文件映射到内存，对内存修改，磁盘的文件同时发生变化\n1 2 void * mem = malloc(size); // size 需要字节对齐 free(mem); 不断的向系统申请内存，不释放会造成内存泄漏，使用已经释放内存的指针称为野指针。\n函数指针 返回值类型 (*指针变量名) ([形参列表]);\n1 2 3 int func(int x); // 声明函数 int (*f) (int x); // 声明函数指针 f = func; 例题 一 从键盘输入三个数求最小值，对变量数据引用，通过地址引用；\n1 2 3 4 5 6 7 8 9 int x,y,z,min; int *px=\u0026amp;x,*py=\u0026amp;y,*pc=\u0026amp;z; printf(\u0026#34;input x,y,z,空格隔开:\u0026#34;) scanf(\u0026#34;%d %d %d\u0026#34;,px,py,pc); min = *px\u0026lt;*py?*px:*py; min = min\u0026gt;*pz?*pz:min; printf(\u0026#34;%d\\n\u0026#34;,min); 二 利用指针引用数组元素的值\n数组名就是数组元素的首地址；\n1 2 3 4 5 \u0026amp;a[0] == a; // 两者等价，首地址 int *p = a; // 使 p 指针指向数组元素首地址 p++; // 指针移动到第二个元素 p+1； // 表示第二个元素，但是指针依然停留在首地址 数组中元素的地址是连续的；\n数组名是首地址，这个地址是固定不变的，constant；因此不能有 a++；\n当一个指针指向数组的首地址，此时指针和数组名具有完全的等价效果；（凡是数组名能做的事情，指针都可以做到）\n1 2 3 4 5 6 7 // 数组名作为地址，可以加减；其余效果待验证； int *p; int a[10] = {1,2,3,4,5,6,7}; p = a+4; // p 指针指向下标为 4 的元素，等价 a[4]; a = a+4; // Error，常量不能赋值 printf(\u0026#34;%d\\n\u0026#34;,*(a+3)); // a是地址，故此等价于 *(p+3) // a[3] == *(a+3) == *(p+3) == p[3] 三 从键盘输入10个数，存入数组中，求10个数平均数，对数组元素的引用使用指针；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int a[10]; int *p = a; int i,sum=0; while(p \u0026lt;= a+9){ // 读入10个元素 scanf(\u0026#34;%d\u0026#34;,p); p++; } p = a; // 将指针恢复到数组首地址 for(i=0; i\u0026lt;10; i++){ sum += *(p+i); // * 的运算符很高，先取地址需要加括号 } printf(\u0026#34;%f\\n\u0026#34;,sum/10.0); // 若是求平均数，一定要除以 浮点数 对指针来说，可以加一个数 or 减一个数，两个指针可以相减，两个指针可以比较大小；\n三 利用指针来引用字符串\n字符串有结束标志 ：\n1 st[i] != \u0026#39;\\0\u0026#39; 从键盘输入一串字符，倒置字符串元素，例如 abced —\u0026gt; decba；\n解题思路：在字符串的首位分别设置一个指针，交换以后i++,j\u0026ndash;；直到两个指针相遇后停止；\n1 2 3 4 5 6 7 8 9 10 11 12 char st[100]; char *i,*j,t; gets(st); i = st; j = st+strlen(st)-1; // 总数-1 = 最后一个下标 while(i\u0026lt;=j){ t = *i; *i = *j; *j = t; i++; j--; } printf(\u0026#34;%s\\n\u0026#34;,st); ","date":"2018-08-22T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E5%8D%81%E4%B8%80%E8%AF%BE-%E6%8C%87%E9%92%88/","title":"第十一课 指针"},{"content":"二维数组 定义 数组元素下标的个数;\n二维数组元素的下标肯定是两个；在二维中，要表达数具体位置我们需要两个下标——行列；\n二维数组是由若干个行列构成； 不论是几位数组，在存储器中都是连续的。\nforcmt：数组名[行数][列数]；\n在定义二维数组同时，可以整体赋值；\n有两赋值格式：\n1 2 3 4 5 6 7 8 9 10 11 12 int a[3][3] = { {2,3,4},{4},{6,} }, /* 1 2 3 4 0 0 6 0 0 */ int a[][3] = {1,2,3,5,3,6}; // 234 // 536 // 000 有行，列有=两个部分构成，行号从 0-n-1；列好 0-m-1； 在定义二维数组时，如果后面有赋值，行可以省略\n例题 一 从旁建输入 12 个数存入数组，输入语句如何写；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int a[3][4]; for(i=0;i\u0026lt;3;i++){ form(j=0; j\u0026lt;4; j++){ scanf(\u0026#34;%d\u0026#34;,\u0026amp;a[i][j]); } } for(i=0; i\u0026lt;3; i++){ for(j=0; j\u0026lt;4; j++){ printf(\u0026#34;%2d\u0026#34;,a[i][j]); } printf(\u0026#34;\\n\u0026#34;); } 输入需要两个循环，一个走行一个走列；\n关于二维数组的概念：\n矩阵：通常就行列相等的二维数组叫做矩阵；\n矩阵对角线：行标和列标是相等的，i == j 主对角线（左），次对角线（右），行标+列表==行数-1\n0，0 主对角线 0，3 次对角线 0+3=4-1\n1，1 1，2 1+2=4-1\n2，2 2，1\n3，3 3，0\n二 从键盘输入一个 4x4 矩阵，求对角线元素之和\n1 2 3 4 5 6 7 8 9 10 11 12 int a[4][4]; int i,j,sum=0; for(i=0; i\u0026lt;4; i++) for(j=0; j\u0026lt;4; j++) scanf(\u0026#34;%d\u0026#34;,\u0026amp;a[i][j]); // 将模块分开，不要读入的时候做 for(i=0; i\u0026lt;4; i++) for(j=0; j\u0026lt;4; j++) if(i=j || i+j==4-1) sum += a[i][j]; printf(\u0026#34;%d\\n\u0026#34;,sum); 矩阵的上三角和下三角，对角线的下面是下三角，上面是上三角；\n不包括对角线：\n下三角：行标大于列标 上三角：行标小于列标 把一个矩阵的上三角和下三角部分对调，就在矩阵转置 a[i][j] 和 a[j][i] 构成转置矩阵；\n三 从键盘输入 4x4 矩阵，输出他的转置矩阵\n解题思路：站在下三角找上三角交换，或者站在上三角找下三角替换\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 int a[4][4]; int i,j,t; for(i=0; i\u0026lt;4; i++) for(j=0; j\u0026lt;4; j++) scanf(\u0026#34;%d\u0026#34;,\u0026amp;a[0][0]); for(i=0; i\u0026lt;4; i++){ for(j=0; j\u0026lt;=i; j++){ t = a[i][j]; a[i][j] = a[j][i]; a[j][i] = t; } } printf(\u0026#34;\\n\\n\u0026#34;); for(i=0; i\u0026lt;4; i++) for(j=0; j\u0026lt;4; j++) printf(\u0026#34;%3d\u0026#34;,a[i][j]); 四 杨辉三角形\n第一列：1 主对角线：1\n除了第一列和主对角线外，a[i][j] = a[i-1][j-1] + a[i-1][j]\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 int a[7][7]; int i,j; for(i=0; i\u0026lt;7; i++) for(j=0; j\u0026lt;strlen;); scanf(\u0026#34;5d\u0026#34;，strlen); for(i=0; i\u0026lt;7; i++){ a[i][0] = 1; a[i][i] = 1; } for(i=2; i\u0026lt;7; i++) for(j=1; j\u0026lt;=i+1; j++) a[i][j] = a[i-19[j-1 + a[i-1][j]; // 待完成 五 从键盘输入 4x4的矩阵 ，求每矩阵每行最小值\n1 2 3 4 5 6 7 8 9 10 int a[4][4]; int i,j,,max,mink; for(i=0; i\u0026lt;4; i++ { max[i] = a[i][0]; for(j=1; j\u0026lt;4; j++) if(max[i]\u0026lt;a[i]]j]); }) scanf(\u0026#34;%d\u0026#34;,\u0026amp;[i][j]); ","date":"2018-08-22T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E5%8D%81%E8%AF%BE-%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84/","title":"第十课 二维数组"},{"content":"字符数组例题 定位置删除 一 从键盘获取一串字符，同时输入一个位置 l，将字符中 l 位置字符删除；\n1 2 3 4 5 6 7 8 9 10 11 12 char st[50]; int i,l,t; printf(\u0026#34;input char:\u0026#34;); gets(st); printf(\u0026#34;清输入位置l：\u0026#34;); scanf(\u0026#34;%d\u0026#34;,\u0026amp;l); for(i=i+1; i\u0026lt;strlen(st)+1; i++){ // +1；注意最后面的 \\0 st[i-1] = st[i]; } printf(\u0026#34;%s\\n\u0026#34;,st); 二 从键盘获取一串字符，再输入一个m，n（m\u0026lt;=n），请删除字符串中 m 到 n 之间字符;\n1 2 3 4 5 6 7 8 9 10 11 12 char st[100]; int i,j,m,n,k=0; gets(st); printf(\u0026#34;input m,n:\u0026#34;) while(m\u0026gt;n) scanf(\u0026#34;%d%*c%d\u0026#34;,\u0026amp;m,\u0026amp;man); i = m; for(j=n+1; j\u0026lt;=strlen(st); j++){ st[i++] = st[j]; } } printf(\u0026#34;%s\\n\u0026#34;,st); 三 定字符删除：从键盘输入一串字符st，再输入一个字符c，将字符串中的c删除\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 char st[100]; int i,j; char c; printf(\u0026#34;input st:\u0026#34;); gets(st); printf(\u0026#34;input c:\u0026#34;) scanf(\u0026#34;%c\u0026#34;,\u0026amp;c); // 假若 gets后跟着getchar，输入的空格是否会被读入 for(i=0; i\u0026lt;strlen(st); i++){ // 查找要删除的字符 if(c == st[i])； for(j=i+1; j\u0026lt;strlen(st)+1; j++){ // 从i+1位置到end（包括），把每个字符往前移动一位，覆盖 a[j-1] = a[j]; } if(st[i]==c) i--; // 此处弥补漏洞,如果下一个数还是c，就i-- } } printf(\u0026#34;%s\\n\u0026#34;,st); 四 子串的查找:已知 st1，问 st2 是否出现在 st1 中，若是出现，返回首次出现的位置，否则返回-1；有两种解决方法，一种直观朴素匹配方法，一种是KMP匹配经典算法；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 经典算法，回溯，这个代码有点儿不流畅，需重新构建 char st1[100],st2[100]; int i,j,k=-1; printf(\u0026#34;input st1:\u0026#34;); gets(st1); printf(\u0026#34;input st2:\u0026#34;); gets(st2); i = 0; while(st1[i]!=\u0026#39;\\0\u0026#39;){ k = i; for(j=0; st2[j]!=\u0026#39;\\0\u0026#39;; j++) if(st1[k]==st2[j]) k++; else break; if(st2[j] == \u0026#39;\\0\u0026#39;){ printf(\u0026#34;%d\\n\u0026#34;,i); break; }else i++; } if(st1[i]==\u0026#39;\\0\u0026#39;){ printf(\u0026#34;-1\u0026#34;); } 如果 st1[i] == st2[j], i++,j++\n如果 st1[i] != st2[j], j=0,i++\n当 st2 到底时，说明找到位置；\n当 st1 到底时，说明没有找到；\n五 用户自己设计程序实现两个字符串的连接\n1 2 3 4 5 6 7 8 9 10 11 12 13 char s1[20] = \u0026#34;aaa\u0026#34;; char s2[] = \u0026#34;bbb\u0026#34;; // 不使用 strcat 函数，拼接字符串 int i,j,k; for(i=0;s1[i]!=\u0026#39;0\u0026#39;;i++); // 将 i 指向末尾，即\u0026#39;\\0\u0026#39;； 获取s1的结束位置 for(j=0; s2[j]!=\u0026#39;\\0\u0026#39;; j++) // 将 s2 开始位置逐一往 s1 连接 s1[i++] = s2[j]; // s2数组拼接在s1后面 s1[i] = \u0026#39;\\0\u0026#39;; // 补上 \u0026#39;\\0\u0026#39; printf(\u0026#34;%s\\n\u0026#34;,s1); // 输出 result 回文判定 什么是回文？从字符串的左边读和从字符串的右边读顺序是相同的；\n例如：abcba\n一 从键盘输入一串字符，判定是否为回文，是输出\u0026quot;yes\u0026quot;，不是输出\u0026quot;no\u0026quot;；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 char st[30]; int i,j; printf(\u0026#34;input st:\u0026#34;); gets(st); i = 0; j = strlen(st)-1; // 区分个数和下标 while(i\u0026lt;=j){ if(st[i] == st[j]){ i++; i--; }else break; } if(i\u0026lt;j) printf(\u0026#34;No\u0026#34;); else printf(\u0026#34;Yes\u0026#34;); 二 从键盘输入一串符号，判定这串符号如果都是数字，输出1，否则输出0；\n1 2 3 4 5 6 7 8 9 10 11 12 char a[100]; int i,j,k; gets(a); for(i=0; i\u0026lt;strlen(a); i++) if(!(a[0]\u0026gt;=48 \u0026amp;\u0026amp; a[0]\u0026lt;=57)) break; if(a[i]==\u0026#39;\\0\u0026#39;) k=1; else k=0; printf(\u0026#34;%d\\n\u0026#34;,k); 更多 一 从键盘输入一串数字符号，把数字符号转化为数\n1 2 3 4 5 6 7 8 9 10 11 char st[100]; int i,j=0,k; printf(\u0026#34;input st:\u0026#34;); gets(st); for(i=0;i\u0026lt;strlen(st);i++){ // 取位 j = st[i]-\u0026#39;0\u0026#39;; // 任何数字符号-\u0026#39;0\u0026#39;都等于数字本身 k=k*10+j; } printf(\u0026#34;%d\\n\u0026#34;,k); 解决思路：\n取位 把这个位和数字符号，要转换为数 取出来一位，前面就和升位，把当前这个位加上去 二 从键盘输入一串字符，统计每个小写字母出现的次数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int st[100],f[26]; int i,j,k=0; printf(\u0026#34;input st:\u0026#34;); gets(st); for(i=0; st[i]!=\u0026#39;\\0\u0026#39;;i++){ if(st[i]\u0026gt;=97 \u0026amp;\u0026amp; st[i]\u0026lt;=122){ f[st[i]-\u0026#39;a\u0026#39;]++; // 通过符号判断下标 } } for(i=0; i\u0026lt;26; i++){ if(f[i]!=0) printf(\u0026#34;%c:%d\\n\u0026#34;,i+\u0026#39;a\u0026#39;,f[i]); } ","date":"2018-08-21T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E4%B9%9D%E8%AF%BE-%E5%AD%97%E7%AC%A6%E6%95%B0%E7%BB%84%E4%BE%8B%E9%A2%98/","title":"第九课 字符数组例题"},{"content":"字符串 数组复习例题 从键盘输入 10 位同学的考试成绩存入数组，按照低分到高分排序；然后输出；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #include \u0026lt;stdbool.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #define arrLen 10 void print(int a[], int size) { for (int i = 0; i \u0026lt; size; i++) { printf(\u0026#34;%d \u0026#34;, a[i]); } printf(\u0026#34;\\n\u0026#34;); } // sort 冒泡排序 void sort(int a[], int size) { // 外层循环 0:n-1 次 for (int i = 0; i \u0026lt; size - 1; i++) { bool exchange = false; // 内存循环 1:n-i 次 for (int j = 1; j \u0026lt; size - i; j++) { if (a[j - 1] \u0026gt; a[j]) { int t = a[j - 1]; a[j - 1] = a[j]; a[j] = t; } } if (exchange) { break; } } } int main(int argc, char const* argv[]) { int a[arrLen]; printf(\u0026#34;请输入 10 个成绩:\\n\u0026#34;); for (int i = 0; i \u0026lt; arrLen; i++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;a[i]); } printf(\u0026#34;正在排序...\\n\u0026#34;); sort(a, arrLen); print(a, arrLen); return 0; } 数组元素拆分，从键盘输入 n，表示数组中存储元素个数，然后输入 n 个数存入数组，把偶数放在b 数组，奇数放在 c 数组中；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #include \u0026lt;stdio.h\u0026gt; void print(int a[], int size) { for (int i = 0; i \u0026lt; size; i++) { printf(\u0026#34;%d \u0026#34;, a[i]); } printf(\u0026#34;\\n\u0026#34;); } int inputNum() { printf(\u0026#34;请输入一个数:\u0026#34;); int v = 0; scanf(\u0026#34;%d\u0026#34;, \u0026amp;v); return v; } void inputArray(int a[], int size) { printf(\u0026#34;请依次输入 %d 个数值\\n\u0026#34;, size); for (int i = 0; i \u0026lt; size; i++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;a[i]); } } int main(int argc, char const* argv[]) { int n = inputNum(); int a[n]; inputArray(a, n); int b[n], c[n]; int b1 = 0, c1 = 0; // 判断数组元素是奇数还是偶数，并且赋值到规定数组 for (int i = 0; i \u0026lt; n; i++) { if (a[i] % 2 == 0) { b[b1] = a[i]; b1++; } else { c[c1] = a[i]; c1++; } } print(b, b1); print(c, c1); return 0; } 已知数组 a，将 0 集中放在数组前面，把 1 放在后半部分；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #include \u0026lt;stdio.h\u0026gt; #define arrLen 10 void print(int a[], int size) { for (int i = 0; i \u0026lt; size; i++) { printf(\u0026#34;%d \u0026#34;, a[i]); } printf(\u0026#34;\\n\u0026#34;); } void core(int a[], int size) { int i = 0, j = size - 1; while (i \u0026lt; j) { if (a[i] == 0) { i++; continue; } if (a[j] != 0) { j--; continue; } int t = a[i]; a[i] = a[j]; a[j] = t; } } int main(int argc, char const* argv[]) { int a[arrLen] = {1, 1, 0, 0, 1, 0, 1, 1, 1, 0}; // result a[] = {0,0,0,0,1,1,1,1,1,1}; 4个0，6个1 core(a, arrLen); print(a, arrLen); return 0; } 字符串 字符串常量的表示，一定要加双引号，字符常量要加单引号；\n字符串概念：是有若干多个符号组成；\n例如：\n1 2 3 \u0026#34;\u0026#34; // 这是字符串，表示空串 \u0026#34;a\u0026#34; \u0026#34;abcde\u0026#34; 字符串变量：\nin c program ,没有字符串数据类型；字符串是用字符数组来存储；字符串变量的定义也就是定义字符数组；\n1 char st[100]; // 字符数组 字符赋值，只有在定义字符串时，才能整体赋值，定义后不能整体赋值；\n字符数组的 sizeof 是 1，每个下标只能存储一个字符；结尾是 \\0，表示结束，存储时仅加一次，若是用户删除插入操作，必须自己手动添加；\n在访问字符串时，只要遇到结束标志，就停止访问；\n1 2 3 4 st[i] != \u0026#39;\\0\u0026#39;; // 访问字符串时的条件 char st[5] = \u0026#34;aaaaa\u0026#34;; // 溢出 char st[5] = \u0026#34;aaaaa\\0\u0026#34;; // 实际存储方式 char st[] = \u0026#34;aaaaa\u0026#34;; // 该存储空间是 6 重点！！,即字符数组额外占用一个char 1 2 scanf(\u0026#34;%s\u0026#34;,字符串名); // 字符串的输入方式，无须+ 取址符号 printf(\u0026#34;%s\u0026#34;,st); // 输出 使用 scanf 获取字符串，输入时不能带有空格，否则空格后面就自动断开；\n1 2 fgets // 输入字符串 fputs // 输出字符串 字符串常量\n1 2 3 4 5 6 char *s = \u0026#34;hello\u0026#34;; char *s1 = \u0026#34;hello\u0026#34;; // s 和 s1 指向的是同一个地址，地址很小，位于程序的代码段，只读!! // 只读不可改 // 想要修改的字符串 char s[] = \u0026#34;hello\u0026#34; c program 关于字符串操作的一些库函数 函数都是在 \u0026lt;string.h\u0026gt; 头文件中；\n1 2 3 4 5 6 7 8 9 strlen(st); // 求字符串长度（个数），不包含结束标志，sizeof 包含 // sizeof 计算的是总共存储空间，而不是仅仅字符串空间 strcat(s1,s2); // 将字符串 s2 连接在 s1 的后面，构成一个整体； 要求字符串 s1 存储空间必须够大 strcpy(s1,s2); // 实现字符串的拷贝，在c语言中字符串不允许赋值，要想对字符串进行赋值，必须用赋值函数 st1 = st2； // Error strcmp(s1,s2); //比较字符串st1与st2是否相等，若是相等返回0，若是不等，返回-1/1； // 逐一位置比较，如果遇到不相等，停止比较，如果s1字符 ascll 值大返回1(s1\u0026gt;s2)，若是s1的 ascll 值小，返回-1(s1\u0026lt;s2) 若是 getchar 获取一个字符，想要的不是字符，而是数字本身，减去 \u0026lsquo;0\u0026rsquo; 即可得到数字本身，看下面例子：\n1 2 3 n = getchar(); // input 2 n-0 = 50; // ascll 即无用功，n 本身就是50 n-\u0026#39;0\u0026#39; = 2; // 数字本身 50-48=2 字符串例题 字符串操作：从键盘输入一串字符，把其中大写字母改成小写字母；\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;stdio.h\u0026gt; int main(int argc, char const* argv[]) { char p[100]; fgets(p, 100, stdin); for (int i = 0; i \u0026lt; p[i] != \u0026#39;\\0\u0026#39;; i++) { if (p[i] \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; p[i] \u0026lt;= \u0026#39;Z\u0026#39;) { p[i] += 32; } } fputs(p, stdout); return 0; } 字符串统计：从键盘输入一串字符（一句话），统计这句话中单词的个数；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \u0026lt;stdio.h\u0026gt; int count(char a[]) { int sum = 0; for (int i = 0; i \u0026lt; a[i] != \u0026#39;\\0\u0026#39;; i++) { if (a[i] == \u0026#39; \u0026#39;) { sum++; } } return sum + 1; } int main(int argc, char const* argv[]) { char a[100]; fgets(a, 100, stdin); int c = count(a); printf(\u0026#34;%d\\n\u0026#34;, c); return 0; } ","date":"2018-08-19T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E5%85%AB%E8%AF%BE-%E5%AD%97%E7%AC%A6%E4%B8%B2/","title":"第八课 字符串"},{"content":"数组 定义 1 2 3 4 5 6 7 8 数据类型 数组名[数组元素个数]； // 数据类型是存储的第一条件 // 数据名引用数组的依据 // 元素的个数必须是常量！ int a[10]; // 定义一个数组，存储 10 个 int 型数据，10 为元素个数，最大下标为 9 // 引用方法 数组名[下标]； // 假设数组的元素个数为 n 个，即下标为 0 至 n-1； 当定义数组时不填写元素个数，即赋值n个，就会自动初始化为n+1\n1 数据类型 数组名[] = {value1,value2,...} 在定义数组时，如果有赋值，赋值的个数不能超过元素个数；若是超过，则溢出报错；\n1 int a[5] = {1,2,3,4,5,6} // 溢出 当赋值个数\u0026lt;元素个数，则多余元素自动初始化为0；\n1 int a[100] = {0}; // 数组所有元素初始化为0，在移植上似乎有问题，详见笔记\u0026#34;三种初始化数组的方法\u0026#34; 数组元素键盘输入(基本都是靠循环)\n1 2 3 4 5 int a[10]; for (int i=0; i\u0026lt;10; i++) { scanf(\u0026#34;%d\u0026#34;,\u0026amp;a[i]); // 可以不加取址符 } 1 2 3 4 // 数组不用取值符号的情况 a[10] = {1}; // 依然初始化为 0 scanf(\u0026#34;%d\u0026#34;,a); // 从键盘获取一个数值给 a scanf(\u0026#34;%d\u0026#34;,a+2); // 从键盘获取一个value 给 a[2]; 例题 数组逆序输出\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;stdio.h\u0026gt; void print(int a[], int size) { int i = size; while (i \u0026gt; 0) { i--; printf(\u0026#34;%d \u0026#34;, a[i]); } printf(\u0026#34;\\n\u0026#34;); } int main(int argc, char const* argv[]) { int a[] = {10, 20, 30, 40, 50, 60, 70, 80, 90, 100}; int i = sizeof(a) / sizeof(a[0]); print(a, i); } 找出最大值，以及其位置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;stdio.h\u0026gt; int main(int argc, char const *argv[]) { int n; int a[100]; printf(\u0026#34;有多少个数: \u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); printf(\u0026#34;请依次输入这些数值\\n\u0026#34;); /* code */ for (int i = 0; i \u0026lt; n; i++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;a[i]); } int max = 0; for (int j = 1; j \u0026lt; n; j++) { if (a[max] \u0026lt; a[j]) max = j; } printf(\u0026#34;%d %d\\n\u0026#34;, a[max], max); return 0; } 数据查找，从键盘输入x，查找首次出现x，在数组中的位置，如果没有返回-1\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 #include \u0026lt;stdio.h\u0026gt; int main(int argc, char const *argv[]) { const int a[] = {10, 20, 30, 40, 50, 60, 70, 80, 90, 100}; printf(\u0026#34;请输入待查找的值:\u0026#34;); int x = 0; scanf(\u0026#34;%d\u0026#34;, \u0026amp;x); int idx = -1; for (int i = 0; i \u0026lt; 10; i++) { if (x == a[i]) { idx = i; break; } } printf(\u0026#34;%d\\n\u0026#34;, idx); return 0; } 统计，从键盘输入10个同学成绩存入数组，统计小于平均分的人数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #include \u0026lt;stdio.h\u0026gt; #define ArrayLen 10 int main(int argc, char const *argv[]) { printf(\u0026#34;请输入 10 位同学的分数:\\n\u0026#34;); int number[ArrayLen]; int sum = 0; for (int i = 0; i \u0026lt; ArrayLen; i++) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;number[i]); sum += number[i]; } printf(\u0026#34;正在统计中...\\n\u0026#34;); int j = 0; for (int i = 0; i \u0026lt; ArrayLen; i++) { // 区分 float 和 int 除法 if (sum / 10.0 \u0026gt; number[i]) j++; } printf(\u0026#34;小于平均分的人数: %d\\n\u0026#34;, j); return 0; } 数组插入，从键盘输入一个位置 l，一个数 x，将 x 插入到 l 的位置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 #include \u0026lt;stdio.h\u0026gt; int main(int argc, char const *argv[]) { int a[5] = {1, 2, 3, 5}; printf(\u0026#34;请输入位置和数值:\u0026#34;); int idx, v; scanf(\u0026#34;%d%*c%d\u0026#34;, \u0026amp;idx, \u0026amp;v); if (idx \u0026lt; 0) { printf(\u0026#34;输入下标有误\\n\u0026#34;); return -1; } for (int i = 4; i \u0026gt; idx; i--) { a[i] = a[i - 1]; } a[idx] = v; for (int i = 0; i \u0026lt; 5; i++) { printf(\u0026#34;%d\\t\u0026#34;, a[i]); } return 0; } 有序插入，将数组中存储数据是有顺序的，把 x 插入到数组中，还有保证数组中元素值仍然有序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #include \u0026lt;stdio.h\u0026gt; int main(int argc, char const *argv[]) { printf(\u0026#34;请输入参数:\u0026#34;); int a[10] = {10, 20, 30, 40, 50, 60, 70, 80, 90}; int v = 9; scanf(\u0026#34;%d\u0026#34;, \u0026amp;v); int idx = 0; // 判断 x 插入的位置 for (int i = 0; i \u0026lt; 10; i++) { if (v \u0026lt;= a[i]) { idx = i; break; } } // 将该位置及以后的所有值全部后移动一位 for (int i = 9; i \u0026gt; idx; i--) { a[i] = a[i - 1]; } // 插入该值 a[idx] = v; // 输出结果 for (int i = 0; i \u0026lt; 10; i++) { printf(\u0026#34;%d\\t\u0026#34;, a[i]); } return 0; } 删除：定位再删除；输入位置 L，删除 L 位置的值\n1 2 3 4 5 6 7 8 9 10 11 12 int a[10] = {23,4,67,3,46,8,40,10,90,40}; int l,i; scanf(\u0026#34;%d\u0026#34;,\u0026amp;l); for(i=l; i\u0026lt;10; i++){ // 删除一个数，直接将后面的数向前覆盖 a[i] = a[i+1]; } // Q：删除覆盖后，最后面空出来的值依然保持原值 for(i=0; i\u0026lt;9; i++){ // 输出结果 printf(\u0026#34;%d \u0026#34;,a[i]); } printf(\u0026#34;\\n\u0026#34;); 指定数据删除：假如要删除x，if（x==a[i]）移动覆盖，记住可能有多个要删除的数据，这时我们删除一个不能停止。必须要把数组中所有数都要删除。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 int a[] = {1,2,3,4,6,2,4,5,6,2}; int x,t，j=0; scanf(\u0026#34;%d\u0026#34;,\u0026amp;x); // 首先对删除的数据进行计数，删除走到最后，保证指定的 valve 全部删除 for(int i=0; i\u0026lt;10; ){ if(x==a[i]){ t = i; for(int i=t; i\u0026lt;10-j; i++){ a[i] = a[i+1]; j++; } if(a[i]!=x) i++; } } for(int i=0; i\u0026lt;10-j; i++){ printf(\u0026#34;%d \u0026#34;,a[i]); } printf(\u0026#34;\\n\u0026#34;); 数组合并，ab合并到c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 #include \u0026lt;stdio.h\u0026gt; #define arrayLen 8 void print(int a[], int size) { for (int i = 0; i \u0026lt; size; i++) { printf(\u0026#34;%d \u0026#34;, a[i]); } printf(\u0026#34;\\n\u0026#34;); } void merge(const int a[], const int b[], int c[], int size) { int i = 0, j = 0; int k = 0; while (i \u0026lt; 4 \u0026amp;\u0026amp; j \u0026lt; 4) { if (a[i] \u0026lt;= b[j]) { c[k] = a[i]; i++; } else { c[k] = b[j]; j++; } k++; } for (int n = i; n \u0026lt; 4; n++) { c[k] = a[n]; k++; } for (int n = j; n \u0026lt; 4; n++) { c[k] = b[n]; k++; } } int main(int argc, char const* argv[]) { const int a[] = {12, 40, 98, 100}; const int b[] = {25, 79, 86, 300}; // 12,25,40,79,86,98,100,300 int c[arrayLen]; // 两个数组无序时，先合并在排序 // 两个数据有序时，一一比较 merge(a, b, c, arrayLen); print(c, arrayLen); return 0; } 注：\n编译器不检查下标是否越界； 数组传递给函数，不带方括号的数组名即可； ","date":"2018-08-17T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E4%B8%83%E8%AF%BE-%E6%95%B0%E7%BB%84/","title":"第七课 数组"},{"content":"循环 while 语句 循环三要素：起点，终点，数据变化规律\nfor 与 while 的区别：从 structure 来说，for 比较严谨，while 比较自由\nwhile 语句使用格式\n1 2 3 4 5 6 7 表达式1； while (表达式2) { sentence； ... 表达式3； } break or continue break：直接跳出循环，任意位置执行即直接跳出循环，无视后面的语句\ncontinue：结束当次循环\n1 2 3 4 5 6 7 8 9 // 求 1-10 奇数 int sum=0; for (int i=1; i\u0026lt;=10; i++) { if(i%2) continue; // 如果是偶数就跳出本次循环 sum+=i; // 否则就相加求和 } printf(\u0026#34;%d\u0026#34;,sum); do\u0026hellip;while 1 2 3 4 do{ sentence; ... }while(表达式1); // first carry out 后判断 该语句至少要被执行一次，而 while 语句可能一次都不会执行\n循环嵌套 1 2 3 4 5 6 7 8 9 // format for (表达式1；2；3){ sentence; ... for (表达式1；2；3){ sentence; ... } } 例题 斐波那契数列的前 20 项（a1=1; a2=1; an=an-1+an-2,n\u0026gt;=3），每行仅仅打印 5 个 ​ if （i%5==0）printf('\\n');\n求两个数最大公约数/最小公倍数\n最大公约数：能同时整除这两个数的最大数 25 15 —— 5\n求解方法：辗转相除\n1 2 3 4 28 % 6 = 4 != 0 6 % 4 = 2 != 0 4 % 2 = 0 // 此时 2 的值就是最大公约数 1 2 3 4 5 6 7 8 9 10 int m,n,r; int a=m,b=n; scanf(\u0026#34;%d%*c%d\u0026#34;,\u0026amp;m,\u0026amp;n); while(m%n!=0) { r = m%n; m = n; n = r; } printf(\u0026#34;最大公约数=%d，最小公倍数=%d\u0026#34;,n，a*b/n); 最小公倍数：两个数的乘积除以最大公约数\n1 2 3 4 // 8和6 ，最大公约数 2 6*8/2 =48/2 =24 不定次数的输入🍮，从键盘输入，以 0 结束，ask input of valve\n1 2 3 4 5 6 7 8 9 10 11 int n,a,i=1; float aver; scanf(\u0026#34;%d\u0026#34;,\u0026amp;a); aver = a; while(n!=0) { scanf(\u0026#34;%d\u0026#34;,\u0026amp;n); aver += n; i++; printf(\u0026#34;%f\u0026#34;,aver/i); // 注意这里似乎在输入结束后才会打印？ } 从键盘输入字符以回车键结束，统计数字符号的个数\n1 2 3 4 5 6 7 char n, int i=0; while((n=getchar())!=\u0026#39;\\n\u0026#39;) { if(n\u0026gt;=48 \u0026amp;\u0026amp; n\u0026lt;=57) i++; } printf(\u0026#34;%d\u0026#34;,i); 从键盘输入 n 求 1！+2！+3！+4！\u0026hellip;+n!\n1 2 3 4 5 6 7 8 9 10 11 int n,sum; int b; scanf(\u0026#34;%d\u0026#34;,\u0026amp;n); for (int i=1; i\u0026lt;=n; i++){ b = 1; for (int j=1; j\u0026lt;=i; j++){ b *= j; } sum += b; } printf(\u0026#34;%d\u0026#34;,sum); 输出 1-1000 之间完数，所有因子的和（不包括自身）等于该数\n1 2 3 4 5 6 7 for (int i=1; i\u0026lt;1000; i++){ // 判断有效范围内数 sum = 0; // 因子之和 for (int j=1; i\u0026lt;i; j++){ // 求因子 if (i%j==0) sum+=j; } if(sum==i) printf(\u0026#34;%d\u0026#34;,i); } 输出 50-100 之间的素数，即只能被1个自身整除\n1 2 3 4 5 6 7 8 9 10 for(int i=50; i\u0026lt;=100; i++){ int f = 0; // 设置机关 for(int j=2;j\u0026lt;i; j++){ // sqrt(1) | i/2 | i-1 if(i%j==0){ f++; break; } } if(f==0) printf(\u0026#34;%d \u0026#34;,i); } 从键盘输入 m,k，输出比 m 大，但是最靠近 m 的 k 个素数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 int m,k; printf(\u0026#34;input m,k:\u0026#34;); scanf(\u0026#34;%d%*c%d\u0026#34;,\u0026amp;m,\u0026amp;k); // 设置范围 for (int i=m+1,j=1; j\u0026lt;=k; i++) { int f = 0; // 无论在哪个位置被忘记初始化 for (int n=2; n\u0026lt;i; n++) { if (i%n==0){ f++; break; } } if(f==1){ printf(\u0026#34;%d \u0026#34;,i); j++;vuvuvu } printf(\u0026#34;\\n\u0026#34;); } 从键盘输入一个整数，求这个整数的各位之和，计算这个整数的位数\n1 2 3 4 5 6 7 8 9 10 11 int number; scanf(\u0026#34;%d\u0026#34;,\u0026amp;number); int i=0; // 计数，是多少位 int sum=0; // 各个位数求和 while(number!=0) { i++; sum += number%10; number /= 10; } printf(\u0026#34;%d-%d\u0026#34;,sum,i); 图形输出（行/列），外循环控制行，内循环控制列\n1 2 3 4 5 6 7 int i,j; for (i=1; i\u0026lt;=7; i++){ for (j=1; j\u0026lt;i+1; j++){ printf(\u0026#34;*\u0026#34;); } printf(\u0026#34;\\n\u0026#34;); } 1 2 3 4 5 6 7 8 9 10 11 // 打印三角形 int i,j; for (i=1; i\u0026lt;=6; i++){ for (j=5; j\u0026gt;=i; j--){ // for (j=1; j\u0026lt;=6-i; j++) printf(\u0026#34; \u0026#34;); } for (int k=1; k\u0026lt;=2*i-1; k++){ printf(\u0026#34;*\u0026#34;); } printf(\u0026#34;\\n\u0026#34;); } 1 2 3 4 5 6 7 8 9 10 11 12 13 // 打印菱形 #include \u0026lt;math.h\u0026gt; int i,j,k; for (i=-4; i\u0026lt;=4; i++){ for (j=1; j\u0026lt;=abs(i); j++){ printf(\u0026#34; \u0026#34;); } for (k=1; k\u0026lt;=9-2*abs(i); k++){ printf(\u0026#34;*\u0026#34;); } printf(\u0026#34;\\n\u0026#34;); } ","date":"2018-08-16T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E5%85%AD%E8%AF%BE-%E5%BE%AA%E7%8E%AF/","title":"第六课 循环"},{"content":"Switch if 嵌套循环 format：\n1 2 3 4 5 6 if (条件1) sentence; else if (条件2) sentence; else sentence; 从条件表达式 1 开始判断，若成立则执行后面的语句，若条件不成立则继续判断，直到遇到条件成立的才执行。\nswitch switch 语句和 if 嵌套语句是不同的；\nx \u0026gt; 10； x \u0026gt; 100; 在 if 下的情况有多个 value 满足条件 x = 10; x = 100; 每种情况都只有 one value，且该值固定 特点：Clear structure\nformat：\n1 2 3 4 5 6 7 8 9 10 switch (object) { case constant1: sentence; break; case constant2: sentence; break; // …… default： sentence; } object with constant 做比较，当两者相等时执行，若所有 constant 皆不等于 object，即执行 default；\nbreak 结束当前任务，continue 结束本轮任务。\ndefault 可以在任意位置！相当于一个 case 来执行，不过该 case 的条件是不匹配当前所有 constant；\n例题 输入年月日，判断该日期属于年内的第 n天 输入年月，判断该月份有多少天 输入一个数，判断能否被 n 整除，能就输入n（3，5，7），都不能就输出 0 判断输入的符号是什么类型：大写，小写，数字，空格 解一元二次方程 简单计算器：加减乘除 补充：\nprintf 只会看双精度，float 型会被提升为 double，scanf 没有类型提升；%lf 在 printf 下是未定义的，要确保可移植性，就要坚持使用 %f；\n在运行时确定宽度，可使用以下代码\n1 printf(\u0026#34;%*d\u0026#34;,weight,x); // 中间的星号表示，在参数列表中第一个int参数作为宽度 当向 scanf 传入数组时，不需要使用取址符号\nscanf 使用 %d 等数值格式符时，不会读取换行，而 gets 本身作为读入字符串的函数，却会将换行读入。故：scanf 和 gets 要么二选一，要么干脆不用\nscanf 会将未匹配的字符留在输入流中\n在 scanf 中，若想任意分隔符\n1 scanf(\u0026#34;%d%*c%d\u0026#34;,\u0026amp;a,\u0026amp;b); scanf 使用 %c 格式符读入字符时，空格字符和转义字符（包括回车）都会被有效字符读入\n对于上一条，scanf 函数 %c 存在的问题！可使用 getchar() 将无效字符读走，以免被后面的字符型变量误读。\nscanf 没有精度修饰词，即 scanf() 不能规定精度\nEPS ，若要判断一个数是否为0，就看 该数的绝对值是不是\u0026lt;= EPS\n在 if/while 的条件表达式里，n%2!=0 等价于 n%2\n","date":"2018-08-14T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E4%BA%94%E8%AF%BE-switch/","title":"第五课 switch"},{"content":"输出控制 复合运算符 在赋值时左右两侧有同一个变量，可进行符合表示。\n1 2 3 4 x += 3; // x += 3; a += b; // 既 a = a + (b); 右侧视为一个整体，同时，复合运算符优先级较低。 a += a -= a * a; // a += a -= 9; a += -6; a = -12 a += a -= a *= a; // a += a -=9; a += 0; a = 0; Go\n不支持这样复杂的符合运算，简洁高效清晰。\n不同进制的表达方式 常规数据以十进制表示，单数有 8、16 进制的表示，没有二进制的表示！\n控制符 表示方法 八进制 %o 023 十六进制 %x 0x7A 输入输出控制符 1 整型\n%md m是控制输入输出位数 m\u0026gt;实际位数，前补空格 %-md ‘-’符号表示左对齐 m\u0026lt;实际位数，无效输出 1 scanf(\u0026#34;%2d%3d\u0026#34;,\u0026amp;x,\u0026amp;y); // 1234567 → x=12, y=345 2 浮点数\n%.nf n表示保留小数位数 %m.nf m表示总位数，小数点算一位 m\u0026lt;实际位数，m的控制无效\n整数截断，浮点数四舍五入\n结构程序设计 c program 是典型的结构化程序设计，面向过程。\n有三大结构：顺序结构，选择结构，循环结构\n顺序结构，自顶向下，逐一执行程序中的每个语句； 选择结构，就是给程序中的某些语句设置执行条件，当条件满足时执行，当条件不满足时跳过； 循环结构，对程序中的语句多次的重复执行； 选择结构之 if 语句 if （表达式），当条件表达式的值是非 0，则条件成立，执行括号内容；若 if 只有一条语句，大括号可省略。\nif …… else …… （语句实现是两种情况的选择）\n选择对象中只有两种可能，我们选择其中两种可能（非此即彼）\neg ： 输入第三边，求是否是三角形，若是求面积\n面积公式：\n​ l = （a+b+c）/2\n​ s = sqrt（l（l-a）（l-b）（l-c））\n​ 三角形定义：任意两边大于第三边\n补充：\n1 宏定义的字符串后一般不以分号结尾，因为宏定义不是 c 语句；\n2 宏常量没有数据类型，只进行简单的字符串替换；\n3 const 常量只能在定义时赋予初值；\n4 在一个赋值语句中，若左右类型不一致，则赋值时右边表达式将进行自动类型转换\n5 双引号扩起来的内容不会发生宏替换\n","date":"2018-08-11T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E5%9B%9B%E8%AF%BE-%E8%BE%93%E5%87%BA%E6%8E%A7%E5%88%B6/","title":"第四课 输出控制"},{"content":"运算符 基本运算符 所有数据的处理，通过运算符来实现；\n两个整型在一起运算结果还是整型；如果有小数参加运算的，运算结果是双精度小数（double）\n1 2 3 3/2 : 1 （舍去小数部分） 3.0/2 : 1.500000（double） Go\n整型运算还是整型\n整型和浮点型运算，需要做类型转换\n%：取余格式：a%b，a and b 必须为整数！\n23 % 6 = 3……5 6 % 23 = 0……6 -23 % 6 = 3……-5 23 % -6 = -3……5\n取余的结果一定要与被取余的数符号保持一致。\n1 2 3 4 5 int x,y; scanf(\u0026#34;%d,%d\u0026#34;,\u0026amp;a,\u0026amp;b); // x % y : 0 x能被y整除 // x % 2 : 0 x是偶数 // x % 2 : 1 x是奇数 任何参数对 10 取余，得到的都是个位\n例题: 从键盘输入一个三位数的整数，交换百位和十位，然后输出\n1 2 3 4 int x = 142 x/100 = 1 // 获取百位 x/10%10 = 4 // 获取十位 142%10 // 获取个位 自加自减 1 ++n； n++；\n符号无论在变量的哪一侧，都是实现自身 +1；++ 只能对变量进行运算\n1 2 (x+y)++； // 错误 7++； // 错误 2 (++n) and (n++) 的区别\n1 2 3 4 5 6 int x = 9,y; // 分别执行以下语句 y = x++; // x=10,y=9 y = ++x; // x=10,y=10 y = ++x + ++x; // x=11,y=22 y = x-- + x--; // x=7,y=18 在运算式中如果 ++ 在变量的前面，先做自身 +1， 然后再做其它运算；\n如果 ++ 在变量的后面，先做运算后自身 +1；\nGo\n仅支持 i++，避免歧义。\n条件运算符 ？： c program 唯一的一个三目运算符\n运算格式 表达式1？ 表达式2 ：表达式3；\n表达式1的值，如果它的值是非0（条件成立），那么运算结果就是表达式2的值；\n如果表达式1的值为0（条件不成立），这时运算结果就是表达式3的值。\n1 2 2\u0026lt;3? 3\u0026gt;4? 2+6 : 2-5 : 2+3 //第一个问号和最后一个冒号外嵌套 2\u0026lt;3? (3\u0026gt;4? 2+6 : 2-5) : 2+3 // -3 a \u0026gt; b? a : b; 取a/b最大值\neg：从键盘输入 4 门课考试成绩，求最低分\n1 2 3 4 5 6 float a,b,c,d,mix; mix = a; mix = (mix\u0026lt;b)? mix:b; // 注意判断取大小值的符号 mix = (mix\u0026lt;c)? mix:c; mix = (mix\u0026lt;d)? mix:d; 判断大小，用 ?: 比 if 语句优势\nGo\n不支持三目运算符，从以上语法中也能看出，复合三目运算极为复杂，难读。\n关系运算符 作用：比较两个对象之间量的大小关系\n常见：\u0026lt; \u0026lt;= \u0026gt; \u0026gt;= == !=\n注：新手常常错在 == 和 = 号上，总是误将判断写成赋值；\n关系运算的结果：True(1) and False(0)（成立 or 不成立）\n1 2 3 4 5 int x,y=1,z=4; x = y == z; // y==z:0 x = 0 x = y = z; // y=4; x=4; x=4 赋值符号 自右向左 x = y != z; // y!=z:1; x=1 赋值符号左侧只能为变量，不能为表达式\n逻辑运算符 （小心短路） 1 作用：逻辑推理或逻辑判断时，用于连接推理的条件。\n运算符有三个：\n逻辑与 \u0026amp;\u0026amp; 要所有条件都成立，推理才成立 逻辑或 || 只要一个条件成立，推理就成立 逻辑非 ！ 取反（ !(2\u0026gt;3) : 2\u0026lt;=3 ） 2 \u0026amp;\u0026amp; and || (小心短路)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 x\u0026gt;=10 \u0026amp;\u0026amp; x\u0026lt;=100; // lvalue 不成立 rvalve 不执行 10\u0026lt;=x\u0026lt;=100 x\u0026gt;10 || x\u0026lt;-100; // lvalue 成立则 rvalue 不判断 /* 表达小写字母 */ char n; scanf(\u0026#34;%c\u0026#34;,\u0026amp;n); n\u0026gt;=\u0026#39;a\u0026#39; \u0026amp;\u0026amp; n\u0026lt;=\u0026#39;z\u0026#39;; /* n\u0026gt;=97 \u0026amp;\u0026amp; n\u0026lt;=122; */ (n\u0026gt;=\u0026#39;a\u0026#39; \u0026amp;\u0026amp; t\u0026lt;=\u0026#39;z\u0026#39;) || (n\u0026gt;=\u0026#39;A\u0026#39; \u0026amp;\u0026amp; n\u0026lt;=\u0026#39;Z\u0026#39;) // 判断是否在字母范围 /* 短路求值例题 */ int a=2,b=3,x; x = (++a\u0026gt;=b) \u0026amp;\u0026amp; (a\u0026lt;b++) // a=3；b=4;x=0 x = (++a\u0026gt;b) \u0026amp;\u0026amp; (a\u0026lt;b++) // a=3;b=3;x=0 x = (++a\u0026gt;=b) \u0026amp;\u0026amp; (a\u0026lt;++b) // a=3;b=4;x=1 x = (++a\u0026gt;=b) || (a\u0026lt;++b) // a=3;b=3;x=1 x = (++a\u0026gt;b) || (a\u0026lt;++b) // a=3;b=4;x=1 3\t逻辑真 与 逻辑假（布尔运算）\n4\t小结\n如果在 a\u0026amp;\u0026amp;b 运算中 a 的值为0，计算机就不会再处理 b 的值。 如果在 a || b 运算中，如果 a 条件成立，计算机不会再处理b eg：表示非数字符号\n1 2 3 4 5 6 7 8 char x; x = getchar(); /* 数字符号 */ x\u0026gt;=\u0026#39;0\u0026#39; \u0026amp;\u0026amp; x\u0026lt;=\u0026#39;9\u0026#39; // 等同于 x\u0026gt;=48 \u0026amp;\u0026amp; x\u0026lt;=57 /* 非数字符号 */ !(x\u0026gt;=\u0026#39;0\u0026#39; \u0026amp;\u0026amp; x\u0026lt;=\u0026#39;9\u0026#39;) 类型强制运算符 不按照自然运算规律进行，按照设计程序员的要求进行类型转换。\n格式：（强制类型）（强制对象）\n1 2 3 (int)2.3+8.9 // 10.9 (int)(2.3+8.9) // 11 (int)(8.9) // 错误 类型强制转换符不能用于常量 类型长度计算（存储占用字节） sizeof()\n格式：sizeof(运算式/具体类型/数组)\n1 2 sizeof(3.0/2); // = 8(double) sizeof(\u0026#39;a\u0026#39;+1); // = 4(int) char 是一个字节，字符串多一个\u0026rsquo;\\0\u0026rsquo;，获取元素个数需要除以单字节。\nGo\nunsafe.Sizeof(any)\n逗号运算符 格式：表达式1，表达式2，表达式3，\n从表达式1开始计算，一直计算到表达式 n，最后把表达式 n 作为运算结果。\n1 2 x = (1,2,3); // x=3 x = (z=1, y=2, x+y); // x= x+y =3 Go\nx,y,z = 1,2,3\n","date":"2018-08-10T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E4%B8%89%E8%AF%BE-%E8%BF%90%E7%AE%97%E7%AC%A6/","title":"第三课 运算符"},{"content":"输入与输出 浮点型：\nfloat：除非特别指定，否则隐含输出6位小数\nName 控制符 Byte 小数点有效位数 float 单精度 %f 4 7 double 双精度 %lf 8 16 科学计数法 1 2 3 10000 =\u0026gt; 1e5 12300 =\u0026gt; 1.23e4 0.0034 =\u0026gt; 3.4e-3 e 后面必须为整数(正负)，且前后必须有参数；\nfloat 可以表示整数，若小数点前面为 0，则 0 可以忽略\n在程序中，字符的表示有两种：\n字符常量：规定符号，不准改变\nName Byte 控制符 char 字符变量 1 %c 字符输入如果没有隔开控制符，千万不要隔开\n若有隔开就用对应的符号隔开\n字符类型仅一个，char 型仅从缓冲区获取一个字符（包括数字）\n1 2 scanf(\u0026#34;%c%c\u0026#34;,\u0026amp;a,\u0026amp;b); // input : ab Ascll 码表 键盘的每个符号都对应一个数值，在 c program 中，符号可参加数运算\n1 2 3 ‘a’ = 97 ~ 122 ‘A’ = 65 ~ 90 ‘0’ = 48 ~ 57 大写对应小写，相差32；凡是键盘符号有序，对应的 ascll 码 value 也是有序的！\n字符的转义表示 不用自身表达自身，而是用另外一种形式；转义符：\\\n两种形式：必须转义 和 8进制、16进制\n1 必须转义\n\u0026rsquo; \\n ' 换行（Newline） \u0026rsquo; \u0026quot; ' 一个双引号 \u0026rsquo; \\r ' 回车（不换行，回到行首） \u0026rsquo; ' ' 单引号 \u0026rsquo; \\0 ' 空字符，字符串结束标志 \u0026rsquo; \\ ' 一个反斜杠 \u0026rsquo; \\b ' 退格（Backspace） \u0026rsquo; \\ddd ' 1 到 3 位八进制 ascll 码 \u0026rsquo; \\f ' 走纸换页（Form Feed） \u0026rsquo; \\xhh ' 1 到 2 位十六进制 asc \u0026rsquo; \\t ' 制表符（水平） \u0026rsquo; \\v ' 制表符（垂直） 2 进制转义\n十进制转换为 N 进制（2，8，16），采用的方法就是 除N取余\n1 e = (d)\u0026#39;101\u0026#39; = (o)\u0026#39;\\145\u0026#39; = (h)\u0026#39;\\7A\u0026#39; 以下表达式相等\n1 2 3 4 5 printf(\u0026#34;%c\u0026#34;,e); printf(\u0026#34;%c\u0026#34;,\u0026#39;/145\u0026#39;); printf(\u0026#34;%c\u0026#34;,\u0026#39;/x7A\u0026#39;); printf(\u0026#34;%c\u0026#34;,0145); printf(\u0026#34;%c\u0026#34;,0x7A); 四 系统的两个专门用于字符输入/输出\n1\tgetchar()\n仅仅获取一个字符，回车表示输入结束；\n⚠️ 该函数没有参数，函数的返回值就是从终端键盘读入的字符\n1 2 char n; n = getchar(); // scanf(\u0026#34;%c\u0026#34;,\u0026amp;n); 2\tputchar()\n该函数的参数就是待输出的字符，仅仅输出一个字符\n1 putchar(n); // 亦可输出常量，不会自动换行 补充：\n整数与浮点实数运算时，其中的整数操作数在运算之前被自动转换为了浮点数（float） 两个整数相除后的商仍是整数（int） 余数的符号与被除数的符号相同（(-10) / 3 = 3\u0026hellip;..(-1)） 求余运算限定参与运算的两个操作数都是整数！（int % int） ","date":"2018-08-09T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E4%BA%8C%E8%AF%BE-%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/","title":"第二课 输入与输出"},{"content":"第一课 认识 C 语言 了解程序语言 三个发展阶段：\n机器语言（二进制 Binary） 汇编语言（符号化语言） 高级语言（数学+英语构成） 除了机器语言和汇编语言外，几乎所有的编程语言都被统称为高级语言。\n高级语言分为 面向过程（结构化程序设计） 和 面向对象，C Program 属于结构化语言；\n结构化有三种：顺序结构、选择结构、循环结构；\n编程流程：需求分析 → 设计 → 编写程序 → 调试程序 → 维护\nC Program 框架 1 main() //任何 c 必须有主函数且唯一主函数； 语句结束：以分号划分，每行语句结束必须有;\n注释语句：便于他人阅读和自己修改\n1 2 // 第一种注释语句，注释语句可以在程序的任何位置（广义） /* 第二种注释语句 */ 复杂框架结构引入函数，模块化设计理念，构成程序的单位是函数，一个主函数 main，若干子函数\n主函数的位置是任意的，但程序的执行必须从主函数开始！\n程序中的数据：数据是程序的生命，没有不处理数据的语言\n数据分类（类型） 基本类型：整型、浮点型、字符型\n整型：\nName Byte 控制符 范围 int 一般整型 4 %d short 短整型 2 %hd -32768~32767 long 长整型 4 %ld unsigned 无符号整型 4 %u unsigned 可以表示整数和无符号数，但不能表示负数\n整型数据在程序中的表示（存储）：\n常量：const 固定不变 变量：可以存储赋值改变的数字 变量规则：\n只能由下划线、字母、数字组成：“a~z”，“A~Z”，“0~9”，“_” 不能以数字开头，并且严格区分大小写，不可和系统关键字冲突。 凡是用户组合的变量：用户标识符 变量必须声明后使用！ 只能对变量进行赋值，变量在赋值符号左侧； 注：c89 中规定所有变量必须在第一条可执行语句之前定义（c99允许）\n在赋值时，若赋值符右侧的数据类型不匹配，则一定要转化为左侧变量一致（int不会四舍五入，只会截断小数点）\n1 int x = 12.96; //resulf : x = 12 在 C program 中无所谓，其它语言不容忍 如果定义了一个变量，但是未对其初始化，则该变量的值是一个随机数(静态变量和全局变量除外)\nGo\n未初始化的变量默认是零值，如 int 零值为 0，bool 零值为 false。\n写 c 语言，声明时应立即初始化。\n四 输入与输出\n键盘输入值：\n1 2 3 scanf(\u0026#34;%d %d\u0026#34;，\u0026amp;a，\u0026amp;b)； // 当输入参数时，若控制符没有隔开，输入的参数之间必须 空格/回车/Tab 隔开 索引：gets（字符串输入） ，getchar（字符输入） 见第二课 ◢ 注：在 scanf 里，当控制符有隔开，输入就需要相同的格式\n​ 在 printf 里，引号内有什么内容，就打印什么内容\n1 2 scanf(\u0026#34;%d---%d\u0026#34;,\u0026amp;a,\u0026amp;b); // input ： 12---34 注意区分 long or unsigned 和其它整型：\n1 2 3 4 123L = long（4Byte） // 若要表达长整型常量，需在数值后面 L（l） 234U = unsigned（4Byte） // 若要表达无符号整型常量，需在数值后面 U（u） 345LU = unsigned long // 无符号长整型常量 1.23F = float // 单精度实型常量 constant 常量 variable 变量 integer 整型 Decimal 十进制 Octal 八进制 Hexadecimal 十六进制 Keyword 关键字 Statement 语句 identifier 标识符 Rules 规则 readability 可读性 comment 注释 separator 分隔符 Header files 头文件 ","date":"2018-08-01T00:00:00Z","permalink":"https://blog.golang.space/p/%E7%AC%AC%E4%B8%80%E8%AF%BE-%E8%AE%A4%E8%AF%86-c-%E8%AF%AD%E8%A8%80/","title":"第一课 认识 C 语言"},{"content":"流媒体服务器 16 核 64GB 存储，尝试 RTMP 推流 1000 路，服务器没有跑满，但是画面产生了延迟或停顿，以及断开连接。\n以下是记录我的解决方案:\n查询 memstats 信息 我尝试通过 /debug/vars 查询程序内信息，此时 GC 次数是 168 次，占用 CPU 比例是 2%，GC 总共停止时间是 263毫秒。\n当前数值的消耗，不应该对程序影响那么大。\n看看 cpu 运行消耗 取一下 CPU 信息，/debug/pprof/profile?seconds=30s\n局部放大\n小对象(mallocgcSmallNoscan)分配占用 34.18% 堆扩容(growslice)占用 7.31% 将涉及到频繁分配对象的代码注释掉，再压测一下看看视频流确实流畅多了，但依然存在卡顿。\n再抓一次 cpu 信息，可以看到主要消耗是系统调用\n多推一会流，在抓 cpu，grow 是一个内存分配的函数，程序在频繁内存扩容\n提前创建一定大小的内存，避免扩容后，节省一半性能\n网络情况\ntx 是出站\ntx 是入站\n","date":"0001-01-01T00:00:00Z","permalink":"https://blog.golang.space/p/","title":""},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://blog.golang.space/p/","title":""}]